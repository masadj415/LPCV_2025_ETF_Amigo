{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sveska za importovanje i pravljenje jobova za CAS-VIT mrežu\n",
    "\n",
    "CAS-ViT se zasniva na Visual Transformer arhitekturi, više informacija na linku.\n",
    "\n",
    "https://paperswithcode.com/paper/cas-vit-convolutional-additive-self-attention\n",
    "\n",
    "(samo sam sortirao po broju parametara i uzeo ovu random mrezu, nemam pojma da li je dobra, i rad za sada ne razumem)\n",
    "\n",
    "Ova sveska uz prateće fajlove automatski skida weightove za CAS-ViT model zadate veličine, i posle taj model šalje na AIHUB za testiranje.\n",
    "\n",
    "Za sada sam pokrenuo samo xs model, koji se izvršava super brzo i ima manje parametara od MobileNetV2, doduše mnogo više layera koji su raspoređeni na više COMPUTE unita, što je koliko ja razumem dobro.\n",
    "\n",
    "Ne znam da li je dobro da modele čuvamo na GIT-u (Drakula neka kaže kako bi to trebalo), pa sam sve fajlove koje se generišu stavio u gitignore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "2025-03-11 13:49:57.861248: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-11 13:49:57.960081: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741697397.999543 1334257 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741697398.012122 1334257 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-11 13:49:58.108357: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import torch\n",
    "import rcvit\n",
    "import torchsummary\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(ROOT_DIR)\n",
    "from utils import helper, input_getter, qai_hub_jobs, tfhelper\n",
    "\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File CASVIT_t.pth already exists.\n"
     ]
    }
   ],
   "source": [
    "# Model selection (options: \"xs\", \"s\", \"m\", \"t\")\n",
    "\n",
    "modelID = \"t\"\n",
    "\n",
    "driveFileIDs = dict()\n",
    "\n",
    "driveFileIDs[\"xs\"] = \"16wKcwF6QMW5w_lyPYnDKjMNuoxQDfrLK\"\n",
    "driveFileIDs[\"s\"]  = \"1facFRq8s8oelYUtK1fj3fcfdoWoKDBQQ\"\n",
    "driveFileIDs[\"m\"]  = \"13sQpSEf0h_uuh0jRy9V0yIW6ZsbDpVGy\"\n",
    "driveFileIDs[\"t\"]  = \"1NqoIUPbwBC91RTjTUvubAbOfGqo1VYT0\"\n",
    "\n",
    "networks = dict()\n",
    "networks[\"xs\"] = rcvit.rcvit_xs\n",
    "networks[\"s\"]  = rcvit.rcvit_s\n",
    "networks[\"m\"]  = rcvit.rcvit_m\n",
    "networks[\"t\"]  = rcvit.rcvit_t\n",
    "\n",
    "file_id = driveFileIDs[modelID]\n",
    "\n",
    "modelName = \"CASVIT_{}\".format(modelID)\n",
    "\n",
    "file_path = modelName + \".pth\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", file_path, quiet=False)\n",
    "    print(\"Model downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"File {file_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCViT(\n",
      "  (patch_embed): Sequential(\n",
      "    (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (network): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "                (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(96, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          (proj): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Embedding(\n",
      "      (proj): Conv2d(96, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Embedding(\n",
      "      (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Embedding(\n",
      "      (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(512, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "                (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          (proj): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (head): Linear(in_features=512, out_features=1000, bias=True)\n",
      "  (dist_head): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net: rcvit.RCViT = networks[modelID]()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 48, 112, 112]           1,344\n",
      "       BatchNorm2d-2         [-1, 48, 112, 112]              96\n",
      "              ReLU-3         [-1, 48, 112, 112]               0\n",
      "            Conv2d-4           [-1, 96, 56, 56]          41,568\n",
      "       BatchNorm2d-5           [-1, 96, 56, 56]             192\n",
      "              ReLU-6           [-1, 96, 56, 56]               0\n",
      "            Conv2d-7           [-1, 96, 56, 56]           9,312\n",
      "       BatchNorm2d-8           [-1, 96, 56, 56]             192\n",
      "            Conv2d-9           [-1, 96, 56, 56]             960\n",
      "             GELU-10           [-1, 96, 56, 56]               0\n",
      "           Conv2d-11           [-1, 96, 56, 56]           9,312\n",
      " LocalIntegration-12           [-1, 96, 56, 56]               0\n",
      "      BatchNorm2d-13           [-1, 96, 56, 56]             192\n",
      "           Conv2d-14          [-1, 288, 56, 56]          27,648\n",
      "           Conv2d-15           [-1, 96, 56, 56]             960\n",
      "      BatchNorm2d-16           [-1, 96, 56, 56]             192\n",
      "             ReLU-17           [-1, 96, 56, 56]               0\n",
      "           Conv2d-18            [-1, 1, 56, 56]              96\n",
      "          Sigmoid-19            [-1, 1, 56, 56]               0\n",
      " SpatialOperation-20           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-21             [-1, 96, 1, 1]               0\n",
      "           Conv2d-22             [-1, 96, 1, 1]           9,216\n",
      "          Sigmoid-23             [-1, 96, 1, 1]               0\n",
      " ChannelOperation-24           [-1, 96, 56, 56]               0\n",
      "           Conv2d-25           [-1, 96, 56, 56]             960\n",
      "      BatchNorm2d-26           [-1, 96, 56, 56]             192\n",
      "             ReLU-27           [-1, 96, 56, 56]               0\n",
      "           Conv2d-28            [-1, 1, 56, 56]              96\n",
      "          Sigmoid-29            [-1, 1, 56, 56]               0\n",
      " SpatialOperation-30           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-31             [-1, 96, 1, 1]               0\n",
      "           Conv2d-32             [-1, 96, 1, 1]           9,216\n",
      "          Sigmoid-33             [-1, 96, 1, 1]               0\n",
      " ChannelOperation-34           [-1, 96, 56, 56]               0\n",
      "           Conv2d-35           [-1, 96, 56, 56]             960\n",
      "           Conv2d-36           [-1, 96, 56, 56]             960\n",
      "          Dropout-37           [-1, 96, 56, 56]               0\n",
      "AdditiveTokenMixer-38           [-1, 96, 56, 56]               0\n",
      "         Identity-39           [-1, 96, 56, 56]               0\n",
      "      BatchNorm2d-40           [-1, 96, 56, 56]             192\n",
      "           Conv2d-41          [-1, 384, 56, 56]          37,248\n",
      "             GELU-42          [-1, 384, 56, 56]               0\n",
      "          Dropout-43          [-1, 384, 56, 56]               0\n",
      "           Conv2d-44           [-1, 96, 56, 56]          36,960\n",
      "          Dropout-45           [-1, 96, 56, 56]               0\n",
      "              Mlp-46           [-1, 96, 56, 56]               0\n",
      "         Identity-47           [-1, 96, 56, 56]               0\n",
      "    AdditiveBlock-48           [-1, 96, 56, 56]               0\n",
      "           Conv2d-49           [-1, 96, 56, 56]           9,312\n",
      "      BatchNorm2d-50           [-1, 96, 56, 56]             192\n",
      "           Conv2d-51           [-1, 96, 56, 56]             960\n",
      "             GELU-52           [-1, 96, 56, 56]               0\n",
      "           Conv2d-53           [-1, 96, 56, 56]           9,312\n",
      " LocalIntegration-54           [-1, 96, 56, 56]               0\n",
      "      BatchNorm2d-55           [-1, 96, 56, 56]             192\n",
      "           Conv2d-56          [-1, 288, 56, 56]          27,648\n",
      "           Conv2d-57           [-1, 96, 56, 56]             960\n",
      "      BatchNorm2d-58           [-1, 96, 56, 56]             192\n",
      "             ReLU-59           [-1, 96, 56, 56]               0\n",
      "           Conv2d-60            [-1, 1, 56, 56]              96\n",
      "          Sigmoid-61            [-1, 1, 56, 56]               0\n",
      " SpatialOperation-62           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-63             [-1, 96, 1, 1]               0\n",
      "           Conv2d-64             [-1, 96, 1, 1]           9,216\n",
      "          Sigmoid-65             [-1, 96, 1, 1]               0\n",
      " ChannelOperation-66           [-1, 96, 56, 56]               0\n",
      "           Conv2d-67           [-1, 96, 56, 56]             960\n",
      "      BatchNorm2d-68           [-1, 96, 56, 56]             192\n",
      "             ReLU-69           [-1, 96, 56, 56]               0\n",
      "           Conv2d-70            [-1, 1, 56, 56]              96\n",
      "          Sigmoid-71            [-1, 1, 56, 56]               0\n",
      " SpatialOperation-72           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-73             [-1, 96, 1, 1]               0\n",
      "           Conv2d-74             [-1, 96, 1, 1]           9,216\n",
      "          Sigmoid-75             [-1, 96, 1, 1]               0\n",
      " ChannelOperation-76           [-1, 96, 56, 56]               0\n",
      "           Conv2d-77           [-1, 96, 56, 56]             960\n",
      "           Conv2d-78           [-1, 96, 56, 56]             960\n",
      "          Dropout-79           [-1, 96, 56, 56]               0\n",
      "AdditiveTokenMixer-80           [-1, 96, 56, 56]               0\n",
      "         Identity-81           [-1, 96, 56, 56]               0\n",
      "      BatchNorm2d-82           [-1, 96, 56, 56]             192\n",
      "           Conv2d-83          [-1, 384, 56, 56]          37,248\n",
      "             GELU-84          [-1, 384, 56, 56]               0\n",
      "          Dropout-85          [-1, 384, 56, 56]               0\n",
      "           Conv2d-86           [-1, 96, 56, 56]          36,960\n",
      "          Dropout-87           [-1, 96, 56, 56]               0\n",
      "              Mlp-88           [-1, 96, 56, 56]               0\n",
      "         Identity-89           [-1, 96, 56, 56]               0\n",
      "    AdditiveBlock-90           [-1, 96, 56, 56]               0\n",
      "           Conv2d-91           [-1, 96, 56, 56]           9,312\n",
      "      BatchNorm2d-92           [-1, 96, 56, 56]             192\n",
      "           Conv2d-93           [-1, 96, 56, 56]             960\n",
      "             GELU-94           [-1, 96, 56, 56]               0\n",
      "           Conv2d-95           [-1, 96, 56, 56]           9,312\n",
      " LocalIntegration-96           [-1, 96, 56, 56]               0\n",
      "      BatchNorm2d-97           [-1, 96, 56, 56]             192\n",
      "           Conv2d-98          [-1, 288, 56, 56]          27,648\n",
      "           Conv2d-99           [-1, 96, 56, 56]             960\n",
      "     BatchNorm2d-100           [-1, 96, 56, 56]             192\n",
      "            ReLU-101           [-1, 96, 56, 56]               0\n",
      "          Conv2d-102            [-1, 1, 56, 56]              96\n",
      "         Sigmoid-103            [-1, 1, 56, 56]               0\n",
      "SpatialOperation-104           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-105             [-1, 96, 1, 1]               0\n",
      "          Conv2d-106             [-1, 96, 1, 1]           9,216\n",
      "         Sigmoid-107             [-1, 96, 1, 1]               0\n",
      "ChannelOperation-108           [-1, 96, 56, 56]               0\n",
      "          Conv2d-109           [-1, 96, 56, 56]             960\n",
      "     BatchNorm2d-110           [-1, 96, 56, 56]             192\n",
      "            ReLU-111           [-1, 96, 56, 56]               0\n",
      "          Conv2d-112            [-1, 1, 56, 56]              96\n",
      "         Sigmoid-113            [-1, 1, 56, 56]               0\n",
      "SpatialOperation-114           [-1, 96, 56, 56]               0\n",
      "AdaptiveAvgPool2d-115             [-1, 96, 1, 1]               0\n",
      "          Conv2d-116             [-1, 96, 1, 1]           9,216\n",
      "         Sigmoid-117             [-1, 96, 1, 1]               0\n",
      "ChannelOperation-118           [-1, 96, 56, 56]               0\n",
      "          Conv2d-119           [-1, 96, 56, 56]             960\n",
      "          Conv2d-120           [-1, 96, 56, 56]             960\n",
      "         Dropout-121           [-1, 96, 56, 56]               0\n",
      "AdditiveTokenMixer-122           [-1, 96, 56, 56]               0\n",
      "        Identity-123           [-1, 96, 56, 56]               0\n",
      "     BatchNorm2d-124           [-1, 96, 56, 56]             192\n",
      "          Conv2d-125          [-1, 384, 56, 56]          37,248\n",
      "            GELU-126          [-1, 384, 56, 56]               0\n",
      "         Dropout-127          [-1, 384, 56, 56]               0\n",
      "          Conv2d-128           [-1, 96, 56, 56]          36,960\n",
      "         Dropout-129           [-1, 96, 56, 56]               0\n",
      "             Mlp-130           [-1, 96, 56, 56]               0\n",
      "        Identity-131           [-1, 96, 56, 56]               0\n",
      "   AdditiveBlock-132           [-1, 96, 56, 56]               0\n",
      "          Conv2d-133          [-1, 128, 28, 28]         110,720\n",
      "     BatchNorm2d-134          [-1, 128, 28, 28]             256\n",
      "       Embedding-135          [-1, 128, 28, 28]               0\n",
      "          Conv2d-136          [-1, 128, 28, 28]          16,512\n",
      "     BatchNorm2d-137          [-1, 128, 28, 28]             256\n",
      "          Conv2d-138          [-1, 128, 28, 28]           1,280\n",
      "            GELU-139          [-1, 128, 28, 28]               0\n",
      "          Conv2d-140          [-1, 128, 28, 28]          16,512\n",
      "LocalIntegration-141          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-142          [-1, 128, 28, 28]             256\n",
      "          Conv2d-143          [-1, 384, 28, 28]          49,152\n",
      "          Conv2d-144          [-1, 128, 28, 28]           1,280\n",
      "     BatchNorm2d-145          [-1, 128, 28, 28]             256\n",
      "            ReLU-146          [-1, 128, 28, 28]               0\n",
      "          Conv2d-147            [-1, 1, 28, 28]             128\n",
      "         Sigmoid-148            [-1, 1, 28, 28]               0\n",
      "SpatialOperation-149          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-150            [-1, 128, 1, 1]               0\n",
      "          Conv2d-151            [-1, 128, 1, 1]          16,384\n",
      "         Sigmoid-152            [-1, 128, 1, 1]               0\n",
      "ChannelOperation-153          [-1, 128, 28, 28]               0\n",
      "          Conv2d-154          [-1, 128, 28, 28]           1,280\n",
      "     BatchNorm2d-155          [-1, 128, 28, 28]             256\n",
      "            ReLU-156          [-1, 128, 28, 28]               0\n",
      "          Conv2d-157            [-1, 1, 28, 28]             128\n",
      "         Sigmoid-158            [-1, 1, 28, 28]               0\n",
      "SpatialOperation-159          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-160            [-1, 128, 1, 1]               0\n",
      "          Conv2d-161            [-1, 128, 1, 1]          16,384\n",
      "         Sigmoid-162            [-1, 128, 1, 1]               0\n",
      "ChannelOperation-163          [-1, 128, 28, 28]               0\n",
      "          Conv2d-164          [-1, 128, 28, 28]           1,280\n",
      "          Conv2d-165          [-1, 128, 28, 28]           1,280\n",
      "         Dropout-166          [-1, 128, 28, 28]               0\n",
      "AdditiveTokenMixer-167          [-1, 128, 28, 28]               0\n",
      "        Identity-168          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-169          [-1, 128, 28, 28]             256\n",
      "          Conv2d-170          [-1, 512, 28, 28]          66,048\n",
      "            GELU-171          [-1, 512, 28, 28]               0\n",
      "         Dropout-172          [-1, 512, 28, 28]               0\n",
      "          Conv2d-173          [-1, 128, 28, 28]          65,664\n",
      "         Dropout-174          [-1, 128, 28, 28]               0\n",
      "             Mlp-175          [-1, 128, 28, 28]               0\n",
      "        Identity-176          [-1, 128, 28, 28]               0\n",
      "   AdditiveBlock-177          [-1, 128, 28, 28]               0\n",
      "          Conv2d-178          [-1, 128, 28, 28]          16,512\n",
      "     BatchNorm2d-179          [-1, 128, 28, 28]             256\n",
      "          Conv2d-180          [-1, 128, 28, 28]           1,280\n",
      "            GELU-181          [-1, 128, 28, 28]               0\n",
      "          Conv2d-182          [-1, 128, 28, 28]          16,512\n",
      "LocalIntegration-183          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-184          [-1, 128, 28, 28]             256\n",
      "          Conv2d-185          [-1, 384, 28, 28]          49,152\n",
      "          Conv2d-186          [-1, 128, 28, 28]           1,280\n",
      "     BatchNorm2d-187          [-1, 128, 28, 28]             256\n",
      "            ReLU-188          [-1, 128, 28, 28]               0\n",
      "          Conv2d-189            [-1, 1, 28, 28]             128\n",
      "         Sigmoid-190            [-1, 1, 28, 28]               0\n",
      "SpatialOperation-191          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-192            [-1, 128, 1, 1]               0\n",
      "          Conv2d-193            [-1, 128, 1, 1]          16,384\n",
      "         Sigmoid-194            [-1, 128, 1, 1]               0\n",
      "ChannelOperation-195          [-1, 128, 28, 28]               0\n",
      "          Conv2d-196          [-1, 128, 28, 28]           1,280\n",
      "     BatchNorm2d-197          [-1, 128, 28, 28]             256\n",
      "            ReLU-198          [-1, 128, 28, 28]               0\n",
      "          Conv2d-199            [-1, 1, 28, 28]             128\n",
      "         Sigmoid-200            [-1, 1, 28, 28]               0\n",
      "SpatialOperation-201          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-202            [-1, 128, 1, 1]               0\n",
      "          Conv2d-203            [-1, 128, 1, 1]          16,384\n",
      "         Sigmoid-204            [-1, 128, 1, 1]               0\n",
      "ChannelOperation-205          [-1, 128, 28, 28]               0\n",
      "          Conv2d-206          [-1, 128, 28, 28]           1,280\n",
      "          Conv2d-207          [-1, 128, 28, 28]           1,280\n",
      "         Dropout-208          [-1, 128, 28, 28]               0\n",
      "AdditiveTokenMixer-209          [-1, 128, 28, 28]               0\n",
      "        Identity-210          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-211          [-1, 128, 28, 28]             256\n",
      "          Conv2d-212          [-1, 512, 28, 28]          66,048\n",
      "            GELU-213          [-1, 512, 28, 28]               0\n",
      "         Dropout-214          [-1, 512, 28, 28]               0\n",
      "          Conv2d-215          [-1, 128, 28, 28]          65,664\n",
      "         Dropout-216          [-1, 128, 28, 28]               0\n",
      "             Mlp-217          [-1, 128, 28, 28]               0\n",
      "        Identity-218          [-1, 128, 28, 28]               0\n",
      "   AdditiveBlock-219          [-1, 128, 28, 28]               0\n",
      "          Conv2d-220          [-1, 128, 28, 28]          16,512\n",
      "     BatchNorm2d-221          [-1, 128, 28, 28]             256\n",
      "          Conv2d-222          [-1, 128, 28, 28]           1,280\n",
      "            GELU-223          [-1, 128, 28, 28]               0\n",
      "          Conv2d-224          [-1, 128, 28, 28]          16,512\n",
      "LocalIntegration-225          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-226          [-1, 128, 28, 28]             256\n",
      "          Conv2d-227          [-1, 384, 28, 28]          49,152\n",
      "          Conv2d-228          [-1, 128, 28, 28]           1,280\n",
      "     BatchNorm2d-229          [-1, 128, 28, 28]             256\n",
      "            ReLU-230          [-1, 128, 28, 28]               0\n",
      "          Conv2d-231            [-1, 1, 28, 28]             128\n",
      "         Sigmoid-232            [-1, 1, 28, 28]               0\n",
      "SpatialOperation-233          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-234            [-1, 128, 1, 1]               0\n",
      "          Conv2d-235            [-1, 128, 1, 1]          16,384\n",
      "         Sigmoid-236            [-1, 128, 1, 1]               0\n",
      "ChannelOperation-237          [-1, 128, 28, 28]               0\n",
      "          Conv2d-238          [-1, 128, 28, 28]           1,280\n",
      "     BatchNorm2d-239          [-1, 128, 28, 28]             256\n",
      "            ReLU-240          [-1, 128, 28, 28]               0\n",
      "          Conv2d-241            [-1, 1, 28, 28]             128\n",
      "         Sigmoid-242            [-1, 1, 28, 28]               0\n",
      "SpatialOperation-243          [-1, 128, 28, 28]               0\n",
      "AdaptiveAvgPool2d-244            [-1, 128, 1, 1]               0\n",
      "          Conv2d-245            [-1, 128, 1, 1]          16,384\n",
      "         Sigmoid-246            [-1, 128, 1, 1]               0\n",
      "ChannelOperation-247          [-1, 128, 28, 28]               0\n",
      "          Conv2d-248          [-1, 128, 28, 28]           1,280\n",
      "          Conv2d-249          [-1, 128, 28, 28]           1,280\n",
      "         Dropout-250          [-1, 128, 28, 28]               0\n",
      "AdditiveTokenMixer-251          [-1, 128, 28, 28]               0\n",
      "        Identity-252          [-1, 128, 28, 28]               0\n",
      "     BatchNorm2d-253          [-1, 128, 28, 28]             256\n",
      "          Conv2d-254          [-1, 512, 28, 28]          66,048\n",
      "            GELU-255          [-1, 512, 28, 28]               0\n",
      "         Dropout-256          [-1, 512, 28, 28]               0\n",
      "          Conv2d-257          [-1, 128, 28, 28]          65,664\n",
      "         Dropout-258          [-1, 128, 28, 28]               0\n",
      "             Mlp-259          [-1, 128, 28, 28]               0\n",
      "        Identity-260          [-1, 128, 28, 28]               0\n",
      "   AdditiveBlock-261          [-1, 128, 28, 28]               0\n",
      "          Conv2d-262          [-1, 256, 14, 14]         295,168\n",
      "     BatchNorm2d-263          [-1, 256, 14, 14]             512\n",
      "       Embedding-264          [-1, 256, 14, 14]               0\n",
      "          Conv2d-265          [-1, 256, 14, 14]          65,792\n",
      "     BatchNorm2d-266          [-1, 256, 14, 14]             512\n",
      "          Conv2d-267          [-1, 256, 14, 14]           2,560\n",
      "            GELU-268          [-1, 256, 14, 14]               0\n",
      "          Conv2d-269          [-1, 256, 14, 14]          65,792\n",
      "LocalIntegration-270          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-271          [-1, 256, 14, 14]             512\n",
      "          Conv2d-272          [-1, 768, 14, 14]         196,608\n",
      "          Conv2d-273          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-274          [-1, 256, 14, 14]             512\n",
      "            ReLU-275          [-1, 256, 14, 14]               0\n",
      "          Conv2d-276            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-277            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-278          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-279            [-1, 256, 1, 1]               0\n",
      "          Conv2d-280            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-281            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-282          [-1, 256, 14, 14]               0\n",
      "          Conv2d-283          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-284          [-1, 256, 14, 14]             512\n",
      "            ReLU-285          [-1, 256, 14, 14]               0\n",
      "          Conv2d-286            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-287            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-288          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-289            [-1, 256, 1, 1]               0\n",
      "          Conv2d-290            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-291            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-292          [-1, 256, 14, 14]               0\n",
      "          Conv2d-293          [-1, 256, 14, 14]           2,560\n",
      "          Conv2d-294          [-1, 256, 14, 14]           2,560\n",
      "         Dropout-295          [-1, 256, 14, 14]               0\n",
      "AdditiveTokenMixer-296          [-1, 256, 14, 14]               0\n",
      "        Identity-297          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-298          [-1, 256, 14, 14]             512\n",
      "          Conv2d-299         [-1, 1024, 14, 14]         263,168\n",
      "            GELU-300         [-1, 1024, 14, 14]               0\n",
      "         Dropout-301         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-302          [-1, 256, 14, 14]         262,400\n",
      "         Dropout-303          [-1, 256, 14, 14]               0\n",
      "             Mlp-304          [-1, 256, 14, 14]               0\n",
      "        Identity-305          [-1, 256, 14, 14]               0\n",
      "   AdditiveBlock-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307          [-1, 256, 14, 14]          65,792\n",
      "     BatchNorm2d-308          [-1, 256, 14, 14]             512\n",
      "          Conv2d-309          [-1, 256, 14, 14]           2,560\n",
      "            GELU-310          [-1, 256, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]          65,792\n",
      "LocalIntegration-312          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-313          [-1, 256, 14, 14]             512\n",
      "          Conv2d-314          [-1, 768, 14, 14]         196,608\n",
      "          Conv2d-315          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-316          [-1, 256, 14, 14]             512\n",
      "            ReLU-317          [-1, 256, 14, 14]               0\n",
      "          Conv2d-318            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-319            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-320          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-321            [-1, 256, 1, 1]               0\n",
      "          Conv2d-322            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-323            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-324          [-1, 256, 14, 14]               0\n",
      "          Conv2d-325          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-326          [-1, 256, 14, 14]             512\n",
      "            ReLU-327          [-1, 256, 14, 14]               0\n",
      "          Conv2d-328            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-329            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-330          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-331            [-1, 256, 1, 1]               0\n",
      "          Conv2d-332            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-333            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-334          [-1, 256, 14, 14]               0\n",
      "          Conv2d-335          [-1, 256, 14, 14]           2,560\n",
      "          Conv2d-336          [-1, 256, 14, 14]           2,560\n",
      "         Dropout-337          [-1, 256, 14, 14]               0\n",
      "AdditiveTokenMixer-338          [-1, 256, 14, 14]               0\n",
      "        Identity-339          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-340          [-1, 256, 14, 14]             512\n",
      "          Conv2d-341         [-1, 1024, 14, 14]         263,168\n",
      "            GELU-342         [-1, 1024, 14, 14]               0\n",
      "         Dropout-343         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         262,400\n",
      "         Dropout-345          [-1, 256, 14, 14]               0\n",
      "             Mlp-346          [-1, 256, 14, 14]               0\n",
      "        Identity-347          [-1, 256, 14, 14]               0\n",
      "   AdditiveBlock-348          [-1, 256, 14, 14]               0\n",
      "          Conv2d-349          [-1, 256, 14, 14]          65,792\n",
      "     BatchNorm2d-350          [-1, 256, 14, 14]             512\n",
      "          Conv2d-351          [-1, 256, 14, 14]           2,560\n",
      "            GELU-352          [-1, 256, 14, 14]               0\n",
      "          Conv2d-353          [-1, 256, 14, 14]          65,792\n",
      "LocalIntegration-354          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "          Conv2d-356          [-1, 768, 14, 14]         196,608\n",
      "          Conv2d-357          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-358          [-1, 256, 14, 14]             512\n",
      "            ReLU-359          [-1, 256, 14, 14]               0\n",
      "          Conv2d-360            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-361            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-362          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-363            [-1, 256, 1, 1]               0\n",
      "          Conv2d-364            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-365            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-368          [-1, 256, 14, 14]             512\n",
      "            ReLU-369          [-1, 256, 14, 14]               0\n",
      "          Conv2d-370            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-371            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-372          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-373            [-1, 256, 1, 1]               0\n",
      "          Conv2d-374            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-375            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377          [-1, 256, 14, 14]           2,560\n",
      "          Conv2d-378          [-1, 256, 14, 14]           2,560\n",
      "         Dropout-379          [-1, 256, 14, 14]               0\n",
      "AdditiveTokenMixer-380          [-1, 256, 14, 14]               0\n",
      "        Identity-381          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "          Conv2d-383         [-1, 1024, 14, 14]         263,168\n",
      "            GELU-384         [-1, 1024, 14, 14]               0\n",
      "         Dropout-385         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-386          [-1, 256, 14, 14]         262,400\n",
      "         Dropout-387          [-1, 256, 14, 14]               0\n",
      "             Mlp-388          [-1, 256, 14, 14]               0\n",
      "        Identity-389          [-1, 256, 14, 14]               0\n",
      "   AdditiveBlock-390          [-1, 256, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]          65,792\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "          Conv2d-393          [-1, 256, 14, 14]           2,560\n",
      "            GELU-394          [-1, 256, 14, 14]               0\n",
      "          Conv2d-395          [-1, 256, 14, 14]          65,792\n",
      "LocalIntegration-396          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-397          [-1, 256, 14, 14]             512\n",
      "          Conv2d-398          [-1, 768, 14, 14]         196,608\n",
      "          Conv2d-399          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-400          [-1, 256, 14, 14]             512\n",
      "            ReLU-401          [-1, 256, 14, 14]               0\n",
      "          Conv2d-402            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-403            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-404          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-405            [-1, 256, 1, 1]               0\n",
      "          Conv2d-406            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-407            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-408          [-1, 256, 14, 14]               0\n",
      "          Conv2d-409          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-410          [-1, 256, 14, 14]             512\n",
      "            ReLU-411          [-1, 256, 14, 14]               0\n",
      "          Conv2d-412            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-413            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-414          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-415            [-1, 256, 1, 1]               0\n",
      "          Conv2d-416            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-417            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-418          [-1, 256, 14, 14]               0\n",
      "          Conv2d-419          [-1, 256, 14, 14]           2,560\n",
      "          Conv2d-420          [-1, 256, 14, 14]           2,560\n",
      "         Dropout-421          [-1, 256, 14, 14]               0\n",
      "AdditiveTokenMixer-422          [-1, 256, 14, 14]               0\n",
      "        Identity-423          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-424          [-1, 256, 14, 14]             512\n",
      "          Conv2d-425         [-1, 1024, 14, 14]         263,168\n",
      "            GELU-426         [-1, 1024, 14, 14]               0\n",
      "         Dropout-427         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-428          [-1, 256, 14, 14]         262,400\n",
      "         Dropout-429          [-1, 256, 14, 14]               0\n",
      "             Mlp-430          [-1, 256, 14, 14]               0\n",
      "        Identity-431          [-1, 256, 14, 14]               0\n",
      "   AdditiveBlock-432          [-1, 256, 14, 14]               0\n",
      "          Conv2d-433          [-1, 256, 14, 14]          65,792\n",
      "     BatchNorm2d-434          [-1, 256, 14, 14]             512\n",
      "          Conv2d-435          [-1, 256, 14, 14]           2,560\n",
      "            GELU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437          [-1, 256, 14, 14]          65,792\n",
      "LocalIntegration-438          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-439          [-1, 256, 14, 14]             512\n",
      "          Conv2d-440          [-1, 768, 14, 14]         196,608\n",
      "          Conv2d-441          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-445            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-446          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-447            [-1, 256, 1, 1]               0\n",
      "          Conv2d-448            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-449            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-450          [-1, 256, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-455            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-456          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-457            [-1, 256, 1, 1]               0\n",
      "          Conv2d-458            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-459            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-460          [-1, 256, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]           2,560\n",
      "          Conv2d-462          [-1, 256, 14, 14]           2,560\n",
      "         Dropout-463          [-1, 256, 14, 14]               0\n",
      "AdditiveTokenMixer-464          [-1, 256, 14, 14]               0\n",
      "        Identity-465          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-466          [-1, 256, 14, 14]             512\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         263,168\n",
      "            GELU-468         [-1, 1024, 14, 14]               0\n",
      "         Dropout-469         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-470          [-1, 256, 14, 14]         262,400\n",
      "         Dropout-471          [-1, 256, 14, 14]               0\n",
      "             Mlp-472          [-1, 256, 14, 14]               0\n",
      "        Identity-473          [-1, 256, 14, 14]               0\n",
      "   AdditiveBlock-474          [-1, 256, 14, 14]               0\n",
      "          Conv2d-475          [-1, 256, 14, 14]          65,792\n",
      "     BatchNorm2d-476          [-1, 256, 14, 14]             512\n",
      "          Conv2d-477          [-1, 256, 14, 14]           2,560\n",
      "            GELU-478          [-1, 256, 14, 14]               0\n",
      "          Conv2d-479          [-1, 256, 14, 14]          65,792\n",
      "LocalIntegration-480          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-481          [-1, 256, 14, 14]             512\n",
      "          Conv2d-482          [-1, 768, 14, 14]         196,608\n",
      "          Conv2d-483          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-484          [-1, 256, 14, 14]             512\n",
      "            ReLU-485          [-1, 256, 14, 14]               0\n",
      "          Conv2d-486            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-487            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-488          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-489            [-1, 256, 1, 1]               0\n",
      "          Conv2d-490            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-491            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-492          [-1, 256, 14, 14]               0\n",
      "          Conv2d-493          [-1, 256, 14, 14]           2,560\n",
      "     BatchNorm2d-494          [-1, 256, 14, 14]             512\n",
      "            ReLU-495          [-1, 256, 14, 14]               0\n",
      "          Conv2d-496            [-1, 1, 14, 14]             256\n",
      "         Sigmoid-497            [-1, 1, 14, 14]               0\n",
      "SpatialOperation-498          [-1, 256, 14, 14]               0\n",
      "AdaptiveAvgPool2d-499            [-1, 256, 1, 1]               0\n",
      "          Conv2d-500            [-1, 256, 1, 1]          65,536\n",
      "         Sigmoid-501            [-1, 256, 1, 1]               0\n",
      "ChannelOperation-502          [-1, 256, 14, 14]               0\n",
      "          Conv2d-503          [-1, 256, 14, 14]           2,560\n",
      "          Conv2d-504          [-1, 256, 14, 14]           2,560\n",
      "         Dropout-505          [-1, 256, 14, 14]               0\n",
      "AdditiveTokenMixer-506          [-1, 256, 14, 14]               0\n",
      "        Identity-507          [-1, 256, 14, 14]               0\n",
      "     BatchNorm2d-508          [-1, 256, 14, 14]             512\n",
      "          Conv2d-509         [-1, 1024, 14, 14]         263,168\n",
      "            GELU-510         [-1, 1024, 14, 14]               0\n",
      "         Dropout-511         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-512          [-1, 256, 14, 14]         262,400\n",
      "         Dropout-513          [-1, 256, 14, 14]               0\n",
      "             Mlp-514          [-1, 256, 14, 14]               0\n",
      "        Identity-515          [-1, 256, 14, 14]               0\n",
      "   AdditiveBlock-516          [-1, 256, 14, 14]               0\n",
      "          Conv2d-517            [-1, 512, 7, 7]       1,180,160\n",
      "     BatchNorm2d-518            [-1, 512, 7, 7]           1,024\n",
      "       Embedding-519            [-1, 512, 7, 7]               0\n",
      "          Conv2d-520            [-1, 512, 7, 7]         262,656\n",
      "     BatchNorm2d-521            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-522            [-1, 512, 7, 7]           5,120\n",
      "            GELU-523            [-1, 512, 7, 7]               0\n",
      "          Conv2d-524            [-1, 512, 7, 7]         262,656\n",
      "LocalIntegration-525            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-526            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-527           [-1, 1536, 7, 7]         786,432\n",
      "          Conv2d-528            [-1, 512, 7, 7]           5,120\n",
      "     BatchNorm2d-529            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-530            [-1, 512, 7, 7]               0\n",
      "          Conv2d-531              [-1, 1, 7, 7]             512\n",
      "         Sigmoid-532              [-1, 1, 7, 7]               0\n",
      "SpatialOperation-533            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-534            [-1, 512, 1, 1]               0\n",
      "          Conv2d-535            [-1, 512, 1, 1]         262,144\n",
      "         Sigmoid-536            [-1, 512, 1, 1]               0\n",
      "ChannelOperation-537            [-1, 512, 7, 7]               0\n",
      "          Conv2d-538            [-1, 512, 7, 7]           5,120\n",
      "     BatchNorm2d-539            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-540            [-1, 512, 7, 7]               0\n",
      "          Conv2d-541              [-1, 1, 7, 7]             512\n",
      "         Sigmoid-542              [-1, 1, 7, 7]               0\n",
      "SpatialOperation-543            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-544            [-1, 512, 1, 1]               0\n",
      "          Conv2d-545            [-1, 512, 1, 1]         262,144\n",
      "         Sigmoid-546            [-1, 512, 1, 1]               0\n",
      "ChannelOperation-547            [-1, 512, 7, 7]               0\n",
      "          Conv2d-548            [-1, 512, 7, 7]           5,120\n",
      "          Conv2d-549            [-1, 512, 7, 7]           5,120\n",
      "         Dropout-550            [-1, 512, 7, 7]               0\n",
      "AdditiveTokenMixer-551            [-1, 512, 7, 7]               0\n",
      "        Identity-552            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-553            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-554           [-1, 2048, 7, 7]       1,050,624\n",
      "            GELU-555           [-1, 2048, 7, 7]               0\n",
      "         Dropout-556           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-557            [-1, 512, 7, 7]       1,049,088\n",
      "         Dropout-558            [-1, 512, 7, 7]               0\n",
      "             Mlp-559            [-1, 512, 7, 7]               0\n",
      "        Identity-560            [-1, 512, 7, 7]               0\n",
      "   AdditiveBlock-561            [-1, 512, 7, 7]               0\n",
      "          Conv2d-562            [-1, 512, 7, 7]         262,656\n",
      "     BatchNorm2d-563            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-564            [-1, 512, 7, 7]           5,120\n",
      "            GELU-565            [-1, 512, 7, 7]               0\n",
      "          Conv2d-566            [-1, 512, 7, 7]         262,656\n",
      "LocalIntegration-567            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-568            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-569           [-1, 1536, 7, 7]         786,432\n",
      "          Conv2d-570            [-1, 512, 7, 7]           5,120\n",
      "     BatchNorm2d-571            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-572            [-1, 512, 7, 7]               0\n",
      "          Conv2d-573              [-1, 1, 7, 7]             512\n",
      "         Sigmoid-574              [-1, 1, 7, 7]               0\n",
      "SpatialOperation-575            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-576            [-1, 512, 1, 1]               0\n",
      "          Conv2d-577            [-1, 512, 1, 1]         262,144\n",
      "         Sigmoid-578            [-1, 512, 1, 1]               0\n",
      "ChannelOperation-579            [-1, 512, 7, 7]               0\n",
      "          Conv2d-580            [-1, 512, 7, 7]           5,120\n",
      "     BatchNorm2d-581            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-582            [-1, 512, 7, 7]               0\n",
      "          Conv2d-583              [-1, 1, 7, 7]             512\n",
      "         Sigmoid-584              [-1, 1, 7, 7]               0\n",
      "SpatialOperation-585            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-586            [-1, 512, 1, 1]               0\n",
      "          Conv2d-587            [-1, 512, 1, 1]         262,144\n",
      "         Sigmoid-588            [-1, 512, 1, 1]               0\n",
      "ChannelOperation-589            [-1, 512, 7, 7]               0\n",
      "          Conv2d-590            [-1, 512, 7, 7]           5,120\n",
      "          Conv2d-591            [-1, 512, 7, 7]           5,120\n",
      "         Dropout-592            [-1, 512, 7, 7]               0\n",
      "AdditiveTokenMixer-593            [-1, 512, 7, 7]               0\n",
      "        Identity-594            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-595            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-596           [-1, 2048, 7, 7]       1,050,624\n",
      "            GELU-597           [-1, 2048, 7, 7]               0\n",
      "         Dropout-598           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-599            [-1, 512, 7, 7]       1,049,088\n",
      "         Dropout-600            [-1, 512, 7, 7]               0\n",
      "             Mlp-601            [-1, 512, 7, 7]               0\n",
      "        Identity-602            [-1, 512, 7, 7]               0\n",
      "   AdditiveBlock-603            [-1, 512, 7, 7]               0\n",
      "          Conv2d-604            [-1, 512, 7, 7]         262,656\n",
      "     BatchNorm2d-605            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-606            [-1, 512, 7, 7]           5,120\n",
      "            GELU-607            [-1, 512, 7, 7]               0\n",
      "          Conv2d-608            [-1, 512, 7, 7]         262,656\n",
      "LocalIntegration-609            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-610            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-611           [-1, 1536, 7, 7]         786,432\n",
      "          Conv2d-612            [-1, 512, 7, 7]           5,120\n",
      "     BatchNorm2d-613            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-614            [-1, 512, 7, 7]               0\n",
      "          Conv2d-615              [-1, 1, 7, 7]             512\n",
      "         Sigmoid-616              [-1, 1, 7, 7]               0\n",
      "SpatialOperation-617            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-618            [-1, 512, 1, 1]               0\n",
      "          Conv2d-619            [-1, 512, 1, 1]         262,144\n",
      "         Sigmoid-620            [-1, 512, 1, 1]               0\n",
      "ChannelOperation-621            [-1, 512, 7, 7]               0\n",
      "          Conv2d-622            [-1, 512, 7, 7]           5,120\n",
      "     BatchNorm2d-623            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-624            [-1, 512, 7, 7]               0\n",
      "          Conv2d-625              [-1, 1, 7, 7]             512\n",
      "         Sigmoid-626              [-1, 1, 7, 7]               0\n",
      "SpatialOperation-627            [-1, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-628            [-1, 512, 1, 1]               0\n",
      "          Conv2d-629            [-1, 512, 1, 1]         262,144\n",
      "         Sigmoid-630            [-1, 512, 1, 1]               0\n",
      "ChannelOperation-631            [-1, 512, 7, 7]               0\n",
      "          Conv2d-632            [-1, 512, 7, 7]           5,120\n",
      "          Conv2d-633            [-1, 512, 7, 7]           5,120\n",
      "         Dropout-634            [-1, 512, 7, 7]               0\n",
      "AdditiveTokenMixer-635            [-1, 512, 7, 7]               0\n",
      "        Identity-636            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-637            [-1, 512, 7, 7]           1,024\n",
      "          Conv2d-638           [-1, 2048, 7, 7]       1,050,624\n",
      "            GELU-639           [-1, 2048, 7, 7]               0\n",
      "         Dropout-640           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-641            [-1, 512, 7, 7]       1,049,088\n",
      "         Dropout-642            [-1, 512, 7, 7]               0\n",
      "             Mlp-643            [-1, 512, 7, 7]               0\n",
      "        Identity-644            [-1, 512, 7, 7]               0\n",
      "   AdditiveBlock-645            [-1, 512, 7, 7]               0\n",
      "     BatchNorm2d-646            [-1, 512, 7, 7]           1,024\n",
      "          Linear-647                 [-1, 1000]         513,000\n",
      "          Linear-648                 [-1, 1000]         513,000\n",
      "================================================================\n",
      "Total params: 21,763,120\n",
      "Trainable params: 21,763,120\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 543.99\n",
      "Params size (MB): 83.02\n",
      "Estimated Total Size (MB): 627.58\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "net = net.cuda()\n",
    "\n",
    "net.eval()\n",
    "\n",
    "torchsummary.summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: '/home/centar15-desktop1/LPCV_2025_T1/datasets/imagenet/new_imgnet_coco/motorcycle/0000170548.jpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m net\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43minput_getter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocal_image_getter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/home/centar15-desktop1/LPCV_2025_T1/datasets/imagenet/new_imgnet_coco/motorcycle/0000170548.jpeg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m net(torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mget_input_torch()\u001b[38;5;241m.\u001b[39mcuda()))\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/LPCV_2025_T1/src/utils/input_getter.py:56\u001b[0m, in \u001b[0;36mlocal_image_getter.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path):\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg \u001b[38;5;241m=\u001b[39m \u001b[43mski\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg \u001b[38;5;241m=\u001b[39m ski\u001b[38;5;241m.\u001b[39mimg_as_float32(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg)\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(np\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg, (\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/skimage/_shared/utils.py:328\u001b[0m, in \u001b[0;36mdeprecate_parameter.__call__.<locals>.fixed_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;66;03m# Assign old value to new one\u001b[39;00m\n\u001b[1;32m    326\u001b[0m         kwargs[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew_name] \u001b[38;5;241m=\u001b[39m deprecated_value\n\u001b[0;32m--> 328\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/skimage/io/_io.py:82\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, **plugin_args)\u001b[0m\n\u001b[1;32m     79\u001b[0m         plugin \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtifffile\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m file_or_url_context(fname) \u001b[38;5;28;01mas\u001b[39;00m fname, _hide_plugin_deprecation_warnings():\n\u001b[0;32m---> 82\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcall_plugin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimread\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplugin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplugin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(img, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/skimage/_shared/utils.py:538\u001b[0m, in \u001b[0;36mdeprecate_func.__call__.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    536\u001b[0m stacklevel \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_stack_length(func) \u001b[38;5;241m-\u001b[39m stack_rank\n\u001b[1;32m    537\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(message, category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39mstacklevel)\n\u001b[0;32m--> 538\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/skimage/io/manage_plugins.py:254\u001b[0m, in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCould not find the plugin \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/skimage/io/_plugins/imageio_plugin.py:11\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(imageio_imread)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mimread\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 11\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimageio_imread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWRITEABLE\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m     13\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/imageio/v3.py:53\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(uri, index, plugin, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m     call_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[0;32m---> 53\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mimopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mplugin_kwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m img_file:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39masarray(img_file\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcall_kwargs))\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/imageio/core/imopen.py:113\u001b[0m, in \u001b[0;36mimopen\u001b[0;34m(uri, io_mode, plugin, extension, format_hint, legacy_mode, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m     request\u001b[38;5;241m.\u001b[39mformat_hint \u001b[38;5;241m=\u001b[39m format_hint\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 113\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[43mRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mio_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_hint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_hint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextension\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m source \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<bytes>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(uri, \u001b[38;5;28mbytes\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m uri\n\u001b[1;32m    117\u001b[0m \u001b[38;5;66;03m# fast-path based on plugin\u001b[39;00m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m# (except in legacy mode)\u001b[39;00m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/imageio/core/request.py:249\u001b[0m, in \u001b[0;36mRequest.__init__\u001b[0;34m(self, uri, mode, extension, format_hint, **kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Request.Mode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Parse what was given\u001b[39;00m\n\u001b[0;32m--> 249\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_uri\u001b[49m\u001b[43m(\u001b[49m\u001b[43muri\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# Set extension\u001b[39;00m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/imageio/core/request.py:409\u001b[0m, in \u001b[0;36mRequest._parse_uri\u001b[0;34m(self, uri)\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_read_request:\n\u001b[1;32m    407\u001b[0m     \u001b[38;5;66;03m# Reading: check that the file exists (but is allowed a dir)\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(fn):\n\u001b[0;32m--> 409\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m fn)\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;66;03m# Writing: check that the directory to write to does exist\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     dn \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(fn)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file: '/home/centar15-desktop1/LPCV_2025_T1/datasets/imagenet/new_imgnet_coco/motorcycle/0000170548.jpeg'"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "input = input_getter.local_image_getter('/home/centar15-desktop1/LPCV_2025_T1/datasets/imagenet/new_imgnet_coco/motorcycle/0000170548.jpeg')\n",
    "net(torch.tensor(input.get_input_torch().cuda())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.get_input_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input.get_input_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading tmpmph5i1pd.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 84.6M/84.6M [00:04<00:00, 21.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled compile job (j5q0z4xop) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/j5q0z4xop/\n",
      "\n",
      "Waiting for compile job (j5q0z4xop) completion. Type Ctrl+C to stop waiting at any time.\n",
      "    ✅ SUCCESS                          \u0007\n",
      "Scheduled profile job (jgl4owdm5) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/jgl4owdm5/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading dataset: 527kB [00:01, 346kB/s]                    <?, ?B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled inference job (j562roxyg) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/j562roxyg/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kada se uradi ovi jobovi na linkovima se moze naci vizuelizacija mreze i informacije za dalju analizu\n",
    "\n",
    "compile, profile, inference = qai_hub_jobs.compile_profile_inference(net.cpu(), input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda\n",
      "NVIDIA GeForce RTX 3050\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"using cuda\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"using mps\")\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    print(\"using cpu\")\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from dataset import DatasetReader\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset.utils as utils\n",
    "import time\n",
    "import datetime\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Lambda(lambda img: img.convert('RGB') if img.mode != 'RGB' else img),\n",
    "    # transforms.RandomHorizontalFlip(p = 0.5),\n",
    "    # transforms.ColorJitter(brightness = 0.5),\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),  \n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672065\n"
     ]
    }
   ],
   "source": [
    "dataset_coco = DatasetReader.COCODataset(annotation_file='../../datasets/coco/annotations/instances_train2017.json',\n",
    "    image_dir= '../../datasets/coco/train2017',\n",
    "    target_classes=[s.lower() for s in utils.GLOBAL_CLASSES],\n",
    "    transform=transform)\n",
    "\n",
    "\n",
    "root_folder = '../../datasets/imagenet/coco_80'\n",
    "class_names = [s.lower().replace(' ', '_') for s in utils.GLOBAL_CLASSES]\n",
    "dataset_imagenet = DatasetReader.CustomImageFolder(root_dir=root_folder, class_names=class_names, transform=transform)\n",
    "\n",
    "dataset = torch.utils.data.ConcatDataset([dataset_coco, dataset_imagenet])\n",
    "\n",
    "batch_size = 384\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=15, prefetch_factor=4, persistent_workers=True)\n",
    "\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=50):\n",
    "    start_datetime = datetime.datetime.now()\n",
    "    os.mkdir(f'models/{start_datetime}')\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        running_loss = 0.0\n",
    "        for i, (images, labels) in enumerate(dataloader):\n",
    "\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "        asdf = time.time() - start_time\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss / len(dataloader):.4f}, Time: {asdf:.4f}s\")\n",
    "        if np.mod(epoch, 5) == 0:\n",
    "            torch.save(model.state_dict(), f\"models/{start_datetime}/model_{epoch}epoha_coco_train_batch_size_{batch_size}.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_embed_dim = {\"xs\": 220, \"s\": 256, \"m\": 384, \"t\": 512}\n",
    "\n",
    "net.dist = False\n",
    "net.head = nn.Linear(last_embed_dim[modelID], 64) # \n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in net.named_parameters():\n",
    "    param.requires_grad = False  # Freeze all layers\n",
    "\n",
    "for param in net.head.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd = torch.load(\"CASVIT_t.pth\")\n",
    "\n",
    "net.load_state_dict(wd[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [10/1751], Loss: 4.2838\n",
      "Epoch [1/100], Step [20/1751], Loss: 4.2698\n",
      "Epoch [1/100], Step [30/1751], Loss: 4.2477\n",
      "Epoch [1/100], Step [40/1751], Loss: 4.2738\n",
      "Epoch [1/100], Step [50/1751], Loss: 4.2535\n",
      "Epoch [1/100], Step [60/1751], Loss: 4.1810\n",
      "Epoch [1/100], Step [70/1751], Loss: 4.2644\n",
      "Epoch [1/100], Step [80/1751], Loss: 4.2376\n",
      "Epoch [1/100], Step [90/1751], Loss: 4.2018\n",
      "Epoch [1/100], Step [100/1751], Loss: 4.2471\n",
      "Epoch [1/100], Step [110/1751], Loss: 4.1921\n",
      "Epoch [1/100], Step [120/1751], Loss: 4.2083\n",
      "Epoch [1/100], Step [130/1751], Loss: 4.2006\n",
      "Epoch [1/100], Step [140/1751], Loss: 4.2023\n",
      "Epoch [1/100], Step [150/1751], Loss: 4.1738\n",
      "Epoch [1/100], Step [160/1751], Loss: 4.1929\n",
      "Epoch [1/100], Step [170/1751], Loss: 4.1552\n",
      "Epoch [1/100], Step [180/1751], Loss: 4.1591\n",
      "Epoch [1/100], Step [190/1751], Loss: 4.1217\n",
      "Epoch [1/100], Step [200/1751], Loss: 4.0791\n",
      "Epoch [1/100], Step [210/1751], Loss: 4.1804\n",
      "Epoch [1/100], Step [220/1751], Loss: 4.1522\n",
      "Epoch [1/100], Step [230/1751], Loss: 4.1087\n",
      "Epoch [1/100], Step [240/1751], Loss: 4.0620\n",
      "Epoch [1/100], Step [250/1751], Loss: 4.1048\n",
      "Epoch [1/100], Step [260/1751], Loss: 4.0867\n",
      "Epoch [1/100], Step [270/1751], Loss: 4.1413\n",
      "Epoch [1/100], Step [280/1751], Loss: 4.1013\n",
      "Epoch [1/100], Step [290/1751], Loss: 4.0832\n",
      "Epoch [1/100], Step [300/1751], Loss: 4.0488\n",
      "Epoch [1/100], Step [310/1751], Loss: 4.0455\n",
      "Epoch [1/100], Step [320/1751], Loss: 4.0455\n",
      "Epoch [1/100], Step [330/1751], Loss: 4.0659\n",
      "Epoch [1/100], Step [340/1751], Loss: 4.0028\n",
      "Epoch [1/100], Step [350/1751], Loss: 4.0344\n",
      "Epoch [1/100], Step [360/1751], Loss: 4.0237\n",
      "Epoch [1/100], Step [370/1751], Loss: 4.0565\n",
      "Epoch [1/100], Step [380/1751], Loss: 4.0704\n",
      "Epoch [1/100], Step [390/1751], Loss: 4.0252\n",
      "Epoch [1/100], Step [400/1751], Loss: 4.0287\n",
      "Epoch [1/100], Step [410/1751], Loss: 3.9829\n",
      "Epoch [1/100], Step [420/1751], Loss: 4.0602\n",
      "Epoch [1/100], Step [430/1751], Loss: 3.9645\n",
      "Epoch [1/100], Step [440/1751], Loss: 3.9314\n",
      "Epoch [1/100], Step [450/1751], Loss: 3.9665\n",
      "Epoch [1/100], Step [460/1751], Loss: 3.9817\n",
      "Epoch [1/100], Step [470/1751], Loss: 3.9847\n",
      "Epoch [1/100], Step [480/1751], Loss: 3.9728\n",
      "Epoch [1/100], Step [490/1751], Loss: 3.9431\n",
      "Epoch [1/100], Step [500/1751], Loss: 4.0021\n",
      "Epoch [1/100], Step [510/1751], Loss: 3.9221\n",
      "Epoch [1/100], Step [520/1751], Loss: 3.9249\n",
      "Epoch [1/100], Step [530/1751], Loss: 3.9448\n",
      "Epoch [1/100], Step [540/1751], Loss: 3.9120\n",
      "Epoch [1/100], Step [550/1751], Loss: 3.9206\n",
      "Epoch [1/100], Step [560/1751], Loss: 3.8882\n",
      "Epoch [1/100], Step [570/1751], Loss: 3.8855\n",
      "Epoch [1/100], Step [580/1751], Loss: 3.9003\n",
      "Epoch [1/100], Step [590/1751], Loss: 3.8734\n",
      "Epoch [1/100], Step [600/1751], Loss: 3.9052\n",
      "Epoch [1/100], Step [610/1751], Loss: 3.8248\n",
      "Epoch [1/100], Step [620/1751], Loss: 3.8373\n",
      "Epoch [1/100], Step [630/1751], Loss: 3.8347\n",
      "Epoch [1/100], Step [640/1751], Loss: 3.8280\n",
      "Epoch [1/100], Step [650/1751], Loss: 3.8676\n",
      "Epoch [1/100], Step [660/1751], Loss: 3.8042\n",
      "Epoch [1/100], Step [670/1751], Loss: 3.8468\n",
      "Epoch [1/100], Step [680/1751], Loss: 3.8585\n",
      "Epoch [1/100], Step [690/1751], Loss: 3.8013\n",
      "Epoch [1/100], Step [700/1751], Loss: 3.8925\n",
      "Epoch [1/100], Step [710/1751], Loss: 3.8254\n",
      "Epoch [1/100], Step [720/1751], Loss: 3.8176\n",
      "Epoch [1/100], Step [730/1751], Loss: 3.7652\n",
      "Epoch [1/100], Step [740/1751], Loss: 3.8020\n",
      "Epoch [1/100], Step [750/1751], Loss: 3.7309\n",
      "Epoch [1/100], Step [760/1751], Loss: 3.7358\n",
      "Epoch [1/100], Step [770/1751], Loss: 3.7504\n",
      "Epoch [1/100], Step [780/1751], Loss: 3.7550\n",
      "Epoch [1/100], Step [790/1751], Loss: 3.7461\n",
      "Epoch [1/100], Step [800/1751], Loss: 3.7127\n",
      "Epoch [1/100], Step [810/1751], Loss: 3.7935\n",
      "Epoch [1/100], Step [820/1751], Loss: 3.7463\n",
      "Epoch [1/100], Step [830/1751], Loss: 3.7401\n",
      "Epoch [1/100], Step [840/1751], Loss: 3.7617\n",
      "Epoch [1/100], Step [850/1751], Loss: 3.7046\n",
      "Epoch [1/100], Step [860/1751], Loss: 3.6973\n",
      "Epoch [1/100], Step [870/1751], Loss: 3.7007\n",
      "Epoch [1/100], Step [880/1751], Loss: 3.7286\n",
      "Epoch [1/100], Step [890/1751], Loss: 3.6649\n",
      "Epoch [1/100], Step [900/1751], Loss: 3.6688\n",
      "Epoch [1/100], Step [910/1751], Loss: 3.6281\n",
      "Epoch [1/100], Step [920/1751], Loss: 3.6701\n",
      "Epoch [1/100], Step [930/1751], Loss: 3.6683\n",
      "Epoch [1/100], Step [940/1751], Loss: 3.6552\n",
      "Epoch [1/100], Step [950/1751], Loss: 3.5799\n",
      "Epoch [1/100], Step [960/1751], Loss: 3.6616\n",
      "Epoch [1/100], Step [970/1751], Loss: 3.6332\n",
      "Epoch [1/100], Step [980/1751], Loss: 3.5990\n",
      "Epoch [1/100], Step [990/1751], Loss: 3.6136\n",
      "Epoch [1/100], Step [1000/1751], Loss: 3.6356\n",
      "Epoch [1/100], Step [1010/1751], Loss: 3.6039\n",
      "Epoch [1/100], Step [1020/1751], Loss: 3.5773\n",
      "Epoch [1/100], Step [1030/1751], Loss: 3.5843\n",
      "Epoch [1/100], Step [1040/1751], Loss: 3.5742\n",
      "Epoch [1/100], Step [1050/1751], Loss: 3.6375\n",
      "Epoch [1/100], Step [1060/1751], Loss: 3.6481\n",
      "Epoch [1/100], Step [1070/1751], Loss: 3.6337\n",
      "Epoch [1/100], Step [1080/1751], Loss: 3.5575\n",
      "Epoch [1/100], Step [1090/1751], Loss: 3.5598\n",
      "Epoch [1/100], Step [1100/1751], Loss: 3.5394\n",
      "Epoch [1/100], Step [1110/1751], Loss: 3.6128\n",
      "Epoch [1/100], Step [1120/1751], Loss: 3.5253\n",
      "Epoch [1/100], Step [1130/1751], Loss: 3.5173\n",
      "Epoch [1/100], Step [1140/1751], Loss: 3.5518\n",
      "Epoch [1/100], Step [1150/1751], Loss: 3.4903\n",
      "Epoch [1/100], Step [1160/1751], Loss: 3.4823\n",
      "Epoch [1/100], Step [1170/1751], Loss: 3.4730\n",
      "Epoch [1/100], Step [1180/1751], Loss: 3.4557\n",
      "Epoch [1/100], Step [1190/1751], Loss: 3.5165\n",
      "Epoch [1/100], Step [1200/1751], Loss: 3.5160\n",
      "Epoch [1/100], Step [1210/1751], Loss: 3.4109\n",
      "Epoch [1/100], Step [1220/1751], Loss: 3.4875\n",
      "Epoch [1/100], Step [1230/1751], Loss: 3.4808\n",
      "Epoch [1/100], Step [1240/1751], Loss: 3.5262\n",
      "Epoch [1/100], Step [1250/1751], Loss: 3.5577\n",
      "Epoch [1/100], Step [1260/1751], Loss: 3.5087\n",
      "Epoch [1/100], Step [1270/1751], Loss: 3.4329\n",
      "Epoch [1/100], Step [1280/1751], Loss: 3.4323\n",
      "Epoch [1/100], Step [1290/1751], Loss: 3.4837\n",
      "Epoch [1/100], Step [1300/1751], Loss: 3.4704\n",
      "Epoch [1/100], Step [1310/1751], Loss: 3.4276\n",
      "Epoch [1/100], Step [1320/1751], Loss: 3.4492\n",
      "Epoch [1/100], Step [1330/1751], Loss: 3.4251\n",
      "Epoch [1/100], Step [1340/1751], Loss: 3.4328\n",
      "Epoch [1/100], Step [1350/1751], Loss: 3.4210\n",
      "Epoch [1/100], Step [1360/1751], Loss: 3.3445\n",
      "Epoch [1/100], Step [1370/1751], Loss: 3.4954\n",
      "Epoch [1/100], Step [1380/1751], Loss: 3.3622\n",
      "Epoch [1/100], Step [1390/1751], Loss: 3.4539\n",
      "Epoch [1/100], Step [1400/1751], Loss: 3.4426\n",
      "Epoch [1/100], Step [1410/1751], Loss: 3.4981\n",
      "Epoch [1/100], Step [1420/1751], Loss: 3.4333\n",
      "Epoch [1/100], Step [1430/1751], Loss: 3.4224\n",
      "Epoch [1/100], Step [1440/1751], Loss: 3.3550\n",
      "Epoch [1/100], Step [1450/1751], Loss: 3.3290\n",
      "Epoch [1/100], Step [1460/1751], Loss: 3.3232\n",
      "Epoch [1/100], Step [1470/1751], Loss: 3.3179\n",
      "Epoch [1/100], Step [1480/1751], Loss: 3.4261\n",
      "Epoch [1/100], Step [1490/1751], Loss: 3.2885\n",
      "Epoch [1/100], Step [1500/1751], Loss: 3.3962\n",
      "Epoch [1/100], Step [1510/1751], Loss: 3.4081\n",
      "Epoch [1/100], Step [1520/1751], Loss: 3.4646\n",
      "Epoch [1/100], Step [1530/1751], Loss: 3.3196\n",
      "Epoch [1/100], Step [1540/1751], Loss: 3.3309\n",
      "Epoch [1/100], Step [1550/1751], Loss: 3.3180\n",
      "Epoch [1/100], Step [1560/1751], Loss: 3.3160\n",
      "Epoch [1/100], Step [1570/1751], Loss: 3.3453\n",
      "Epoch [1/100], Step [1580/1751], Loss: 3.2488\n",
      "Epoch [1/100], Step [1590/1751], Loss: 3.2661\n",
      "Epoch [1/100], Step [1600/1751], Loss: 3.2399\n",
      "Epoch [1/100], Step [1610/1751], Loss: 3.2628\n",
      "Epoch [1/100], Step [1620/1751], Loss: 3.2776\n",
      "Epoch [1/100], Step [1630/1751], Loss: 3.2355\n",
      "Epoch [1/100], Step [1640/1751], Loss: 3.3608\n",
      "Epoch [1/100], Step [1650/1751], Loss: 3.1844\n",
      "Epoch [1/100], Step [1660/1751], Loss: 3.2993\n",
      "Epoch [1/100], Step [1670/1751], Loss: 3.2626\n",
      "Epoch [1/100], Step [1680/1751], Loss: 3.1982\n",
      "Epoch [1/100], Step [1690/1751], Loss: 3.2129\n",
      "Epoch [1/100], Step [1700/1751], Loss: 3.2218\n",
      "Epoch [1/100], Step [1710/1751], Loss: 3.2380\n",
      "Epoch [1/100], Step [1720/1751], Loss: 3.2983\n",
      "Epoch [1/100], Step [1730/1751], Loss: 3.2950\n",
      "Epoch [1/100], Step [1740/1751], Loss: 3.2458\n",
      "Epoch [1/100], Step [1750/1751], Loss: 3.1822\n",
      "Epoch [1/100], Average Loss: 3.7145, Time: 1619.7914s\n",
      "Epoch [2/100], Step [10/1751], Loss: 3.2347\n",
      "Epoch [2/100], Step [20/1751], Loss: 3.2171\n",
      "Epoch [2/100], Step [30/1751], Loss: 3.1924\n",
      "Epoch [2/100], Step [40/1751], Loss: 3.1937\n",
      "Epoch [2/100], Step [50/1751], Loss: 3.1580\n",
      "Epoch [2/100], Step [60/1751], Loss: 3.1690\n",
      "Epoch [2/100], Step [70/1751], Loss: 3.1379\n",
      "Epoch [2/100], Step [80/1751], Loss: 3.1592\n",
      "Epoch [2/100], Step [90/1751], Loss: 3.1519\n",
      "Epoch [2/100], Step [100/1751], Loss: 3.1695\n",
      "Epoch [2/100], Step [110/1751], Loss: 3.0681\n",
      "Epoch [2/100], Step [120/1751], Loss: 3.1334\n",
      "Epoch [2/100], Step [130/1751], Loss: 3.2022\n",
      "Epoch [2/100], Step [140/1751], Loss: 3.1218\n",
      "Epoch [2/100], Step [150/1751], Loss: 3.1315\n",
      "Epoch [2/100], Step [160/1751], Loss: 3.1399\n",
      "Epoch [2/100], Step [170/1751], Loss: 3.1519\n",
      "Epoch [2/100], Step [180/1751], Loss: 3.1579\n",
      "Epoch [2/100], Step [190/1751], Loss: 3.1551\n",
      "Epoch [2/100], Step [200/1751], Loss: 3.0562\n",
      "Epoch [2/100], Step [210/1751], Loss: 3.1225\n",
      "Epoch [2/100], Step [220/1751], Loss: 3.0761\n",
      "Epoch [2/100], Step [230/1751], Loss: 3.0631\n",
      "Epoch [2/100], Step [240/1751], Loss: 2.9923\n",
      "Epoch [2/100], Step [250/1751], Loss: 3.0544\n",
      "Epoch [2/100], Step [260/1751], Loss: 3.0179\n",
      "Epoch [2/100], Step [270/1751], Loss: 3.1515\n",
      "Epoch [2/100], Step [280/1751], Loss: 3.1195\n",
      "Epoch [2/100], Step [290/1751], Loss: 3.1028\n",
      "Epoch [2/100], Step [300/1751], Loss: 3.0441\n",
      "Epoch [2/100], Step [310/1751], Loss: 3.0984\n",
      "Epoch [2/100], Step [320/1751], Loss: 2.9823\n",
      "Epoch [2/100], Step [330/1751], Loss: 3.0358\n",
      "Epoch [2/100], Step [340/1751], Loss: 3.0669\n",
      "Epoch [2/100], Step [350/1751], Loss: 2.9790\n",
      "Epoch [2/100], Step [360/1751], Loss: 3.0967\n",
      "Epoch [2/100], Step [370/1751], Loss: 2.9263\n",
      "Epoch [2/100], Step [380/1751], Loss: 3.0186\n",
      "Epoch [2/100], Step [390/1751], Loss: 3.0476\n",
      "Epoch [2/100], Step [400/1751], Loss: 3.0320\n",
      "Epoch [2/100], Step [410/1751], Loss: 3.0024\n",
      "Epoch [2/100], Step [420/1751], Loss: 2.9875\n",
      "Epoch [2/100], Step [430/1751], Loss: 3.0275\n",
      "Epoch [2/100], Step [440/1751], Loss: 2.9428\n",
      "Epoch [2/100], Step [450/1751], Loss: 3.0583\n",
      "Epoch [2/100], Step [460/1751], Loss: 2.9933\n",
      "Epoch [2/100], Step [470/1751], Loss: 2.9473\n",
      "Epoch [2/100], Step [480/1751], Loss: 3.1393\n",
      "Epoch [2/100], Step [490/1751], Loss: 2.9384\n",
      "Epoch [2/100], Step [500/1751], Loss: 3.0849\n",
      "Epoch [2/100], Step [510/1751], Loss: 2.9250\n",
      "Epoch [2/100], Step [520/1751], Loss: 2.9489\n",
      "Epoch [2/100], Step [530/1751], Loss: 2.9192\n",
      "Epoch [2/100], Step [540/1751], Loss: 2.9685\n",
      "Epoch [2/100], Step [550/1751], Loss: 2.9166\n",
      "Epoch [2/100], Step [560/1751], Loss: 2.8495\n",
      "Epoch [2/100], Step [570/1751], Loss: 3.0232\n",
      "Epoch [2/100], Step [580/1751], Loss: 2.9610\n",
      "Epoch [2/100], Step [590/1751], Loss: 2.9612\n",
      "Epoch [2/100], Step [600/1751], Loss: 2.9334\n",
      "Epoch [2/100], Step [610/1751], Loss: 2.8128\n",
      "Epoch [2/100], Step [620/1751], Loss: 2.9976\n",
      "Epoch [2/100], Step [630/1751], Loss: 2.9272\n",
      "Epoch [2/100], Step [640/1751], Loss: 2.9869\n",
      "Epoch [2/100], Step [650/1751], Loss: 2.9216\n",
      "Epoch [2/100], Step [660/1751], Loss: 2.8976\n",
      "Epoch [2/100], Step [670/1751], Loss: 2.9261\n",
      "Epoch [2/100], Step [680/1751], Loss: 2.9637\n",
      "Epoch [2/100], Step [690/1751], Loss: 2.8120\n",
      "Epoch [2/100], Step [700/1751], Loss: 2.8181\n",
      "Epoch [2/100], Step [710/1751], Loss: 2.8258\n",
      "Epoch [2/100], Step [720/1751], Loss: 2.9110\n",
      "Epoch [2/100], Step [730/1751], Loss: 2.7675\n",
      "Epoch [2/100], Step [740/1751], Loss: 2.8898\n",
      "Epoch [2/100], Step [750/1751], Loss: 2.8539\n",
      "Epoch [2/100], Step [760/1751], Loss: 2.8398\n",
      "Epoch [2/100], Step [770/1751], Loss: 2.7828\n",
      "Epoch [2/100], Step [780/1751], Loss: 2.9058\n",
      "Epoch [2/100], Step [790/1751], Loss: 2.7719\n",
      "Epoch [2/100], Step [800/1751], Loss: 2.8734\n",
      "Epoch [2/100], Step [810/1751], Loss: 2.7907\n",
      "Epoch [2/100], Step [820/1751], Loss: 2.8701\n",
      "Epoch [2/100], Step [830/1751], Loss: 2.7523\n",
      "Epoch [2/100], Step [840/1751], Loss: 2.8000\n",
      "Epoch [2/100], Step [850/1751], Loss: 2.8551\n",
      "Epoch [2/100], Step [860/1751], Loss: 2.8582\n",
      "Epoch [2/100], Step [870/1751], Loss: 2.7615\n",
      "Epoch [2/100], Step [880/1751], Loss: 2.7773\n",
      "Epoch [2/100], Step [890/1751], Loss: 2.6960\n",
      "Epoch [2/100], Step [900/1751], Loss: 2.8113\n",
      "Epoch [2/100], Step [910/1751], Loss: 2.7664\n",
      "Epoch [2/100], Step [920/1751], Loss: 2.8938\n",
      "Epoch [2/100], Step [930/1751], Loss: 2.7443\n",
      "Epoch [2/100], Step [940/1751], Loss: 2.6695\n",
      "Epoch [2/100], Step [950/1751], Loss: 2.7068\n",
      "Epoch [2/100], Step [960/1751], Loss: 2.7461\n",
      "Epoch [2/100], Step [970/1751], Loss: 2.7361\n",
      "Epoch [2/100], Step [980/1751], Loss: 2.8000\n",
      "Epoch [2/100], Step [990/1751], Loss: 2.8282\n",
      "Epoch [2/100], Step [1000/1751], Loss: 2.6889\n",
      "Epoch [2/100], Step [1010/1751], Loss: 2.6297\n",
      "Epoch [2/100], Step [1020/1751], Loss: 2.7925\n",
      "Epoch [2/100], Step [1030/1751], Loss: 2.6363\n",
      "Epoch [2/100], Step [1040/1751], Loss: 2.6374\n",
      "Epoch [2/100], Step [1050/1751], Loss: 2.7394\n",
      "Epoch [2/100], Step [1060/1751], Loss: 2.7265\n",
      "Epoch [2/100], Step [1070/1751], Loss: 2.7079\n",
      "Epoch [2/100], Step [1080/1751], Loss: 2.6280\n",
      "Epoch [2/100], Step [1090/1751], Loss: 2.8351\n",
      "Epoch [2/100], Step [1100/1751], Loss: 2.6062\n",
      "Epoch [2/100], Step [1110/1751], Loss: 2.6981\n",
      "Epoch [2/100], Step [1120/1751], Loss: 2.7578\n",
      "Epoch [2/100], Step [1130/1751], Loss: 2.5871\n",
      "Epoch [2/100], Step [1140/1751], Loss: 2.7002\n",
      "Epoch [2/100], Step [1150/1751], Loss: 2.6055\n",
      "Epoch [2/100], Step [1160/1751], Loss: 2.6782\n",
      "Epoch [2/100], Step [1170/1751], Loss: 2.6622\n",
      "Epoch [2/100], Step [1180/1751], Loss: 2.5777\n",
      "Epoch [2/100], Step [1190/1751], Loss: 2.5899\n",
      "Epoch [2/100], Step [1200/1751], Loss: 2.7856\n",
      "Epoch [2/100], Step [1210/1751], Loss: 2.8266\n",
      "Epoch [2/100], Step [1220/1751], Loss: 2.6331\n",
      "Epoch [2/100], Step [1230/1751], Loss: 2.6847\n",
      "Epoch [2/100], Step [1240/1751], Loss: 2.6587\n",
      "Epoch [2/100], Step [1250/1751], Loss: 2.5911\n",
      "Epoch [2/100], Step [1260/1751], Loss: 2.5481\n",
      "Epoch [2/100], Step [1270/1751], Loss: 2.6495\n",
      "Epoch [2/100], Step [1280/1751], Loss: 2.6663\n",
      "Epoch [2/100], Step [1290/1751], Loss: 2.6430\n",
      "Epoch [2/100], Step [1300/1751], Loss: 2.6359\n",
      "Epoch [2/100], Step [1310/1751], Loss: 2.7348\n",
      "Epoch [2/100], Step [1320/1751], Loss: 2.5244\n",
      "Epoch [2/100], Step [1330/1751], Loss: 2.7078\n",
      "Epoch [2/100], Step [1340/1751], Loss: 2.6720\n",
      "Epoch [2/100], Step [1350/1751], Loss: 2.6754\n",
      "Epoch [2/100], Step [1360/1751], Loss: 2.6281\n",
      "Epoch [2/100], Step [1370/1751], Loss: 2.5548\n",
      "Epoch [2/100], Step [1380/1751], Loss: 2.5990\n",
      "Epoch [2/100], Step [1390/1751], Loss: 2.6471\n",
      "Epoch [2/100], Step [1400/1751], Loss: 2.6466\n",
      "Epoch [2/100], Step [1410/1751], Loss: 2.6463\n",
      "Epoch [2/100], Step [1420/1751], Loss: 2.6332\n",
      "Epoch [2/100], Step [1430/1751], Loss: 2.7004\n",
      "Epoch [2/100], Step [1440/1751], Loss: 2.5788\n",
      "Epoch [2/100], Step [1450/1751], Loss: 2.6194\n",
      "Epoch [2/100], Step [1460/1751], Loss: 2.6528\n",
      "Epoch [2/100], Step [1470/1751], Loss: 2.5595\n",
      "Epoch [2/100], Step [1480/1751], Loss: 2.5664\n",
      "Epoch [2/100], Step [1490/1751], Loss: 2.5781\n",
      "Epoch [2/100], Step [1500/1751], Loss: 2.4974\n",
      "Epoch [2/100], Step [1510/1751], Loss: 2.5519\n",
      "Epoch [2/100], Step [1520/1751], Loss: 2.4758\n",
      "Epoch [2/100], Step [1530/1751], Loss: 2.4757\n",
      "Epoch [2/100], Step [1540/1751], Loss: 2.4859\n",
      "Epoch [2/100], Step [1550/1751], Loss: 2.5331\n",
      "Epoch [2/100], Step [1560/1751], Loss: 2.6070\n",
      "Epoch [2/100], Step [1570/1751], Loss: 2.6132\n",
      "Epoch [2/100], Step [1580/1751], Loss: 2.5094\n",
      "Epoch [2/100], Step [1590/1751], Loss: 2.5357\n",
      "Epoch [2/100], Step [1600/1751], Loss: 2.5642\n",
      "Epoch [2/100], Step [1610/1751], Loss: 2.6139\n",
      "Epoch [2/100], Step [1620/1751], Loss: 2.4611\n",
      "Epoch [2/100], Step [1630/1751], Loss: 2.5605\n",
      "Epoch [2/100], Step [1640/1751], Loss: 2.4854\n",
      "Epoch [2/100], Step [1650/1751], Loss: 2.4247\n",
      "Epoch [2/100], Step [1660/1751], Loss: 2.5250\n",
      "Epoch [2/100], Step [1670/1751], Loss: 2.2934\n",
      "Epoch [2/100], Step [1680/1751], Loss: 2.6002\n",
      "Epoch [2/100], Step [1690/1751], Loss: 2.5254\n",
      "Epoch [2/100], Step [1700/1751], Loss: 2.7242\n",
      "Epoch [2/100], Step [1710/1751], Loss: 2.6137\n",
      "Epoch [2/100], Step [1720/1751], Loss: 2.5162\n",
      "Epoch [2/100], Step [1730/1751], Loss: 2.4630\n",
      "Epoch [2/100], Step [1740/1751], Loss: 2.5635\n",
      "Epoch [2/100], Step [1750/1751], Loss: 2.3761\n",
      "Epoch [2/100], Average Loss: 2.8151, Time: 1634.6513s\n",
      "Epoch [3/100], Step [10/1751], Loss: 2.4690\n",
      "Epoch [3/100], Step [20/1751], Loss: 2.5706\n",
      "Epoch [3/100], Step [30/1751], Loss: 2.3579\n",
      "Epoch [3/100], Step [40/1751], Loss: 2.4444\n",
      "Epoch [3/100], Step [50/1751], Loss: 2.4969\n",
      "Epoch [3/100], Step [60/1751], Loss: 2.5244\n",
      "Epoch [3/100], Step [70/1751], Loss: 2.3153\n",
      "Epoch [3/100], Step [80/1751], Loss: 2.4711\n",
      "Epoch [3/100], Step [90/1751], Loss: 2.4643\n",
      "Epoch [3/100], Step [100/1751], Loss: 2.2349\n",
      "Epoch [3/100], Step [110/1751], Loss: 2.4813\n",
      "Epoch [3/100], Step [120/1751], Loss: 2.4694\n",
      "Epoch [3/100], Step [130/1751], Loss: 2.5119\n",
      "Epoch [3/100], Step [140/1751], Loss: 2.4393\n",
      "Epoch [3/100], Step [150/1751], Loss: 2.4720\n",
      "Epoch [3/100], Step [160/1751], Loss: 2.3417\n",
      "Epoch [3/100], Step [170/1751], Loss: 2.3540\n",
      "Epoch [3/100], Step [180/1751], Loss: 2.3870\n",
      "Epoch [3/100], Step [190/1751], Loss: 2.5183\n",
      "Epoch [3/100], Step [200/1751], Loss: 2.3413\n",
      "Epoch [3/100], Step [210/1751], Loss: 2.5182\n",
      "Epoch [3/100], Step [220/1751], Loss: 2.4239\n",
      "Epoch [3/100], Step [230/1751], Loss: 2.5060\n",
      "Epoch [3/100], Step [240/1751], Loss: 2.4762\n",
      "Epoch [3/100], Step [250/1751], Loss: 2.4813\n",
      "Epoch [3/100], Step [260/1751], Loss: 2.4588\n",
      "Epoch [3/100], Step [270/1751], Loss: 2.3798\n",
      "Epoch [3/100], Step [280/1751], Loss: 2.3960\n",
      "Epoch [3/100], Step [290/1751], Loss: 2.4432\n",
      "Epoch [3/100], Step [300/1751], Loss: 2.4425\n",
      "Epoch [3/100], Step [310/1751], Loss: 2.3479\n",
      "Epoch [3/100], Step [320/1751], Loss: 2.3343\n",
      "Epoch [3/100], Step [330/1751], Loss: 2.4053\n",
      "Epoch [3/100], Step [340/1751], Loss: 2.4559\n",
      "Epoch [3/100], Step [350/1751], Loss: 2.3571\n",
      "Epoch [3/100], Step [360/1751], Loss: 2.3023\n",
      "Epoch [3/100], Step [370/1751], Loss: 2.3321\n",
      "Epoch [3/100], Step [380/1751], Loss: 2.4324\n",
      "Epoch [3/100], Step [390/1751], Loss: 2.3699\n",
      "Epoch [3/100], Step [400/1751], Loss: 2.3156\n",
      "Epoch [3/100], Step [410/1751], Loss: 2.4223\n",
      "Epoch [3/100], Step [420/1751], Loss: 2.2220\n",
      "Epoch [3/100], Step [430/1751], Loss: 2.3383\n",
      "Epoch [3/100], Step [440/1751], Loss: 2.3214\n",
      "Epoch [3/100], Step [450/1751], Loss: 2.2788\n",
      "Epoch [3/100], Step [460/1751], Loss: 2.2764\n",
      "Epoch [3/100], Step [470/1751], Loss: 2.3913\n",
      "Epoch [3/100], Step [480/1751], Loss: 2.4475\n",
      "Epoch [3/100], Step [490/1751], Loss: 2.2883\n",
      "Epoch [3/100], Step [500/1751], Loss: 2.3618\n",
      "Epoch [3/100], Step [510/1751], Loss: 2.3174\n",
      "Epoch [3/100], Step [520/1751], Loss: 2.3279\n",
      "Epoch [3/100], Step [530/1751], Loss: 2.4185\n",
      "Epoch [3/100], Step [540/1751], Loss: 2.2343\n",
      "Epoch [3/100], Step [550/1751], Loss: 2.3263\n",
      "Epoch [3/100], Step [560/1751], Loss: 2.4188\n",
      "Epoch [3/100], Step [570/1751], Loss: 2.5110\n",
      "Epoch [3/100], Step [580/1751], Loss: 2.1750\n",
      "Epoch [3/100], Step [590/1751], Loss: 2.1798\n",
      "Epoch [3/100], Step [600/1751], Loss: 2.4210\n",
      "Epoch [3/100], Step [610/1751], Loss: 2.3239\n",
      "Epoch [3/100], Step [620/1751], Loss: 2.1818\n",
      "Epoch [3/100], Step [630/1751], Loss: 2.2814\n",
      "Epoch [3/100], Step [640/1751], Loss: 2.2818\n",
      "Epoch [3/100], Step [650/1751], Loss: 2.2703\n",
      "Epoch [3/100], Step [660/1751], Loss: 2.2533\n",
      "Epoch [3/100], Step [670/1751], Loss: 2.4072\n",
      "Epoch [3/100], Step [680/1751], Loss: 2.2114\n",
      "Epoch [3/100], Step [690/1751], Loss: 2.2968\n",
      "Epoch [3/100], Step [700/1751], Loss: 2.0938\n",
      "Epoch [3/100], Step [710/1751], Loss: 2.2735\n",
      "Epoch [3/100], Step [720/1751], Loss: 2.2998\n",
      "Epoch [3/100], Step [730/1751], Loss: 2.2866\n",
      "Epoch [3/100], Step [740/1751], Loss: 2.3344\n",
      "Epoch [3/100], Step [750/1751], Loss: 2.2554\n",
      "Epoch [3/100], Step [760/1751], Loss: 2.2417\n",
      "Epoch [3/100], Step [770/1751], Loss: 2.2780\n",
      "Epoch [3/100], Step [780/1751], Loss: 2.1868\n",
      "Epoch [3/100], Step [790/1751], Loss: 2.3343\n",
      "Epoch [3/100], Step [800/1751], Loss: 2.3445\n",
      "Epoch [3/100], Step [810/1751], Loss: 2.3505\n",
      "Epoch [3/100], Step [820/1751], Loss: 2.1206\n",
      "Epoch [3/100], Step [830/1751], Loss: 2.2526\n",
      "Epoch [3/100], Step [840/1751], Loss: 2.2516\n",
      "Epoch [3/100], Step [850/1751], Loss: 2.2054\n",
      "Epoch [3/100], Step [860/1751], Loss: 2.2362\n",
      "Epoch [3/100], Step [870/1751], Loss: 2.2531\n",
      "Epoch [3/100], Step [880/1751], Loss: 2.0560\n",
      "Epoch [3/100], Step [890/1751], Loss: 2.2391\n",
      "Epoch [3/100], Step [900/1751], Loss: 2.3884\n",
      "Epoch [3/100], Step [910/1751], Loss: 2.3639\n",
      "Epoch [3/100], Step [920/1751], Loss: 2.3281\n",
      "Epoch [3/100], Step [930/1751], Loss: 2.3099\n",
      "Epoch [3/100], Step [940/1751], Loss: 2.3184\n",
      "Epoch [3/100], Step [950/1751], Loss: 2.0635\n",
      "Epoch [3/100], Step [960/1751], Loss: 2.3556\n",
      "Epoch [3/100], Step [970/1751], Loss: 2.1336\n",
      "Epoch [3/100], Step [980/1751], Loss: 2.1198\n",
      "Epoch [3/100], Step [990/1751], Loss: 2.1140\n",
      "Epoch [3/100], Step [1000/1751], Loss: 2.2293\n",
      "Epoch [3/100], Step [1010/1751], Loss: 2.1652\n",
      "Epoch [3/100], Step [1020/1751], Loss: 2.2881\n",
      "Epoch [3/100], Step [1030/1751], Loss: 2.3231\n",
      "Epoch [3/100], Step [1040/1751], Loss: 2.2526\n",
      "Epoch [3/100], Step [1050/1751], Loss: 2.2425\n",
      "Epoch [3/100], Step [1060/1751], Loss: 2.0984\n",
      "Epoch [3/100], Step [1070/1751], Loss: 2.3096\n",
      "Epoch [3/100], Step [1080/1751], Loss: 2.0309\n",
      "Epoch [3/100], Step [1090/1751], Loss: 2.0921\n",
      "Epoch [3/100], Step [1100/1751], Loss: 2.2292\n",
      "Epoch [3/100], Step [1110/1751], Loss: 2.0822\n",
      "Epoch [3/100], Step [1120/1751], Loss: 2.1537\n",
      "Epoch [3/100], Step [1130/1751], Loss: 2.0971\n",
      "Epoch [3/100], Step [1140/1751], Loss: 2.0584\n",
      "Epoch [3/100], Step [1150/1751], Loss: 2.2436\n",
      "Epoch [3/100], Step [1160/1751], Loss: 2.2434\n",
      "Epoch [3/100], Step [1170/1751], Loss: 1.9813\n",
      "Epoch [3/100], Step [1180/1751], Loss: 2.2569\n",
      "Epoch [3/100], Step [1190/1751], Loss: 2.1380\n",
      "Epoch [3/100], Step [1200/1751], Loss: 2.1998\n",
      "Epoch [3/100], Step [1210/1751], Loss: 2.2151\n",
      "Epoch [3/100], Step [1220/1751], Loss: 2.0341\n",
      "Epoch [3/100], Step [1230/1751], Loss: 2.1432\n",
      "Epoch [3/100], Step [1240/1751], Loss: 2.3434\n",
      "Epoch [3/100], Step [1250/1751], Loss: 2.1284\n",
      "Epoch [3/100], Step [1260/1751], Loss: 2.0820\n",
      "Epoch [3/100], Step [1270/1751], Loss: 2.1873\n",
      "Epoch [3/100], Step [1280/1751], Loss: 2.1114\n",
      "Epoch [3/100], Step [1290/1751], Loss: 2.1435\n",
      "Epoch [3/100], Step [1300/1751], Loss: 2.2875\n",
      "Epoch [3/100], Step [1310/1751], Loss: 2.0596\n",
      "Epoch [3/100], Step [1320/1751], Loss: 2.2174\n",
      "Epoch [3/100], Step [1330/1751], Loss: 2.0845\n",
      "Epoch [3/100], Step [1340/1751], Loss: 2.0991\n",
      "Epoch [3/100], Step [1350/1751], Loss: 2.1375\n",
      "Epoch [3/100], Step [1360/1751], Loss: 2.2157\n",
      "Epoch [3/100], Step [1370/1751], Loss: 2.1347\n",
      "Epoch [3/100], Step [1380/1751], Loss: 2.2617\n",
      "Epoch [3/100], Step [1390/1751], Loss: 2.2621\n",
      "Epoch [3/100], Step [1400/1751], Loss: 2.0126\n",
      "Epoch [3/100], Step [1410/1751], Loss: 2.1747\n",
      "Epoch [3/100], Step [1420/1751], Loss: 2.0933\n",
      "Epoch [3/100], Step [1430/1751], Loss: 2.2959\n",
      "Epoch [3/100], Step [1440/1751], Loss: 2.1048\n",
      "Epoch [3/100], Step [1450/1751], Loss: 2.1014\n",
      "Epoch [3/100], Step [1460/1751], Loss: 2.2114\n",
      "Epoch [3/100], Step [1470/1751], Loss: 2.2059\n",
      "Epoch [3/100], Step [1480/1751], Loss: 2.1848\n",
      "Epoch [3/100], Step [1490/1751], Loss: 2.1274\n",
      "Epoch [3/100], Step [1500/1751], Loss: 2.1515\n",
      "Epoch [3/100], Step [1510/1751], Loss: 2.2210\n",
      "Epoch [3/100], Step [1520/1751], Loss: 2.0719\n",
      "Epoch [3/100], Step [1530/1751], Loss: 2.0235\n",
      "Epoch [3/100], Step [1540/1751], Loss: 2.1144\n",
      "Epoch [3/100], Step [1550/1751], Loss: 2.1993\n",
      "Epoch [3/100], Step [1560/1751], Loss: 2.1652\n",
      "Epoch [3/100], Step [1570/1751], Loss: 2.0337\n",
      "Epoch [3/100], Step [1580/1751], Loss: 2.2612\n",
      "Epoch [3/100], Step [1590/1751], Loss: 2.2580\n",
      "Epoch [3/100], Step [1600/1751], Loss: 2.0766\n",
      "Epoch [3/100], Step [1610/1751], Loss: 2.1043\n",
      "Epoch [3/100], Step [1620/1751], Loss: 1.9762\n",
      "Epoch [3/100], Step [1630/1751], Loss: 2.1623\n",
      "Epoch [3/100], Step [1640/1751], Loss: 2.0650\n",
      "Epoch [3/100], Step [1650/1751], Loss: 2.1634\n",
      "Epoch [3/100], Step [1660/1751], Loss: 2.0594\n",
      "Epoch [3/100], Step [1670/1751], Loss: 2.0720\n",
      "Epoch [3/100], Step [1680/1751], Loss: 1.8949\n",
      "Epoch [3/100], Step [1690/1751], Loss: 2.0057\n",
      "Epoch [3/100], Step [1700/1751], Loss: 2.0229\n",
      "Epoch [3/100], Step [1710/1751], Loss: 2.0298\n",
      "Epoch [3/100], Step [1720/1751], Loss: 1.9862\n",
      "Epoch [3/100], Step [1730/1751], Loss: 2.1589\n",
      "Epoch [3/100], Step [1740/1751], Loss: 2.2636\n",
      "Epoch [3/100], Step [1750/1751], Loss: 2.0437\n",
      "Epoch [3/100], Average Loss: 2.2607, Time: 1635.5460s\n",
      "Epoch [4/100], Step [10/1751], Loss: 1.9288\n",
      "Epoch [4/100], Step [20/1751], Loss: 1.9747\n",
      "Epoch [4/100], Step [30/1751], Loss: 1.9985\n",
      "Epoch [4/100], Step [40/1751], Loss: 2.1312\n",
      "Epoch [4/100], Step [50/1751], Loss: 1.9715\n",
      "Epoch [4/100], Step [60/1751], Loss: 2.1060\n",
      "Epoch [4/100], Step [70/1751], Loss: 1.9853\n",
      "Epoch [4/100], Step [80/1751], Loss: 2.2816\n",
      "Epoch [4/100], Step [90/1751], Loss: 2.0067\n",
      "Epoch [4/100], Step [100/1751], Loss: 2.1758\n",
      "Epoch [4/100], Step [110/1751], Loss: 1.9288\n",
      "Epoch [4/100], Step [120/1751], Loss: 1.9051\n",
      "Epoch [4/100], Step [130/1751], Loss: 2.0211\n",
      "Epoch [4/100], Step [140/1751], Loss: 2.1009\n",
      "Epoch [4/100], Step [150/1751], Loss: 2.1840\n",
      "Epoch [4/100], Step [160/1751], Loss: 2.0352\n",
      "Epoch [4/100], Step [170/1751], Loss: 1.9310\n",
      "Epoch [4/100], Step [180/1751], Loss: 2.1612\n",
      "Epoch [4/100], Step [190/1751], Loss: 2.0541\n",
      "Epoch [4/100], Step [200/1751], Loss: 2.0209\n",
      "Epoch [4/100], Step [210/1751], Loss: 1.8115\n",
      "Epoch [4/100], Step [220/1751], Loss: 2.0493\n",
      "Epoch [4/100], Step [230/1751], Loss: 1.8363\n",
      "Epoch [4/100], Step [240/1751], Loss: 2.0564\n",
      "Epoch [4/100], Step [250/1751], Loss: 2.0738\n",
      "Epoch [4/100], Step [260/1751], Loss: 1.8604\n",
      "Epoch [4/100], Step [270/1751], Loss: 2.1027\n",
      "Epoch [4/100], Step [280/1751], Loss: 1.9485\n",
      "Epoch [4/100], Step [290/1751], Loss: 2.0637\n",
      "Epoch [4/100], Step [300/1751], Loss: 2.0721\n",
      "Epoch [4/100], Step [310/1751], Loss: 2.2424\n",
      "Epoch [4/100], Step [320/1751], Loss: 1.8642\n",
      "Epoch [4/100], Step [330/1751], Loss: 1.8879\n",
      "Epoch [4/100], Step [340/1751], Loss: 1.9874\n",
      "Epoch [4/100], Step [350/1751], Loss: 1.9989\n",
      "Epoch [4/100], Step [360/1751], Loss: 2.0381\n",
      "Epoch [4/100], Step [370/1751], Loss: 1.9641\n",
      "Epoch [4/100], Step [380/1751], Loss: 2.0759\n",
      "Epoch [4/100], Step [390/1751], Loss: 1.9443\n",
      "Epoch [4/100], Step [400/1751], Loss: 1.9900\n",
      "Epoch [4/100], Step [410/1751], Loss: 2.1134\n",
      "Epoch [4/100], Step [420/1751], Loss: 1.9240\n",
      "Epoch [4/100], Step [430/1751], Loss: 2.0046\n",
      "Epoch [4/100], Step [440/1751], Loss: 1.9905\n",
      "Epoch [4/100], Step [450/1751], Loss: 1.9580\n",
      "Epoch [4/100], Step [460/1751], Loss: 1.9540\n",
      "Epoch [4/100], Step [470/1751], Loss: 1.9423\n",
      "Epoch [4/100], Step [480/1751], Loss: 2.0011\n",
      "Epoch [4/100], Step [490/1751], Loss: 1.8664\n",
      "Epoch [4/100], Step [500/1751], Loss: 1.9313\n",
      "Epoch [4/100], Step [510/1751], Loss: 2.0348\n",
      "Epoch [4/100], Step [520/1751], Loss: 1.8851\n",
      "Epoch [4/100], Step [530/1751], Loss: 2.0664\n",
      "Epoch [4/100], Step [540/1751], Loss: 1.9810\n",
      "Epoch [4/100], Step [550/1751], Loss: 2.0167\n",
      "Epoch [4/100], Step [560/1751], Loss: 1.8858\n",
      "Epoch [4/100], Step [570/1751], Loss: 2.0571\n",
      "Epoch [4/100], Step [580/1751], Loss: 2.1561\n",
      "Epoch [4/100], Step [590/1751], Loss: 1.9920\n",
      "Epoch [4/100], Step [600/1751], Loss: 1.9673\n",
      "Epoch [4/100], Step [610/1751], Loss: 2.0016\n",
      "Epoch [4/100], Step [620/1751], Loss: 1.9021\n",
      "Epoch [4/100], Step [630/1751], Loss: 2.0193\n",
      "Epoch [4/100], Step [640/1751], Loss: 1.8313\n",
      "Epoch [4/100], Step [650/1751], Loss: 2.0127\n",
      "Epoch [4/100], Step [660/1751], Loss: 1.9638\n",
      "Epoch [4/100], Step [670/1751], Loss: 2.0480\n",
      "Epoch [4/100], Step [680/1751], Loss: 2.0048\n",
      "Epoch [4/100], Step [690/1751], Loss: 1.9654\n",
      "Epoch [4/100], Step [700/1751], Loss: 1.9650\n",
      "Epoch [4/100], Step [710/1751], Loss: 1.8956\n",
      "Epoch [4/100], Step [720/1751], Loss: 1.9938\n",
      "Epoch [4/100], Step [730/1751], Loss: 1.8144\n",
      "Epoch [4/100], Step [740/1751], Loss: 1.9701\n",
      "Epoch [4/100], Step [750/1751], Loss: 1.9245\n",
      "Epoch [4/100], Step [760/1751], Loss: 1.8393\n",
      "Epoch [4/100], Step [770/1751], Loss: 1.8150\n",
      "Epoch [4/100], Step [780/1751], Loss: 1.8862\n",
      "Epoch [4/100], Step [790/1751], Loss: 1.8173\n",
      "Epoch [4/100], Step [800/1751], Loss: 2.0136\n",
      "Epoch [4/100], Step [810/1751], Loss: 2.1185\n",
      "Epoch [4/100], Step [820/1751], Loss: 2.0206\n",
      "Epoch [4/100], Step [830/1751], Loss: 1.9037\n",
      "Epoch [4/100], Step [840/1751], Loss: 1.8574\n",
      "Epoch [4/100], Step [850/1751], Loss: 1.9839\n",
      "Epoch [4/100], Step [860/1751], Loss: 1.8524\n",
      "Epoch [4/100], Step [870/1751], Loss: 2.0105\n",
      "Epoch [4/100], Step [880/1751], Loss: 1.8734\n",
      "Epoch [4/100], Step [890/1751], Loss: 1.8175\n",
      "Epoch [4/100], Step [900/1751], Loss: 2.0536\n",
      "Epoch [4/100], Step [910/1751], Loss: 1.9548\n",
      "Epoch [4/100], Step [920/1751], Loss: 1.9731\n",
      "Epoch [4/100], Step [930/1751], Loss: 1.8604\n",
      "Epoch [4/100], Step [940/1751], Loss: 1.9146\n",
      "Epoch [4/100], Step [950/1751], Loss: 1.8903\n",
      "Epoch [4/100], Step [960/1751], Loss: 1.9337\n",
      "Epoch [4/100], Step [970/1751], Loss: 2.0231\n",
      "Epoch [4/100], Step [980/1751], Loss: 1.9150\n",
      "Epoch [4/100], Step [990/1751], Loss: 2.1188\n",
      "Epoch [4/100], Step [1000/1751], Loss: 1.8963\n",
      "Epoch [4/100], Step [1010/1751], Loss: 1.7906\n",
      "Epoch [4/100], Step [1020/1751], Loss: 1.8329\n",
      "Epoch [4/100], Step [1030/1751], Loss: 1.9185\n",
      "Epoch [4/100], Step [1040/1751], Loss: 1.8133\n",
      "Epoch [4/100], Step [1050/1751], Loss: 1.9828\n",
      "Epoch [4/100], Step [1060/1751], Loss: 1.8708\n",
      "Epoch [4/100], Step [1070/1751], Loss: 1.7688\n",
      "Epoch [4/100], Step [1080/1751], Loss: 1.8794\n",
      "Epoch [4/100], Step [1090/1751], Loss: 1.9006\n",
      "Epoch [4/100], Step [1100/1751], Loss: 2.1672\n",
      "Epoch [4/100], Step [1110/1751], Loss: 1.9802\n",
      "Epoch [4/100], Step [1120/1751], Loss: 1.7759\n",
      "Epoch [4/100], Step [1130/1751], Loss: 1.9138\n",
      "Epoch [4/100], Step [1140/1751], Loss: 1.8689\n",
      "Epoch [4/100], Step [1150/1751], Loss: 1.8852\n",
      "Epoch [4/100], Step [1160/1751], Loss: 1.8985\n",
      "Epoch [4/100], Step [1170/1751], Loss: 1.9408\n",
      "Epoch [4/100], Step [1180/1751], Loss: 1.9547\n",
      "Epoch [4/100], Step [1190/1751], Loss: 1.9398\n",
      "Epoch [4/100], Step [1200/1751], Loss: 1.9449\n",
      "Epoch [4/100], Step [1210/1751], Loss: 1.8087\n",
      "Epoch [4/100], Step [1220/1751], Loss: 1.9107\n",
      "Epoch [4/100], Step [1230/1751], Loss: 1.8963\n",
      "Epoch [4/100], Step [1240/1751], Loss: 1.7294\n",
      "Epoch [4/100], Step [1250/1751], Loss: 1.8782\n",
      "Epoch [4/100], Step [1260/1751], Loss: 1.8942\n",
      "Epoch [4/100], Step [1270/1751], Loss: 1.7850\n",
      "Epoch [4/100], Step [1280/1751], Loss: 1.9058\n",
      "Epoch [4/100], Step [1290/1751], Loss: 1.8756\n",
      "Epoch [4/100], Step [1300/1751], Loss: 1.8684\n",
      "Epoch [4/100], Step [1310/1751], Loss: 1.8976\n",
      "Epoch [4/100], Step [1320/1751], Loss: 1.8865\n",
      "Epoch [4/100], Step [1330/1751], Loss: 2.0032\n",
      "Epoch [4/100], Step [1340/1751], Loss: 1.8905\n",
      "Epoch [4/100], Step [1350/1751], Loss: 1.8235\n",
      "Epoch [4/100], Step [1360/1751], Loss: 1.7673\n",
      "Epoch [4/100], Step [1370/1751], Loss: 1.7941\n",
      "Epoch [4/100], Step [1380/1751], Loss: 1.9868\n",
      "Epoch [4/100], Step [1390/1751], Loss: 1.7626\n",
      "Epoch [4/100], Step [1400/1751], Loss: 1.8564\n",
      "Epoch [4/100], Step [1410/1751], Loss: 1.7731\n",
      "Epoch [4/100], Step [1420/1751], Loss: 1.9387\n",
      "Epoch [4/100], Step [1430/1751], Loss: 1.8888\n",
      "Epoch [4/100], Step [1440/1751], Loss: 1.9456\n",
      "Epoch [4/100], Step [1450/1751], Loss: 1.7392\n",
      "Epoch [4/100], Step [1460/1751], Loss: 1.9041\n",
      "Epoch [4/100], Step [1470/1751], Loss: 1.9098\n",
      "Epoch [4/100], Step [1480/1751], Loss: 1.9506\n",
      "Epoch [4/100], Step [1490/1751], Loss: 1.7457\n",
      "Epoch [4/100], Step [1500/1751], Loss: 1.8850\n",
      "Epoch [4/100], Step [1510/1751], Loss: 1.7969\n",
      "Epoch [4/100], Step [1520/1751], Loss: 1.8583\n",
      "Epoch [4/100], Step [1530/1751], Loss: 2.0414\n",
      "Epoch [4/100], Step [1540/1751], Loss: 1.8487\n",
      "Epoch [4/100], Step [1550/1751], Loss: 1.9687\n",
      "Epoch [4/100], Step [1560/1751], Loss: 1.9787\n",
      "Epoch [4/100], Step [1570/1751], Loss: 1.8436\n",
      "Epoch [4/100], Step [1580/1751], Loss: 1.8083\n",
      "Epoch [4/100], Step [1590/1751], Loss: 2.0440\n",
      "Epoch [4/100], Step [1600/1751], Loss: 1.7922\n",
      "Epoch [4/100], Step [1610/1751], Loss: 1.7905\n",
      "Epoch [4/100], Step [1620/1751], Loss: 1.8383\n",
      "Epoch [4/100], Step [1630/1751], Loss: 1.7671\n",
      "Epoch [4/100], Step [1640/1751], Loss: 1.8294\n",
      "Epoch [4/100], Step [1650/1751], Loss: 1.8174\n",
      "Epoch [4/100], Step [1660/1751], Loss: 1.8067\n",
      "Epoch [4/100], Step [1670/1751], Loss: 1.8824\n",
      "Epoch [4/100], Step [1680/1751], Loss: 1.8013\n",
      "Epoch [4/100], Step [1690/1751], Loss: 1.7637\n",
      "Epoch [4/100], Step [1700/1751], Loss: 1.9480\n",
      "Epoch [4/100], Step [1710/1751], Loss: 1.6895\n",
      "Epoch [4/100], Step [1720/1751], Loss: 1.8104\n",
      "Epoch [4/100], Step [1730/1751], Loss: 1.8292\n",
      "Epoch [4/100], Step [1740/1751], Loss: 1.7427\n",
      "Epoch [4/100], Step [1750/1751], Loss: 1.8296\n",
      "Epoch [4/100], Average Loss: 1.9415, Time: 1636.4757s\n",
      "Epoch [5/100], Step [10/1751], Loss: 1.7874\n",
      "Epoch [5/100], Step [20/1751], Loss: 1.8983\n",
      "Epoch [5/100], Step [30/1751], Loss: 1.7100\n",
      "Epoch [5/100], Step [40/1751], Loss: 1.7758\n",
      "Epoch [5/100], Step [50/1751], Loss: 1.8779\n",
      "Epoch [5/100], Step [60/1751], Loss: 1.8380\n",
      "Epoch [5/100], Step [70/1751], Loss: 1.9438\n",
      "Epoch [5/100], Step [80/1751], Loss: 1.8772\n",
      "Epoch [5/100], Step [90/1751], Loss: 1.9192\n",
      "Epoch [5/100], Step [100/1751], Loss: 1.8266\n",
      "Epoch [5/100], Step [110/1751], Loss: 1.9182\n",
      "Epoch [5/100], Step [120/1751], Loss: 1.6733\n",
      "Epoch [5/100], Step [130/1751], Loss: 1.8440\n",
      "Epoch [5/100], Step [140/1751], Loss: 1.9909\n",
      "Epoch [5/100], Step [150/1751], Loss: 1.8132\n",
      "Epoch [5/100], Step [160/1751], Loss: 1.6297\n",
      "Epoch [5/100], Step [170/1751], Loss: 1.6998\n",
      "Epoch [5/100], Step [180/1751], Loss: 1.8783\n",
      "Epoch [5/100], Step [190/1751], Loss: 1.7504\n",
      "Epoch [5/100], Step [200/1751], Loss: 1.7590\n",
      "Epoch [5/100], Step [210/1751], Loss: 1.7651\n",
      "Epoch [5/100], Step [220/1751], Loss: 1.6948\n",
      "Epoch [5/100], Step [230/1751], Loss: 1.9944\n",
      "Epoch [5/100], Step [240/1751], Loss: 1.9980\n",
      "Epoch [5/100], Step [250/1751], Loss: 1.7720\n",
      "Epoch [5/100], Step [260/1751], Loss: 1.6245\n",
      "Epoch [5/100], Step [270/1751], Loss: 1.8704\n",
      "Epoch [5/100], Step [280/1751], Loss: 1.7554\n",
      "Epoch [5/100], Step [290/1751], Loss: 1.8510\n",
      "Epoch [5/100], Step [300/1751], Loss: 1.9431\n",
      "Epoch [5/100], Step [310/1751], Loss: 1.7722\n",
      "Epoch [5/100], Step [320/1751], Loss: 1.7006\n",
      "Epoch [5/100], Step [330/1751], Loss: 1.7767\n",
      "Epoch [5/100], Step [340/1751], Loss: 1.8912\n",
      "Epoch [5/100], Step [350/1751], Loss: 1.7026\n",
      "Epoch [5/100], Step [360/1751], Loss: 1.7316\n",
      "Epoch [5/100], Step [370/1751], Loss: 1.8184\n",
      "Epoch [5/100], Step [380/1751], Loss: 1.5669\n",
      "Epoch [5/100], Step [390/1751], Loss: 1.7468\n",
      "Epoch [5/100], Step [400/1751], Loss: 1.8696\n",
      "Epoch [5/100], Step [410/1751], Loss: 1.8694\n",
      "Epoch [5/100], Step [420/1751], Loss: 1.7757\n",
      "Epoch [5/100], Step [430/1751], Loss: 1.6247\n",
      "Epoch [5/100], Step [440/1751], Loss: 1.8528\n",
      "Epoch [5/100], Step [450/1751], Loss: 1.7765\n",
      "Epoch [5/100], Step [460/1751], Loss: 1.9489\n",
      "Epoch [5/100], Step [470/1751], Loss: 1.8810\n",
      "Epoch [5/100], Step [480/1751], Loss: 1.8727\n",
      "Epoch [5/100], Step [490/1751], Loss: 1.9156\n",
      "Epoch [5/100], Step [500/1751], Loss: 1.8855\n",
      "Epoch [5/100], Step [510/1751], Loss: 1.8659\n",
      "Epoch [5/100], Step [520/1751], Loss: 1.6432\n",
      "Epoch [5/100], Step [530/1751], Loss: 1.7564\n",
      "Epoch [5/100], Step [540/1751], Loss: 1.9138\n",
      "Epoch [5/100], Step [550/1751], Loss: 1.8375\n",
      "Epoch [5/100], Step [560/1751], Loss: 1.7208\n",
      "Epoch [5/100], Step [570/1751], Loss: 1.8036\n",
      "Epoch [5/100], Step [580/1751], Loss: 1.7983\n",
      "Epoch [5/100], Step [590/1751], Loss: 1.8091\n",
      "Epoch [5/100], Step [600/1751], Loss: 1.8215\n",
      "Epoch [5/100], Step [610/1751], Loss: 1.9008\n",
      "Epoch [5/100], Step [620/1751], Loss: 1.7153\n",
      "Epoch [5/100], Step [630/1751], Loss: 1.8163\n",
      "Epoch [5/100], Step [640/1751], Loss: 1.7609\n",
      "Epoch [5/100], Step [650/1751], Loss: 1.6964\n",
      "Epoch [5/100], Step [660/1751], Loss: 1.7715\n",
      "Epoch [5/100], Step [670/1751], Loss: 1.8575\n",
      "Epoch [5/100], Step [680/1751], Loss: 1.9042\n",
      "Epoch [5/100], Step [690/1751], Loss: 1.8103\n",
      "Epoch [5/100], Step [700/1751], Loss: 1.6747\n",
      "Epoch [5/100], Step [710/1751], Loss: 1.7682\n",
      "Epoch [5/100], Step [720/1751], Loss: 1.8257\n",
      "Epoch [5/100], Step [730/1751], Loss: 1.8797\n",
      "Epoch [5/100], Step [740/1751], Loss: 1.7112\n",
      "Epoch [5/100], Step [750/1751], Loss: 1.7966\n",
      "Epoch [5/100], Step [760/1751], Loss: 1.7511\n",
      "Epoch [5/100], Step [770/1751], Loss: 1.6870\n",
      "Epoch [5/100], Step [780/1751], Loss: 1.8065\n",
      "Epoch [5/100], Step [790/1751], Loss: 1.5621\n",
      "Epoch [5/100], Step [800/1751], Loss: 1.6772\n",
      "Epoch [5/100], Step [810/1751], Loss: 1.7304\n",
      "Epoch [5/100], Step [820/1751], Loss: 1.6955\n",
      "Epoch [5/100], Step [830/1751], Loss: 1.7457\n",
      "Epoch [5/100], Step [840/1751], Loss: 1.6901\n",
      "Epoch [5/100], Step [850/1751], Loss: 1.8685\n",
      "Epoch [5/100], Step [860/1751], Loss: 1.8962\n",
      "Epoch [5/100], Step [870/1751], Loss: 1.7458\n",
      "Epoch [5/100], Step [880/1751], Loss: 1.7290\n",
      "Epoch [5/100], Step [890/1751], Loss: 1.7179\n",
      "Epoch [5/100], Step [900/1751], Loss: 1.6849\n",
      "Epoch [5/100], Step [910/1751], Loss: 1.6904\n",
      "Epoch [5/100], Step [920/1751], Loss: 1.7733\n",
      "Epoch [5/100], Step [930/1751], Loss: 1.7738\n",
      "Epoch [5/100], Step [940/1751], Loss: 1.7943\n",
      "Epoch [5/100], Step [950/1751], Loss: 1.6471\n",
      "Epoch [5/100], Step [960/1751], Loss: 1.8434\n",
      "Epoch [5/100], Step [970/1751], Loss: 1.6812\n",
      "Epoch [5/100], Step [980/1751], Loss: 1.7588\n",
      "Epoch [5/100], Step [990/1751], Loss: 1.6151\n",
      "Epoch [5/100], Step [1000/1751], Loss: 1.8790\n",
      "Epoch [5/100], Step [1010/1751], Loss: 1.7357\n",
      "Epoch [5/100], Step [1020/1751], Loss: 1.6517\n",
      "Epoch [5/100], Step [1030/1751], Loss: 1.6784\n",
      "Epoch [5/100], Step [1040/1751], Loss: 1.6555\n",
      "Epoch [5/100], Step [1050/1751], Loss: 1.8258\n",
      "Epoch [5/100], Step [1060/1751], Loss: 1.7572\n",
      "Epoch [5/100], Step [1070/1751], Loss: 1.8036\n",
      "Epoch [5/100], Step [1080/1751], Loss: 1.6534\n",
      "Epoch [5/100], Step [1090/1751], Loss: 1.7242\n",
      "Epoch [5/100], Step [1100/1751], Loss: 1.6651\n",
      "Epoch [5/100], Step [1110/1751], Loss: 1.7518\n",
      "Epoch [5/100], Step [1120/1751], Loss: 1.7560\n",
      "Epoch [5/100], Step [1130/1751], Loss: 1.5685\n",
      "Epoch [5/100], Step [1140/1751], Loss: 1.7111\n",
      "Epoch [5/100], Step [1150/1751], Loss: 1.7676\n",
      "Epoch [5/100], Step [1160/1751], Loss: 1.7054\n",
      "Epoch [5/100], Step [1170/1751], Loss: 1.6892\n",
      "Epoch [5/100], Step [1180/1751], Loss: 1.6886\n",
      "Epoch [5/100], Step [1190/1751], Loss: 1.8158\n",
      "Epoch [5/100], Step [1200/1751], Loss: 1.7202\n",
      "Epoch [5/100], Step [1210/1751], Loss: 1.6841\n",
      "Epoch [5/100], Step [1220/1751], Loss: 1.9484\n",
      "Epoch [5/100], Step [1230/1751], Loss: 1.7503\n",
      "Epoch [5/100], Step [1240/1751], Loss: 1.5315\n",
      "Epoch [5/100], Step [1250/1751], Loss: 1.5749\n",
      "Epoch [5/100], Step [1260/1751], Loss: 1.7596\n",
      "Epoch [5/100], Step [1270/1751], Loss: 1.8157\n",
      "Epoch [5/100], Step [1280/1751], Loss: 1.7734\n",
      "Epoch [5/100], Step [1290/1751], Loss: 1.5504\n",
      "Epoch [5/100], Step [1300/1751], Loss: 1.7484\n",
      "Epoch [5/100], Step [1310/1751], Loss: 1.7309\n",
      "Epoch [5/100], Step [1320/1751], Loss: 1.8051\n",
      "Epoch [5/100], Step [1330/1751], Loss: 1.6435\n",
      "Epoch [5/100], Step [1340/1751], Loss: 1.7934\n",
      "Epoch [5/100], Step [1350/1751], Loss: 1.7042\n",
      "Epoch [5/100], Step [1360/1751], Loss: 1.8620\n",
      "Epoch [5/100], Step [1370/1751], Loss: 1.6684\n",
      "Epoch [5/100], Step [1380/1751], Loss: 1.5586\n",
      "Epoch [5/100], Step [1390/1751], Loss: 1.7813\n",
      "Epoch [5/100], Step [1400/1751], Loss: 1.6129\n",
      "Epoch [5/100], Step [1410/1751], Loss: 1.9286\n",
      "Epoch [5/100], Step [1420/1751], Loss: 1.6730\n",
      "Epoch [5/100], Step [1430/1751], Loss: 1.6998\n",
      "Epoch [5/100], Step [1440/1751], Loss: 1.6267\n",
      "Epoch [5/100], Step [1450/1751], Loss: 1.6603\n",
      "Epoch [5/100], Step [1460/1751], Loss: 1.5115\n",
      "Epoch [5/100], Step [1470/1751], Loss: 1.8308\n",
      "Epoch [5/100], Step [1480/1751], Loss: 1.7467\n",
      "Epoch [5/100], Step [1490/1751], Loss: 1.7190\n",
      "Epoch [5/100], Step [1500/1751], Loss: 1.7616\n",
      "Epoch [5/100], Step [1510/1751], Loss: 1.5113\n",
      "Epoch [5/100], Step [1520/1751], Loss: 1.7782\n",
      "Epoch [5/100], Step [1530/1751], Loss: 1.6500\n",
      "Epoch [5/100], Step [1540/1751], Loss: 1.6246\n",
      "Epoch [5/100], Step [1550/1751], Loss: 1.5864\n",
      "Epoch [5/100], Step [1560/1751], Loss: 1.7195\n",
      "Epoch [5/100], Step [1570/1751], Loss: 1.5791\n",
      "Epoch [5/100], Step [1580/1751], Loss: 1.6481\n",
      "Epoch [5/100], Step [1590/1751], Loss: 1.7251\n",
      "Epoch [5/100], Step [1600/1751], Loss: 1.7642\n",
      "Epoch [5/100], Step [1610/1751], Loss: 1.6692\n",
      "Epoch [5/100], Step [1620/1751], Loss: 1.7397\n",
      "Epoch [5/100], Step [1630/1751], Loss: 1.8126\n",
      "Epoch [5/100], Step [1640/1751], Loss: 1.7795\n",
      "Epoch [5/100], Step [1650/1751], Loss: 1.6251\n",
      "Epoch [5/100], Step [1660/1751], Loss: 1.7355\n",
      "Epoch [5/100], Step [1670/1751], Loss: 1.6713\n",
      "Epoch [5/100], Step [1680/1751], Loss: 1.5625\n",
      "Epoch [5/100], Step [1690/1751], Loss: 1.7240\n",
      "Epoch [5/100], Step [1700/1751], Loss: 1.8373\n",
      "Epoch [5/100], Step [1710/1751], Loss: 1.6936\n",
      "Epoch [5/100], Step [1720/1751], Loss: 1.7290\n",
      "Epoch [5/100], Step [1730/1751], Loss: 1.7751\n",
      "Epoch [5/100], Step [1740/1751], Loss: 1.6930\n",
      "Epoch [5/100], Step [1750/1751], Loss: 1.6420\n",
      "Epoch [5/100], Average Loss: 1.7504, Time: 1637.1923s\n",
      "Epoch [6/100], Step [10/1751], Loss: 1.6490\n",
      "Epoch [6/100], Step [20/1751], Loss: 1.6830\n",
      "Epoch [6/100], Step [30/1751], Loss: 1.4696\n",
      "Epoch [6/100], Step [40/1751], Loss: 1.6606\n",
      "Epoch [6/100], Step [50/1751], Loss: 1.7041\n",
      "Epoch [6/100], Step [60/1751], Loss: 1.7490\n",
      "Epoch [6/100], Step [70/1751], Loss: 1.6494\n",
      "Epoch [6/100], Step [80/1751], Loss: 1.7839\n",
      "Epoch [6/100], Step [90/1751], Loss: 1.6756\n",
      "Epoch [6/100], Step [100/1751], Loss: 1.7307\n",
      "Epoch [6/100], Step [110/1751], Loss: 1.7976\n",
      "Epoch [6/100], Step [120/1751], Loss: 1.5976\n",
      "Epoch [6/100], Step [130/1751], Loss: 1.5750\n",
      "Epoch [6/100], Step [140/1751], Loss: 1.6323\n",
      "Epoch [6/100], Step [150/1751], Loss: 1.7177\n",
      "Epoch [6/100], Step [160/1751], Loss: 1.5390\n",
      "Epoch [6/100], Step [170/1751], Loss: 1.6299\n",
      "Epoch [6/100], Step [180/1751], Loss: 1.6801\n",
      "Epoch [6/100], Step [190/1751], Loss: 1.6035\n",
      "Epoch [6/100], Step [200/1751], Loss: 1.7017\n",
      "Epoch [6/100], Step [210/1751], Loss: 1.8005\n",
      "Epoch [6/100], Step [220/1751], Loss: 1.6349\n",
      "Epoch [6/100], Step [230/1751], Loss: 1.5236\n",
      "Epoch [6/100], Step [240/1751], Loss: 1.5698\n",
      "Epoch [6/100], Step [250/1751], Loss: 1.6881\n",
      "Epoch [6/100], Step [260/1751], Loss: 1.8925\n",
      "Epoch [6/100], Step [270/1751], Loss: 1.5369\n",
      "Epoch [6/100], Step [280/1751], Loss: 1.6921\n",
      "Epoch [6/100], Step [290/1751], Loss: 1.6311\n",
      "Epoch [6/100], Step [300/1751], Loss: 1.7292\n",
      "Epoch [6/100], Step [310/1751], Loss: 1.6494\n",
      "Epoch [6/100], Step [320/1751], Loss: 1.6314\n",
      "Epoch [6/100], Step [330/1751], Loss: 1.5846\n",
      "Epoch [6/100], Step [340/1751], Loss: 1.3863\n",
      "Epoch [6/100], Step [350/1751], Loss: 1.6452\n",
      "Epoch [6/100], Step [360/1751], Loss: 1.6368\n",
      "Epoch [6/100], Step [370/1751], Loss: 1.6802\n",
      "Epoch [6/100], Step [380/1751], Loss: 1.6361\n",
      "Epoch [6/100], Step [390/1751], Loss: 1.6338\n",
      "Epoch [6/100], Step [400/1751], Loss: 1.7780\n",
      "Epoch [6/100], Step [410/1751], Loss: 1.7212\n",
      "Epoch [6/100], Step [420/1751], Loss: 1.6327\n",
      "Epoch [6/100], Step [430/1751], Loss: 1.6689\n",
      "Epoch [6/100], Step [440/1751], Loss: 1.5793\n",
      "Epoch [6/100], Step [450/1751], Loss: 1.5678\n",
      "Epoch [6/100], Step [460/1751], Loss: 1.7163\n",
      "Epoch [6/100], Step [470/1751], Loss: 1.5021\n",
      "Epoch [6/100], Step [480/1751], Loss: 1.8262\n",
      "Epoch [6/100], Step [490/1751], Loss: 1.7450\n",
      "Epoch [6/100], Step [500/1751], Loss: 1.5966\n",
      "Epoch [6/100], Step [510/1751], Loss: 1.8907\n",
      "Epoch [6/100], Step [520/1751], Loss: 1.7453\n",
      "Epoch [6/100], Step [530/1751], Loss: 1.6242\n",
      "Epoch [6/100], Step [540/1751], Loss: 1.5744\n",
      "Epoch [6/100], Step [550/1751], Loss: 1.6761\n",
      "Epoch [6/100], Step [560/1751], Loss: 1.7052\n",
      "Epoch [6/100], Step [570/1751], Loss: 1.5205\n",
      "Epoch [6/100], Step [580/1751], Loss: 1.6928\n",
      "Epoch [6/100], Step [590/1751], Loss: 1.8115\n",
      "Epoch [6/100], Step [600/1751], Loss: 1.6065\n",
      "Epoch [6/100], Step [610/1751], Loss: 1.7879\n",
      "Epoch [6/100], Step [620/1751], Loss: 1.7044\n",
      "Epoch [6/100], Step [630/1751], Loss: 1.6964\n",
      "Epoch [6/100], Step [640/1751], Loss: 1.6803\n",
      "Epoch [6/100], Step [650/1751], Loss: 1.4811\n",
      "Epoch [6/100], Step [660/1751], Loss: 1.6101\n",
      "Epoch [6/100], Step [670/1751], Loss: 1.7299\n",
      "Epoch [6/100], Step [680/1751], Loss: 1.7567\n",
      "Epoch [6/100], Step [690/1751], Loss: 1.7424\n",
      "Epoch [6/100], Step [700/1751], Loss: 1.6167\n",
      "Epoch [6/100], Step [710/1751], Loss: 1.6977\n",
      "Epoch [6/100], Step [720/1751], Loss: 1.5372\n",
      "Epoch [6/100], Step [730/1751], Loss: 1.6679\n",
      "Epoch [6/100], Step [740/1751], Loss: 1.6381\n",
      "Epoch [6/100], Step [750/1751], Loss: 1.5190\n",
      "Epoch [6/100], Step [760/1751], Loss: 1.7457\n",
      "Epoch [6/100], Step [770/1751], Loss: 1.6482\n",
      "Epoch [6/100], Step [780/1751], Loss: 1.7517\n",
      "Epoch [6/100], Step [790/1751], Loss: 1.6316\n",
      "Epoch [6/100], Step [800/1751], Loss: 1.6470\n",
      "Epoch [6/100], Step [810/1751], Loss: 1.6842\n",
      "Epoch [6/100], Step [820/1751], Loss: 1.5397\n",
      "Epoch [6/100], Step [830/1751], Loss: 1.4605\n",
      "Epoch [6/100], Step [840/1751], Loss: 1.5866\n",
      "Epoch [6/100], Step [850/1751], Loss: 1.4398\n",
      "Epoch [6/100], Step [860/1751], Loss: 1.6097\n",
      "Epoch [6/100], Step [870/1751], Loss: 1.6362\n",
      "Epoch [6/100], Step [880/1751], Loss: 1.6847\n",
      "Epoch [6/100], Step [890/1751], Loss: 1.5449\n",
      "Epoch [6/100], Step [900/1751], Loss: 1.5050\n",
      "Epoch [6/100], Step [910/1751], Loss: 1.7644\n",
      "Epoch [6/100], Step [920/1751], Loss: 1.6377\n",
      "Epoch [6/100], Step [930/1751], Loss: 1.6797\n",
      "Epoch [6/100], Step [940/1751], Loss: 1.7219\n",
      "Epoch [6/100], Step [950/1751], Loss: 1.6208\n",
      "Epoch [6/100], Step [960/1751], Loss: 1.6289\n",
      "Epoch [6/100], Step [970/1751], Loss: 1.7527\n",
      "Epoch [6/100], Step [980/1751], Loss: 1.5591\n",
      "Epoch [6/100], Step [990/1751], Loss: 1.6101\n",
      "Epoch [6/100], Step [1000/1751], Loss: 1.5988\n",
      "Epoch [6/100], Step [1010/1751], Loss: 1.7506\n",
      "Epoch [6/100], Step [1020/1751], Loss: 1.5191\n",
      "Epoch [6/100], Step [1030/1751], Loss: 1.6194\n",
      "Epoch [6/100], Step [1040/1751], Loss: 1.7860\n",
      "Epoch [6/100], Step [1050/1751], Loss: 1.6275\n",
      "Epoch [6/100], Step [1060/1751], Loss: 1.6839\n",
      "Epoch [6/100], Step [1070/1751], Loss: 1.7622\n",
      "Epoch [6/100], Step [1080/1751], Loss: 1.5815\n",
      "Epoch [6/100], Step [1090/1751], Loss: 1.5851\n",
      "Epoch [6/100], Step [1100/1751], Loss: 1.6457\n",
      "Epoch [6/100], Step [1110/1751], Loss: 1.6420\n",
      "Epoch [6/100], Step [1120/1751], Loss: 1.4889\n",
      "Epoch [6/100], Step [1130/1751], Loss: 1.7623\n",
      "Epoch [6/100], Step [1140/1751], Loss: 1.6884\n",
      "Epoch [6/100], Step [1150/1751], Loss: 1.5079\n",
      "Epoch [6/100], Step [1160/1751], Loss: 1.5141\n",
      "Epoch [6/100], Step [1170/1751], Loss: 1.6920\n",
      "Epoch [6/100], Step [1180/1751], Loss: 1.7456\n",
      "Epoch [6/100], Step [1190/1751], Loss: 1.4216\n",
      "Epoch [6/100], Step [1200/1751], Loss: 1.5466\n",
      "Epoch [6/100], Step [1210/1751], Loss: 1.6285\n",
      "Epoch [6/100], Step [1220/1751], Loss: 1.5103\n",
      "Epoch [6/100], Step [1230/1751], Loss: 1.5944\n",
      "Epoch [6/100], Step [1240/1751], Loss: 1.5142\n",
      "Epoch [6/100], Step [1250/1751], Loss: 1.5742\n",
      "Epoch [6/100], Step [1260/1751], Loss: 1.5583\n",
      "Epoch [6/100], Step [1270/1751], Loss: 1.5596\n",
      "Epoch [6/100], Step [1280/1751], Loss: 1.5980\n",
      "Epoch [6/100], Step [1290/1751], Loss: 1.5639\n",
      "Epoch [6/100], Step [1300/1751], Loss: 1.5815\n",
      "Epoch [6/100], Step [1310/1751], Loss: 1.6708\n",
      "Epoch [6/100], Step [1320/1751], Loss: 1.6356\n",
      "Epoch [6/100], Step [1330/1751], Loss: 1.7184\n",
      "Epoch [6/100], Step [1340/1751], Loss: 1.4268\n",
      "Epoch [6/100], Step [1350/1751], Loss: 1.5432\n",
      "Epoch [6/100], Step [1360/1751], Loss: 1.5642\n",
      "Epoch [6/100], Step [1370/1751], Loss: 1.7372\n",
      "Epoch [6/100], Step [1380/1751], Loss: 1.5593\n",
      "Epoch [6/100], Step [1390/1751], Loss: 1.6092\n",
      "Epoch [6/100], Step [1400/1751], Loss: 1.6597\n",
      "Epoch [6/100], Step [1410/1751], Loss: 1.4760\n",
      "Epoch [6/100], Step [1420/1751], Loss: 1.4379\n",
      "Epoch [6/100], Step [1430/1751], Loss: 1.5513\n",
      "Epoch [6/100], Step [1440/1751], Loss: 1.5821\n",
      "Epoch [6/100], Step [1450/1751], Loss: 1.6092\n",
      "Epoch [6/100], Step [1460/1751], Loss: 1.6631\n",
      "Epoch [6/100], Step [1470/1751], Loss: 1.6465\n",
      "Epoch [6/100], Step [1480/1751], Loss: 1.4764\n",
      "Epoch [6/100], Step [1490/1751], Loss: 1.6062\n",
      "Epoch [6/100], Step [1500/1751], Loss: 1.6458\n",
      "Epoch [6/100], Step [1510/1751], Loss: 1.6488\n",
      "Epoch [6/100], Step [1520/1751], Loss: 1.6085\n",
      "Epoch [6/100], Step [1530/1751], Loss: 1.4731\n",
      "Epoch [6/100], Step [1540/1751], Loss: 1.5780\n",
      "Epoch [6/100], Step [1550/1751], Loss: 1.6217\n",
      "Epoch [6/100], Step [1560/1751], Loss: 1.4967\n",
      "Epoch [6/100], Step [1570/1751], Loss: 1.6600\n",
      "Epoch [6/100], Step [1580/1751], Loss: 1.6567\n",
      "Epoch [6/100], Step [1590/1751], Loss: 1.7245\n",
      "Epoch [6/100], Step [1600/1751], Loss: 1.8048\n",
      "Epoch [6/100], Step [1610/1751], Loss: 1.7176\n",
      "Epoch [6/100], Step [1620/1751], Loss: 1.5123\n",
      "Epoch [6/100], Step [1630/1751], Loss: 1.3737\n",
      "Epoch [6/100], Step [1640/1751], Loss: 1.6005\n",
      "Epoch [6/100], Step [1650/1751], Loss: 1.5773\n",
      "Epoch [6/100], Step [1660/1751], Loss: 1.6918\n",
      "Epoch [6/100], Step [1670/1751], Loss: 1.5917\n",
      "Epoch [6/100], Step [1680/1751], Loss: 1.5709\n",
      "Epoch [6/100], Step [1690/1751], Loss: 1.6658\n",
      "Epoch [6/100], Step [1700/1751], Loss: 1.5579\n",
      "Epoch [6/100], Step [1710/1751], Loss: 1.5422\n",
      "Epoch [6/100], Step [1720/1751], Loss: 1.3707\n",
      "Epoch [6/100], Step [1730/1751], Loss: 1.6006\n",
      "Epoch [6/100], Step [1740/1751], Loss: 1.6155\n",
      "Epoch [6/100], Step [1750/1751], Loss: 1.6576\n",
      "Epoch [6/100], Average Loss: 1.6299, Time: 1637.6004s\n",
      "Epoch [7/100], Step [10/1751], Loss: 1.5619\n",
      "Epoch [7/100], Step [20/1751], Loss: 1.3254\n",
      "Epoch [7/100], Step [30/1751], Loss: 1.6943\n",
      "Epoch [7/100], Step [40/1751], Loss: 1.5242\n",
      "Epoch [7/100], Step [50/1751], Loss: 1.5685\n",
      "Epoch [7/100], Step [60/1751], Loss: 1.5943\n",
      "Epoch [7/100], Step [70/1751], Loss: 1.6714\n",
      "Epoch [7/100], Step [80/1751], Loss: 1.4507\n",
      "Epoch [7/100], Step [90/1751], Loss: 1.6907\n",
      "Epoch [7/100], Step [100/1751], Loss: 1.5235\n",
      "Epoch [7/100], Step [110/1751], Loss: 1.6212\n",
      "Epoch [7/100], Step [120/1751], Loss: 1.5573\n",
      "Epoch [7/100], Step [130/1751], Loss: 1.5976\n",
      "Epoch [7/100], Step [140/1751], Loss: 1.6015\n",
      "Epoch [7/100], Step [150/1751], Loss: 1.5818\n",
      "Epoch [7/100], Step [160/1751], Loss: 1.6405\n",
      "Epoch [7/100], Step [170/1751], Loss: 1.5383\n",
      "Epoch [7/100], Step [180/1751], Loss: 1.5571\n",
      "Epoch [7/100], Step [190/1751], Loss: 1.6002\n",
      "Epoch [7/100], Step [200/1751], Loss: 1.4367\n",
      "Epoch [7/100], Step [210/1751], Loss: 1.6279\n",
      "Epoch [7/100], Step [220/1751], Loss: 1.4785\n",
      "Epoch [7/100], Step [230/1751], Loss: 1.4941\n",
      "Epoch [7/100], Step [240/1751], Loss: 1.5090\n",
      "Epoch [7/100], Step [250/1751], Loss: 1.5700\n",
      "Epoch [7/100], Step [260/1751], Loss: 1.5380\n",
      "Epoch [7/100], Step [270/1751], Loss: 1.4860\n",
      "Epoch [7/100], Step [280/1751], Loss: 1.4047\n",
      "Epoch [7/100], Step [290/1751], Loss: 1.6417\n",
      "Epoch [7/100], Step [300/1751], Loss: 1.6012\n",
      "Epoch [7/100], Step [310/1751], Loss: 1.6296\n",
      "Epoch [7/100], Step [320/1751], Loss: 1.5783\n",
      "Epoch [7/100], Step [330/1751], Loss: 1.4550\n",
      "Epoch [7/100], Step [340/1751], Loss: 1.6528\n",
      "Epoch [7/100], Step [350/1751], Loss: 1.5326\n",
      "Epoch [7/100], Step [360/1751], Loss: 1.5291\n",
      "Epoch [7/100], Step [370/1751], Loss: 1.5440\n",
      "Epoch [7/100], Step [380/1751], Loss: 1.5930\n",
      "Epoch [7/100], Step [390/1751], Loss: 1.6957\n",
      "Epoch [7/100], Step [400/1751], Loss: 1.8073\n",
      "Epoch [7/100], Step [410/1751], Loss: 1.5252\n",
      "Epoch [7/100], Step [420/1751], Loss: 1.6066\n",
      "Epoch [7/100], Step [430/1751], Loss: 1.5868\n",
      "Epoch [7/100], Step [440/1751], Loss: 1.6020\n",
      "Epoch [7/100], Step [450/1751], Loss: 1.5270\n",
      "Epoch [7/100], Step [460/1751], Loss: 1.8297\n",
      "Epoch [7/100], Step [470/1751], Loss: 1.6062\n",
      "Epoch [7/100], Step [480/1751], Loss: 1.6160\n",
      "Epoch [7/100], Step [490/1751], Loss: 1.6650\n",
      "Epoch [7/100], Step [500/1751], Loss: 1.5541\n",
      "Epoch [7/100], Step [510/1751], Loss: 1.5790\n",
      "Epoch [7/100], Step [520/1751], Loss: 1.7277\n",
      "Epoch [7/100], Step [530/1751], Loss: 1.7041\n",
      "Epoch [7/100], Step [540/1751], Loss: 1.5464\n",
      "Epoch [7/100], Step [550/1751], Loss: 1.5526\n",
      "Epoch [7/100], Step [560/1751], Loss: 1.6302\n",
      "Epoch [7/100], Step [570/1751], Loss: 1.3824\n",
      "Epoch [7/100], Step [580/1751], Loss: 1.5667\n",
      "Epoch [7/100], Step [590/1751], Loss: 1.6840\n",
      "Epoch [7/100], Step [600/1751], Loss: 1.3514\n",
      "Epoch [7/100], Step [610/1751], Loss: 1.4660\n",
      "Epoch [7/100], Step [620/1751], Loss: 1.4827\n",
      "Epoch [7/100], Step [630/1751], Loss: 1.4764\n",
      "Epoch [7/100], Step [640/1751], Loss: 1.5810\n",
      "Epoch [7/100], Step [650/1751], Loss: 1.4022\n",
      "Epoch [7/100], Step [660/1751], Loss: 1.5331\n",
      "Epoch [7/100], Step [670/1751], Loss: 1.5503\n",
      "Epoch [7/100], Step [680/1751], Loss: 1.8251\n",
      "Epoch [7/100], Step [690/1751], Loss: 1.5809\n",
      "Epoch [7/100], Step [700/1751], Loss: 1.4301\n",
      "Epoch [7/100], Step [710/1751], Loss: 1.6641\n",
      "Epoch [7/100], Step [720/1751], Loss: 1.5565\n",
      "Epoch [7/100], Step [730/1751], Loss: 1.5990\n",
      "Epoch [7/100], Step [740/1751], Loss: 1.6221\n",
      "Epoch [7/100], Step [750/1751], Loss: 1.4249\n",
      "Epoch [7/100], Step [760/1751], Loss: 1.4330\n",
      "Epoch [7/100], Step [770/1751], Loss: 1.6460\n",
      "Epoch [7/100], Step [780/1751], Loss: 1.5505\n",
      "Epoch [7/100], Step [790/1751], Loss: 1.7418\n",
      "Epoch [7/100], Step [800/1751], Loss: 1.5797\n",
      "Epoch [7/100], Step [810/1751], Loss: 1.5980\n",
      "Epoch [7/100], Step [820/1751], Loss: 1.5983\n",
      "Epoch [7/100], Step [830/1751], Loss: 1.3380\n",
      "Epoch [7/100], Step [840/1751], Loss: 1.5075\n",
      "Epoch [7/100], Step [850/1751], Loss: 1.5510\n",
      "Epoch [7/100], Step [860/1751], Loss: 1.5753\n",
      "Epoch [7/100], Step [870/1751], Loss: 1.4896\n",
      "Epoch [7/100], Step [880/1751], Loss: 1.4829\n",
      "Epoch [7/100], Step [890/1751], Loss: 1.4904\n",
      "Epoch [7/100], Step [900/1751], Loss: 1.6258\n",
      "Epoch [7/100], Step [910/1751], Loss: 1.5028\n",
      "Epoch [7/100], Step [920/1751], Loss: 1.5568\n",
      "Epoch [7/100], Step [930/1751], Loss: 1.6306\n",
      "Epoch [7/100], Step [940/1751], Loss: 1.5792\n",
      "Epoch [7/100], Step [950/1751], Loss: 1.5460\n",
      "Epoch [7/100], Step [960/1751], Loss: 1.4418\n",
      "Epoch [7/100], Step [970/1751], Loss: 1.5087\n",
      "Epoch [7/100], Step [980/1751], Loss: 1.5182\n",
      "Epoch [7/100], Step [990/1751], Loss: 1.7491\n",
      "Epoch [7/100], Step [1000/1751], Loss: 1.5701\n",
      "Epoch [7/100], Step [1010/1751], Loss: 1.5891\n",
      "Epoch [7/100], Step [1020/1751], Loss: 1.4514\n",
      "Epoch [7/100], Step [1030/1751], Loss: 1.5210\n",
      "Epoch [7/100], Step [1040/1751], Loss: 1.6407\n",
      "Epoch [7/100], Step [1050/1751], Loss: 1.4610\n",
      "Epoch [7/100], Step [1060/1751], Loss: 1.5249\n",
      "Epoch [7/100], Step [1070/1751], Loss: 1.4212\n",
      "Epoch [7/100], Step [1080/1751], Loss: 1.4560\n",
      "Epoch [7/100], Step [1090/1751], Loss: 1.6026\n",
      "Epoch [7/100], Step [1100/1751], Loss: 1.4760\n",
      "Epoch [7/100], Step [1110/1751], Loss: 1.3910\n",
      "Epoch [7/100], Step [1120/1751], Loss: 1.4819\n",
      "Epoch [7/100], Step [1130/1751], Loss: 1.5276\n",
      "Epoch [7/100], Step [1140/1751], Loss: 1.5493\n",
      "Epoch [7/100], Step [1150/1751], Loss: 1.6247\n",
      "Epoch [7/100], Step [1160/1751], Loss: 1.6069\n",
      "Epoch [7/100], Step [1170/1751], Loss: 1.7995\n",
      "Epoch [7/100], Step [1180/1751], Loss: 1.5766\n",
      "Epoch [7/100], Step [1190/1751], Loss: 1.5630\n",
      "Epoch [7/100], Step [1200/1751], Loss: 1.5217\n",
      "Epoch [7/100], Step [1210/1751], Loss: 1.5204\n",
      "Epoch [7/100], Step [1220/1751], Loss: 1.6160\n",
      "Epoch [7/100], Step [1230/1751], Loss: 1.4070\n",
      "Epoch [7/100], Step [1240/1751], Loss: 1.4488\n",
      "Epoch [7/100], Step [1250/1751], Loss: 1.5360\n",
      "Epoch [7/100], Step [1260/1751], Loss: 1.5287\n",
      "Epoch [7/100], Step [1270/1751], Loss: 1.5646\n",
      "Epoch [7/100], Step [1280/1751], Loss: 1.5703\n",
      "Epoch [7/100], Step [1290/1751], Loss: 1.4574\n",
      "Epoch [7/100], Step [1300/1751], Loss: 1.6480\n",
      "Epoch [7/100], Step [1310/1751], Loss: 1.4739\n",
      "Epoch [7/100], Step [1320/1751], Loss: 1.5147\n",
      "Epoch [7/100], Step [1330/1751], Loss: 1.5029\n",
      "Epoch [7/100], Step [1340/1751], Loss: 1.5521\n",
      "Epoch [7/100], Step [1350/1751], Loss: 1.5006\n",
      "Epoch [7/100], Step [1360/1751], Loss: 1.5692\n",
      "Epoch [7/100], Step [1370/1751], Loss: 1.6674\n",
      "Epoch [7/100], Step [1380/1751], Loss: 1.5714\n",
      "Epoch [7/100], Step [1390/1751], Loss: 1.5181\n",
      "Epoch [7/100], Step [1400/1751], Loss: 1.4201\n",
      "Epoch [7/100], Step [1410/1751], Loss: 1.3750\n",
      "Epoch [7/100], Step [1420/1751], Loss: 1.5056\n",
      "Epoch [7/100], Step [1430/1751], Loss: 1.6463\n",
      "Epoch [7/100], Step [1440/1751], Loss: 1.6641\n",
      "Epoch [7/100], Step [1450/1751], Loss: 1.4255\n",
      "Epoch [7/100], Step [1460/1751], Loss: 1.3635\n",
      "Epoch [7/100], Step [1470/1751], Loss: 1.4486\n",
      "Epoch [7/100], Step [1480/1751], Loss: 1.4929\n",
      "Epoch [7/100], Step [1490/1751], Loss: 1.6614\n",
      "Epoch [7/100], Step [1500/1751], Loss: 1.4320\n",
      "Epoch [7/100], Step [1510/1751], Loss: 1.5287\n",
      "Epoch [7/100], Step [1520/1751], Loss: 1.4265\n",
      "Epoch [7/100], Step [1530/1751], Loss: 1.5548\n",
      "Epoch [7/100], Step [1540/1751], Loss: 1.4585\n",
      "Epoch [7/100], Step [1550/1751], Loss: 1.6185\n",
      "Epoch [7/100], Step [1560/1751], Loss: 1.5454\n",
      "Epoch [7/100], Step [1570/1751], Loss: 1.7909\n",
      "Epoch [7/100], Step [1580/1751], Loss: 1.5197\n",
      "Epoch [7/100], Step [1590/1751], Loss: 1.4942\n",
      "Epoch [7/100], Step [1600/1751], Loss: 1.5919\n",
      "Epoch [7/100], Step [1610/1751], Loss: 1.3959\n",
      "Epoch [7/100], Step [1620/1751], Loss: 1.5874\n",
      "Epoch [7/100], Step [1630/1751], Loss: 1.4506\n",
      "Epoch [7/100], Step [1640/1751], Loss: 1.4907\n",
      "Epoch [7/100], Step [1650/1751], Loss: 1.3650\n",
      "Epoch [7/100], Step [1660/1751], Loss: 1.6095\n",
      "Epoch [7/100], Step [1670/1751], Loss: 1.5179\n",
      "Epoch [7/100], Step [1680/1751], Loss: 1.5081\n",
      "Epoch [7/100], Step [1690/1751], Loss: 1.5872\n",
      "Epoch [7/100], Step [1700/1751], Loss: 1.4423\n",
      "Epoch [7/100], Step [1710/1751], Loss: 1.3715\n",
      "Epoch [7/100], Step [1720/1751], Loss: 1.6445\n",
      "Epoch [7/100], Step [1730/1751], Loss: 1.5127\n",
      "Epoch [7/100], Step [1740/1751], Loss: 1.3654\n",
      "Epoch [7/100], Step [1750/1751], Loss: 1.6115\n",
      "Epoch [7/100], Average Loss: 1.5475, Time: 1637.8162s\n",
      "Epoch [8/100], Step [10/1751], Loss: 1.4457\n",
      "Epoch [8/100], Step [20/1751], Loss: 1.5987\n",
      "Epoch [8/100], Step [30/1751], Loss: 1.5489\n",
      "Epoch [8/100], Step [40/1751], Loss: 1.5464\n",
      "Epoch [8/100], Step [50/1751], Loss: 1.5458\n",
      "Epoch [8/100], Step [60/1751], Loss: 1.4000\n",
      "Epoch [8/100], Step [70/1751], Loss: 1.5137\n",
      "Epoch [8/100], Step [80/1751], Loss: 1.4532\n",
      "Epoch [8/100], Step [90/1751], Loss: 1.4075\n",
      "Epoch [8/100], Step [100/1751], Loss: 1.5635\n",
      "Epoch [8/100], Step [110/1751], Loss: 1.4041\n",
      "Epoch [8/100], Step [120/1751], Loss: 1.6918\n",
      "Epoch [8/100], Step [130/1751], Loss: 1.4879\n",
      "Epoch [8/100], Step [140/1751], Loss: 1.4236\n",
      "Epoch [8/100], Step [150/1751], Loss: 1.3099\n",
      "Epoch [8/100], Step [160/1751], Loss: 1.5250\n",
      "Epoch [8/100], Step [170/1751], Loss: 1.5004\n",
      "Epoch [8/100], Step [180/1751], Loss: 1.4208\n",
      "Epoch [8/100], Step [190/1751], Loss: 1.4235\n",
      "Epoch [8/100], Step [200/1751], Loss: 1.3378\n",
      "Epoch [8/100], Step [210/1751], Loss: 1.4676\n",
      "Epoch [8/100], Step [220/1751], Loss: 1.4517\n",
      "Epoch [8/100], Step [230/1751], Loss: 1.4744\n",
      "Epoch [8/100], Step [240/1751], Loss: 1.6291\n",
      "Epoch [8/100], Step [250/1751], Loss: 1.5476\n",
      "Epoch [8/100], Step [260/1751], Loss: 1.3037\n",
      "Epoch [8/100], Step [270/1751], Loss: 1.4607\n",
      "Epoch [8/100], Step [280/1751], Loss: 1.4765\n",
      "Epoch [8/100], Step [290/1751], Loss: 1.4873\n",
      "Epoch [8/100], Step [300/1751], Loss: 1.5723\n",
      "Epoch [8/100], Step [310/1751], Loss: 1.4642\n",
      "Epoch [8/100], Step [320/1751], Loss: 1.5716\n",
      "Epoch [8/100], Step [330/1751], Loss: 1.5827\n",
      "Epoch [8/100], Step [340/1751], Loss: 1.5113\n",
      "Epoch [8/100], Step [350/1751], Loss: 1.4713\n",
      "Epoch [8/100], Step [360/1751], Loss: 1.5187\n",
      "Epoch [8/100], Step [370/1751], Loss: 1.4147\n",
      "Epoch [8/100], Step [380/1751], Loss: 1.5400\n",
      "Epoch [8/100], Step [390/1751], Loss: 1.6342\n",
      "Epoch [8/100], Step [400/1751], Loss: 1.7067\n",
      "Epoch [8/100], Step [410/1751], Loss: 1.3670\n",
      "Epoch [8/100], Step [420/1751], Loss: 1.5519\n",
      "Epoch [8/100], Step [430/1751], Loss: 1.6747\n",
      "Epoch [8/100], Step [440/1751], Loss: 1.5734\n",
      "Epoch [8/100], Step [450/1751], Loss: 1.3600\n",
      "Epoch [8/100], Step [460/1751], Loss: 1.4124\n",
      "Epoch [8/100], Step [470/1751], Loss: 1.6406\n",
      "Epoch [8/100], Step [480/1751], Loss: 1.5091\n",
      "Epoch [8/100], Step [490/1751], Loss: 1.4149\n",
      "Epoch [8/100], Step [500/1751], Loss: 1.5366\n",
      "Epoch [8/100], Step [510/1751], Loss: 1.3763\n",
      "Epoch [8/100], Step [520/1751], Loss: 1.6288\n",
      "Epoch [8/100], Step [530/1751], Loss: 1.4335\n",
      "Epoch [8/100], Step [540/1751], Loss: 1.5921\n",
      "Epoch [8/100], Step [550/1751], Loss: 1.5654\n",
      "Epoch [8/100], Step [560/1751], Loss: 1.4072\n",
      "Epoch [8/100], Step [570/1751], Loss: 1.4813\n",
      "Epoch [8/100], Step [580/1751], Loss: 1.3784\n",
      "Epoch [8/100], Step [590/1751], Loss: 1.6209\n",
      "Epoch [8/100], Step [600/1751], Loss: 1.4864\n",
      "Epoch [8/100], Step [610/1751], Loss: 1.5880\n",
      "Epoch [8/100], Step [620/1751], Loss: 1.4850\n",
      "Epoch [8/100], Step [630/1751], Loss: 1.4579\n",
      "Epoch [8/100], Step [640/1751], Loss: 1.5377\n",
      "Epoch [8/100], Step [650/1751], Loss: 1.4331\n",
      "Epoch [8/100], Step [660/1751], Loss: 1.6824\n",
      "Epoch [8/100], Step [670/1751], Loss: 1.5821\n",
      "Epoch [8/100], Step [680/1751], Loss: 1.4846\n",
      "Epoch [8/100], Step [690/1751], Loss: 1.4889\n",
      "Epoch [8/100], Step [700/1751], Loss: 1.5881\n",
      "Epoch [8/100], Step [710/1751], Loss: 1.5093\n",
      "Epoch [8/100], Step [720/1751], Loss: 1.5355\n",
      "Epoch [8/100], Step [730/1751], Loss: 1.3521\n",
      "Epoch [8/100], Step [740/1751], Loss: 1.3910\n",
      "Epoch [8/100], Step [750/1751], Loss: 1.5443\n",
      "Epoch [8/100], Step [760/1751], Loss: 1.5551\n",
      "Epoch [8/100], Step [770/1751], Loss: 1.5339\n",
      "Epoch [8/100], Step [780/1751], Loss: 1.3930\n",
      "Epoch [8/100], Step [790/1751], Loss: 1.5099\n",
      "Epoch [8/100], Step [800/1751], Loss: 1.5388\n",
      "Epoch [8/100], Step [810/1751], Loss: 1.4885\n",
      "Epoch [8/100], Step [820/1751], Loss: 1.5048\n",
      "Epoch [8/100], Step [830/1751], Loss: 1.4336\n",
      "Epoch [8/100], Step [840/1751], Loss: 1.4791\n",
      "Epoch [8/100], Step [850/1751], Loss: 1.3848\n",
      "Epoch [8/100], Step [860/1751], Loss: 1.4361\n",
      "Epoch [8/100], Step [870/1751], Loss: 1.5348\n",
      "Epoch [8/100], Step [880/1751], Loss: 1.5454\n",
      "Epoch [8/100], Step [890/1751], Loss: 1.4567\n",
      "Epoch [8/100], Step [900/1751], Loss: 1.5931\n",
      "Epoch [8/100], Step [910/1751], Loss: 1.4828\n",
      "Epoch [8/100], Step [920/1751], Loss: 1.5314\n",
      "Epoch [8/100], Step [930/1751], Loss: 1.4537\n",
      "Epoch [8/100], Step [940/1751], Loss: 1.4883\n",
      "Epoch [8/100], Step [950/1751], Loss: 1.4622\n",
      "Epoch [8/100], Step [960/1751], Loss: 1.4880\n",
      "Epoch [8/100], Step [970/1751], Loss: 1.4116\n",
      "Epoch [8/100], Step [980/1751], Loss: 1.4511\n",
      "Epoch [8/100], Step [990/1751], Loss: 1.4793\n",
      "Epoch [8/100], Step [1000/1751], Loss: 1.5747\n",
      "Epoch [8/100], Step [1010/1751], Loss: 1.3565\n",
      "Epoch [8/100], Step [1020/1751], Loss: 1.4548\n",
      "Epoch [8/100], Step [1030/1751], Loss: 1.3844\n",
      "Epoch [8/100], Step [1040/1751], Loss: 1.5475\n",
      "Epoch [8/100], Step [1050/1751], Loss: 1.5348\n",
      "Epoch [8/100], Step [1060/1751], Loss: 1.5839\n",
      "Epoch [8/100], Step [1070/1751], Loss: 1.5150\n",
      "Epoch [8/100], Step [1080/1751], Loss: 1.5387\n",
      "Epoch [8/100], Step [1090/1751], Loss: 1.5329\n",
      "Epoch [8/100], Step [1100/1751], Loss: 1.3431\n",
      "Epoch [8/100], Step [1110/1751], Loss: 1.5646\n",
      "Epoch [8/100], Step [1120/1751], Loss: 1.4710\n",
      "Epoch [8/100], Step [1130/1751], Loss: 1.5328\n",
      "Epoch [8/100], Step [1140/1751], Loss: 1.4696\n",
      "Epoch [8/100], Step [1150/1751], Loss: 1.5127\n",
      "Epoch [8/100], Step [1160/1751], Loss: 1.4854\n",
      "Epoch [8/100], Step [1170/1751], Loss: 1.3555\n",
      "Epoch [8/100], Step [1180/1751], Loss: 1.3875\n",
      "Epoch [8/100], Step [1190/1751], Loss: 1.6268\n",
      "Epoch [8/100], Step [1200/1751], Loss: 1.7138\n",
      "Epoch [8/100], Step [1210/1751], Loss: 1.4684\n",
      "Epoch [8/100], Step [1220/1751], Loss: 1.4620\n",
      "Epoch [8/100], Step [1230/1751], Loss: 1.5195\n",
      "Epoch [8/100], Step [1240/1751], Loss: 1.4517\n",
      "Epoch [8/100], Step [1250/1751], Loss: 1.5809\n",
      "Epoch [8/100], Step [1260/1751], Loss: 1.6506\n",
      "Epoch [8/100], Step [1270/1751], Loss: 1.4293\n",
      "Epoch [8/100], Step [1280/1751], Loss: 1.4664\n",
      "Epoch [8/100], Step [1290/1751], Loss: 1.5035\n",
      "Epoch [8/100], Step [1300/1751], Loss: 1.4154\n",
      "Epoch [8/100], Step [1310/1751], Loss: 1.3962\n",
      "Epoch [8/100], Step [1320/1751], Loss: 1.5027\n",
      "Epoch [8/100], Step [1330/1751], Loss: 1.4781\n",
      "Epoch [8/100], Step [1340/1751], Loss: 1.5777\n",
      "Epoch [8/100], Step [1350/1751], Loss: 1.5457\n",
      "Epoch [8/100], Step [1360/1751], Loss: 1.6273\n",
      "Epoch [8/100], Step [1370/1751], Loss: 1.4540\n",
      "Epoch [8/100], Step [1380/1751], Loss: 1.5056\n",
      "Epoch [8/100], Step [1390/1751], Loss: 1.4520\n",
      "Epoch [8/100], Step [1400/1751], Loss: 1.4491\n",
      "Epoch [8/100], Step [1410/1751], Loss: 1.5095\n",
      "Epoch [8/100], Step [1420/1751], Loss: 1.3970\n",
      "Epoch [8/100], Step [1430/1751], Loss: 1.5887\n",
      "Epoch [8/100], Step [1440/1751], Loss: 1.4088\n",
      "Epoch [8/100], Step [1450/1751], Loss: 1.4555\n",
      "Epoch [8/100], Step [1460/1751], Loss: 1.4273\n",
      "Epoch [8/100], Step [1470/1751], Loss: 1.3500\n",
      "Epoch [8/100], Step [1480/1751], Loss: 1.5052\n",
      "Epoch [8/100], Step [1490/1751], Loss: 1.4298\n",
      "Epoch [8/100], Step [1500/1751], Loss: 1.4377\n",
      "Epoch [8/100], Step [1510/1751], Loss: 1.3995\n",
      "Epoch [8/100], Step [1520/1751], Loss: 1.4442\n",
      "Epoch [8/100], Step [1530/1751], Loss: 1.4426\n",
      "Epoch [8/100], Step [1540/1751], Loss: 1.4416\n",
      "Epoch [8/100], Step [1550/1751], Loss: 1.3290\n",
      "Epoch [8/100], Step [1560/1751], Loss: 1.5334\n",
      "Epoch [8/100], Step [1570/1751], Loss: 1.5685\n",
      "Epoch [8/100], Step [1580/1751], Loss: 1.4028\n",
      "Epoch [8/100], Step [1590/1751], Loss: 1.4556\n",
      "Epoch [8/100], Step [1600/1751], Loss: 1.5000\n",
      "Epoch [8/100], Step [1610/1751], Loss: 1.3766\n",
      "Epoch [8/100], Step [1620/1751], Loss: 1.3472\n",
      "Epoch [8/100], Step [1630/1751], Loss: 1.5869\n",
      "Epoch [8/100], Step [1640/1751], Loss: 1.3765\n",
      "Epoch [8/100], Step [1650/1751], Loss: 1.4655\n",
      "Epoch [8/100], Step [1660/1751], Loss: 1.5417\n",
      "Epoch [8/100], Step [1670/1751], Loss: 1.3546\n",
      "Epoch [8/100], Step [1680/1751], Loss: 1.4694\n",
      "Epoch [8/100], Step [1690/1751], Loss: 1.5897\n",
      "Epoch [8/100], Step [1700/1751], Loss: 1.6882\n",
      "Epoch [8/100], Step [1710/1751], Loss: 1.4356\n",
      "Epoch [8/100], Step [1720/1751], Loss: 1.2937\n",
      "Epoch [8/100], Step [1730/1751], Loss: 1.5580\n",
      "Epoch [8/100], Step [1740/1751], Loss: 1.4630\n",
      "Epoch [8/100], Step [1750/1751], Loss: 1.6624\n",
      "Epoch [8/100], Average Loss: 1.4903, Time: 1637.2486s\n",
      "Epoch [9/100], Step [10/1751], Loss: 1.5805\n",
      "Epoch [9/100], Step [20/1751], Loss: 1.5173\n",
      "Epoch [9/100], Step [30/1751], Loss: 1.3592\n",
      "Epoch [9/100], Step [40/1751], Loss: 1.4741\n",
      "Epoch [9/100], Step [50/1751], Loss: 1.3697\n",
      "Epoch [9/100], Step [60/1751], Loss: 1.3722\n",
      "Epoch [9/100], Step [70/1751], Loss: 1.5374\n",
      "Epoch [9/100], Step [80/1751], Loss: 1.3078\n",
      "Epoch [9/100], Step [90/1751], Loss: 1.4185\n",
      "Epoch [9/100], Step [100/1751], Loss: 1.4698\n",
      "Epoch [9/100], Step [110/1751], Loss: 1.5608\n",
      "Epoch [9/100], Step [120/1751], Loss: 1.4632\n",
      "Epoch [9/100], Step [130/1751], Loss: 1.4472\n",
      "Epoch [9/100], Step [140/1751], Loss: 1.4401\n",
      "Epoch [9/100], Step [150/1751], Loss: 1.5108\n",
      "Epoch [9/100], Step [160/1751], Loss: 1.5034\n",
      "Epoch [9/100], Step [170/1751], Loss: 1.4535\n",
      "Epoch [9/100], Step [180/1751], Loss: 1.5094\n",
      "Epoch [9/100], Step [190/1751], Loss: 1.4145\n",
      "Epoch [9/100], Step [200/1751], Loss: 1.5003\n",
      "Epoch [9/100], Step [210/1751], Loss: 1.5258\n",
      "Epoch [9/100], Step [220/1751], Loss: 1.3829\n",
      "Epoch [9/100], Step [230/1751], Loss: 1.3806\n",
      "Epoch [9/100], Step [240/1751], Loss: 1.3230\n",
      "Epoch [9/100], Step [250/1751], Loss: 1.5574\n",
      "Epoch [9/100], Step [260/1751], Loss: 1.3839\n",
      "Epoch [9/100], Step [270/1751], Loss: 1.6129\n",
      "Epoch [9/100], Step [280/1751], Loss: 1.4650\n",
      "Epoch [9/100], Step [290/1751], Loss: 1.5325\n",
      "Epoch [9/100], Step [300/1751], Loss: 1.4142\n",
      "Epoch [9/100], Step [310/1751], Loss: 1.4014\n",
      "Epoch [9/100], Step [320/1751], Loss: 1.4092\n",
      "Epoch [9/100], Step [330/1751], Loss: 1.7361\n",
      "Epoch [9/100], Step [340/1751], Loss: 1.5073\n",
      "Epoch [9/100], Step [350/1751], Loss: 1.4308\n",
      "Epoch [9/100], Step [360/1751], Loss: 1.5568\n",
      "Epoch [9/100], Step [370/1751], Loss: 1.3813\n",
      "Epoch [9/100], Step [380/1751], Loss: 1.5138\n",
      "Epoch [9/100], Step [390/1751], Loss: 1.4119\n",
      "Epoch [9/100], Step [400/1751], Loss: 1.6682\n",
      "Epoch [9/100], Step [410/1751], Loss: 1.5157\n",
      "Epoch [9/100], Step [420/1751], Loss: 1.4194\n",
      "Epoch [9/100], Step [430/1751], Loss: 1.5003\n",
      "Epoch [9/100], Step [440/1751], Loss: 1.3814\n",
      "Epoch [9/100], Step [450/1751], Loss: 1.4360\n",
      "Epoch [9/100], Step [460/1751], Loss: 1.4492\n",
      "Epoch [9/100], Step [470/1751], Loss: 1.4200\n",
      "Epoch [9/100], Step [480/1751], Loss: 1.6253\n",
      "Epoch [9/100], Step [490/1751], Loss: 1.4258\n",
      "Epoch [9/100], Step [500/1751], Loss: 1.4195\n",
      "Epoch [9/100], Step [510/1751], Loss: 1.4604\n",
      "Epoch [9/100], Step [520/1751], Loss: 1.3016\n",
      "Epoch [9/100], Step [530/1751], Loss: 1.4123\n",
      "Epoch [9/100], Step [540/1751], Loss: 1.3251\n",
      "Epoch [9/100], Step [550/1751], Loss: 1.6487\n",
      "Epoch [9/100], Step [560/1751], Loss: 1.4895\n",
      "Epoch [9/100], Step [570/1751], Loss: 1.4022\n",
      "Epoch [9/100], Step [580/1751], Loss: 1.4942\n",
      "Epoch [9/100], Step [590/1751], Loss: 1.4866\n",
      "Epoch [9/100], Step [600/1751], Loss: 1.3986\n",
      "Epoch [9/100], Step [610/1751], Loss: 1.4382\n",
      "Epoch [9/100], Step [620/1751], Loss: 1.3141\n",
      "Epoch [9/100], Step [630/1751], Loss: 1.4207\n",
      "Epoch [9/100], Step [640/1751], Loss: 1.4215\n",
      "Epoch [9/100], Step [650/1751], Loss: 1.5287\n",
      "Epoch [9/100], Step [660/1751], Loss: 1.4196\n",
      "Epoch [9/100], Step [670/1751], Loss: 1.6618\n",
      "Epoch [9/100], Step [680/1751], Loss: 1.3920\n",
      "Epoch [9/100], Step [690/1751], Loss: 1.4734\n",
      "Epoch [9/100], Step [700/1751], Loss: 1.3956\n",
      "Epoch [9/100], Step [710/1751], Loss: 1.4961\n",
      "Epoch [9/100], Step [720/1751], Loss: 1.4405\n",
      "Epoch [9/100], Step [730/1751], Loss: 1.4038\n",
      "Epoch [9/100], Step [740/1751], Loss: 1.2852\n",
      "Epoch [9/100], Step [750/1751], Loss: 1.6257\n",
      "Epoch [9/100], Step [760/1751], Loss: 1.4539\n",
      "Epoch [9/100], Step [770/1751], Loss: 1.5424\n",
      "Epoch [9/100], Step [780/1751], Loss: 1.4414\n",
      "Epoch [9/100], Step [790/1751], Loss: 1.4843\n",
      "Epoch [9/100], Step [800/1751], Loss: 1.4365\n",
      "Epoch [9/100], Step [810/1751], Loss: 1.5688\n",
      "Epoch [9/100], Step [820/1751], Loss: 1.5669\n",
      "Epoch [9/100], Step [830/1751], Loss: 1.3193\n",
      "Epoch [9/100], Step [840/1751], Loss: 1.3729\n",
      "Epoch [9/100], Step [850/1751], Loss: 1.4143\n",
      "Epoch [9/100], Step [860/1751], Loss: 1.5092\n",
      "Epoch [9/100], Step [870/1751], Loss: 1.4096\n",
      "Epoch [9/100], Step [880/1751], Loss: 1.1888\n",
      "Epoch [9/100], Step [890/1751], Loss: 1.3691\n",
      "Epoch [9/100], Step [900/1751], Loss: 1.2609\n",
      "Epoch [9/100], Step [910/1751], Loss: 1.5680\n",
      "Epoch [9/100], Step [920/1751], Loss: 1.4149\n",
      "Epoch [9/100], Step [930/1751], Loss: 1.3515\n",
      "Epoch [9/100], Step [940/1751], Loss: 1.4984\n",
      "Epoch [9/100], Step [950/1751], Loss: 1.4108\n",
      "Epoch [9/100], Step [960/1751], Loss: 1.4440\n",
      "Epoch [9/100], Step [970/1751], Loss: 1.5358\n",
      "Epoch [9/100], Step [980/1751], Loss: 1.5447\n",
      "Epoch [9/100], Step [990/1751], Loss: 1.3805\n",
      "Epoch [9/100], Step [1000/1751], Loss: 1.4536\n",
      "Epoch [9/100], Step [1010/1751], Loss: 1.4749\n",
      "Epoch [9/100], Step [1020/1751], Loss: 1.4704\n",
      "Epoch [9/100], Step [1030/1751], Loss: 1.4700\n",
      "Epoch [9/100], Step [1040/1751], Loss: 1.4929\n",
      "Epoch [9/100], Step [1050/1751], Loss: 1.4612\n",
      "Epoch [9/100], Step [1060/1751], Loss: 1.3249\n",
      "Epoch [9/100], Step [1070/1751], Loss: 1.3809\n",
      "Epoch [9/100], Step [1080/1751], Loss: 1.5427\n",
      "Epoch [9/100], Step [1090/1751], Loss: 1.3576\n",
      "Epoch [9/100], Step [1100/1751], Loss: 1.4693\n",
      "Epoch [9/100], Step [1110/1751], Loss: 1.4977\n",
      "Epoch [9/100], Step [1120/1751], Loss: 1.5004\n",
      "Epoch [9/100], Step [1130/1751], Loss: 1.5303\n",
      "Epoch [9/100], Step [1140/1751], Loss: 1.3922\n",
      "Epoch [9/100], Step [1150/1751], Loss: 1.3228\n",
      "Epoch [9/100], Step [1160/1751], Loss: 1.5026\n",
      "Epoch [9/100], Step [1170/1751], Loss: 1.3945\n",
      "Epoch [9/100], Step [1180/1751], Loss: 1.4658\n",
      "Epoch [9/100], Step [1190/1751], Loss: 1.4113\n",
      "Epoch [9/100], Step [1200/1751], Loss: 1.5212\n",
      "Epoch [9/100], Step [1210/1751], Loss: 1.5150\n",
      "Epoch [9/100], Step [1220/1751], Loss: 1.3910\n",
      "Epoch [9/100], Step [1230/1751], Loss: 1.4551\n",
      "Epoch [9/100], Step [1240/1751], Loss: 1.4598\n",
      "Epoch [9/100], Step [1250/1751], Loss: 1.4433\n",
      "Epoch [9/100], Step [1260/1751], Loss: 1.3346\n",
      "Epoch [9/100], Step [1270/1751], Loss: 1.2986\n",
      "Epoch [9/100], Step [1280/1751], Loss: 1.4453\n",
      "Epoch [9/100], Step [1290/1751], Loss: 1.4813\n",
      "Epoch [9/100], Step [1300/1751], Loss: 1.3849\n",
      "Epoch [9/100], Step [1310/1751], Loss: 1.3871\n",
      "Epoch [9/100], Step [1320/1751], Loss: 1.3805\n",
      "Epoch [9/100], Step [1330/1751], Loss: 1.3724\n",
      "Epoch [9/100], Step [1340/1751], Loss: 1.4638\n",
      "Epoch [9/100], Step [1350/1751], Loss: 1.4776\n",
      "Epoch [9/100], Step [1360/1751], Loss: 1.4574\n",
      "Epoch [9/100], Step [1370/1751], Loss: 1.5512\n",
      "Epoch [9/100], Step [1380/1751], Loss: 1.4015\n",
      "Epoch [9/100], Step [1390/1751], Loss: 1.4235\n",
      "Epoch [9/100], Step [1400/1751], Loss: 1.3757\n",
      "Epoch [9/100], Step [1410/1751], Loss: 1.3848\n",
      "Epoch [9/100], Step [1420/1751], Loss: 1.3034\n",
      "Epoch [9/100], Step [1430/1751], Loss: 1.3263\n",
      "Epoch [9/100], Step [1440/1751], Loss: 1.4850\n",
      "Epoch [9/100], Step [1450/1751], Loss: 1.5112\n",
      "Epoch [9/100], Step [1460/1751], Loss: 1.4604\n",
      "Epoch [9/100], Step [1470/1751], Loss: 1.3120\n",
      "Epoch [9/100], Step [1480/1751], Loss: 1.3742\n",
      "Epoch [9/100], Step [1490/1751], Loss: 1.4305\n",
      "Epoch [9/100], Step [1500/1751], Loss: 1.4641\n",
      "Epoch [9/100], Step [1510/1751], Loss: 1.4692\n",
      "Epoch [9/100], Step [1520/1751], Loss: 1.3902\n",
      "Epoch [9/100], Step [1530/1751], Loss: 1.5070\n",
      "Epoch [9/100], Step [1540/1751], Loss: 1.3396\n",
      "Epoch [9/100], Step [1550/1751], Loss: 1.4493\n",
      "Epoch [9/100], Step [1560/1751], Loss: 1.4247\n",
      "Epoch [9/100], Step [1570/1751], Loss: 1.5438\n",
      "Epoch [9/100], Step [1580/1751], Loss: 1.1680\n",
      "Epoch [9/100], Step [1590/1751], Loss: 1.4388\n",
      "Epoch [9/100], Step [1600/1751], Loss: 1.3815\n",
      "Epoch [9/100], Step [1610/1751], Loss: 1.5879\n",
      "Epoch [9/100], Step [1620/1751], Loss: 1.2843\n",
      "Epoch [9/100], Step [1630/1751], Loss: 1.5033\n",
      "Epoch [9/100], Step [1640/1751], Loss: 1.4961\n",
      "Epoch [9/100], Step [1650/1751], Loss: 1.3748\n",
      "Epoch [9/100], Step [1660/1751], Loss: 1.4300\n",
      "Epoch [9/100], Step [1670/1751], Loss: 1.4451\n",
      "Epoch [9/100], Step [1680/1751], Loss: 1.3741\n",
      "Epoch [9/100], Step [1690/1751], Loss: 1.3667\n",
      "Epoch [9/100], Step [1700/1751], Loss: 1.2405\n",
      "Epoch [9/100], Step [1710/1751], Loss: 1.0990\n",
      "Epoch [9/100], Step [1720/1751], Loss: 1.3338\n",
      "Epoch [9/100], Step [1730/1751], Loss: 1.4476\n",
      "Epoch [9/100], Step [1740/1751], Loss: 1.3893\n",
      "Epoch [9/100], Step [1750/1751], Loss: 1.3588\n",
      "Epoch [9/100], Average Loss: 1.4472, Time: 1637.0982s\n",
      "Epoch [10/100], Step [10/1751], Loss: 1.3444\n",
      "Epoch [10/100], Step [20/1751], Loss: 1.4622\n",
      "Epoch [10/100], Step [30/1751], Loss: 1.3453\n",
      "Epoch [10/100], Step [40/1751], Loss: 1.3928\n",
      "Epoch [10/100], Step [50/1751], Loss: 1.5050\n",
      "Epoch [10/100], Step [60/1751], Loss: 1.4519\n",
      "Epoch [10/100], Step [70/1751], Loss: 1.5477\n",
      "Epoch [10/100], Step [80/1751], Loss: 1.3304\n",
      "Epoch [10/100], Step [90/1751], Loss: 1.4578\n",
      "Epoch [10/100], Step [100/1751], Loss: 1.4680\n",
      "Epoch [10/100], Step [110/1751], Loss: 1.3243\n",
      "Epoch [10/100], Step [120/1751], Loss: 1.4325\n",
      "Epoch [10/100], Step [130/1751], Loss: 1.4209\n",
      "Epoch [10/100], Step [140/1751], Loss: 1.4348\n",
      "Epoch [10/100], Step [150/1751], Loss: 1.6259\n",
      "Epoch [10/100], Step [160/1751], Loss: 1.5919\n",
      "Epoch [10/100], Step [170/1751], Loss: 1.4616\n",
      "Epoch [10/100], Step [180/1751], Loss: 1.3525\n",
      "Epoch [10/100], Step [190/1751], Loss: 1.3797\n",
      "Epoch [10/100], Step [200/1751], Loss: 1.4196\n",
      "Epoch [10/100], Step [210/1751], Loss: 1.6118\n",
      "Epoch [10/100], Step [220/1751], Loss: 1.4492\n",
      "Epoch [10/100], Step [230/1751], Loss: 1.2517\n",
      "Epoch [10/100], Step [240/1751], Loss: 1.4400\n",
      "Epoch [10/100], Step [250/1751], Loss: 1.5652\n",
      "Epoch [10/100], Step [260/1751], Loss: 1.3415\n",
      "Epoch [10/100], Step [270/1751], Loss: 1.4207\n",
      "Epoch [10/100], Step [280/1751], Loss: 1.5666\n",
      "Epoch [10/100], Step [290/1751], Loss: 1.5012\n",
      "Epoch [10/100], Step [300/1751], Loss: 1.4540\n",
      "Epoch [10/100], Step [310/1751], Loss: 1.2816\n",
      "Epoch [10/100], Step [320/1751], Loss: 1.4369\n",
      "Epoch [10/100], Step [330/1751], Loss: 1.3136\n",
      "Epoch [10/100], Step [340/1751], Loss: 1.4358\n",
      "Epoch [10/100], Step [350/1751], Loss: 1.3958\n",
      "Epoch [10/100], Step [360/1751], Loss: 1.4644\n",
      "Epoch [10/100], Step [370/1751], Loss: 1.3917\n",
      "Epoch [10/100], Step [380/1751], Loss: 1.3945\n",
      "Epoch [10/100], Step [390/1751], Loss: 1.4688\n",
      "Epoch [10/100], Step [400/1751], Loss: 1.5663\n",
      "Epoch [10/100], Step [410/1751], Loss: 1.4622\n",
      "Epoch [10/100], Step [420/1751], Loss: 1.3767\n",
      "Epoch [10/100], Step [430/1751], Loss: 1.4129\n",
      "Epoch [10/100], Step [440/1751], Loss: 1.4194\n",
      "Epoch [10/100], Step [450/1751], Loss: 1.2903\n",
      "Epoch [10/100], Step [460/1751], Loss: 1.4509\n",
      "Epoch [10/100], Step [470/1751], Loss: 1.5581\n",
      "Epoch [10/100], Step [480/1751], Loss: 1.2899\n",
      "Epoch [10/100], Step [490/1751], Loss: 1.3835\n",
      "Epoch [10/100], Step [500/1751], Loss: 1.3705\n",
      "Epoch [10/100], Step [510/1751], Loss: 1.4494\n",
      "Epoch [10/100], Step [520/1751], Loss: 1.3624\n",
      "Epoch [10/100], Step [530/1751], Loss: 1.3918\n",
      "Epoch [10/100], Step [540/1751], Loss: 1.3282\n",
      "Epoch [10/100], Step [550/1751], Loss: 1.4068\n",
      "Epoch [10/100], Step [560/1751], Loss: 1.4345\n",
      "Epoch [10/100], Step [570/1751], Loss: 1.3226\n",
      "Epoch [10/100], Step [580/1751], Loss: 1.5080\n",
      "Epoch [10/100], Step [590/1751], Loss: 1.5255\n",
      "Epoch [10/100], Step [600/1751], Loss: 1.4798\n",
      "Epoch [10/100], Step [610/1751], Loss: 1.3869\n",
      "Epoch [10/100], Step [620/1751], Loss: 1.4488\n",
      "Epoch [10/100], Step [630/1751], Loss: 1.4720\n",
      "Epoch [10/100], Step [640/1751], Loss: 1.5067\n",
      "Epoch [10/100], Step [650/1751], Loss: 1.3857\n",
      "Epoch [10/100], Step [660/1751], Loss: 1.4570\n",
      "Epoch [10/100], Step [670/1751], Loss: 1.3455\n",
      "Epoch [10/100], Step [680/1751], Loss: 1.3636\n",
      "Epoch [10/100], Step [690/1751], Loss: 1.4158\n",
      "Epoch [10/100], Step [700/1751], Loss: 1.4813\n",
      "Epoch [10/100], Step [710/1751], Loss: 1.4189\n",
      "Epoch [10/100], Step [720/1751], Loss: 1.2860\n",
      "Epoch [10/100], Step [730/1751], Loss: 1.3767\n",
      "Epoch [10/100], Step [740/1751], Loss: 1.5800\n",
      "Epoch [10/100], Step [750/1751], Loss: 1.4335\n",
      "Epoch [10/100], Step [760/1751], Loss: 1.5494\n",
      "Epoch [10/100], Step [770/1751], Loss: 1.4140\n",
      "Epoch [10/100], Step [780/1751], Loss: 1.3131\n",
      "Epoch [10/100], Step [790/1751], Loss: 1.4240\n",
      "Epoch [10/100], Step [800/1751], Loss: 1.3578\n",
      "Epoch [10/100], Step [810/1751], Loss: 1.4059\n",
      "Epoch [10/100], Step [820/1751], Loss: 1.5178\n",
      "Epoch [10/100], Step [830/1751], Loss: 1.4397\n",
      "Epoch [10/100], Step [840/1751], Loss: 1.4755\n",
      "Epoch [10/100], Step [850/1751], Loss: 1.5512\n",
      "Epoch [10/100], Step [860/1751], Loss: 1.2620\n",
      "Epoch [10/100], Step [870/1751], Loss: 1.4129\n",
      "Epoch [10/100], Step [880/1751], Loss: 1.3580\n",
      "Epoch [10/100], Step [890/1751], Loss: 1.5214\n",
      "Epoch [10/100], Step [900/1751], Loss: 1.3956\n",
      "Epoch [10/100], Step [910/1751], Loss: 1.3547\n",
      "Epoch [10/100], Step [920/1751], Loss: 1.4717\n",
      "Epoch [10/100], Step [930/1751], Loss: 1.4744\n",
      "Epoch [10/100], Step [940/1751], Loss: 1.3634\n",
      "Epoch [10/100], Step [950/1751], Loss: 1.3490\n",
      "Epoch [10/100], Step [960/1751], Loss: 1.4803\n",
      "Epoch [10/100], Step [970/1751], Loss: 1.5183\n",
      "Epoch [10/100], Step [980/1751], Loss: 1.4177\n",
      "Epoch [10/100], Step [990/1751], Loss: 1.3642\n",
      "Epoch [10/100], Step [1000/1751], Loss: 1.5320\n",
      "Epoch [10/100], Step [1010/1751], Loss: 1.4758\n",
      "Epoch [10/100], Step [1020/1751], Loss: 1.3346\n",
      "Epoch [10/100], Step [1030/1751], Loss: 1.4414\n",
      "Epoch [10/100], Step [1040/1751], Loss: 1.4686\n",
      "Epoch [10/100], Step [1050/1751], Loss: 1.4006\n",
      "Epoch [10/100], Step [1060/1751], Loss: 1.5283\n",
      "Epoch [10/100], Step [1070/1751], Loss: 1.4213\n",
      "Epoch [10/100], Step [1080/1751], Loss: 1.4011\n",
      "Epoch [10/100], Step [1090/1751], Loss: 1.3308\n",
      "Epoch [10/100], Step [1100/1751], Loss: 1.4888\n",
      "Epoch [10/100], Step [1110/1751], Loss: 1.3803\n",
      "Epoch [10/100], Step [1120/1751], Loss: 1.4611\n",
      "Epoch [10/100], Step [1130/1751], Loss: 1.3291\n",
      "Epoch [10/100], Step [1140/1751], Loss: 1.3475\n",
      "Epoch [10/100], Step [1150/1751], Loss: 1.3288\n",
      "Epoch [10/100], Step [1160/1751], Loss: 1.5028\n",
      "Epoch [10/100], Step [1170/1751], Loss: 1.5500\n",
      "Epoch [10/100], Step [1180/1751], Loss: 1.4665\n",
      "Epoch [10/100], Step [1190/1751], Loss: 1.4490\n",
      "Epoch [10/100], Step [1200/1751], Loss: 1.5170\n",
      "Epoch [10/100], Step [1210/1751], Loss: 1.3954\n",
      "Epoch [10/100], Step [1220/1751], Loss: 1.4088\n",
      "Epoch [10/100], Step [1230/1751], Loss: 1.2422\n",
      "Epoch [10/100], Step [1240/1751], Loss: 1.4771\n",
      "Epoch [10/100], Step [1250/1751], Loss: 1.2625\n",
      "Epoch [10/100], Step [1260/1751], Loss: 1.3969\n",
      "Epoch [10/100], Step [1270/1751], Loss: 1.5299\n",
      "Epoch [10/100], Step [1280/1751], Loss: 1.4324\n",
      "Epoch [10/100], Step [1290/1751], Loss: 1.4266\n",
      "Epoch [10/100], Step [1300/1751], Loss: 1.4194\n",
      "Epoch [10/100], Step [1310/1751], Loss: 1.3071\n",
      "Epoch [10/100], Step [1320/1751], Loss: 1.3229\n",
      "Epoch [10/100], Step [1330/1751], Loss: 1.3838\n",
      "Epoch [10/100], Step [1340/1751], Loss: 1.2769\n",
      "Epoch [10/100], Step [1350/1751], Loss: 1.4096\n",
      "Epoch [10/100], Step [1360/1751], Loss: 1.4496\n",
      "Epoch [10/100], Step [1370/1751], Loss: 1.3096\n",
      "Epoch [10/100], Step [1380/1751], Loss: 1.3440\n",
      "Epoch [10/100], Step [1390/1751], Loss: 1.4681\n",
      "Epoch [10/100], Step [1400/1751], Loss: 1.5578\n",
      "Epoch [10/100], Step [1410/1751], Loss: 1.4359\n",
      "Epoch [10/100], Step [1420/1751], Loss: 1.4731\n",
      "Epoch [10/100], Step [1430/1751], Loss: 1.6259\n",
      "Epoch [10/100], Step [1440/1751], Loss: 1.2442\n",
      "Epoch [10/100], Step [1450/1751], Loss: 1.4610\n",
      "Epoch [10/100], Step [1460/1751], Loss: 1.6172\n",
      "Epoch [10/100], Step [1470/1751], Loss: 1.4316\n",
      "Epoch [10/100], Step [1480/1751], Loss: 1.4541\n",
      "Epoch [10/100], Step [1490/1751], Loss: 1.5166\n",
      "Epoch [10/100], Step [1500/1751], Loss: 1.3944\n",
      "Epoch [10/100], Step [1510/1751], Loss: 1.3256\n",
      "Epoch [10/100], Step [1520/1751], Loss: 1.3394\n",
      "Epoch [10/100], Step [1530/1751], Loss: 1.3967\n",
      "Epoch [10/100], Step [1540/1751], Loss: 1.4903\n",
      "Epoch [10/100], Step [1550/1751], Loss: 1.3967\n",
      "Epoch [10/100], Step [1560/1751], Loss: 1.3517\n",
      "Epoch [10/100], Step [1570/1751], Loss: 1.3918\n",
      "Epoch [10/100], Step [1580/1751], Loss: 1.3411\n",
      "Epoch [10/100], Step [1590/1751], Loss: 1.4947\n",
      "Epoch [10/100], Step [1600/1751], Loss: 1.5144\n",
      "Epoch [10/100], Step [1610/1751], Loss: 1.3814\n",
      "Epoch [10/100], Step [1620/1751], Loss: 1.3837\n",
      "Epoch [10/100], Step [1630/1751], Loss: 1.4306\n",
      "Epoch [10/100], Step [1640/1751], Loss: 1.3114\n",
      "Epoch [10/100], Step [1650/1751], Loss: 1.4425\n",
      "Epoch [10/100], Step [1660/1751], Loss: 1.2830\n",
      "Epoch [10/100], Step [1670/1751], Loss: 1.4480\n",
      "Epoch [10/100], Step [1680/1751], Loss: 1.5044\n",
      "Epoch [10/100], Step [1690/1751], Loss: 1.3941\n",
      "Epoch [10/100], Step [1700/1751], Loss: 1.4635\n",
      "Epoch [10/100], Step [1710/1751], Loss: 1.4502\n",
      "Epoch [10/100], Step [1720/1751], Loss: 1.3731\n",
      "Epoch [10/100], Step [1730/1751], Loss: 1.2586\n",
      "Epoch [10/100], Step [1740/1751], Loss: 1.4712\n",
      "Epoch [10/100], Step [1750/1751], Loss: 1.2788\n",
      "Epoch [10/100], Average Loss: 1.4154, Time: 1637.3393s\n",
      "Epoch [11/100], Step [10/1751], Loss: 1.5122\n",
      "Epoch [11/100], Step [20/1751], Loss: 1.4012\n",
      "Epoch [11/100], Step [30/1751], Loss: 1.4337\n",
      "Epoch [11/100], Step [40/1751], Loss: 1.2615\n",
      "Epoch [11/100], Step [50/1751], Loss: 1.2994\n",
      "Epoch [11/100], Step [60/1751], Loss: 1.4763\n",
      "Epoch [11/100], Step [70/1751], Loss: 1.4042\n",
      "Epoch [11/100], Step [80/1751], Loss: 1.5063\n",
      "Epoch [11/100], Step [90/1751], Loss: 1.4098\n",
      "Epoch [11/100], Step [100/1751], Loss: 1.4907\n",
      "Epoch [11/100], Step [110/1751], Loss: 1.4515\n",
      "Epoch [11/100], Step [120/1751], Loss: 1.3889\n",
      "Epoch [11/100], Step [130/1751], Loss: 1.3654\n",
      "Epoch [11/100], Step [140/1751], Loss: 1.3075\n",
      "Epoch [11/100], Step [150/1751], Loss: 1.3166\n",
      "Epoch [11/100], Step [160/1751], Loss: 1.2540\n",
      "Epoch [11/100], Step [170/1751], Loss: 1.4211\n",
      "Epoch [11/100], Step [180/1751], Loss: 1.3681\n",
      "Epoch [11/100], Step [190/1751], Loss: 1.3558\n",
      "Epoch [11/100], Step [200/1751], Loss: 1.4607\n",
      "Epoch [11/100], Step [210/1751], Loss: 1.4226\n",
      "Epoch [11/100], Step [220/1751], Loss: 1.3748\n",
      "Epoch [11/100], Step [230/1751], Loss: 1.3014\n",
      "Epoch [11/100], Step [240/1751], Loss: 1.3494\n",
      "Epoch [11/100], Step [250/1751], Loss: 1.2461\n",
      "Epoch [11/100], Step [260/1751], Loss: 1.4403\n",
      "Epoch [11/100], Step [270/1751], Loss: 1.3413\n",
      "Epoch [11/100], Step [280/1751], Loss: 1.3986\n",
      "Epoch [11/100], Step [290/1751], Loss: 1.5108\n",
      "Epoch [11/100], Step [300/1751], Loss: 1.5574\n",
      "Epoch [11/100], Step [310/1751], Loss: 1.6069\n",
      "Epoch [11/100], Step [320/1751], Loss: 1.3337\n",
      "Epoch [11/100], Step [330/1751], Loss: 1.3115\n",
      "Epoch [11/100], Step [340/1751], Loss: 1.4460\n",
      "Epoch [11/100], Step [350/1751], Loss: 1.3789\n",
      "Epoch [11/100], Step [360/1751], Loss: 1.6039\n",
      "Epoch [11/100], Step [370/1751], Loss: 1.4639\n",
      "Epoch [11/100], Step [380/1751], Loss: 1.4604\n",
      "Epoch [11/100], Step [390/1751], Loss: 1.3677\n",
      "Epoch [11/100], Step [400/1751], Loss: 1.3907\n",
      "Epoch [11/100], Step [410/1751], Loss: 1.2379\n",
      "Epoch [11/100], Step [420/1751], Loss: 1.4612\n",
      "Epoch [11/100], Step [430/1751], Loss: 1.3559\n",
      "Epoch [11/100], Step [440/1751], Loss: 1.4845\n",
      "Epoch [11/100], Step [450/1751], Loss: 1.2699\n",
      "Epoch [11/100], Step [460/1751], Loss: 1.3296\n",
      "Epoch [11/100], Step [470/1751], Loss: 1.4375\n",
      "Epoch [11/100], Step [480/1751], Loss: 1.5066\n",
      "Epoch [11/100], Step [490/1751], Loss: 1.3065\n",
      "Epoch [11/100], Step [500/1751], Loss: 1.4872\n",
      "Epoch [11/100], Step [510/1751], Loss: 1.4318\n",
      "Epoch [11/100], Step [520/1751], Loss: 1.3868\n",
      "Epoch [11/100], Step [530/1751], Loss: 1.3701\n",
      "Epoch [11/100], Step [540/1751], Loss: 1.3886\n",
      "Epoch [11/100], Step [550/1751], Loss: 1.3899\n",
      "Epoch [11/100], Step [560/1751], Loss: 1.4047\n",
      "Epoch [11/100], Step [570/1751], Loss: 1.2867\n",
      "Epoch [11/100], Step [580/1751], Loss: 1.4005\n",
      "Epoch [11/100], Step [590/1751], Loss: 1.3670\n",
      "Epoch [11/100], Step [600/1751], Loss: 1.4443\n",
      "Epoch [11/100], Step [610/1751], Loss: 1.4865\n",
      "Epoch [11/100], Step [620/1751], Loss: 1.4937\n",
      "Epoch [11/100], Step [630/1751], Loss: 1.3611\n",
      "Epoch [11/100], Step [640/1751], Loss: 1.3486\n",
      "Epoch [11/100], Step [650/1751], Loss: 1.5017\n",
      "Epoch [11/100], Step [660/1751], Loss: 1.4672\n",
      "Epoch [11/100], Step [670/1751], Loss: 1.5170\n",
      "Epoch [11/100], Step [680/1751], Loss: 1.3101\n",
      "Epoch [11/100], Step [690/1751], Loss: 1.3700\n",
      "Epoch [11/100], Step [700/1751], Loss: 1.4048\n",
      "Epoch [11/100], Step [710/1751], Loss: 1.3458\n",
      "Epoch [11/100], Step [720/1751], Loss: 1.4831\n",
      "Epoch [11/100], Step [730/1751], Loss: 1.4395\n",
      "Epoch [11/100], Step [740/1751], Loss: 1.4494\n",
      "Epoch [11/100], Step [750/1751], Loss: 1.3823\n",
      "Epoch [11/100], Step [760/1751], Loss: 1.3650\n",
      "Epoch [11/100], Step [770/1751], Loss: 1.4291\n",
      "Epoch [11/100], Step [780/1751], Loss: 1.3922\n",
      "Epoch [11/100], Step [790/1751], Loss: 1.1939\n",
      "Epoch [11/100], Step [800/1751], Loss: 1.4601\n",
      "Epoch [11/100], Step [810/1751], Loss: 1.4830\n",
      "Epoch [11/100], Step [820/1751], Loss: 1.4311\n",
      "Epoch [11/100], Step [830/1751], Loss: 1.3050\n",
      "Epoch [11/100], Step [840/1751], Loss: 1.2326\n",
      "Epoch [11/100], Step [850/1751], Loss: 1.5623\n",
      "Epoch [11/100], Step [860/1751], Loss: 1.3475\n",
      "Epoch [11/100], Step [870/1751], Loss: 1.2972\n",
      "Epoch [11/100], Step [880/1751], Loss: 1.4264\n",
      "Epoch [11/100], Step [890/1751], Loss: 1.3838\n",
      "Epoch [11/100], Step [900/1751], Loss: 1.3717\n",
      "Epoch [11/100], Step [910/1751], Loss: 1.4276\n",
      "Epoch [11/100], Step [920/1751], Loss: 1.4102\n",
      "Epoch [11/100], Step [930/1751], Loss: 1.2270\n",
      "Epoch [11/100], Step [940/1751], Loss: 1.4346\n",
      "Epoch [11/100], Step [950/1751], Loss: 1.2646\n",
      "Epoch [11/100], Step [960/1751], Loss: 1.2769\n",
      "Epoch [11/100], Step [970/1751], Loss: 1.2462\n",
      "Epoch [11/100], Step [980/1751], Loss: 1.4751\n",
      "Epoch [11/100], Step [990/1751], Loss: 1.3449\n",
      "Epoch [11/100], Step [1000/1751], Loss: 1.4450\n",
      "Epoch [11/100], Step [1010/1751], Loss: 1.2224\n",
      "Epoch [11/100], Step [1020/1751], Loss: 1.4081\n",
      "Epoch [11/100], Step [1030/1751], Loss: 1.3396\n",
      "Epoch [11/100], Step [1040/1751], Loss: 1.4586\n",
      "Epoch [11/100], Step [1050/1751], Loss: 1.2764\n",
      "Epoch [11/100], Step [1060/1751], Loss: 1.5755\n",
      "Epoch [11/100], Step [1070/1751], Loss: 1.3267\n",
      "Epoch [11/100], Step [1080/1751], Loss: 1.3034\n",
      "Epoch [11/100], Step [1090/1751], Loss: 1.4896\n",
      "Epoch [11/100], Step [1100/1751], Loss: 1.4422\n",
      "Epoch [11/100], Step [1110/1751], Loss: 1.2104\n",
      "Epoch [11/100], Step [1120/1751], Loss: 1.3045\n",
      "Epoch [11/100], Step [1130/1751], Loss: 1.3573\n",
      "Epoch [11/100], Step [1140/1751], Loss: 1.2967\n",
      "Epoch [11/100], Step [1150/1751], Loss: 1.5536\n",
      "Epoch [11/100], Step [1160/1751], Loss: 1.5306\n",
      "Epoch [11/100], Step [1170/1751], Loss: 1.3993\n",
      "Epoch [11/100], Step [1180/1751], Loss: 1.4086\n",
      "Epoch [11/100], Step [1190/1751], Loss: 1.2253\n",
      "Epoch [11/100], Step [1200/1751], Loss: 1.3277\n",
      "Epoch [11/100], Step [1210/1751], Loss: 1.2675\n",
      "Epoch [11/100], Step [1220/1751], Loss: 1.4502\n",
      "Epoch [11/100], Step [1230/1751], Loss: 1.5054\n",
      "Epoch [11/100], Step [1240/1751], Loss: 1.2667\n",
      "Epoch [11/100], Step [1250/1751], Loss: 1.5064\n",
      "Epoch [11/100], Step [1260/1751], Loss: 1.3988\n",
      "Epoch [11/100], Step [1270/1751], Loss: 1.4883\n",
      "Epoch [11/100], Step [1280/1751], Loss: 1.4243\n",
      "Epoch [11/100], Step [1290/1751], Loss: 1.3408\n",
      "Epoch [11/100], Step [1300/1751], Loss: 1.2947\n",
      "Epoch [11/100], Step [1310/1751], Loss: 1.3400\n",
      "Epoch [11/100], Step [1320/1751], Loss: 1.4443\n",
      "Epoch [11/100], Step [1330/1751], Loss: 1.3735\n",
      "Epoch [11/100], Step [1340/1751], Loss: 1.4184\n",
      "Epoch [11/100], Step [1350/1751], Loss: 1.3625\n",
      "Epoch [11/100], Step [1360/1751], Loss: 1.4420\n",
      "Epoch [11/100], Step [1370/1751], Loss: 1.3267\n",
      "Epoch [11/100], Step [1380/1751], Loss: 1.2940\n",
      "Epoch [11/100], Step [1390/1751], Loss: 1.2970\n",
      "Epoch [11/100], Step [1400/1751], Loss: 1.2618\n",
      "Epoch [11/100], Step [1410/1751], Loss: 1.4485\n",
      "Epoch [11/100], Step [1420/1751], Loss: 1.4516\n",
      "Epoch [11/100], Step [1430/1751], Loss: 1.3839\n",
      "Epoch [11/100], Step [1440/1751], Loss: 1.5165\n",
      "Epoch [11/100], Step [1450/1751], Loss: 1.4691\n",
      "Epoch [11/100], Step [1460/1751], Loss: 1.3482\n",
      "Epoch [11/100], Step [1470/1751], Loss: 1.2968\n",
      "Epoch [11/100], Step [1480/1751], Loss: 1.4738\n",
      "Epoch [11/100], Step [1490/1751], Loss: 1.3743\n",
      "Epoch [11/100], Step [1500/1751], Loss: 1.3108\n",
      "Epoch [11/100], Step [1510/1751], Loss: 1.2096\n",
      "Epoch [11/100], Step [1520/1751], Loss: 1.5106\n",
      "Epoch [11/100], Step [1530/1751], Loss: 1.3215\n",
      "Epoch [11/100], Step [1540/1751], Loss: 1.2539\n",
      "Epoch [11/100], Step [1550/1751], Loss: 1.3429\n",
      "Epoch [11/100], Step [1560/1751], Loss: 1.4181\n",
      "Epoch [11/100], Step [1570/1751], Loss: 1.3503\n",
      "Epoch [11/100], Step [1580/1751], Loss: 1.3158\n",
      "Epoch [11/100], Step [1590/1751], Loss: 1.5331\n",
      "Epoch [11/100], Step [1600/1751], Loss: 1.3889\n",
      "Epoch [11/100], Step [1610/1751], Loss: 1.4476\n",
      "Epoch [11/100], Step [1620/1751], Loss: 1.2643\n",
      "Epoch [11/100], Step [1630/1751], Loss: 1.3300\n",
      "Epoch [11/100], Step [1640/1751], Loss: 1.4324\n",
      "Epoch [11/100], Step [1650/1751], Loss: 1.4060\n",
      "Epoch [11/100], Step [1660/1751], Loss: 1.3302\n",
      "Epoch [11/100], Step [1670/1751], Loss: 1.2437\n",
      "Epoch [11/100], Step [1680/1751], Loss: 1.2771\n",
      "Epoch [11/100], Step [1690/1751], Loss: 1.2347\n",
      "Epoch [11/100], Step [1700/1751], Loss: 1.2072\n",
      "Epoch [11/100], Step [1710/1751], Loss: 1.3523\n",
      "Epoch [11/100], Step [1720/1751], Loss: 1.3854\n",
      "Epoch [11/100], Step [1730/1751], Loss: 1.4366\n",
      "Epoch [11/100], Step [1740/1751], Loss: 1.3090\n",
      "Epoch [11/100], Step [1750/1751], Loss: 1.4588\n",
      "Epoch [11/100], Average Loss: 1.3886, Time: 1636.5108s\n",
      "Epoch [12/100], Step [10/1751], Loss: 1.4884\n",
      "Epoch [12/100], Step [20/1751], Loss: 1.4206\n",
      "Epoch [12/100], Step [30/1751], Loss: 1.4742\n",
      "Epoch [12/100], Step [40/1751], Loss: 1.5389\n",
      "Epoch [12/100], Step [50/1751], Loss: 1.4447\n",
      "Epoch [12/100], Step [60/1751], Loss: 1.2690\n",
      "Epoch [12/100], Step [70/1751], Loss: 1.2906\n",
      "Epoch [12/100], Step [80/1751], Loss: 1.4483\n",
      "Epoch [12/100], Step [90/1751], Loss: 1.4925\n",
      "Epoch [12/100], Step [100/1751], Loss: 1.5305\n",
      "Epoch [12/100], Step [110/1751], Loss: 1.2693\n",
      "Epoch [12/100], Step [120/1751], Loss: 1.5664\n",
      "Epoch [12/100], Step [130/1751], Loss: 1.1521\n",
      "Epoch [12/100], Step [140/1751], Loss: 1.3274\n",
      "Epoch [12/100], Step [150/1751], Loss: 1.3404\n",
      "Epoch [12/100], Step [160/1751], Loss: 1.3135\n",
      "Epoch [12/100], Step [170/1751], Loss: 1.3839\n",
      "Epoch [12/100], Step [180/1751], Loss: 1.3935\n",
      "Epoch [12/100], Step [190/1751], Loss: 1.4318\n",
      "Epoch [12/100], Step [200/1751], Loss: 1.3338\n",
      "Epoch [12/100], Step [210/1751], Loss: 1.4109\n",
      "Epoch [12/100], Step [220/1751], Loss: 1.2319\n",
      "Epoch [12/100], Step [230/1751], Loss: 1.3445\n",
      "Epoch [12/100], Step [240/1751], Loss: 1.3427\n",
      "Epoch [12/100], Step [250/1751], Loss: 1.4804\n",
      "Epoch [12/100], Step [260/1751], Loss: 1.4384\n",
      "Epoch [12/100], Step [270/1751], Loss: 1.3156\n",
      "Epoch [12/100], Step [280/1751], Loss: 1.4875\n",
      "Epoch [12/100], Step [290/1751], Loss: 1.3684\n",
      "Epoch [12/100], Step [300/1751], Loss: 1.2795\n",
      "Epoch [12/100], Step [310/1751], Loss: 1.2088\n",
      "Epoch [12/100], Step [320/1751], Loss: 1.4305\n",
      "Epoch [12/100], Step [330/1751], Loss: 1.4861\n",
      "Epoch [12/100], Step [340/1751], Loss: 1.4052\n",
      "Epoch [12/100], Step [350/1751], Loss: 1.5204\n",
      "Epoch [12/100], Step [360/1751], Loss: 1.4318\n",
      "Epoch [12/100], Step [370/1751], Loss: 1.1785\n",
      "Epoch [12/100], Step [380/1751], Loss: 1.3488\n",
      "Epoch [12/100], Step [390/1751], Loss: 1.3460\n",
      "Epoch [12/100], Step [400/1751], Loss: 1.1832\n",
      "Epoch [12/100], Step [410/1751], Loss: 1.3621\n",
      "Epoch [12/100], Step [420/1751], Loss: 1.2839\n",
      "Epoch [12/100], Step [430/1751], Loss: 1.3048\n",
      "Epoch [12/100], Step [440/1751], Loss: 1.3796\n",
      "Epoch [12/100], Step [450/1751], Loss: 1.2735\n",
      "Epoch [12/100], Step [460/1751], Loss: 1.2885\n",
      "Epoch [12/100], Step [470/1751], Loss: 1.2719\n",
      "Epoch [12/100], Step [480/1751], Loss: 1.3326\n",
      "Epoch [12/100], Step [490/1751], Loss: 1.2924\n",
      "Epoch [12/100], Step [500/1751], Loss: 1.2897\n",
      "Epoch [12/100], Step [510/1751], Loss: 1.3675\n",
      "Epoch [12/100], Step [520/1751], Loss: 1.2915\n",
      "Epoch [12/100], Step [530/1751], Loss: 1.3765\n",
      "Epoch [12/100], Step [540/1751], Loss: 1.2889\n",
      "Epoch [12/100], Step [550/1751], Loss: 1.4367\n",
      "Epoch [12/100], Step [560/1751], Loss: 1.5540\n",
      "Epoch [12/100], Step [570/1751], Loss: 1.3411\n",
      "Epoch [12/100], Step [580/1751], Loss: 1.5523\n",
      "Epoch [12/100], Step [590/1751], Loss: 1.3166\n",
      "Epoch [12/100], Step [600/1751], Loss: 1.4428\n",
      "Epoch [12/100], Step [610/1751], Loss: 1.2582\n",
      "Epoch [12/100], Step [620/1751], Loss: 1.5194\n",
      "Epoch [12/100], Step [630/1751], Loss: 1.4131\n",
      "Epoch [12/100], Step [640/1751], Loss: 1.3450\n",
      "Epoch [12/100], Step [650/1751], Loss: 1.3407\n",
      "Epoch [12/100], Step [660/1751], Loss: 1.4968\n",
      "Epoch [12/100], Step [670/1751], Loss: 1.2730\n",
      "Epoch [12/100], Step [680/1751], Loss: 1.4730\n",
      "Epoch [12/100], Step [690/1751], Loss: 1.3012\n",
      "Epoch [12/100], Step [700/1751], Loss: 1.2354\n",
      "Epoch [12/100], Step [710/1751], Loss: 1.4013\n",
      "Epoch [12/100], Step [720/1751], Loss: 1.2937\n",
      "Epoch [12/100], Step [730/1751], Loss: 1.3867\n",
      "Epoch [12/100], Step [740/1751], Loss: 1.3035\n",
      "Epoch [12/100], Step [750/1751], Loss: 1.2661\n",
      "Epoch [12/100], Step [760/1751], Loss: 1.4254\n",
      "Epoch [12/100], Step [770/1751], Loss: 1.4391\n",
      "Epoch [12/100], Step [780/1751], Loss: 1.3581\n",
      "Epoch [12/100], Step [790/1751], Loss: 1.3363\n",
      "Epoch [12/100], Step [800/1751], Loss: 1.4016\n",
      "Epoch [12/100], Step [810/1751], Loss: 1.4187\n",
      "Epoch [12/100], Step [820/1751], Loss: 1.5716\n",
      "Epoch [12/100], Step [830/1751], Loss: 1.3461\n",
      "Epoch [12/100], Step [840/1751], Loss: 1.2453\n",
      "Epoch [12/100], Step [850/1751], Loss: 1.4062\n",
      "Epoch [12/100], Step [860/1751], Loss: 1.3394\n",
      "Epoch [12/100], Step [870/1751], Loss: 1.3160\n",
      "Epoch [12/100], Step [880/1751], Loss: 1.3865\n",
      "Epoch [12/100], Step [890/1751], Loss: 1.3512\n",
      "Epoch [12/100], Step [900/1751], Loss: 1.2561\n",
      "Epoch [12/100], Step [910/1751], Loss: 1.5201\n",
      "Epoch [12/100], Step [920/1751], Loss: 1.2341\n",
      "Epoch [12/100], Step [930/1751], Loss: 1.3313\n",
      "Epoch [12/100], Step [940/1751], Loss: 1.3049\n",
      "Epoch [12/100], Step [950/1751], Loss: 1.5027\n",
      "Epoch [12/100], Step [960/1751], Loss: 1.4731\n",
      "Epoch [12/100], Step [970/1751], Loss: 1.3804\n",
      "Epoch [12/100], Step [980/1751], Loss: 1.3335\n",
      "Epoch [12/100], Step [990/1751], Loss: 1.2817\n",
      "Epoch [12/100], Step [1000/1751], Loss: 1.3697\n",
      "Epoch [12/100], Step [1010/1751], Loss: 1.4726\n",
      "Epoch [12/100], Step [1020/1751], Loss: 1.3886\n",
      "Epoch [12/100], Step [1030/1751], Loss: 1.3109\n",
      "Epoch [12/100], Step [1040/1751], Loss: 1.3229\n",
      "Epoch [12/100], Step [1050/1751], Loss: 1.3521\n",
      "Epoch [12/100], Step [1060/1751], Loss: 1.4058\n",
      "Epoch [12/100], Step [1070/1751], Loss: 1.3643\n",
      "Epoch [12/100], Step [1080/1751], Loss: 1.2871\n",
      "Epoch [12/100], Step [1090/1751], Loss: 1.4415\n",
      "Epoch [12/100], Step [1100/1751], Loss: 1.4601\n",
      "Epoch [12/100], Step [1110/1751], Loss: 1.2898\n",
      "Epoch [12/100], Step [1120/1751], Loss: 1.2620\n",
      "Epoch [12/100], Step [1130/1751], Loss: 1.5141\n",
      "Epoch [12/100], Step [1140/1751], Loss: 1.3692\n",
      "Epoch [12/100], Step [1150/1751], Loss: 1.3339\n",
      "Epoch [12/100], Step [1160/1751], Loss: 1.4167\n",
      "Epoch [12/100], Step [1170/1751], Loss: 1.3570\n",
      "Epoch [12/100], Step [1180/1751], Loss: 1.4176\n",
      "Epoch [12/100], Step [1190/1751], Loss: 1.4016\n",
      "Epoch [12/100], Step [1200/1751], Loss: 1.3486\n",
      "Epoch [12/100], Step [1210/1751], Loss: 1.3349\n",
      "Epoch [12/100], Step [1220/1751], Loss: 1.3742\n",
      "Epoch [12/100], Step [1230/1751], Loss: 1.3026\n",
      "Epoch [12/100], Step [1240/1751], Loss: 1.2923\n",
      "Epoch [12/100], Step [1250/1751], Loss: 1.2666\n",
      "Epoch [12/100], Step [1260/1751], Loss: 1.3503\n",
      "Epoch [12/100], Step [1270/1751], Loss: 1.3521\n",
      "Epoch [12/100], Step [1280/1751], Loss: 1.2425\n",
      "Epoch [12/100], Step [1290/1751], Loss: 1.2751\n",
      "Epoch [12/100], Step [1300/1751], Loss: 1.4433\n",
      "Epoch [12/100], Step [1310/1751], Loss: 1.3608\n",
      "Epoch [12/100], Step [1320/1751], Loss: 1.2445\n",
      "Epoch [12/100], Step [1330/1751], Loss: 1.4099\n",
      "Epoch [12/100], Step [1340/1751], Loss: 1.2056\n",
      "Epoch [12/100], Step [1350/1751], Loss: 1.5065\n",
      "Epoch [12/100], Step [1360/1751], Loss: 1.2736\n",
      "Epoch [12/100], Step [1370/1751], Loss: 1.4844\n",
      "Epoch [12/100], Step [1380/1751], Loss: 1.2776\n",
      "Epoch [12/100], Step [1390/1751], Loss: 1.2760\n",
      "Epoch [12/100], Step [1400/1751], Loss: 1.4020\n",
      "Epoch [12/100], Step [1410/1751], Loss: 1.2805\n",
      "Epoch [12/100], Step [1420/1751], Loss: 1.2340\n",
      "Epoch [12/100], Step [1430/1751], Loss: 1.3076\n",
      "Epoch [12/100], Step [1440/1751], Loss: 1.1981\n",
      "Epoch [12/100], Step [1450/1751], Loss: 1.3813\n",
      "Epoch [12/100], Step [1460/1751], Loss: 1.4104\n",
      "Epoch [12/100], Step [1470/1751], Loss: 1.1875\n",
      "Epoch [12/100], Step [1480/1751], Loss: 1.4083\n",
      "Epoch [12/100], Step [1490/1751], Loss: 1.3387\n",
      "Epoch [12/100], Step [1500/1751], Loss: 1.4114\n",
      "Epoch [12/100], Step [1510/1751], Loss: 1.5331\n",
      "Epoch [12/100], Step [1520/1751], Loss: 1.6095\n",
      "Epoch [12/100], Step [1530/1751], Loss: 1.5129\n",
      "Epoch [12/100], Step [1540/1751], Loss: 1.3635\n",
      "Epoch [12/100], Step [1550/1751], Loss: 1.4092\n",
      "Epoch [12/100], Step [1560/1751], Loss: 1.4453\n",
      "Epoch [12/100], Step [1570/1751], Loss: 1.2667\n",
      "Epoch [12/100], Step [1580/1751], Loss: 1.4439\n",
      "Epoch [12/100], Step [1590/1751], Loss: 1.3653\n",
      "Epoch [12/100], Step [1600/1751], Loss: 1.3575\n",
      "Epoch [12/100], Step [1610/1751], Loss: 1.3776\n",
      "Epoch [12/100], Step [1620/1751], Loss: 1.2656\n",
      "Epoch [12/100], Step [1630/1751], Loss: 1.3181\n",
      "Epoch [12/100], Step [1640/1751], Loss: 1.4756\n",
      "Epoch [12/100], Step [1650/1751], Loss: 1.3060\n",
      "Epoch [12/100], Step [1660/1751], Loss: 1.4354\n",
      "Epoch [12/100], Step [1670/1751], Loss: 1.2995\n",
      "Epoch [12/100], Step [1680/1751], Loss: 1.4712\n",
      "Epoch [12/100], Step [1690/1751], Loss: 1.5170\n",
      "Epoch [12/100], Step [1700/1751], Loss: 1.4066\n",
      "Epoch [12/100], Step [1710/1751], Loss: 1.4399\n",
      "Epoch [12/100], Step [1720/1751], Loss: 1.4531\n",
      "Epoch [12/100], Step [1730/1751], Loss: 1.3432\n",
      "Epoch [12/100], Step [1740/1751], Loss: 1.3291\n",
      "Epoch [12/100], Step [1750/1751], Loss: 1.3638\n",
      "Epoch [12/100], Average Loss: 1.3689, Time: 1636.7113s\n",
      "Epoch [13/100], Step [10/1751], Loss: 1.4418\n",
      "Epoch [13/100], Step [20/1751], Loss: 1.2329\n",
      "Epoch [13/100], Step [30/1751], Loss: 1.3863\n",
      "Epoch [13/100], Step [40/1751], Loss: 1.3974\n",
      "Epoch [13/100], Step [50/1751], Loss: 1.3306\n",
      "Epoch [13/100], Step [60/1751], Loss: 1.4154\n",
      "Epoch [13/100], Step [70/1751], Loss: 1.3821\n",
      "Epoch [13/100], Step [80/1751], Loss: 1.4435\n",
      "Epoch [13/100], Step [90/1751], Loss: 1.2905\n",
      "Epoch [13/100], Step [100/1751], Loss: 1.3774\n",
      "Epoch [13/100], Step [110/1751], Loss: 1.1590\n",
      "Epoch [13/100], Step [120/1751], Loss: 1.3085\n",
      "Epoch [13/100], Step [130/1751], Loss: 1.2702\n",
      "Epoch [13/100], Step [140/1751], Loss: 1.3579\n",
      "Epoch [13/100], Step [150/1751], Loss: 1.4725\n",
      "Epoch [13/100], Step [160/1751], Loss: 1.1709\n",
      "Epoch [13/100], Step [170/1751], Loss: 1.2015\n",
      "Epoch [13/100], Step [180/1751], Loss: 1.3914\n",
      "Epoch [13/100], Step [190/1751], Loss: 1.4995\n",
      "Epoch [13/100], Step [200/1751], Loss: 1.4336\n",
      "Epoch [13/100], Step [210/1751], Loss: 1.3999\n",
      "Epoch [13/100], Step [220/1751], Loss: 1.4015\n",
      "Epoch [13/100], Step [230/1751], Loss: 1.4124\n",
      "Epoch [13/100], Step [240/1751], Loss: 1.3222\n",
      "Epoch [13/100], Step [250/1751], Loss: 1.3080\n",
      "Epoch [13/100], Step [260/1751], Loss: 1.4295\n",
      "Epoch [13/100], Step [270/1751], Loss: 1.4488\n",
      "Epoch [13/100], Step [280/1751], Loss: 1.5504\n",
      "Epoch [13/100], Step [290/1751], Loss: 1.2877\n",
      "Epoch [13/100], Step [300/1751], Loss: 1.5021\n",
      "Epoch [13/100], Step [310/1751], Loss: 1.2965\n",
      "Epoch [13/100], Step [320/1751], Loss: 1.2796\n",
      "Epoch [13/100], Step [330/1751], Loss: 1.3658\n",
      "Epoch [13/100], Step [340/1751], Loss: 1.4507\n",
      "Epoch [13/100], Step [350/1751], Loss: 1.3284\n",
      "Epoch [13/100], Step [360/1751], Loss: 1.3776\n",
      "Epoch [13/100], Step [370/1751], Loss: 1.4942\n",
      "Epoch [13/100], Step [380/1751], Loss: 1.3525\n",
      "Epoch [13/100], Step [390/1751], Loss: 1.1752\n",
      "Epoch [13/100], Step [400/1751], Loss: 1.2482\n",
      "Epoch [13/100], Step [410/1751], Loss: 1.2059\n",
      "Epoch [13/100], Step [420/1751], Loss: 1.3824\n",
      "Epoch [13/100], Step [430/1751], Loss: 1.4063\n",
      "Epoch [13/100], Step [440/1751], Loss: 1.4319\n",
      "Epoch [13/100], Step [450/1751], Loss: 1.3505\n",
      "Epoch [13/100], Step [460/1751], Loss: 1.4538\n",
      "Epoch [13/100], Step [470/1751], Loss: 1.3097\n",
      "Epoch [13/100], Step [480/1751], Loss: 1.2132\n",
      "Epoch [13/100], Step [490/1751], Loss: 1.3581\n",
      "Epoch [13/100], Step [500/1751], Loss: 1.2724\n",
      "Epoch [13/100], Step [510/1751], Loss: 1.3666\n",
      "Epoch [13/100], Step [520/1751], Loss: 1.3879\n",
      "Epoch [13/100], Step [530/1751], Loss: 1.1895\n",
      "Epoch [13/100], Step [540/1751], Loss: 1.3698\n",
      "Epoch [13/100], Step [550/1751], Loss: 1.3482\n",
      "Epoch [13/100], Step [560/1751], Loss: 1.3485\n",
      "Epoch [13/100], Step [570/1751], Loss: 1.2923\n",
      "Epoch [13/100], Step [580/1751], Loss: 1.5523\n",
      "Epoch [13/100], Step [590/1751], Loss: 1.4036\n",
      "Epoch [13/100], Step [600/1751], Loss: 1.3913\n",
      "Epoch [13/100], Step [610/1751], Loss: 1.4584\n",
      "Epoch [13/100], Step [620/1751], Loss: 1.2618\n",
      "Epoch [13/100], Step [630/1751], Loss: 1.1314\n",
      "Epoch [13/100], Step [640/1751], Loss: 1.4002\n",
      "Epoch [13/100], Step [650/1751], Loss: 1.2660\n",
      "Epoch [13/100], Step [660/1751], Loss: 1.2627\n",
      "Epoch [13/100], Step [670/1751], Loss: 1.2719\n",
      "Epoch [13/100], Step [680/1751], Loss: 1.3388\n",
      "Epoch [13/100], Step [690/1751], Loss: 1.3598\n",
      "Epoch [13/100], Step [700/1751], Loss: 1.3050\n",
      "Epoch [13/100], Step [710/1751], Loss: 1.4141\n",
      "Epoch [13/100], Step [720/1751], Loss: 1.4495\n",
      "Epoch [13/100], Step [730/1751], Loss: 1.2982\n",
      "Epoch [13/100], Step [740/1751], Loss: 1.4089\n",
      "Epoch [13/100], Step [750/1751], Loss: 1.4164\n",
      "Epoch [13/100], Step [760/1751], Loss: 1.3259\n",
      "Epoch [13/100], Step [770/1751], Loss: 1.3221\n",
      "Epoch [13/100], Step [780/1751], Loss: 1.5385\n",
      "Epoch [13/100], Step [790/1751], Loss: 1.3091\n",
      "Epoch [13/100], Step [800/1751], Loss: 1.2535\n",
      "Epoch [13/100], Step [810/1751], Loss: 1.4335\n",
      "Epoch [13/100], Step [820/1751], Loss: 1.4726\n",
      "Epoch [13/100], Step [830/1751], Loss: 1.2592\n",
      "Epoch [13/100], Step [840/1751], Loss: 1.5310\n",
      "Epoch [13/100], Step [850/1751], Loss: 1.3224\n",
      "Epoch [13/100], Step [860/1751], Loss: 1.3781\n",
      "Epoch [13/100], Step [870/1751], Loss: 1.1365\n",
      "Epoch [13/100], Step [880/1751], Loss: 1.4116\n",
      "Epoch [13/100], Step [890/1751], Loss: 1.2902\n",
      "Epoch [13/100], Step [900/1751], Loss: 1.4416\n",
      "Epoch [13/100], Step [910/1751], Loss: 1.4258\n",
      "Epoch [13/100], Step [920/1751], Loss: 1.4990\n",
      "Epoch [13/100], Step [930/1751], Loss: 1.4353\n",
      "Epoch [13/100], Step [940/1751], Loss: 1.3463\n",
      "Epoch [13/100], Step [950/1751], Loss: 1.3549\n",
      "Epoch [13/100], Step [960/1751], Loss: 1.4422\n",
      "Epoch [13/100], Step [970/1751], Loss: 1.4124\n",
      "Epoch [13/100], Step [980/1751], Loss: 1.3457\n",
      "Epoch [13/100], Step [990/1751], Loss: 1.4069\n",
      "Epoch [13/100], Step [1000/1751], Loss: 1.3913\n",
      "Epoch [13/100], Step [1010/1751], Loss: 1.3799\n",
      "Epoch [13/100], Step [1020/1751], Loss: 1.3400\n",
      "Epoch [13/100], Step [1030/1751], Loss: 1.4610\n",
      "Epoch [13/100], Step [1040/1751], Loss: 1.3974\n",
      "Epoch [13/100], Step [1050/1751], Loss: 1.3866\n",
      "Epoch [13/100], Step [1060/1751], Loss: 1.2492\n",
      "Epoch [13/100], Step [1070/1751], Loss: 1.4463\n",
      "Epoch [13/100], Step [1080/1751], Loss: 1.3328\n",
      "Epoch [13/100], Step [1090/1751], Loss: 1.1616\n",
      "Epoch [13/100], Step [1100/1751], Loss: 1.3347\n",
      "Epoch [13/100], Step [1110/1751], Loss: 1.3066\n",
      "Epoch [13/100], Step [1120/1751], Loss: 1.1805\n",
      "Epoch [13/100], Step [1130/1751], Loss: 1.5743\n",
      "Epoch [13/100], Step [1140/1751], Loss: 1.3542\n",
      "Epoch [13/100], Step [1150/1751], Loss: 1.3909\n",
      "Epoch [13/100], Step [1160/1751], Loss: 1.2346\n",
      "Epoch [13/100], Step [1170/1751], Loss: 1.3534\n",
      "Epoch [13/100], Step [1180/1751], Loss: 1.2757\n",
      "Epoch [13/100], Step [1190/1751], Loss: 1.2820\n",
      "Epoch [13/100], Step [1200/1751], Loss: 1.2193\n",
      "Epoch [13/100], Step [1210/1751], Loss: 1.3175\n",
      "Epoch [13/100], Step [1220/1751], Loss: 1.2804\n",
      "Epoch [13/100], Step [1230/1751], Loss: 1.2786\n",
      "Epoch [13/100], Step [1240/1751], Loss: 1.5244\n",
      "Epoch [13/100], Step [1250/1751], Loss: 1.3019\n",
      "Epoch [13/100], Step [1260/1751], Loss: 1.4439\n",
      "Epoch [13/100], Step [1270/1751], Loss: 1.3442\n",
      "Epoch [13/100], Step [1280/1751], Loss: 1.3878\n",
      "Epoch [13/100], Step [1290/1751], Loss: 1.3316\n",
      "Epoch [13/100], Step [1300/1751], Loss: 1.2348\n",
      "Epoch [13/100], Step [1310/1751], Loss: 1.2937\n",
      "Epoch [13/100], Step [1320/1751], Loss: 1.2685\n",
      "Epoch [13/100], Step [1330/1751], Loss: 1.4950\n",
      "Epoch [13/100], Step [1340/1751], Loss: 1.2927\n",
      "Epoch [13/100], Step [1350/1751], Loss: 1.3938\n",
      "Epoch [13/100], Step [1360/1751], Loss: 1.3489\n",
      "Epoch [13/100], Step [1370/1751], Loss: 1.2706\n",
      "Epoch [13/100], Step [1380/1751], Loss: 1.3913\n",
      "Epoch [13/100], Step [1390/1751], Loss: 1.3851\n",
      "Epoch [13/100], Step [1400/1751], Loss: 1.2858\n",
      "Epoch [13/100], Step [1410/1751], Loss: 1.3312\n",
      "Epoch [13/100], Step [1420/1751], Loss: 1.2711\n",
      "Epoch [13/100], Step [1430/1751], Loss: 1.3628\n",
      "Epoch [13/100], Step [1440/1751], Loss: 1.5830\n",
      "Epoch [13/100], Step [1450/1751], Loss: 1.1364\n",
      "Epoch [13/100], Step [1460/1751], Loss: 1.3603\n",
      "Epoch [13/100], Step [1470/1751], Loss: 1.3922\n",
      "Epoch [13/100], Step [1480/1751], Loss: 1.3052\n",
      "Epoch [13/100], Step [1490/1751], Loss: 1.3080\n",
      "Epoch [13/100], Step [1500/1751], Loss: 1.3920\n",
      "Epoch [13/100], Step [1510/1751], Loss: 1.3817\n",
      "Epoch [13/100], Step [1520/1751], Loss: 1.3476\n",
      "Epoch [13/100], Step [1530/1751], Loss: 1.3857\n",
      "Epoch [13/100], Step [1540/1751], Loss: 1.2473\n",
      "Epoch [13/100], Step [1550/1751], Loss: 1.3116\n",
      "Epoch [13/100], Step [1560/1751], Loss: 1.3736\n",
      "Epoch [13/100], Step [1570/1751], Loss: 1.3938\n",
      "Epoch [13/100], Step [1580/1751], Loss: 1.2589\n",
      "Epoch [13/100], Step [1590/1751], Loss: 1.2307\n",
      "Epoch [13/100], Step [1600/1751], Loss: 1.2453\n",
      "Epoch [13/100], Step [1610/1751], Loss: 1.2590\n",
      "Epoch [13/100], Step [1620/1751], Loss: 1.4249\n",
      "Epoch [13/100], Step [1630/1751], Loss: 1.2937\n",
      "Epoch [13/100], Step [1640/1751], Loss: 1.2468\n",
      "Epoch [13/100], Step [1650/1751], Loss: 1.5213\n",
      "Epoch [13/100], Step [1660/1751], Loss: 1.4012\n",
      "Epoch [13/100], Step [1670/1751], Loss: 1.2670\n",
      "Epoch [13/100], Step [1680/1751], Loss: 1.4193\n",
      "Epoch [13/100], Step [1690/1751], Loss: 1.2512\n",
      "Epoch [13/100], Step [1700/1751], Loss: 1.3053\n",
      "Epoch [13/100], Step [1710/1751], Loss: 1.2993\n",
      "Epoch [13/100], Step [1720/1751], Loss: 1.3275\n",
      "Epoch [13/100], Step [1730/1751], Loss: 1.2402\n",
      "Epoch [13/100], Step [1740/1751], Loss: 1.4150\n",
      "Epoch [13/100], Step [1750/1751], Loss: 1.4387\n",
      "Epoch [13/100], Average Loss: 1.3519, Time: 1638.1356s\n",
      "Epoch [14/100], Step [10/1751], Loss: 1.4150\n",
      "Epoch [14/100], Step [20/1751], Loss: 1.3513\n",
      "Epoch [14/100], Step [30/1751], Loss: 1.3161\n",
      "Epoch [14/100], Step [40/1751], Loss: 1.4495\n",
      "Epoch [14/100], Step [50/1751], Loss: 1.2725\n",
      "Epoch [14/100], Step [60/1751], Loss: 1.4313\n",
      "Epoch [14/100], Step [70/1751], Loss: 1.3059\n",
      "Epoch [14/100], Step [80/1751], Loss: 1.3965\n",
      "Epoch [14/100], Step [90/1751], Loss: 1.4755\n",
      "Epoch [14/100], Step [100/1751], Loss: 1.2959\n",
      "Epoch [14/100], Step [110/1751], Loss: 1.2544\n",
      "Epoch [14/100], Step [120/1751], Loss: 1.2947\n",
      "Epoch [14/100], Step [130/1751], Loss: 1.3126\n",
      "Epoch [14/100], Step [140/1751], Loss: 1.3705\n",
      "Epoch [14/100], Step [150/1751], Loss: 1.1650\n",
      "Epoch [14/100], Step [160/1751], Loss: 1.3629\n",
      "Epoch [14/100], Step [170/1751], Loss: 1.1743\n",
      "Epoch [14/100], Step [180/1751], Loss: 1.1942\n",
      "Epoch [14/100], Step [190/1751], Loss: 1.1727\n",
      "Epoch [14/100], Step [200/1751], Loss: 1.4458\n",
      "Epoch [14/100], Step [210/1751], Loss: 1.2982\n",
      "Epoch [14/100], Step [220/1751], Loss: 1.3763\n",
      "Epoch [14/100], Step [230/1751], Loss: 1.2216\n",
      "Epoch [14/100], Step [240/1751], Loss: 1.4423\n",
      "Epoch [14/100], Step [250/1751], Loss: 1.4562\n",
      "Epoch [14/100], Step [260/1751], Loss: 1.2997\n",
      "Epoch [14/100], Step [270/1751], Loss: 1.4488\n",
      "Epoch [14/100], Step [280/1751], Loss: 1.3632\n",
      "Epoch [14/100], Step [290/1751], Loss: 1.3660\n",
      "Epoch [14/100], Step [300/1751], Loss: 1.3372\n",
      "Epoch [14/100], Step [310/1751], Loss: 1.3158\n",
      "Epoch [14/100], Step [320/1751], Loss: 1.2289\n",
      "Epoch [14/100], Step [330/1751], Loss: 1.1943\n",
      "Epoch [14/100], Step [340/1751], Loss: 1.3472\n",
      "Epoch [14/100], Step [350/1751], Loss: 1.3171\n",
      "Epoch [14/100], Step [360/1751], Loss: 1.2959\n",
      "Epoch [14/100], Step [370/1751], Loss: 1.4145\n",
      "Epoch [14/100], Step [380/1751], Loss: 1.4918\n",
      "Epoch [14/100], Step [390/1751], Loss: 1.2367\n",
      "Epoch [14/100], Step [400/1751], Loss: 1.3760\n",
      "Epoch [14/100], Step [410/1751], Loss: 1.3761\n",
      "Epoch [14/100], Step [420/1751], Loss: 1.3959\n",
      "Epoch [14/100], Step [430/1751], Loss: 1.4452\n",
      "Epoch [14/100], Step [440/1751], Loss: 1.3117\n",
      "Epoch [14/100], Step [450/1751], Loss: 1.3747\n",
      "Epoch [14/100], Step [460/1751], Loss: 1.4039\n",
      "Epoch [14/100], Step [470/1751], Loss: 1.4480\n",
      "Epoch [14/100], Step [480/1751], Loss: 1.3476\n",
      "Epoch [14/100], Step [490/1751], Loss: 1.2444\n",
      "Epoch [14/100], Step [500/1751], Loss: 1.2319\n",
      "Epoch [14/100], Step [510/1751], Loss: 1.4449\n",
      "Epoch [14/100], Step [520/1751], Loss: 1.3513\n",
      "Epoch [14/100], Step [530/1751], Loss: 1.2993\n",
      "Epoch [14/100], Step [540/1751], Loss: 1.1727\n",
      "Epoch [14/100], Step [550/1751], Loss: 1.4676\n",
      "Epoch [14/100], Step [560/1751], Loss: 1.4735\n",
      "Epoch [14/100], Step [570/1751], Loss: 1.2614\n",
      "Epoch [14/100], Step [580/1751], Loss: 1.2066\n",
      "Epoch [14/100], Step [590/1751], Loss: 1.5412\n",
      "Epoch [14/100], Step [600/1751], Loss: 1.2537\n",
      "Epoch [14/100], Step [610/1751], Loss: 1.5365\n",
      "Epoch [14/100], Step [620/1751], Loss: 1.2704\n",
      "Epoch [14/100], Step [630/1751], Loss: 1.3868\n",
      "Epoch [14/100], Step [640/1751], Loss: 1.3072\n",
      "Epoch [14/100], Step [650/1751], Loss: 1.3680\n",
      "Epoch [14/100], Step [660/1751], Loss: 1.3002\n",
      "Epoch [14/100], Step [670/1751], Loss: 1.4240\n",
      "Epoch [14/100], Step [680/1751], Loss: 1.3862\n",
      "Epoch [14/100], Step [690/1751], Loss: 1.2547\n",
      "Epoch [14/100], Step [700/1751], Loss: 1.3105\n",
      "Epoch [14/100], Step [710/1751], Loss: 1.2585\n",
      "Epoch [14/100], Step [720/1751], Loss: 1.2492\n",
      "Epoch [14/100], Step [730/1751], Loss: 1.3703\n",
      "Epoch [14/100], Step [740/1751], Loss: 1.3148\n",
      "Epoch [14/100], Step [750/1751], Loss: 1.3572\n",
      "Epoch [14/100], Step [760/1751], Loss: 1.2660\n",
      "Epoch [14/100], Step [770/1751], Loss: 1.4763\n",
      "Epoch [14/100], Step [780/1751], Loss: 1.4465\n",
      "Epoch [14/100], Step [790/1751], Loss: 1.3687\n",
      "Epoch [14/100], Step [800/1751], Loss: 1.5464\n",
      "Epoch [14/100], Step [810/1751], Loss: 1.2906\n",
      "Epoch [14/100], Step [820/1751], Loss: 1.4854\n",
      "Epoch [14/100], Step [830/1751], Loss: 1.2396\n",
      "Epoch [14/100], Step [840/1751], Loss: 1.3503\n",
      "Epoch [14/100], Step [850/1751], Loss: 1.3647\n",
      "Epoch [14/100], Step [860/1751], Loss: 1.2705\n",
      "Epoch [14/100], Step [870/1751], Loss: 1.4148\n",
      "Epoch [14/100], Step [880/1751], Loss: 1.3475\n",
      "Epoch [14/100], Step [890/1751], Loss: 1.3551\n",
      "Epoch [14/100], Step [900/1751], Loss: 1.3693\n",
      "Epoch [14/100], Step [910/1751], Loss: 1.1828\n",
      "Epoch [14/100], Step [920/1751], Loss: 1.3020\n",
      "Epoch [14/100], Step [930/1751], Loss: 1.3328\n",
      "Epoch [14/100], Step [940/1751], Loss: 1.4452\n",
      "Epoch [14/100], Step [950/1751], Loss: 1.2960\n",
      "Epoch [14/100], Step [960/1751], Loss: 1.3617\n",
      "Epoch [14/100], Step [970/1751], Loss: 1.2403\n",
      "Epoch [14/100], Step [980/1751], Loss: 1.2449\n",
      "Epoch [14/100], Step [990/1751], Loss: 1.2377\n",
      "Epoch [14/100], Step [1000/1751], Loss: 1.2760\n",
      "Epoch [14/100], Step [1010/1751], Loss: 1.4292\n",
      "Epoch [14/100], Step [1020/1751], Loss: 1.3057\n",
      "Epoch [14/100], Step [1030/1751], Loss: 1.2940\n",
      "Epoch [14/100], Step [1040/1751], Loss: 1.2797\n",
      "Epoch [14/100], Step [1050/1751], Loss: 1.3479\n",
      "Epoch [14/100], Step [1060/1751], Loss: 1.3473\n",
      "Epoch [14/100], Step [1070/1751], Loss: 1.5026\n",
      "Epoch [14/100], Step [1080/1751], Loss: 1.3785\n",
      "Epoch [14/100], Step [1090/1751], Loss: 1.2994\n",
      "Epoch [14/100], Step [1100/1751], Loss: 1.3429\n",
      "Epoch [14/100], Step [1110/1751], Loss: 1.2619\n",
      "Epoch [14/100], Step [1120/1751], Loss: 1.3831\n",
      "Epoch [14/100], Step [1130/1751], Loss: 1.3495\n",
      "Epoch [14/100], Step [1140/1751], Loss: 1.3572\n",
      "Epoch [14/100], Step [1150/1751], Loss: 1.3984\n",
      "Epoch [14/100], Step [1160/1751], Loss: 1.3496\n",
      "Epoch [14/100], Step [1170/1751], Loss: 1.4631\n",
      "Epoch [14/100], Step [1180/1751], Loss: 1.4227\n",
      "Epoch [14/100], Step [1190/1751], Loss: 1.4162\n",
      "Epoch [14/100], Step [1200/1751], Loss: 1.4099\n",
      "Epoch [14/100], Step [1210/1751], Loss: 1.2491\n",
      "Epoch [14/100], Step [1220/1751], Loss: 1.4092\n",
      "Epoch [14/100], Step [1230/1751], Loss: 1.1226\n",
      "Epoch [14/100], Step [1240/1751], Loss: 1.1971\n",
      "Epoch [14/100], Step [1250/1751], Loss: 1.3461\n",
      "Epoch [14/100], Step [1260/1751], Loss: 1.3489\n",
      "Epoch [14/100], Step [1270/1751], Loss: 1.2327\n",
      "Epoch [14/100], Step [1280/1751], Loss: 1.2272\n",
      "Epoch [14/100], Step [1290/1751], Loss: 1.2308\n",
      "Epoch [14/100], Step [1300/1751], Loss: 1.3042\n",
      "Epoch [14/100], Step [1310/1751], Loss: 1.3479\n",
      "Epoch [14/100], Step [1320/1751], Loss: 1.1445\n",
      "Epoch [14/100], Step [1330/1751], Loss: 1.3682\n",
      "Epoch [14/100], Step [1340/1751], Loss: 1.5463\n",
      "Epoch [14/100], Step [1350/1751], Loss: 1.2344\n",
      "Epoch [14/100], Step [1360/1751], Loss: 1.2926\n",
      "Epoch [14/100], Step [1370/1751], Loss: 1.1909\n",
      "Epoch [14/100], Step [1380/1751], Loss: 1.3037\n",
      "Epoch [14/100], Step [1390/1751], Loss: 1.4089\n",
      "Epoch [14/100], Step [1400/1751], Loss: 1.1927\n",
      "Epoch [14/100], Step [1410/1751], Loss: 1.4916\n",
      "Epoch [14/100], Step [1420/1751], Loss: 1.3677\n",
      "Epoch [14/100], Step [1430/1751], Loss: 1.2937\n",
      "Epoch [14/100], Step [1440/1751], Loss: 1.4299\n",
      "Epoch [14/100], Step [1450/1751], Loss: 1.2600\n",
      "Epoch [14/100], Step [1460/1751], Loss: 1.1445\n",
      "Epoch [14/100], Step [1470/1751], Loss: 1.2757\n",
      "Epoch [14/100], Step [1480/1751], Loss: 1.3960\n",
      "Epoch [14/100], Step [1490/1751], Loss: 1.2064\n",
      "Epoch [14/100], Step [1500/1751], Loss: 1.3055\n",
      "Epoch [14/100], Step [1510/1751], Loss: 1.4439\n",
      "Epoch [14/100], Step [1520/1751], Loss: 1.2288\n",
      "Epoch [14/100], Step [1530/1751], Loss: 1.2989\n",
      "Epoch [14/100], Step [1540/1751], Loss: 1.2612\n",
      "Epoch [14/100], Step [1550/1751], Loss: 1.2581\n",
      "Epoch [14/100], Step [1560/1751], Loss: 1.1917\n",
      "Epoch [14/100], Step [1570/1751], Loss: 1.2122\n",
      "Epoch [14/100], Step [1580/1751], Loss: 1.1975\n",
      "Epoch [14/100], Step [1590/1751], Loss: 1.3548\n",
      "Epoch [14/100], Step [1600/1751], Loss: 1.3001\n",
      "Epoch [14/100], Step [1610/1751], Loss: 1.1791\n",
      "Epoch [14/100], Step [1620/1751], Loss: 1.3634\n",
      "Epoch [14/100], Step [1630/1751], Loss: 1.2581\n",
      "Epoch [14/100], Step [1640/1751], Loss: 1.4903\n",
      "Epoch [14/100], Step [1650/1751], Loss: 1.3414\n",
      "Epoch [14/100], Step [1660/1751], Loss: 1.2809\n",
      "Epoch [14/100], Step [1670/1751], Loss: 1.2597\n",
      "Epoch [14/100], Step [1680/1751], Loss: 1.3715\n",
      "Epoch [14/100], Step [1690/1751], Loss: 1.4786\n",
      "Epoch [14/100], Step [1700/1751], Loss: 1.2737\n",
      "Epoch [14/100], Step [1710/1751], Loss: 1.2900\n",
      "Epoch [14/100], Step [1720/1751], Loss: 1.3350\n",
      "Epoch [14/100], Step [1730/1751], Loss: 1.3391\n",
      "Epoch [14/100], Step [1740/1751], Loss: 1.4855\n",
      "Epoch [14/100], Step [1750/1751], Loss: 1.2775\n",
      "Epoch [14/100], Average Loss: 1.3370, Time: 1637.9244s\n",
      "Epoch [15/100], Step [10/1751], Loss: 1.4533\n",
      "Epoch [15/100], Step [20/1751], Loss: 1.3834\n",
      "Epoch [15/100], Step [30/1751], Loss: 1.3335\n",
      "Epoch [15/100], Step [40/1751], Loss: 1.3095\n",
      "Epoch [15/100], Step [50/1751], Loss: 1.3814\n",
      "Epoch [15/100], Step [60/1751], Loss: 1.2395\n",
      "Epoch [15/100], Step [70/1751], Loss: 1.3878\n",
      "Epoch [15/100], Step [80/1751], Loss: 1.3460\n",
      "Epoch [15/100], Step [90/1751], Loss: 1.3343\n",
      "Epoch [15/100], Step [100/1751], Loss: 1.2074\n",
      "Epoch [15/100], Step [110/1751], Loss: 1.3061\n",
      "Epoch [15/100], Step [120/1751], Loss: 1.3034\n",
      "Epoch [15/100], Step [130/1751], Loss: 1.2314\n",
      "Epoch [15/100], Step [140/1751], Loss: 1.3978\n",
      "Epoch [15/100], Step [150/1751], Loss: 1.3033\n",
      "Epoch [15/100], Step [160/1751], Loss: 1.3908\n",
      "Epoch [15/100], Step [170/1751], Loss: 1.2633\n",
      "Epoch [15/100], Step [180/1751], Loss: 1.2590\n",
      "Epoch [15/100], Step [190/1751], Loss: 1.4389\n",
      "Epoch [15/100], Step [200/1751], Loss: 1.3345\n",
      "Epoch [15/100], Step [210/1751], Loss: 1.4814\n",
      "Epoch [15/100], Step [220/1751], Loss: 1.4376\n",
      "Epoch [15/100], Step [230/1751], Loss: 1.2809\n",
      "Epoch [15/100], Step [240/1751], Loss: 1.2433\n",
      "Epoch [15/100], Step [250/1751], Loss: 1.2512\n",
      "Epoch [15/100], Step [260/1751], Loss: 1.4118\n",
      "Epoch [15/100], Step [270/1751], Loss: 1.4111\n",
      "Epoch [15/100], Step [280/1751], Loss: 1.2554\n",
      "Epoch [15/100], Step [290/1751], Loss: 1.4451\n",
      "Epoch [15/100], Step [300/1751], Loss: 1.3098\n",
      "Epoch [15/100], Step [310/1751], Loss: 1.3772\n",
      "Epoch [15/100], Step [320/1751], Loss: 1.2935\n",
      "Epoch [15/100], Step [330/1751], Loss: 1.3647\n",
      "Epoch [15/100], Step [340/1751], Loss: 1.4247\n",
      "Epoch [15/100], Step [350/1751], Loss: 1.4587\n",
      "Epoch [15/100], Step [360/1751], Loss: 1.2848\n",
      "Epoch [15/100], Step [370/1751], Loss: 1.2086\n",
      "Epoch [15/100], Step [380/1751], Loss: 1.3143\n",
      "Epoch [15/100], Step [390/1751], Loss: 1.2037\n",
      "Epoch [15/100], Step [400/1751], Loss: 1.4524\n",
      "Epoch [15/100], Step [410/1751], Loss: 1.2095\n",
      "Epoch [15/100], Step [420/1751], Loss: 1.3478\n",
      "Epoch [15/100], Step [430/1751], Loss: 1.4884\n",
      "Epoch [15/100], Step [440/1751], Loss: 1.3059\n",
      "Epoch [15/100], Step [450/1751], Loss: 1.3725\n",
      "Epoch [15/100], Step [460/1751], Loss: 1.1906\n",
      "Epoch [15/100], Step [470/1751], Loss: 1.2874\n",
      "Epoch [15/100], Step [480/1751], Loss: 1.2851\n",
      "Epoch [15/100], Step [490/1751], Loss: 1.3417\n",
      "Epoch [15/100], Step [500/1751], Loss: 1.1174\n",
      "Epoch [15/100], Step [510/1751], Loss: 1.2742\n",
      "Epoch [15/100], Step [520/1751], Loss: 1.2381\n",
      "Epoch [15/100], Step [530/1751], Loss: 1.3126\n",
      "Epoch [15/100], Step [540/1751], Loss: 1.4040\n",
      "Epoch [15/100], Step [550/1751], Loss: 1.3637\n",
      "Epoch [15/100], Step [560/1751], Loss: 1.3054\n",
      "Epoch [15/100], Step [570/1751], Loss: 1.4654\n",
      "Epoch [15/100], Step [580/1751], Loss: 1.3994\n",
      "Epoch [15/100], Step [590/1751], Loss: 1.2403\n",
      "Epoch [15/100], Step [600/1751], Loss: 1.4008\n",
      "Epoch [15/100], Step [610/1751], Loss: 1.1386\n",
      "Epoch [15/100], Step [620/1751], Loss: 1.2905\n",
      "Epoch [15/100], Step [630/1751], Loss: 1.3147\n",
      "Epoch [15/100], Step [640/1751], Loss: 1.4550\n",
      "Epoch [15/100], Step [650/1751], Loss: 1.4034\n",
      "Epoch [15/100], Step [660/1751], Loss: 1.3536\n",
      "Epoch [15/100], Step [670/1751], Loss: 1.3945\n",
      "Epoch [15/100], Step [680/1751], Loss: 1.3605\n",
      "Epoch [15/100], Step [690/1751], Loss: 1.2507\n",
      "Epoch [15/100], Step [700/1751], Loss: 1.4286\n",
      "Epoch [15/100], Step [710/1751], Loss: 1.3853\n",
      "Epoch [15/100], Step [720/1751], Loss: 1.1492\n",
      "Epoch [15/100], Step [730/1751], Loss: 1.1964\n",
      "Epoch [15/100], Step [740/1751], Loss: 1.3108\n",
      "Epoch [15/100], Step [750/1751], Loss: 1.2367\n",
      "Epoch [15/100], Step [760/1751], Loss: 1.3275\n",
      "Epoch [15/100], Step [770/1751], Loss: 1.2474\n",
      "Epoch [15/100], Step [780/1751], Loss: 1.4799\n",
      "Epoch [15/100], Step [790/1751], Loss: 1.3727\n",
      "Epoch [15/100], Step [800/1751], Loss: 1.3177\n",
      "Epoch [15/100], Step [810/1751], Loss: 1.4169\n",
      "Epoch [15/100], Step [820/1751], Loss: 1.4390\n",
      "Epoch [15/100], Step [830/1751], Loss: 1.3339\n",
      "Epoch [15/100], Step [840/1751], Loss: 1.3646\n",
      "Epoch [15/100], Step [850/1751], Loss: 1.3355\n",
      "Epoch [15/100], Step [860/1751], Loss: 1.3169\n",
      "Epoch [15/100], Step [870/1751], Loss: 1.3276\n",
      "Epoch [15/100], Step [880/1751], Loss: 1.2259\n",
      "Epoch [15/100], Step [890/1751], Loss: 1.2502\n",
      "Epoch [15/100], Step [900/1751], Loss: 1.2179\n",
      "Epoch [15/100], Step [910/1751], Loss: 1.2771\n",
      "Epoch [15/100], Step [920/1751], Loss: 1.3162\n",
      "Epoch [15/100], Step [930/1751], Loss: 1.3765\n",
      "Epoch [15/100], Step [940/1751], Loss: 1.3099\n",
      "Epoch [15/100], Step [950/1751], Loss: 1.2841\n",
      "Epoch [15/100], Step [960/1751], Loss: 1.3617\n",
      "Epoch [15/100], Step [970/1751], Loss: 1.3640\n",
      "Epoch [15/100], Step [980/1751], Loss: 1.2686\n",
      "Epoch [15/100], Step [990/1751], Loss: 1.4424\n",
      "Epoch [15/100], Step [1000/1751], Loss: 1.4470\n",
      "Epoch [15/100], Step [1010/1751], Loss: 1.2731\n",
      "Epoch [15/100], Step [1020/1751], Loss: 1.3561\n",
      "Epoch [15/100], Step [1030/1751], Loss: 1.4308\n",
      "Epoch [15/100], Step [1040/1751], Loss: 1.2328\n",
      "Epoch [15/100], Step [1050/1751], Loss: 1.3170\n",
      "Epoch [15/100], Step [1060/1751], Loss: 1.3373\n",
      "Epoch [15/100], Step [1070/1751], Loss: 1.2523\n",
      "Epoch [15/100], Step [1080/1751], Loss: 1.4272\n",
      "Epoch [15/100], Step [1090/1751], Loss: 1.3236\n",
      "Epoch [15/100], Step [1100/1751], Loss: 1.3396\n",
      "Epoch [15/100], Step [1110/1751], Loss: 1.2705\n",
      "Epoch [15/100], Step [1120/1751], Loss: 1.3191\n",
      "Epoch [15/100], Step [1130/1751], Loss: 1.2428\n",
      "Epoch [15/100], Step [1140/1751], Loss: 1.2574\n",
      "Epoch [15/100], Step [1150/1751], Loss: 1.5136\n",
      "Epoch [15/100], Step [1160/1751], Loss: 1.5167\n",
      "Epoch [15/100], Step [1170/1751], Loss: 1.2693\n",
      "Epoch [15/100], Step [1180/1751], Loss: 1.4552\n",
      "Epoch [15/100], Step [1190/1751], Loss: 1.3434\n",
      "Epoch [15/100], Step [1200/1751], Loss: 1.3542\n",
      "Epoch [15/100], Step [1210/1751], Loss: 1.1258\n",
      "Epoch [15/100], Step [1220/1751], Loss: 1.2539\n",
      "Epoch [15/100], Step [1230/1751], Loss: 1.4665\n",
      "Epoch [15/100], Step [1240/1751], Loss: 1.2898\n",
      "Epoch [15/100], Step [1250/1751], Loss: 1.3971\n",
      "Epoch [15/100], Step [1260/1751], Loss: 1.2067\n",
      "Epoch [15/100], Step [1270/1751], Loss: 1.3568\n",
      "Epoch [15/100], Step [1280/1751], Loss: 1.3014\n",
      "Epoch [15/100], Step [1290/1751], Loss: 1.3173\n",
      "Epoch [15/100], Step [1300/1751], Loss: 1.3081\n",
      "Epoch [15/100], Step [1310/1751], Loss: 1.3143\n",
      "Epoch [15/100], Step [1320/1751], Loss: 1.2890\n",
      "Epoch [15/100], Step [1330/1751], Loss: 1.4815\n",
      "Epoch [15/100], Step [1340/1751], Loss: 1.2119\n",
      "Epoch [15/100], Step [1350/1751], Loss: 1.1338\n",
      "Epoch [15/100], Step [1360/1751], Loss: 1.5349\n",
      "Epoch [15/100], Step [1370/1751], Loss: 1.2404\n",
      "Epoch [15/100], Step [1380/1751], Loss: 1.4440\n",
      "Epoch [15/100], Step [1390/1751], Loss: 1.2895\n",
      "Epoch [15/100], Step [1400/1751], Loss: 1.2993\n",
      "Epoch [15/100], Step [1410/1751], Loss: 1.3189\n",
      "Epoch [15/100], Step [1420/1751], Loss: 1.3224\n",
      "Epoch [15/100], Step [1430/1751], Loss: 1.3436\n",
      "Epoch [15/100], Step [1440/1751], Loss: 1.3649\n",
      "Epoch [15/100], Step [1450/1751], Loss: 1.4315\n",
      "Epoch [15/100], Step [1460/1751], Loss: 1.2470\n",
      "Epoch [15/100], Step [1470/1751], Loss: 1.3130\n",
      "Epoch [15/100], Step [1480/1751], Loss: 1.3436\n",
      "Epoch [15/100], Step [1490/1751], Loss: 1.3708\n",
      "Epoch [15/100], Step [1500/1751], Loss: 1.2373\n",
      "Epoch [15/100], Step [1510/1751], Loss: 1.3904\n",
      "Epoch [15/100], Step [1520/1751], Loss: 1.2605\n",
      "Epoch [15/100], Step [1530/1751], Loss: 1.4190\n",
      "Epoch [15/100], Step [1540/1751], Loss: 1.3356\n",
      "Epoch [15/100], Step [1550/1751], Loss: 1.2705\n",
      "Epoch [15/100], Step [1560/1751], Loss: 1.3499\n",
      "Epoch [15/100], Step [1570/1751], Loss: 1.2872\n",
      "Epoch [15/100], Step [1580/1751], Loss: 1.1639\n",
      "Epoch [15/100], Step [1590/1751], Loss: 1.2217\n",
      "Epoch [15/100], Step [1600/1751], Loss: 1.3025\n",
      "Epoch [15/100], Step [1610/1751], Loss: 1.3131\n",
      "Epoch [15/100], Step [1620/1751], Loss: 1.4293\n",
      "Epoch [15/100], Step [1630/1751], Loss: 1.2298\n",
      "Epoch [15/100], Step [1640/1751], Loss: 1.2520\n",
      "Epoch [15/100], Step [1650/1751], Loss: 1.2668\n",
      "Epoch [15/100], Step [1660/1751], Loss: 1.1593\n",
      "Epoch [15/100], Step [1670/1751], Loss: 1.3607\n",
      "Epoch [15/100], Step [1680/1751], Loss: 1.2842\n",
      "Epoch [15/100], Step [1690/1751], Loss: 1.4040\n",
      "Epoch [15/100], Step [1700/1751], Loss: 1.1493\n",
      "Epoch [15/100], Step [1710/1751], Loss: 1.3095\n",
      "Epoch [15/100], Step [1720/1751], Loss: 1.2349\n",
      "Epoch [15/100], Step [1730/1751], Loss: 1.1620\n",
      "Epoch [15/100], Step [1740/1751], Loss: 1.2399\n",
      "Epoch [15/100], Step [1750/1751], Loss: 1.3237\n",
      "Epoch [15/100], Average Loss: 1.3250, Time: 1637.9240s\n",
      "Epoch [16/100], Step [10/1751], Loss: 1.2327\n",
      "Epoch [16/100], Step [20/1751], Loss: 1.3469\n",
      "Epoch [16/100], Step [30/1751], Loss: 1.3373\n",
      "Epoch [16/100], Step [40/1751], Loss: 1.3813\n",
      "Epoch [16/100], Step [50/1751], Loss: 1.3523\n",
      "Epoch [16/100], Step [60/1751], Loss: 1.3266\n",
      "Epoch [16/100], Step [70/1751], Loss: 1.3831\n",
      "Epoch [16/100], Step [80/1751], Loss: 1.4193\n",
      "Epoch [16/100], Step [90/1751], Loss: 1.2212\n",
      "Epoch [16/100], Step [100/1751], Loss: 1.3095\n",
      "Epoch [16/100], Step [110/1751], Loss: 1.2018\n",
      "Epoch [16/100], Step [120/1751], Loss: 1.4869\n",
      "Epoch [16/100], Step [130/1751], Loss: 1.3151\n",
      "Epoch [16/100], Step [140/1751], Loss: 1.4015\n",
      "Epoch [16/100], Step [150/1751], Loss: 1.2888\n",
      "Epoch [16/100], Step [160/1751], Loss: 1.3904\n",
      "Epoch [16/100], Step [170/1751], Loss: 1.2999\n",
      "Epoch [16/100], Step [180/1751], Loss: 1.2160\n",
      "Epoch [16/100], Step [190/1751], Loss: 1.2721\n",
      "Epoch [16/100], Step [200/1751], Loss: 1.3358\n",
      "Epoch [16/100], Step [210/1751], Loss: 1.2923\n",
      "Epoch [16/100], Step [220/1751], Loss: 1.2564\n",
      "Epoch [16/100], Step [230/1751], Loss: 1.3330\n",
      "Epoch [16/100], Step [240/1751], Loss: 1.0960\n",
      "Epoch [16/100], Step [250/1751], Loss: 1.4844\n",
      "Epoch [16/100], Step [260/1751], Loss: 1.2378\n",
      "Epoch [16/100], Step [270/1751], Loss: 1.2811\n",
      "Epoch [16/100], Step [280/1751], Loss: 1.3877\n",
      "Epoch [16/100], Step [290/1751], Loss: 1.1944\n",
      "Epoch [16/100], Step [300/1751], Loss: 1.1528\n",
      "Epoch [16/100], Step [310/1751], Loss: 1.2223\n",
      "Epoch [16/100], Step [320/1751], Loss: 1.4231\n",
      "Epoch [16/100], Step [330/1751], Loss: 1.2555\n",
      "Epoch [16/100], Step [340/1751], Loss: 1.2948\n",
      "Epoch [16/100], Step [350/1751], Loss: 1.4516\n",
      "Epoch [16/100], Step [360/1751], Loss: 1.2519\n",
      "Epoch [16/100], Step [370/1751], Loss: 1.3271\n",
      "Epoch [16/100], Step [380/1751], Loss: 1.2270\n",
      "Epoch [16/100], Step [390/1751], Loss: 1.2743\n",
      "Epoch [16/100], Step [400/1751], Loss: 1.3203\n",
      "Epoch [16/100], Step [410/1751], Loss: 1.3668\n",
      "Epoch [16/100], Step [420/1751], Loss: 1.2581\n",
      "Epoch [16/100], Step [430/1751], Loss: 1.2944\n",
      "Epoch [16/100], Step [440/1751], Loss: 1.2250\n",
      "Epoch [16/100], Step [450/1751], Loss: 1.2932\n",
      "Epoch [16/100], Step [460/1751], Loss: 1.1931\n",
      "Epoch [16/100], Step [470/1751], Loss: 1.4140\n",
      "Epoch [16/100], Step [480/1751], Loss: 1.2251\n",
      "Epoch [16/100], Step [490/1751], Loss: 1.2088\n",
      "Epoch [16/100], Step [500/1751], Loss: 1.2673\n",
      "Epoch [16/100], Step [510/1751], Loss: 1.2268\n",
      "Epoch [16/100], Step [520/1751], Loss: 1.3537\n",
      "Epoch [16/100], Step [530/1751], Loss: 1.1942\n",
      "Epoch [16/100], Step [540/1751], Loss: 1.2729\n",
      "Epoch [16/100], Step [550/1751], Loss: 1.2789\n",
      "Epoch [16/100], Step [560/1751], Loss: 1.2127\n",
      "Epoch [16/100], Step [570/1751], Loss: 1.2506\n",
      "Epoch [16/100], Step [580/1751], Loss: 1.5165\n",
      "Epoch [16/100], Step [590/1751], Loss: 1.1699\n",
      "Epoch [16/100], Step [600/1751], Loss: 1.2077\n",
      "Epoch [16/100], Step [610/1751], Loss: 1.2635\n",
      "Epoch [16/100], Step [620/1751], Loss: 1.4234\n",
      "Epoch [16/100], Step [630/1751], Loss: 1.3404\n",
      "Epoch [16/100], Step [640/1751], Loss: 1.3481\n",
      "Epoch [16/100], Step [650/1751], Loss: 1.2878\n",
      "Epoch [16/100], Step [660/1751], Loss: 1.2247\n",
      "Epoch [16/100], Step [670/1751], Loss: 1.4315\n",
      "Epoch [16/100], Step [680/1751], Loss: 1.3828\n",
      "Epoch [16/100], Step [690/1751], Loss: 1.2937\n",
      "Epoch [16/100], Step [700/1751], Loss: 1.3063\n",
      "Epoch [16/100], Step [710/1751], Loss: 1.3055\n",
      "Epoch [16/100], Step [720/1751], Loss: 1.2938\n",
      "Epoch [16/100], Step [730/1751], Loss: 1.3082\n",
      "Epoch [16/100], Step [740/1751], Loss: 1.3099\n",
      "Epoch [16/100], Step [750/1751], Loss: 1.2920\n",
      "Epoch [16/100], Step [760/1751], Loss: 1.4187\n",
      "Epoch [16/100], Step [770/1751], Loss: 1.3218\n",
      "Epoch [16/100], Step [780/1751], Loss: 1.3021\n",
      "Epoch [16/100], Step [790/1751], Loss: 1.2763\n",
      "Epoch [16/100], Step [800/1751], Loss: 1.3238\n",
      "Epoch [16/100], Step [810/1751], Loss: 1.2562\n",
      "Epoch [16/100], Step [820/1751], Loss: 1.2597\n",
      "Epoch [16/100], Step [830/1751], Loss: 1.3266\n",
      "Epoch [16/100], Step [840/1751], Loss: 1.3294\n",
      "Epoch [16/100], Step [850/1751], Loss: 1.4314\n",
      "Epoch [16/100], Step [860/1751], Loss: 1.1612\n",
      "Epoch [16/100], Step [870/1751], Loss: 1.2815\n",
      "Epoch [16/100], Step [880/1751], Loss: 1.2038\n",
      "Epoch [16/100], Step [890/1751], Loss: 1.2754\n",
      "Epoch [16/100], Step [900/1751], Loss: 1.3744\n",
      "Epoch [16/100], Step [910/1751], Loss: 1.3249\n",
      "Epoch [16/100], Step [920/1751], Loss: 1.4312\n",
      "Epoch [16/100], Step [930/1751], Loss: 1.3323\n",
      "Epoch [16/100], Step [940/1751], Loss: 1.2333\n",
      "Epoch [16/100], Step [950/1751], Loss: 1.3017\n",
      "Epoch [16/100], Step [960/1751], Loss: 1.4053\n",
      "Epoch [16/100], Step [970/1751], Loss: 1.2612\n",
      "Epoch [16/100], Step [980/1751], Loss: 1.4036\n",
      "Epoch [16/100], Step [990/1751], Loss: 1.5762\n",
      "Epoch [16/100], Step [1000/1751], Loss: 1.2243\n",
      "Epoch [16/100], Step [1010/1751], Loss: 1.3691\n",
      "Epoch [16/100], Step [1020/1751], Loss: 1.2542\n",
      "Epoch [16/100], Step [1030/1751], Loss: 1.3079\n",
      "Epoch [16/100], Step [1040/1751], Loss: 1.3134\n",
      "Epoch [16/100], Step [1050/1751], Loss: 1.4211\n",
      "Epoch [16/100], Step [1060/1751], Loss: 1.3936\n",
      "Epoch [16/100], Step [1070/1751], Loss: 1.2018\n",
      "Epoch [16/100], Step [1080/1751], Loss: 1.2993\n",
      "Epoch [16/100], Step [1090/1751], Loss: 1.2237\n",
      "Epoch [16/100], Step [1100/1751], Loss: 1.3611\n",
      "Epoch [16/100], Step [1110/1751], Loss: 1.3641\n",
      "Epoch [16/100], Step [1120/1751], Loss: 1.3315\n",
      "Epoch [16/100], Step [1130/1751], Loss: 1.2027\n",
      "Epoch [16/100], Step [1140/1751], Loss: 1.2609\n",
      "Epoch [16/100], Step [1150/1751], Loss: 1.1674\n",
      "Epoch [16/100], Step [1160/1751], Loss: 1.4360\n",
      "Epoch [16/100], Step [1170/1751], Loss: 1.2049\n",
      "Epoch [16/100], Step [1180/1751], Loss: 1.3753\n",
      "Epoch [16/100], Step [1190/1751], Loss: 1.2220\n",
      "Epoch [16/100], Step [1200/1751], Loss: 1.2340\n",
      "Epoch [16/100], Step [1210/1751], Loss: 1.1955\n",
      "Epoch [16/100], Step [1220/1751], Loss: 1.3462\n",
      "Epoch [16/100], Step [1230/1751], Loss: 1.3524\n",
      "Epoch [16/100], Step [1240/1751], Loss: 1.4408\n",
      "Epoch [16/100], Step [1250/1751], Loss: 1.3161\n",
      "Epoch [16/100], Step [1260/1751], Loss: 1.1811\n",
      "Epoch [16/100], Step [1270/1751], Loss: 1.5680\n",
      "Epoch [16/100], Step [1280/1751], Loss: 1.4527\n",
      "Epoch [16/100], Step [1290/1751], Loss: 1.2965\n",
      "Epoch [16/100], Step [1300/1751], Loss: 1.2721\n",
      "Epoch [16/100], Step [1310/1751], Loss: 1.2862\n",
      "Epoch [16/100], Step [1320/1751], Loss: 1.2971\n",
      "Epoch [16/100], Step [1330/1751], Loss: 1.2814\n",
      "Epoch [16/100], Step [1340/1751], Loss: 1.4147\n",
      "Epoch [16/100], Step [1350/1751], Loss: 1.2753\n",
      "Epoch [16/100], Step [1360/1751], Loss: 1.3149\n",
      "Epoch [16/100], Step [1370/1751], Loss: 1.3540\n",
      "Epoch [16/100], Step [1380/1751], Loss: 1.4675\n",
      "Epoch [16/100], Step [1390/1751], Loss: 1.2852\n",
      "Epoch [16/100], Step [1400/1751], Loss: 1.3375\n",
      "Epoch [16/100], Step [1410/1751], Loss: 1.3246\n",
      "Epoch [16/100], Step [1420/1751], Loss: 1.3861\n",
      "Epoch [16/100], Step [1430/1751], Loss: 1.3931\n",
      "Epoch [16/100], Step [1440/1751], Loss: 1.2833\n",
      "Epoch [16/100], Step [1450/1751], Loss: 1.2403\n",
      "Epoch [16/100], Step [1460/1751], Loss: 1.2427\n",
      "Epoch [16/100], Step [1470/1751], Loss: 1.2948\n",
      "Epoch [16/100], Step [1480/1751], Loss: 1.2853\n",
      "Epoch [16/100], Step [1490/1751], Loss: 1.3242\n",
      "Epoch [16/100], Step [1500/1751], Loss: 1.4495\n",
      "Epoch [16/100], Step [1510/1751], Loss: 1.2707\n",
      "Epoch [16/100], Step [1520/1751], Loss: 1.3642\n",
      "Epoch [16/100], Step [1530/1751], Loss: 1.1964\n",
      "Epoch [16/100], Step [1540/1751], Loss: 1.2982\n",
      "Epoch [16/100], Step [1550/1751], Loss: 1.3052\n",
      "Epoch [16/100], Step [1560/1751], Loss: 1.3125\n",
      "Epoch [16/100], Step [1570/1751], Loss: 1.3073\n",
      "Epoch [16/100], Step [1580/1751], Loss: 1.2986\n",
      "Epoch [16/100], Step [1590/1751], Loss: 1.2558\n",
      "Epoch [16/100], Step [1600/1751], Loss: 1.1764\n",
      "Epoch [16/100], Step [1610/1751], Loss: 1.3334\n",
      "Epoch [16/100], Step [1620/1751], Loss: 1.3228\n",
      "Epoch [16/100], Step [1630/1751], Loss: 1.3258\n",
      "Epoch [16/100], Step [1640/1751], Loss: 1.1606\n",
      "Epoch [16/100], Step [1650/1751], Loss: 1.3893\n",
      "Epoch [16/100], Step [1660/1751], Loss: 1.4002\n",
      "Epoch [16/100], Step [1670/1751], Loss: 1.2123\n",
      "Epoch [16/100], Step [1680/1751], Loss: 1.1995\n",
      "Epoch [16/100], Step [1690/1751], Loss: 1.3852\n",
      "Epoch [16/100], Step [1700/1751], Loss: 1.3714\n",
      "Epoch [16/100], Step [1710/1751], Loss: 1.2759\n",
      "Epoch [16/100], Step [1720/1751], Loss: 1.3816\n",
      "Epoch [16/100], Step [1730/1751], Loss: 1.2242\n",
      "Epoch [16/100], Step [1740/1751], Loss: 1.2735\n",
      "Epoch [16/100], Step [1750/1751], Loss: 1.3237\n",
      "Epoch [16/100], Average Loss: 1.3140, Time: 1637.4860s\n",
      "Epoch [17/100], Step [10/1751], Loss: 1.2929\n",
      "Epoch [17/100], Step [20/1751], Loss: 1.3336\n",
      "Epoch [17/100], Step [30/1751], Loss: 1.2589\n",
      "Epoch [17/100], Step [40/1751], Loss: 1.4008\n",
      "Epoch [17/100], Step [50/1751], Loss: 1.3719\n",
      "Epoch [17/100], Step [60/1751], Loss: 1.1110\n",
      "Epoch [17/100], Step [70/1751], Loss: 1.2099\n",
      "Epoch [17/100], Step [80/1751], Loss: 1.1124\n",
      "Epoch [17/100], Step [90/1751], Loss: 1.3633\n",
      "Epoch [17/100], Step [100/1751], Loss: 1.3459\n",
      "Epoch [17/100], Step [110/1751], Loss: 1.3967\n",
      "Epoch [17/100], Step [120/1751], Loss: 1.3215\n",
      "Epoch [17/100], Step [130/1751], Loss: 1.4148\n",
      "Epoch [17/100], Step [140/1751], Loss: 1.4435\n",
      "Epoch [17/100], Step [150/1751], Loss: 1.2977\n",
      "Epoch [17/100], Step [160/1751], Loss: 1.3850\n",
      "Epoch [17/100], Step [170/1751], Loss: 1.3191\n",
      "Epoch [17/100], Step [180/1751], Loss: 1.3058\n",
      "Epoch [17/100], Step [190/1751], Loss: 1.1503\n",
      "Epoch [17/100], Step [200/1751], Loss: 1.3363\n",
      "Epoch [17/100], Step [210/1751], Loss: 1.1610\n",
      "Epoch [17/100], Step [220/1751], Loss: 1.3584\n",
      "Epoch [17/100], Step [230/1751], Loss: 1.2642\n",
      "Epoch [17/100], Step [240/1751], Loss: 1.2201\n",
      "Epoch [17/100], Step [250/1751], Loss: 1.1993\n",
      "Epoch [17/100], Step [260/1751], Loss: 1.2991\n",
      "Epoch [17/100], Step [270/1751], Loss: 1.2673\n",
      "Epoch [17/100], Step [280/1751], Loss: 1.1545\n",
      "Epoch [17/100], Step [290/1751], Loss: 1.3665\n",
      "Epoch [17/100], Step [300/1751], Loss: 1.3405\n",
      "Epoch [17/100], Step [310/1751], Loss: 1.1539\n",
      "Epoch [17/100], Step [320/1751], Loss: 1.2642\n",
      "Epoch [17/100], Step [330/1751], Loss: 1.4700\n",
      "Epoch [17/100], Step [340/1751], Loss: 1.3933\n",
      "Epoch [17/100], Step [350/1751], Loss: 1.1560\n",
      "Epoch [17/100], Step [360/1751], Loss: 1.3342\n",
      "Epoch [17/100], Step [370/1751], Loss: 1.2171\n",
      "Epoch [17/100], Step [380/1751], Loss: 1.2752\n",
      "Epoch [17/100], Step [390/1751], Loss: 1.4380\n",
      "Epoch [17/100], Step [400/1751], Loss: 1.2776\n",
      "Epoch [17/100], Step [410/1751], Loss: 1.2558\n",
      "Epoch [17/100], Step [420/1751], Loss: 1.1733\n",
      "Epoch [17/100], Step [430/1751], Loss: 1.3617\n",
      "Epoch [17/100], Step [440/1751], Loss: 1.1851\n",
      "Epoch [17/100], Step [450/1751], Loss: 1.2690\n",
      "Epoch [17/100], Step [460/1751], Loss: 1.3039\n",
      "Epoch [17/100], Step [470/1751], Loss: 1.2683\n",
      "Epoch [17/100], Step [480/1751], Loss: 1.2757\n",
      "Epoch [17/100], Step [490/1751], Loss: 1.3250\n",
      "Epoch [17/100], Step [500/1751], Loss: 1.3444\n",
      "Epoch [17/100], Step [510/1751], Loss: 1.2406\n",
      "Epoch [17/100], Step [520/1751], Loss: 1.3164\n",
      "Epoch [17/100], Step [530/1751], Loss: 1.3439\n",
      "Epoch [17/100], Step [540/1751], Loss: 1.4169\n",
      "Epoch [17/100], Step [550/1751], Loss: 1.3547\n",
      "Epoch [17/100], Step [560/1751], Loss: 1.3566\n",
      "Epoch [17/100], Step [570/1751], Loss: 1.4277\n",
      "Epoch [17/100], Step [580/1751], Loss: 1.2567\n",
      "Epoch [17/100], Step [590/1751], Loss: 1.3324\n",
      "Epoch [17/100], Step [600/1751], Loss: 1.4160\n",
      "Epoch [17/100], Step [610/1751], Loss: 1.3413\n",
      "Epoch [17/100], Step [620/1751], Loss: 1.3210\n",
      "Epoch [17/100], Step [630/1751], Loss: 1.3323\n",
      "Epoch [17/100], Step [640/1751], Loss: 1.3829\n",
      "Epoch [17/100], Step [650/1751], Loss: 1.2811\n",
      "Epoch [17/100], Step [660/1751], Loss: 1.4065\n",
      "Epoch [17/100], Step [670/1751], Loss: 1.2607\n",
      "Epoch [17/100], Step [680/1751], Loss: 1.3660\n",
      "Epoch [17/100], Step [690/1751], Loss: 1.2740\n",
      "Epoch [17/100], Step [700/1751], Loss: 1.2679\n",
      "Epoch [17/100], Step [710/1751], Loss: 1.1029\n",
      "Epoch [17/100], Step [720/1751], Loss: 1.2062\n",
      "Epoch [17/100], Step [730/1751], Loss: 1.4099\n",
      "Epoch [17/100], Step [740/1751], Loss: 1.3419\n",
      "Epoch [17/100], Step [750/1751], Loss: 1.3663\n",
      "Epoch [17/100], Step [760/1751], Loss: 1.3695\n",
      "Epoch [17/100], Step [770/1751], Loss: 1.1857\n",
      "Epoch [17/100], Step [780/1751], Loss: 1.2878\n",
      "Epoch [17/100], Step [790/1751], Loss: 1.4581\n",
      "Epoch [17/100], Step [800/1751], Loss: 1.3440\n",
      "Epoch [17/100], Step [810/1751], Loss: 1.2667\n",
      "Epoch [17/100], Step [820/1751], Loss: 1.2922\n",
      "Epoch [17/100], Step [830/1751], Loss: 1.3944\n",
      "Epoch [17/100], Step [840/1751], Loss: 1.2092\n",
      "Epoch [17/100], Step [850/1751], Loss: 1.3282\n",
      "Epoch [17/100], Step [860/1751], Loss: 1.3604\n",
      "Epoch [17/100], Step [870/1751], Loss: 1.3916\n",
      "Epoch [17/100], Step [880/1751], Loss: 1.4148\n",
      "Epoch [17/100], Step [890/1751], Loss: 1.2978\n",
      "Epoch [17/100], Step [900/1751], Loss: 1.3202\n",
      "Epoch [17/100], Step [910/1751], Loss: 1.2628\n",
      "Epoch [17/100], Step [920/1751], Loss: 1.3809\n",
      "Epoch [17/100], Step [930/1751], Loss: 1.3186\n",
      "Epoch [17/100], Step [940/1751], Loss: 1.2494\n",
      "Epoch [17/100], Step [950/1751], Loss: 1.3653\n",
      "Epoch [17/100], Step [960/1751], Loss: 1.2966\n",
      "Epoch [17/100], Step [970/1751], Loss: 1.3807\n",
      "Epoch [17/100], Step [980/1751], Loss: 1.2680\n",
      "Epoch [17/100], Step [990/1751], Loss: 1.3799\n",
      "Epoch [17/100], Step [1000/1751], Loss: 1.1483\n",
      "Epoch [17/100], Step [1010/1751], Loss: 1.3656\n",
      "Epoch [17/100], Step [1020/1751], Loss: 1.3020\n",
      "Epoch [17/100], Step [1030/1751], Loss: 1.3211\n",
      "Epoch [17/100], Step [1040/1751], Loss: 1.3005\n",
      "Epoch [17/100], Step [1050/1751], Loss: 1.2545\n",
      "Epoch [17/100], Step [1060/1751], Loss: 1.2385\n",
      "Epoch [17/100], Step [1070/1751], Loss: 1.1267\n",
      "Epoch [17/100], Step [1080/1751], Loss: 1.2548\n",
      "Epoch [17/100], Step [1090/1751], Loss: 1.3464\n",
      "Epoch [17/100], Step [1100/1751], Loss: 1.3688\n",
      "Epoch [17/100], Step [1110/1751], Loss: 1.3561\n",
      "Epoch [17/100], Step [1120/1751], Loss: 1.2508\n",
      "Epoch [17/100], Step [1130/1751], Loss: 1.1516\n",
      "Epoch [17/100], Step [1140/1751], Loss: 1.4170\n",
      "Epoch [17/100], Step [1150/1751], Loss: 1.3406\n",
      "Epoch [17/100], Step [1160/1751], Loss: 1.3237\n",
      "Epoch [17/100], Step [1170/1751], Loss: 1.1402\n",
      "Epoch [17/100], Step [1180/1751], Loss: 1.4076\n",
      "Epoch [17/100], Step [1190/1751], Loss: 1.2977\n",
      "Epoch [17/100], Step [1200/1751], Loss: 1.3220\n",
      "Epoch [17/100], Step [1210/1751], Loss: 1.3544\n",
      "Epoch [17/100], Step [1220/1751], Loss: 1.2413\n",
      "Epoch [17/100], Step [1230/1751], Loss: 1.2560\n",
      "Epoch [17/100], Step [1240/1751], Loss: 1.2431\n",
      "Epoch [17/100], Step [1250/1751], Loss: 1.1981\n",
      "Epoch [17/100], Step [1260/1751], Loss: 1.3278\n",
      "Epoch [17/100], Step [1270/1751], Loss: 1.2422\n",
      "Epoch [17/100], Step [1280/1751], Loss: 1.1317\n",
      "Epoch [17/100], Step [1290/1751], Loss: 1.2757\n",
      "Epoch [17/100], Step [1300/1751], Loss: 1.2372\n",
      "Epoch [17/100], Step [1310/1751], Loss: 1.2056\n",
      "Epoch [17/100], Step [1320/1751], Loss: 1.4264\n",
      "Epoch [17/100], Step [1330/1751], Loss: 1.3264\n",
      "Epoch [17/100], Step [1340/1751], Loss: 1.3379\n",
      "Epoch [17/100], Step [1350/1751], Loss: 1.4379\n",
      "Epoch [17/100], Step [1360/1751], Loss: 1.2054\n",
      "Epoch [17/100], Step [1370/1751], Loss: 1.3443\n",
      "Epoch [17/100], Step [1380/1751], Loss: 1.3671\n",
      "Epoch [17/100], Step [1390/1751], Loss: 1.3076\n",
      "Epoch [17/100], Step [1400/1751], Loss: 1.2822\n",
      "Epoch [17/100], Step [1410/1751], Loss: 1.4116\n",
      "Epoch [17/100], Step [1420/1751], Loss: 1.4286\n",
      "Epoch [17/100], Step [1430/1751], Loss: 1.3384\n",
      "Epoch [17/100], Step [1440/1751], Loss: 1.3245\n",
      "Epoch [17/100], Step [1450/1751], Loss: 1.2970\n",
      "Epoch [17/100], Step [1460/1751], Loss: 1.2504\n",
      "Epoch [17/100], Step [1470/1751], Loss: 1.2674\n",
      "Epoch [17/100], Step [1480/1751], Loss: 1.2268\n",
      "Epoch [17/100], Step [1490/1751], Loss: 1.4387\n",
      "Epoch [17/100], Step [1500/1751], Loss: 1.3230\n",
      "Epoch [17/100], Step [1510/1751], Loss: 1.2204\n",
      "Epoch [17/100], Step [1520/1751], Loss: 1.2142\n",
      "Epoch [17/100], Step [1530/1751], Loss: 1.3470\n",
      "Epoch [17/100], Step [1540/1751], Loss: 1.3128\n",
      "Epoch [17/100], Step [1550/1751], Loss: 1.1620\n",
      "Epoch [17/100], Step [1560/1751], Loss: 1.2447\n",
      "Epoch [17/100], Step [1570/1751], Loss: 1.3128\n",
      "Epoch [17/100], Step [1580/1751], Loss: 1.3179\n",
      "Epoch [17/100], Step [1590/1751], Loss: 1.1859\n",
      "Epoch [17/100], Step [1600/1751], Loss: 1.2323\n",
      "Epoch [17/100], Step [1610/1751], Loss: 1.2836\n",
      "Epoch [17/100], Step [1620/1751], Loss: 1.3476\n",
      "Epoch [17/100], Step [1630/1751], Loss: 1.2768\n",
      "Epoch [17/100], Step [1640/1751], Loss: 1.3932\n",
      "Epoch [17/100], Step [1650/1751], Loss: 1.2343\n",
      "Epoch [17/100], Step [1660/1751], Loss: 1.3964\n",
      "Epoch [17/100], Step [1670/1751], Loss: 1.1926\n",
      "Epoch [17/100], Step [1680/1751], Loss: 1.1603\n",
      "Epoch [17/100], Step [1690/1751], Loss: 1.2566\n",
      "Epoch [17/100], Step [1700/1751], Loss: 1.3546\n",
      "Epoch [17/100], Step [1710/1751], Loss: 1.3496\n",
      "Epoch [17/100], Step [1720/1751], Loss: 1.2683\n",
      "Epoch [17/100], Step [1730/1751], Loss: 1.3001\n",
      "Epoch [17/100], Step [1740/1751], Loss: 1.3289\n",
      "Epoch [17/100], Step [1750/1751], Loss: 1.2930\n",
      "Epoch [17/100], Average Loss: 1.3043, Time: 1638.1556s\n",
      "Epoch [18/100], Step [10/1751], Loss: 1.3295\n",
      "Epoch [18/100], Step [20/1751], Loss: 1.2948\n",
      "Epoch [18/100], Step [30/1751], Loss: 1.3151\n",
      "Epoch [18/100], Step [40/1751], Loss: 1.2350\n",
      "Epoch [18/100], Step [50/1751], Loss: 1.2649\n",
      "Epoch [18/100], Step [60/1751], Loss: 1.3133\n",
      "Epoch [18/100], Step [70/1751], Loss: 1.2604\n",
      "Epoch [18/100], Step [80/1751], Loss: 1.3034\n",
      "Epoch [18/100], Step [90/1751], Loss: 1.3581\n",
      "Epoch [18/100], Step [100/1751], Loss: 1.3769\n",
      "Epoch [18/100], Step [110/1751], Loss: 1.2502\n",
      "Epoch [18/100], Step [120/1751], Loss: 1.3201\n",
      "Epoch [18/100], Step [130/1751], Loss: 1.2441\n",
      "Epoch [18/100], Step [140/1751], Loss: 1.2769\n",
      "Epoch [18/100], Step [150/1751], Loss: 1.2890\n",
      "Epoch [18/100], Step [160/1751], Loss: 1.3063\n",
      "Epoch [18/100], Step [170/1751], Loss: 1.1335\n",
      "Epoch [18/100], Step [180/1751], Loss: 1.5279\n",
      "Epoch [18/100], Step [190/1751], Loss: 1.3076\n",
      "Epoch [18/100], Step [200/1751], Loss: 1.2333\n",
      "Epoch [18/100], Step [210/1751], Loss: 1.2479\n",
      "Epoch [18/100], Step [220/1751], Loss: 1.3917\n",
      "Epoch [18/100], Step [230/1751], Loss: 1.2808\n",
      "Epoch [18/100], Step [240/1751], Loss: 1.3371\n",
      "Epoch [18/100], Step [250/1751], Loss: 1.3951\n",
      "Epoch [18/100], Step [260/1751], Loss: 1.4217\n",
      "Epoch [18/100], Step [270/1751], Loss: 1.4336\n",
      "Epoch [18/100], Step [280/1751], Loss: 1.4086\n",
      "Epoch [18/100], Step [290/1751], Loss: 1.1952\n",
      "Epoch [18/100], Step [300/1751], Loss: 1.1052\n",
      "Epoch [18/100], Step [310/1751], Loss: 1.1710\n",
      "Epoch [18/100], Step [320/1751], Loss: 1.2147\n",
      "Epoch [18/100], Step [330/1751], Loss: 1.2889\n",
      "Epoch [18/100], Step [340/1751], Loss: 1.3562\n",
      "Epoch [18/100], Step [350/1751], Loss: 1.1366\n",
      "Epoch [18/100], Step [360/1751], Loss: 1.2983\n",
      "Epoch [18/100], Step [370/1751], Loss: 1.1747\n",
      "Epoch [18/100], Step [380/1751], Loss: 1.1919\n",
      "Epoch [18/100], Step [390/1751], Loss: 1.2336\n",
      "Epoch [18/100], Step [400/1751], Loss: 1.1074\n",
      "Epoch [18/100], Step [410/1751], Loss: 1.2015\n",
      "Epoch [18/100], Step [420/1751], Loss: 1.3174\n",
      "Epoch [18/100], Step [430/1751], Loss: 1.1920\n",
      "Epoch [18/100], Step [440/1751], Loss: 1.3145\n",
      "Epoch [18/100], Step [450/1751], Loss: 1.4277\n",
      "Epoch [18/100], Step [460/1751], Loss: 1.3467\n",
      "Epoch [18/100], Step [470/1751], Loss: 1.3165\n",
      "Epoch [18/100], Step [480/1751], Loss: 1.4456\n",
      "Epoch [18/100], Step [490/1751], Loss: 1.2741\n",
      "Epoch [18/100], Step [500/1751], Loss: 1.4068\n",
      "Epoch [18/100], Step [510/1751], Loss: 1.2932\n",
      "Epoch [18/100], Step [520/1751], Loss: 1.2372\n",
      "Epoch [18/100], Step [530/1751], Loss: 1.3009\n",
      "Epoch [18/100], Step [540/1751], Loss: 1.1221\n",
      "Epoch [18/100], Step [550/1751], Loss: 1.4524\n",
      "Epoch [18/100], Step [560/1751], Loss: 1.2433\n",
      "Epoch [18/100], Step [570/1751], Loss: 1.4466\n",
      "Epoch [18/100], Step [580/1751], Loss: 1.3793\n",
      "Epoch [18/100], Step [590/1751], Loss: 1.2880\n",
      "Epoch [18/100], Step [600/1751], Loss: 1.2973\n",
      "Epoch [18/100], Step [610/1751], Loss: 1.4093\n",
      "Epoch [18/100], Step [620/1751], Loss: 1.2679\n",
      "Epoch [18/100], Step [630/1751], Loss: 1.2612\n",
      "Epoch [18/100], Step [640/1751], Loss: 1.3365\n",
      "Epoch [18/100], Step [650/1751], Loss: 1.2514\n",
      "Epoch [18/100], Step [660/1751], Loss: 1.1950\n",
      "Epoch [18/100], Step [670/1751], Loss: 1.4049\n",
      "Epoch [18/100], Step [680/1751], Loss: 1.2128\n",
      "Epoch [18/100], Step [690/1751], Loss: 1.3620\n",
      "Epoch [18/100], Step [700/1751], Loss: 1.1603\n",
      "Epoch [18/100], Step [710/1751], Loss: 1.2241\n",
      "Epoch [18/100], Step [720/1751], Loss: 1.3446\n",
      "Epoch [18/100], Step [730/1751], Loss: 1.3318\n",
      "Epoch [18/100], Step [740/1751], Loss: 1.3118\n",
      "Epoch [18/100], Step [750/1751], Loss: 1.3365\n",
      "Epoch [18/100], Step [760/1751], Loss: 1.2571\n",
      "Epoch [18/100], Step [770/1751], Loss: 1.3009\n",
      "Epoch [18/100], Step [780/1751], Loss: 1.3361\n",
      "Epoch [18/100], Step [790/1751], Loss: 1.3139\n",
      "Epoch [18/100], Step [800/1751], Loss: 1.3763\n",
      "Epoch [18/100], Step [810/1751], Loss: 1.2034\n",
      "Epoch [18/100], Step [820/1751], Loss: 1.5059\n",
      "Epoch [18/100], Step [830/1751], Loss: 1.3098\n",
      "Epoch [18/100], Step [840/1751], Loss: 1.5059\n",
      "Epoch [18/100], Step [850/1751], Loss: 1.2182\n",
      "Epoch [18/100], Step [860/1751], Loss: 1.2443\n",
      "Epoch [18/100], Step [870/1751], Loss: 1.2746\n",
      "Epoch [18/100], Step [880/1751], Loss: 1.2214\n",
      "Epoch [18/100], Step [890/1751], Loss: 1.2152\n",
      "Epoch [18/100], Step [900/1751], Loss: 1.2759\n",
      "Epoch [18/100], Step [910/1751], Loss: 1.4315\n",
      "Epoch [18/100], Step [920/1751], Loss: 1.3257\n",
      "Epoch [18/100], Step [930/1751], Loss: 1.2966\n",
      "Epoch [18/100], Step [940/1751], Loss: 1.3436\n",
      "Epoch [18/100], Step [950/1751], Loss: 1.3165\n",
      "Epoch [18/100], Step [960/1751], Loss: 1.3616\n",
      "Epoch [18/100], Step [970/1751], Loss: 1.2753\n",
      "Epoch [18/100], Step [980/1751], Loss: 1.1335\n",
      "Epoch [18/100], Step [990/1751], Loss: 1.3092\n",
      "Epoch [18/100], Step [1000/1751], Loss: 1.2150\n",
      "Epoch [18/100], Step [1010/1751], Loss: 1.2306\n",
      "Epoch [18/100], Step [1020/1751], Loss: 1.3514\n",
      "Epoch [18/100], Step [1030/1751], Loss: 1.3471\n",
      "Epoch [18/100], Step [1040/1751], Loss: 1.2384\n",
      "Epoch [18/100], Step [1050/1751], Loss: 1.3495\n",
      "Epoch [18/100], Step [1060/1751], Loss: 1.2655\n",
      "Epoch [18/100], Step [1070/1751], Loss: 1.4087\n",
      "Epoch [18/100], Step [1080/1751], Loss: 1.0649\n",
      "Epoch [18/100], Step [1090/1751], Loss: 1.2965\n",
      "Epoch [18/100], Step [1100/1751], Loss: 1.3738\n",
      "Epoch [18/100], Step [1110/1751], Loss: 1.3309\n",
      "Epoch [18/100], Step [1120/1751], Loss: 1.4615\n",
      "Epoch [18/100], Step [1130/1751], Loss: 1.3764\n",
      "Epoch [18/100], Step [1140/1751], Loss: 1.2311\n",
      "Epoch [18/100], Step [1150/1751], Loss: 1.2800\n",
      "Epoch [18/100], Step [1160/1751], Loss: 1.3156\n",
      "Epoch [18/100], Step [1170/1751], Loss: 1.3109\n",
      "Epoch [18/100], Step [1180/1751], Loss: 1.3814\n",
      "Epoch [18/100], Step [1190/1751], Loss: 1.2780\n",
      "Epoch [18/100], Step [1200/1751], Loss: 1.2191\n",
      "Epoch [18/100], Step [1210/1751], Loss: 1.4314\n",
      "Epoch [18/100], Step [1220/1751], Loss: 1.2769\n",
      "Epoch [18/100], Step [1230/1751], Loss: 1.2163\n",
      "Epoch [18/100], Step [1240/1751], Loss: 1.2480\n",
      "Epoch [18/100], Step [1250/1751], Loss: 1.3485\n",
      "Epoch [18/100], Step [1260/1751], Loss: 1.2625\n",
      "Epoch [18/100], Step [1270/1751], Loss: 1.4052\n",
      "Epoch [18/100], Step [1280/1751], Loss: 1.3430\n",
      "Epoch [18/100], Step [1290/1751], Loss: 1.4240\n",
      "Epoch [18/100], Step [1300/1751], Loss: 1.2579\n",
      "Epoch [18/100], Step [1310/1751], Loss: 1.3377\n",
      "Epoch [18/100], Step [1320/1751], Loss: 1.2307\n",
      "Epoch [18/100], Step [1330/1751], Loss: 1.4132\n",
      "Epoch [18/100], Step [1340/1751], Loss: 1.3414\n",
      "Epoch [18/100], Step [1350/1751], Loss: 1.3397\n",
      "Epoch [18/100], Step [1360/1751], Loss: 1.3751\n",
      "Epoch [18/100], Step [1370/1751], Loss: 1.3739\n",
      "Epoch [18/100], Step [1380/1751], Loss: 1.2548\n",
      "Epoch [18/100], Step [1390/1751], Loss: 1.2174\n",
      "Epoch [18/100], Step [1400/1751], Loss: 1.1987\n",
      "Epoch [18/100], Step [1410/1751], Loss: 1.2694\n",
      "Epoch [18/100], Step [1420/1751], Loss: 1.3268\n",
      "Epoch [18/100], Step [1430/1751], Loss: 1.1769\n",
      "Epoch [18/100], Step [1440/1751], Loss: 1.5128\n",
      "Epoch [18/100], Step [1450/1751], Loss: 1.2773\n",
      "Epoch [18/100], Step [1460/1751], Loss: 1.2888\n",
      "Epoch [18/100], Step [1470/1751], Loss: 1.3514\n",
      "Epoch [18/100], Step [1480/1751], Loss: 1.2121\n",
      "Epoch [18/100], Step [1490/1751], Loss: 1.1909\n",
      "Epoch [18/100], Step [1500/1751], Loss: 1.2773\n",
      "Epoch [18/100], Step [1510/1751], Loss: 1.1871\n",
      "Epoch [18/100], Step [1520/1751], Loss: 1.2242\n",
      "Epoch [18/100], Step [1530/1751], Loss: 1.2962\n",
      "Epoch [18/100], Step [1540/1751], Loss: 1.3061\n",
      "Epoch [18/100], Step [1550/1751], Loss: 1.2610\n",
      "Epoch [18/100], Step [1560/1751], Loss: 1.3413\n",
      "Epoch [18/100], Step [1570/1751], Loss: 1.3732\n",
      "Epoch [18/100], Step [1580/1751], Loss: 1.3718\n",
      "Epoch [18/100], Step [1590/1751], Loss: 1.2918\n",
      "Epoch [18/100], Step [1600/1751], Loss: 1.3690\n",
      "Epoch [18/100], Step [1610/1751], Loss: 1.3438\n",
      "Epoch [18/100], Step [1620/1751], Loss: 1.1474\n",
      "Epoch [18/100], Step [1630/1751], Loss: 1.3371\n",
      "Epoch [18/100], Step [1640/1751], Loss: 1.3441\n",
      "Epoch [18/100], Step [1650/1751], Loss: 1.3260\n",
      "Epoch [18/100], Step [1660/1751], Loss: 1.3584\n",
      "Epoch [18/100], Step [1670/1751], Loss: 1.2940\n",
      "Epoch [18/100], Step [1680/1751], Loss: 1.2325\n",
      "Epoch [18/100], Step [1690/1751], Loss: 1.3173\n",
      "Epoch [18/100], Step [1700/1751], Loss: 1.3536\n",
      "Epoch [18/100], Step [1710/1751], Loss: 1.2451\n",
      "Epoch [18/100], Step [1720/1751], Loss: 1.3458\n",
      "Epoch [18/100], Step [1730/1751], Loss: 1.2975\n",
      "Epoch [18/100], Step [1740/1751], Loss: 1.1751\n",
      "Epoch [18/100], Step [1750/1751], Loss: 1.2253\n",
      "Epoch [18/100], Average Loss: 1.2964, Time: 1637.8732s\n",
      "Epoch [19/100], Step [10/1751], Loss: 1.2499\n",
      "Epoch [19/100], Step [20/1751], Loss: 1.0918\n",
      "Epoch [19/100], Step [30/1751], Loss: 1.2675\n",
      "Epoch [19/100], Step [40/1751], Loss: 1.2665\n",
      "Epoch [19/100], Step [50/1751], Loss: 1.3648\n",
      "Epoch [19/100], Step [60/1751], Loss: 1.4342\n",
      "Epoch [19/100], Step [70/1751], Loss: 1.3814\n",
      "Epoch [19/100], Step [80/1751], Loss: 1.3453\n",
      "Epoch [19/100], Step [90/1751], Loss: 1.2482\n",
      "Epoch [19/100], Step [100/1751], Loss: 1.3483\n",
      "Epoch [19/100], Step [110/1751], Loss: 1.2918\n",
      "Epoch [19/100], Step [120/1751], Loss: 1.2260\n",
      "Epoch [19/100], Step [130/1751], Loss: 1.2572\n",
      "Epoch [19/100], Step [140/1751], Loss: 1.1832\n",
      "Epoch [19/100], Step [150/1751], Loss: 1.3685\n",
      "Epoch [19/100], Step [160/1751], Loss: 1.3119\n",
      "Epoch [19/100], Step [170/1751], Loss: 1.3017\n",
      "Epoch [19/100], Step [180/1751], Loss: 1.2646\n",
      "Epoch [19/100], Step [190/1751], Loss: 1.3388\n",
      "Epoch [19/100], Step [200/1751], Loss: 1.4119\n",
      "Epoch [19/100], Step [210/1751], Loss: 1.2804\n",
      "Epoch [19/100], Step [220/1751], Loss: 1.3387\n",
      "Epoch [19/100], Step [230/1751], Loss: 1.2921\n",
      "Epoch [19/100], Step [240/1751], Loss: 1.2506\n",
      "Epoch [19/100], Step [250/1751], Loss: 1.1637\n",
      "Epoch [19/100], Step [260/1751], Loss: 1.2653\n",
      "Epoch [19/100], Step [270/1751], Loss: 1.2820\n",
      "Epoch [19/100], Step [280/1751], Loss: 1.3027\n",
      "Epoch [19/100], Step [290/1751], Loss: 1.3892\n",
      "Epoch [19/100], Step [300/1751], Loss: 1.2232\n",
      "Epoch [19/100], Step [310/1751], Loss: 1.4216\n",
      "Epoch [19/100], Step [320/1751], Loss: 1.2330\n",
      "Epoch [19/100], Step [330/1751], Loss: 1.1931\n",
      "Epoch [19/100], Step [340/1751], Loss: 1.2495\n",
      "Epoch [19/100], Step [350/1751], Loss: 1.3527\n",
      "Epoch [19/100], Step [360/1751], Loss: 1.2792\n",
      "Epoch [19/100], Step [370/1751], Loss: 1.2663\n",
      "Epoch [19/100], Step [380/1751], Loss: 1.3334\n",
      "Epoch [19/100], Step [390/1751], Loss: 1.3921\n",
      "Epoch [19/100], Step [400/1751], Loss: 1.2998\n",
      "Epoch [19/100], Step [410/1751], Loss: 1.1454\n",
      "Epoch [19/100], Step [420/1751], Loss: 1.2830\n",
      "Epoch [19/100], Step [430/1751], Loss: 1.2666\n",
      "Epoch [19/100], Step [440/1751], Loss: 1.2851\n",
      "Epoch [19/100], Step [450/1751], Loss: 1.3731\n",
      "Epoch [19/100], Step [460/1751], Loss: 1.1127\n",
      "Epoch [19/100], Step [470/1751], Loss: 1.2008\n",
      "Epoch [19/100], Step [480/1751], Loss: 1.4326\n",
      "Epoch [19/100], Step [490/1751], Loss: 1.3277\n",
      "Epoch [19/100], Step [500/1751], Loss: 1.3549\n",
      "Epoch [19/100], Step [510/1751], Loss: 1.2826\n",
      "Epoch [19/100], Step [520/1751], Loss: 1.2907\n",
      "Epoch [19/100], Step [530/1751], Loss: 1.2555\n",
      "Epoch [19/100], Step [540/1751], Loss: 1.2225\n",
      "Epoch [19/100], Step [550/1751], Loss: 1.2741\n",
      "Epoch [19/100], Step [560/1751], Loss: 1.3029\n",
      "Epoch [19/100], Step [570/1751], Loss: 1.3669\n",
      "Epoch [19/100], Step [580/1751], Loss: 1.2727\n",
      "Epoch [19/100], Step [590/1751], Loss: 1.1661\n",
      "Epoch [19/100], Step [600/1751], Loss: 1.3862\n",
      "Epoch [19/100], Step [610/1751], Loss: 1.2648\n",
      "Epoch [19/100], Step [620/1751], Loss: 1.2988\n",
      "Epoch [19/100], Step [630/1751], Loss: 1.2056\n",
      "Epoch [19/100], Step [640/1751], Loss: 1.2157\n",
      "Epoch [19/100], Step [650/1751], Loss: 1.2971\n",
      "Epoch [19/100], Step [660/1751], Loss: 1.3835\n",
      "Epoch [19/100], Step [670/1751], Loss: 1.4154\n",
      "Epoch [19/100], Step [680/1751], Loss: 1.2361\n",
      "Epoch [19/100], Step [690/1751], Loss: 1.2362\n",
      "Epoch [19/100], Step [700/1751], Loss: 1.3118\n",
      "Epoch [19/100], Step [710/1751], Loss: 1.2604\n",
      "Epoch [19/100], Step [720/1751], Loss: 1.3878\n",
      "Epoch [19/100], Step [730/1751], Loss: 1.3267\n",
      "Epoch [19/100], Step [740/1751], Loss: 1.4247\n",
      "Epoch [19/100], Step [750/1751], Loss: 1.1834\n",
      "Epoch [19/100], Step [760/1751], Loss: 1.2578\n",
      "Epoch [19/100], Step [770/1751], Loss: 1.2748\n",
      "Epoch [19/100], Step [780/1751], Loss: 1.3483\n",
      "Epoch [19/100], Step [790/1751], Loss: 1.4361\n",
      "Epoch [19/100], Step [800/1751], Loss: 1.2539\n",
      "Epoch [19/100], Step [810/1751], Loss: 1.3293\n",
      "Epoch [19/100], Step [820/1751], Loss: 1.1125\n",
      "Epoch [19/100], Step [830/1751], Loss: 1.2139\n",
      "Epoch [19/100], Step [840/1751], Loss: 1.1678\n",
      "Epoch [19/100], Step [850/1751], Loss: 1.4174\n",
      "Epoch [19/100], Step [860/1751], Loss: 1.1944\n",
      "Epoch [19/100], Step [870/1751], Loss: 1.2448\n",
      "Epoch [19/100], Step [880/1751], Loss: 1.3262\n",
      "Epoch [19/100], Step [890/1751], Loss: 1.1335\n",
      "Epoch [19/100], Step [900/1751], Loss: 1.2845\n",
      "Epoch [19/100], Step [910/1751], Loss: 1.1669\n",
      "Epoch [19/100], Step [920/1751], Loss: 1.4051\n",
      "Epoch [19/100], Step [930/1751], Loss: 1.2236\n",
      "Epoch [19/100], Step [940/1751], Loss: 1.3330\n",
      "Epoch [19/100], Step [950/1751], Loss: 1.5054\n",
      "Epoch [19/100], Step [960/1751], Loss: 1.2198\n",
      "Epoch [19/100], Step [970/1751], Loss: 1.2485\n",
      "Epoch [19/100], Step [980/1751], Loss: 1.2979\n",
      "Epoch [19/100], Step [990/1751], Loss: 1.2505\n",
      "Epoch [19/100], Step [1000/1751], Loss: 1.3401\n",
      "Epoch [19/100], Step [1010/1751], Loss: 1.4170\n",
      "Epoch [19/100], Step [1020/1751], Loss: 1.1404\n",
      "Epoch [19/100], Step [1030/1751], Loss: 1.2322\n",
      "Epoch [19/100], Step [1040/1751], Loss: 1.1705\n",
      "Epoch [19/100], Step [1050/1751], Loss: 1.4011\n",
      "Epoch [19/100], Step [1060/1751], Loss: 1.2197\n",
      "Epoch [19/100], Step [1070/1751], Loss: 1.2319\n",
      "Epoch [19/100], Step [1080/1751], Loss: 1.2111\n",
      "Epoch [19/100], Step [1090/1751], Loss: 1.2989\n",
      "Epoch [19/100], Step [1100/1751], Loss: 1.2704\n",
      "Epoch [19/100], Step [1110/1751], Loss: 1.2608\n",
      "Epoch [19/100], Step [1120/1751], Loss: 1.4311\n",
      "Epoch [19/100], Step [1130/1751], Loss: 1.1340\n",
      "Epoch [19/100], Step [1140/1751], Loss: 1.1534\n",
      "Epoch [19/100], Step [1150/1751], Loss: 1.3180\n",
      "Epoch [19/100], Step [1160/1751], Loss: 1.1446\n",
      "Epoch [19/100], Step [1170/1751], Loss: 1.2886\n",
      "Epoch [19/100], Step [1180/1751], Loss: 1.2538\n",
      "Epoch [19/100], Step [1190/1751], Loss: 1.2551\n",
      "Epoch [19/100], Step [1200/1751], Loss: 1.2580\n",
      "Epoch [19/100], Step [1210/1751], Loss: 1.4580\n",
      "Epoch [19/100], Step [1220/1751], Loss: 1.2126\n",
      "Epoch [19/100], Step [1230/1751], Loss: 1.1614\n",
      "Epoch [19/100], Step [1240/1751], Loss: 1.1668\n",
      "Epoch [19/100], Step [1250/1751], Loss: 1.2958\n",
      "Epoch [19/100], Step [1260/1751], Loss: 1.3277\n",
      "Epoch [19/100], Step [1270/1751], Loss: 1.1336\n",
      "Epoch [19/100], Step [1280/1751], Loss: 1.2302\n",
      "Epoch [19/100], Step [1290/1751], Loss: 1.2858\n",
      "Epoch [19/100], Step [1300/1751], Loss: 1.2952\n",
      "Epoch [19/100], Step [1310/1751], Loss: 1.1893\n",
      "Epoch [19/100], Step [1320/1751], Loss: 1.3060\n",
      "Epoch [19/100], Step [1330/1751], Loss: 1.1968\n",
      "Epoch [19/100], Step [1340/1751], Loss: 1.1302\n",
      "Epoch [19/100], Step [1350/1751], Loss: 1.3382\n",
      "Epoch [19/100], Step [1360/1751], Loss: 1.2739\n",
      "Epoch [19/100], Step [1370/1751], Loss: 1.3029\n",
      "Epoch [19/100], Step [1380/1751], Loss: 1.2194\n",
      "Epoch [19/100], Step [1390/1751], Loss: 1.2388\n",
      "Epoch [19/100], Step [1400/1751], Loss: 1.2492\n",
      "Epoch [19/100], Step [1410/1751], Loss: 1.2158\n",
      "Epoch [19/100], Step [1420/1751], Loss: 1.2941\n",
      "Epoch [19/100], Step [1430/1751], Loss: 1.2843\n",
      "Epoch [19/100], Step [1440/1751], Loss: 1.2972\n",
      "Epoch [19/100], Step [1450/1751], Loss: 1.3889\n",
      "Epoch [19/100], Step [1460/1751], Loss: 1.3614\n",
      "Epoch [19/100], Step [1470/1751], Loss: 1.3488\n",
      "Epoch [19/100], Step [1480/1751], Loss: 1.3251\n",
      "Epoch [19/100], Step [1490/1751], Loss: 1.4044\n",
      "Epoch [19/100], Step [1500/1751], Loss: 1.2368\n",
      "Epoch [19/100], Step [1510/1751], Loss: 1.1964\n",
      "Epoch [19/100], Step [1520/1751], Loss: 1.3637\n",
      "Epoch [19/100], Step [1530/1751], Loss: 1.1794\n",
      "Epoch [19/100], Step [1540/1751], Loss: 1.2003\n",
      "Epoch [19/100], Step [1550/1751], Loss: 1.2622\n",
      "Epoch [19/100], Step [1560/1751], Loss: 1.3415\n",
      "Epoch [19/100], Step [1570/1751], Loss: 1.2369\n",
      "Epoch [19/100], Step [1580/1751], Loss: 1.2927\n",
      "Epoch [19/100], Step [1590/1751], Loss: 1.3221\n",
      "Epoch [19/100], Step [1600/1751], Loss: 1.2049\n",
      "Epoch [19/100], Step [1610/1751], Loss: 1.2607\n",
      "Epoch [19/100], Step [1620/1751], Loss: 1.2225\n",
      "Epoch [19/100], Step [1630/1751], Loss: 1.1696\n",
      "Epoch [19/100], Step [1640/1751], Loss: 1.4113\n",
      "Epoch [19/100], Step [1650/1751], Loss: 1.2363\n",
      "Epoch [19/100], Step [1660/1751], Loss: 1.2864\n",
      "Epoch [19/100], Step [1670/1751], Loss: 1.3883\n",
      "Epoch [19/100], Step [1680/1751], Loss: 1.2562\n",
      "Epoch [19/100], Step [1690/1751], Loss: 1.3418\n",
      "Epoch [19/100], Step [1700/1751], Loss: 1.2886\n",
      "Epoch [19/100], Step [1710/1751], Loss: 1.2571\n",
      "Epoch [19/100], Step [1720/1751], Loss: 1.3802\n",
      "Epoch [19/100], Step [1730/1751], Loss: 1.2598\n",
      "Epoch [19/100], Step [1740/1751], Loss: 1.2193\n",
      "Epoch [19/100], Step [1750/1751], Loss: 1.2419\n",
      "Epoch [19/100], Average Loss: 1.2895, Time: 1638.1579s\n",
      "Epoch [20/100], Step [10/1751], Loss: 1.1296\n",
      "Epoch [20/100], Step [20/1751], Loss: 1.2529\n",
      "Epoch [20/100], Step [30/1751], Loss: 1.3970\n",
      "Epoch [20/100], Step [40/1751], Loss: 1.2719\n",
      "Epoch [20/100], Step [50/1751], Loss: 1.1635\n",
      "Epoch [20/100], Step [60/1751], Loss: 1.3352\n",
      "Epoch [20/100], Step [70/1751], Loss: 1.2394\n",
      "Epoch [20/100], Step [80/1751], Loss: 1.2614\n",
      "Epoch [20/100], Step [90/1751], Loss: 1.4368\n",
      "Epoch [20/100], Step [100/1751], Loss: 1.3135\n",
      "Epoch [20/100], Step [110/1751], Loss: 1.2860\n",
      "Epoch [20/100], Step [120/1751], Loss: 1.3652\n",
      "Epoch [20/100], Step [130/1751], Loss: 1.2816\n",
      "Epoch [20/100], Step [140/1751], Loss: 1.2860\n",
      "Epoch [20/100], Step [150/1751], Loss: 1.3332\n",
      "Epoch [20/100], Step [160/1751], Loss: 1.1960\n",
      "Epoch [20/100], Step [170/1751], Loss: 1.2942\n",
      "Epoch [20/100], Step [180/1751], Loss: 1.3918\n",
      "Epoch [20/100], Step [190/1751], Loss: 1.2383\n",
      "Epoch [20/100], Step [200/1751], Loss: 1.3675\n",
      "Epoch [20/100], Step [210/1751], Loss: 1.2273\n",
      "Epoch [20/100], Step [220/1751], Loss: 1.3445\n",
      "Epoch [20/100], Step [230/1751], Loss: 1.2899\n",
      "Epoch [20/100], Step [240/1751], Loss: 1.2012\n",
      "Epoch [20/100], Step [250/1751], Loss: 1.5109\n",
      "Epoch [20/100], Step [260/1751], Loss: 1.2993\n",
      "Epoch [20/100], Step [270/1751], Loss: 1.1978\n",
      "Epoch [20/100], Step [280/1751], Loss: 1.3501\n",
      "Epoch [20/100], Step [290/1751], Loss: 1.3702\n",
      "Epoch [20/100], Step [300/1751], Loss: 1.1633\n",
      "Epoch [20/100], Step [310/1751], Loss: 1.2141\n",
      "Epoch [20/100], Step [320/1751], Loss: 1.1543\n",
      "Epoch [20/100], Step [330/1751], Loss: 1.1867\n",
      "Epoch [20/100], Step [340/1751], Loss: 1.2571\n",
      "Epoch [20/100], Step [350/1751], Loss: 1.4313\n",
      "Epoch [20/100], Step [360/1751], Loss: 1.4961\n",
      "Epoch [20/100], Step [370/1751], Loss: 1.3263\n",
      "Epoch [20/100], Step [380/1751], Loss: 1.3628\n",
      "Epoch [20/100], Step [390/1751], Loss: 1.3191\n",
      "Epoch [20/100], Step [400/1751], Loss: 1.2923\n",
      "Epoch [20/100], Step [410/1751], Loss: 1.2638\n",
      "Epoch [20/100], Step [420/1751], Loss: 1.2201\n",
      "Epoch [20/100], Step [430/1751], Loss: 1.2080\n",
      "Epoch [20/100], Step [440/1751], Loss: 1.2374\n",
      "Epoch [20/100], Step [450/1751], Loss: 1.3272\n",
      "Epoch [20/100], Step [460/1751], Loss: 1.2634\n",
      "Epoch [20/100], Step [470/1751], Loss: 1.2743\n",
      "Epoch [20/100], Step [480/1751], Loss: 1.2142\n",
      "Epoch [20/100], Step [490/1751], Loss: 1.3041\n",
      "Epoch [20/100], Step [500/1751], Loss: 1.1994\n",
      "Epoch [20/100], Step [510/1751], Loss: 1.2034\n",
      "Epoch [20/100], Step [520/1751], Loss: 1.3958\n",
      "Epoch [20/100], Step [530/1751], Loss: 1.2497\n",
      "Epoch [20/100], Step [540/1751], Loss: 1.5036\n",
      "Epoch [20/100], Step [550/1751], Loss: 1.3167\n",
      "Epoch [20/100], Step [560/1751], Loss: 1.2898\n",
      "Epoch [20/100], Step [570/1751], Loss: 1.2872\n",
      "Epoch [20/100], Step [580/1751], Loss: 1.2767\n",
      "Epoch [20/100], Step [590/1751], Loss: 1.0573\n",
      "Epoch [20/100], Step [600/1751], Loss: 1.2625\n",
      "Epoch [20/100], Step [610/1751], Loss: 1.2640\n",
      "Epoch [20/100], Step [620/1751], Loss: 1.3278\n",
      "Epoch [20/100], Step [630/1751], Loss: 1.3269\n",
      "Epoch [20/100], Step [640/1751], Loss: 1.2394\n",
      "Epoch [20/100], Step [650/1751], Loss: 1.2844\n",
      "Epoch [20/100], Step [660/1751], Loss: 1.2772\n",
      "Epoch [20/100], Step [670/1751], Loss: 1.3063\n",
      "Epoch [20/100], Step [680/1751], Loss: 1.2942\n",
      "Epoch [20/100], Step [690/1751], Loss: 1.2049\n",
      "Epoch [20/100], Step [700/1751], Loss: 1.2785\n",
      "Epoch [20/100], Step [710/1751], Loss: 1.2963\n",
      "Epoch [20/100], Step [720/1751], Loss: 1.2434\n",
      "Epoch [20/100], Step [730/1751], Loss: 1.2512\n",
      "Epoch [20/100], Step [740/1751], Loss: 1.3088\n",
      "Epoch [20/100], Step [750/1751], Loss: 1.2988\n",
      "Epoch [20/100], Step [760/1751], Loss: 1.1852\n",
      "Epoch [20/100], Step [770/1751], Loss: 1.3833\n",
      "Epoch [20/100], Step [780/1751], Loss: 1.3681\n",
      "Epoch [20/100], Step [790/1751], Loss: 1.2690\n",
      "Epoch [20/100], Step [800/1751], Loss: 1.3642\n",
      "Epoch [20/100], Step [810/1751], Loss: 1.2297\n",
      "Epoch [20/100], Step [820/1751], Loss: 1.1410\n",
      "Epoch [20/100], Step [830/1751], Loss: 1.1524\n",
      "Epoch [20/100], Step [840/1751], Loss: 1.2948\n",
      "Epoch [20/100], Step [850/1751], Loss: 1.1417\n",
      "Epoch [20/100], Step [860/1751], Loss: 1.4098\n",
      "Epoch [20/100], Step [870/1751], Loss: 1.2072\n",
      "Epoch [20/100], Step [880/1751], Loss: 1.2900\n",
      "Epoch [20/100], Step [890/1751], Loss: 1.1673\n",
      "Epoch [20/100], Step [900/1751], Loss: 1.2615\n",
      "Epoch [20/100], Step [910/1751], Loss: 1.1889\n",
      "Epoch [20/100], Step [920/1751], Loss: 1.2909\n",
      "Epoch [20/100], Step [930/1751], Loss: 1.3273\n",
      "Epoch [20/100], Step [940/1751], Loss: 1.3215\n",
      "Epoch [20/100], Step [950/1751], Loss: 1.3693\n",
      "Epoch [20/100], Step [960/1751], Loss: 1.3102\n",
      "Epoch [20/100], Step [970/1751], Loss: 1.1737\n",
      "Epoch [20/100], Step [980/1751], Loss: 1.3031\n",
      "Epoch [20/100], Step [990/1751], Loss: 1.3713\n",
      "Epoch [20/100], Step [1000/1751], Loss: 1.3457\n",
      "Epoch [20/100], Step [1010/1751], Loss: 1.3322\n",
      "Epoch [20/100], Step [1020/1751], Loss: 1.4453\n",
      "Epoch [20/100], Step [1030/1751], Loss: 1.2392\n",
      "Epoch [20/100], Step [1040/1751], Loss: 1.3420\n",
      "Epoch [20/100], Step [1050/1751], Loss: 1.2106\n",
      "Epoch [20/100], Step [1060/1751], Loss: 1.2937\n",
      "Epoch [20/100], Step [1070/1751], Loss: 1.1967\n",
      "Epoch [20/100], Step [1080/1751], Loss: 1.3340\n",
      "Epoch [20/100], Step [1090/1751], Loss: 1.2693\n",
      "Epoch [20/100], Step [1100/1751], Loss: 1.3302\n",
      "Epoch [20/100], Step [1110/1751], Loss: 1.2520\n",
      "Epoch [20/100], Step [1120/1751], Loss: 1.2804\n",
      "Epoch [20/100], Step [1130/1751], Loss: 1.2140\n",
      "Epoch [20/100], Step [1140/1751], Loss: 1.2687\n",
      "Epoch [20/100], Step [1150/1751], Loss: 1.0278\n",
      "Epoch [20/100], Step [1160/1751], Loss: 1.2763\n",
      "Epoch [20/100], Step [1170/1751], Loss: 1.1774\n",
      "Epoch [20/100], Step [1180/1751], Loss: 1.2907\n",
      "Epoch [20/100], Step [1190/1751], Loss: 1.3708\n",
      "Epoch [20/100], Step [1200/1751], Loss: 1.4271\n",
      "Epoch [20/100], Step [1210/1751], Loss: 1.3252\n",
      "Epoch [20/100], Step [1220/1751], Loss: 1.0881\n",
      "Epoch [20/100], Step [1230/1751], Loss: 1.4439\n",
      "Epoch [20/100], Step [1240/1751], Loss: 1.3410\n",
      "Epoch [20/100], Step [1250/1751], Loss: 1.2563\n",
      "Epoch [20/100], Step [1260/1751], Loss: 1.4440\n",
      "Epoch [20/100], Step [1270/1751], Loss: 1.3879\n",
      "Epoch [20/100], Step [1280/1751], Loss: 1.2839\n",
      "Epoch [20/100], Step [1290/1751], Loss: 1.3413\n",
      "Epoch [20/100], Step [1300/1751], Loss: 1.2787\n",
      "Epoch [20/100], Step [1310/1751], Loss: 1.2245\n",
      "Epoch [20/100], Step [1320/1751], Loss: 1.3171\n",
      "Epoch [20/100], Step [1330/1751], Loss: 1.1975\n",
      "Epoch [20/100], Step [1340/1751], Loss: 1.2019\n",
      "Epoch [20/100], Step [1350/1751], Loss: 1.2928\n",
      "Epoch [20/100], Step [1360/1751], Loss: 1.2982\n",
      "Epoch [20/100], Step [1370/1751], Loss: 1.2993\n",
      "Epoch [20/100], Step [1380/1751], Loss: 1.4124\n",
      "Epoch [20/100], Step [1390/1751], Loss: 1.2050\n",
      "Epoch [20/100], Step [1400/1751], Loss: 1.3538\n",
      "Epoch [20/100], Step [1410/1751], Loss: 1.3605\n",
      "Epoch [20/100], Step [1420/1751], Loss: 1.2557\n",
      "Epoch [20/100], Step [1430/1751], Loss: 1.2597\n",
      "Epoch [20/100], Step [1440/1751], Loss: 1.3622\n",
      "Epoch [20/100], Step [1450/1751], Loss: 1.2807\n",
      "Epoch [20/100], Step [1460/1751], Loss: 1.1830\n",
      "Epoch [20/100], Step [1470/1751], Loss: 1.3728\n",
      "Epoch [20/100], Step [1480/1751], Loss: 1.3936\n",
      "Epoch [20/100], Step [1490/1751], Loss: 1.1678\n",
      "Epoch [20/100], Step [1500/1751], Loss: 1.4514\n",
      "Epoch [20/100], Step [1510/1751], Loss: 1.2210\n",
      "Epoch [20/100], Step [1520/1751], Loss: 1.2916\n",
      "Epoch [20/100], Step [1530/1751], Loss: 1.2740\n",
      "Epoch [20/100], Step [1540/1751], Loss: 1.3843\n",
      "Epoch [20/100], Step [1550/1751], Loss: 1.1295\n",
      "Epoch [20/100], Step [1560/1751], Loss: 1.1691\n",
      "Epoch [20/100], Step [1570/1751], Loss: 1.2323\n",
      "Epoch [20/100], Step [1580/1751], Loss: 1.1984\n",
      "Epoch [20/100], Step [1590/1751], Loss: 1.3338\n",
      "Epoch [20/100], Step [1600/1751], Loss: 1.3873\n",
      "Epoch [20/100], Step [1610/1751], Loss: 1.1833\n",
      "Epoch [20/100], Step [1620/1751], Loss: 1.3643\n",
      "Epoch [20/100], Step [1630/1751], Loss: 1.3283\n",
      "Epoch [20/100], Step [1640/1751], Loss: 1.3979\n",
      "Epoch [20/100], Step [1650/1751], Loss: 1.2786\n",
      "Epoch [20/100], Step [1660/1751], Loss: 1.2673\n",
      "Epoch [20/100], Step [1670/1751], Loss: 1.2331\n",
      "Epoch [20/100], Step [1680/1751], Loss: 1.1593\n",
      "Epoch [20/100], Step [1690/1751], Loss: 1.2243\n",
      "Epoch [20/100], Step [1700/1751], Loss: 1.4229\n",
      "Epoch [20/100], Step [1710/1751], Loss: 1.2778\n",
      "Epoch [20/100], Step [1720/1751], Loss: 1.3320\n",
      "Epoch [20/100], Step [1730/1751], Loss: 1.3151\n",
      "Epoch [20/100], Step [1740/1751], Loss: 1.4081\n",
      "Epoch [20/100], Step [1750/1751], Loss: 1.1675\n",
      "Epoch [20/100], Average Loss: 1.2833, Time: 1638.7214s\n",
      "Epoch [21/100], Step [10/1751], Loss: 1.3767\n",
      "Epoch [21/100], Step [20/1751], Loss: 1.1634\n",
      "Epoch [21/100], Step [30/1751], Loss: 1.2633\n",
      "Epoch [21/100], Step [40/1751], Loss: 1.2415\n",
      "Epoch [21/100], Step [50/1751], Loss: 1.4533\n",
      "Epoch [21/100], Step [60/1751], Loss: 1.2410\n",
      "Epoch [21/100], Step [70/1751], Loss: 1.5061\n",
      "Epoch [21/100], Step [80/1751], Loss: 1.2214\n",
      "Epoch [21/100], Step [90/1751], Loss: 1.2733\n",
      "Epoch [21/100], Step [100/1751], Loss: 1.2750\n",
      "Epoch [21/100], Step [110/1751], Loss: 1.3657\n",
      "Epoch [21/100], Step [120/1751], Loss: 1.2158\n",
      "Epoch [21/100], Step [130/1751], Loss: 1.3261\n",
      "Epoch [21/100], Step [140/1751], Loss: 1.4272\n",
      "Epoch [21/100], Step [150/1751], Loss: 1.2568\n",
      "Epoch [21/100], Step [160/1751], Loss: 1.4019\n",
      "Epoch [21/100], Step [170/1751], Loss: 1.3058\n",
      "Epoch [21/100], Step [180/1751], Loss: 1.3942\n",
      "Epoch [21/100], Step [190/1751], Loss: 1.3617\n",
      "Epoch [21/100], Step [200/1751], Loss: 1.3202\n",
      "Epoch [21/100], Step [210/1751], Loss: 1.3297\n",
      "Epoch [21/100], Step [220/1751], Loss: 1.3018\n",
      "Epoch [21/100], Step [230/1751], Loss: 1.3727\n",
      "Epoch [21/100], Step [240/1751], Loss: 1.2040\n",
      "Epoch [21/100], Step [250/1751], Loss: 1.5263\n",
      "Epoch [21/100], Step [260/1751], Loss: 1.2251\n",
      "Epoch [21/100], Step [270/1751], Loss: 1.3129\n",
      "Epoch [21/100], Step [280/1751], Loss: 1.2893\n",
      "Epoch [21/100], Step [290/1751], Loss: 1.2689\n",
      "Epoch [21/100], Step [300/1751], Loss: 1.3377\n",
      "Epoch [21/100], Step [310/1751], Loss: 1.1989\n",
      "Epoch [21/100], Step [320/1751], Loss: 1.2672\n",
      "Epoch [21/100], Step [330/1751], Loss: 1.2348\n",
      "Epoch [21/100], Step [340/1751], Loss: 1.3662\n",
      "Epoch [21/100], Step [350/1751], Loss: 1.1906\n",
      "Epoch [21/100], Step [360/1751], Loss: 1.2531\n",
      "Epoch [21/100], Step [370/1751], Loss: 1.3104\n",
      "Epoch [21/100], Step [380/1751], Loss: 1.3145\n",
      "Epoch [21/100], Step [390/1751], Loss: 1.3215\n",
      "Epoch [21/100], Step [400/1751], Loss: 1.2422\n",
      "Epoch [21/100], Step [410/1751], Loss: 1.2649\n",
      "Epoch [21/100], Step [420/1751], Loss: 1.3285\n",
      "Epoch [21/100], Step [430/1751], Loss: 1.3336\n",
      "Epoch [21/100], Step [440/1751], Loss: 1.2134\n",
      "Epoch [21/100], Step [450/1751], Loss: 1.3690\n",
      "Epoch [21/100], Step [460/1751], Loss: 1.2437\n",
      "Epoch [21/100], Step [470/1751], Loss: 1.2493\n",
      "Epoch [21/100], Step [480/1751], Loss: 1.2902\n",
      "Epoch [21/100], Step [490/1751], Loss: 1.3271\n",
      "Epoch [21/100], Step [500/1751], Loss: 1.3169\n",
      "Epoch [21/100], Step [510/1751], Loss: 1.2487\n",
      "Epoch [21/100], Step [520/1751], Loss: 1.2996\n",
      "Epoch [21/100], Step [530/1751], Loss: 1.2361\n",
      "Epoch [21/100], Step [540/1751], Loss: 1.3510\n",
      "Epoch [21/100], Step [550/1751], Loss: 1.3298\n",
      "Epoch [21/100], Step [560/1751], Loss: 1.3313\n",
      "Epoch [21/100], Step [570/1751], Loss: 1.4313\n",
      "Epoch [21/100], Step [580/1751], Loss: 1.2754\n",
      "Epoch [21/100], Step [590/1751], Loss: 1.2280\n",
      "Epoch [21/100], Step [600/1751], Loss: 1.2112\n",
      "Epoch [21/100], Step [610/1751], Loss: 1.2770\n",
      "Epoch [21/100], Step [620/1751], Loss: 1.3215\n",
      "Epoch [21/100], Step [630/1751], Loss: 1.2758\n",
      "Epoch [21/100], Step [640/1751], Loss: 1.2822\n",
      "Epoch [21/100], Step [650/1751], Loss: 1.3567\n",
      "Epoch [21/100], Step [660/1751], Loss: 1.3243\n",
      "Epoch [21/100], Step [670/1751], Loss: 1.3091\n",
      "Epoch [21/100], Step [680/1751], Loss: 1.3902\n",
      "Epoch [21/100], Step [690/1751], Loss: 1.3976\n",
      "Epoch [21/100], Step [700/1751], Loss: 1.3042\n",
      "Epoch [21/100], Step [710/1751], Loss: 1.2757\n",
      "Epoch [21/100], Step [720/1751], Loss: 1.2249\n",
      "Epoch [21/100], Step [730/1751], Loss: 1.1781\n",
      "Epoch [21/100], Step [740/1751], Loss: 1.2773\n",
      "Epoch [21/100], Step [750/1751], Loss: 1.3394\n",
      "Epoch [21/100], Step [760/1751], Loss: 1.2376\n",
      "Epoch [21/100], Step [770/1751], Loss: 1.4293\n",
      "Epoch [21/100], Step [780/1751], Loss: 1.2960\n",
      "Epoch [21/100], Step [790/1751], Loss: 1.1675\n",
      "Epoch [21/100], Step [800/1751], Loss: 1.2320\n",
      "Epoch [21/100], Step [810/1751], Loss: 1.3351\n",
      "Epoch [21/100], Step [820/1751], Loss: 1.2146\n",
      "Epoch [21/100], Step [830/1751], Loss: 1.2974\n",
      "Epoch [21/100], Step [840/1751], Loss: 1.2104\n",
      "Epoch [21/100], Step [850/1751], Loss: 1.3417\n",
      "Epoch [21/100], Step [860/1751], Loss: 1.2798\n",
      "Epoch [21/100], Step [870/1751], Loss: 1.2105\n",
      "Epoch [21/100], Step [880/1751], Loss: 1.3002\n",
      "Epoch [21/100], Step [890/1751], Loss: 1.2580\n",
      "Epoch [21/100], Step [900/1751], Loss: 1.2795\n",
      "Epoch [21/100], Step [910/1751], Loss: 1.3419\n",
      "Epoch [21/100], Step [920/1751], Loss: 1.3372\n",
      "Epoch [21/100], Step [930/1751], Loss: 1.2826\n",
      "Epoch [21/100], Step [940/1751], Loss: 1.3376\n",
      "Epoch [21/100], Step [950/1751], Loss: 1.2704\n",
      "Epoch [21/100], Step [960/1751], Loss: 1.3076\n",
      "Epoch [21/100], Step [970/1751], Loss: 1.4120\n",
      "Epoch [21/100], Step [980/1751], Loss: 1.3185\n",
      "Epoch [21/100], Step [990/1751], Loss: 1.2570\n",
      "Epoch [21/100], Step [1000/1751], Loss: 1.1648\n",
      "Epoch [21/100], Step [1010/1751], Loss: 1.2406\n",
      "Epoch [21/100], Step [1020/1751], Loss: 1.3286\n",
      "Epoch [21/100], Step [1030/1751], Loss: 1.1739\n",
      "Epoch [21/100], Step [1040/1751], Loss: 1.2341\n",
      "Epoch [21/100], Step [1050/1751], Loss: 1.3285\n",
      "Epoch [21/100], Step [1060/1751], Loss: 1.2412\n",
      "Epoch [21/100], Step [1070/1751], Loss: 1.2006\n",
      "Epoch [21/100], Step [1080/1751], Loss: 1.3273\n",
      "Epoch [21/100], Step [1090/1751], Loss: 1.4496\n",
      "Epoch [21/100], Step [1100/1751], Loss: 1.3373\n",
      "Epoch [21/100], Step [1110/1751], Loss: 1.2203\n",
      "Epoch [21/100], Step [1120/1751], Loss: 1.2743\n",
      "Epoch [21/100], Step [1130/1751], Loss: 1.4205\n",
      "Epoch [21/100], Step [1140/1751], Loss: 1.3202\n",
      "Epoch [21/100], Step [1150/1751], Loss: 1.2279\n",
      "Epoch [21/100], Step [1160/1751], Loss: 1.3058\n",
      "Epoch [21/100], Step [1170/1751], Loss: 1.1749\n",
      "Epoch [21/100], Step [1180/1751], Loss: 1.2781\n",
      "Epoch [21/100], Step [1190/1751], Loss: 1.2869\n",
      "Epoch [21/100], Step [1200/1751], Loss: 1.2903\n",
      "Epoch [21/100], Step [1210/1751], Loss: 1.1784\n",
      "Epoch [21/100], Step [1220/1751], Loss: 1.3048\n",
      "Epoch [21/100], Step [1230/1751], Loss: 1.2330\n",
      "Epoch [21/100], Step [1240/1751], Loss: 1.4200\n",
      "Epoch [21/100], Step [1250/1751], Loss: 1.3330\n",
      "Epoch [21/100], Step [1260/1751], Loss: 1.1260\n",
      "Epoch [21/100], Step [1270/1751], Loss: 1.2210\n",
      "Epoch [21/100], Step [1280/1751], Loss: 1.2872\n",
      "Epoch [21/100], Step [1290/1751], Loss: 1.3938\n",
      "Epoch [21/100], Step [1300/1751], Loss: 1.4024\n",
      "Epoch [21/100], Step [1310/1751], Loss: 1.1594\n",
      "Epoch [21/100], Step [1320/1751], Loss: 1.1873\n",
      "Epoch [21/100], Step [1330/1751], Loss: 1.4459\n",
      "Epoch [21/100], Step [1340/1751], Loss: 1.1720\n",
      "Epoch [21/100], Step [1350/1751], Loss: 1.5340\n",
      "Epoch [21/100], Step [1360/1751], Loss: 1.3577\n",
      "Epoch [21/100], Step [1370/1751], Loss: 1.2546\n",
      "Epoch [21/100], Step [1380/1751], Loss: 1.1789\n",
      "Epoch [21/100], Step [1390/1751], Loss: 1.2467\n",
      "Epoch [21/100], Step [1400/1751], Loss: 1.4597\n",
      "Epoch [21/100], Step [1410/1751], Loss: 1.1419\n",
      "Epoch [21/100], Step [1420/1751], Loss: 1.3933\n",
      "Epoch [21/100], Step [1430/1751], Loss: 1.3207\n",
      "Epoch [21/100], Step [1440/1751], Loss: 1.2993\n",
      "Epoch [21/100], Step [1450/1751], Loss: 1.1148\n",
      "Epoch [21/100], Step [1460/1751], Loss: 1.2313\n",
      "Epoch [21/100], Step [1470/1751], Loss: 1.2039\n",
      "Epoch [21/100], Step [1480/1751], Loss: 1.3448\n",
      "Epoch [21/100], Step [1490/1751], Loss: 1.2651\n",
      "Epoch [21/100], Step [1500/1751], Loss: 1.1923\n",
      "Epoch [21/100], Step [1510/1751], Loss: 1.0472\n",
      "Epoch [21/100], Step [1520/1751], Loss: 1.2887\n",
      "Epoch [21/100], Step [1530/1751], Loss: 1.1952\n",
      "Epoch [21/100], Step [1540/1751], Loss: 1.3532\n",
      "Epoch [21/100], Step [1550/1751], Loss: 1.1693\n",
      "Epoch [21/100], Step [1560/1751], Loss: 1.2501\n",
      "Epoch [21/100], Step [1570/1751], Loss: 1.2481\n",
      "Epoch [21/100], Step [1580/1751], Loss: 1.3556\n",
      "Epoch [21/100], Step [1590/1751], Loss: 1.2395\n",
      "Epoch [21/100], Step [1600/1751], Loss: 1.2618\n",
      "Epoch [21/100], Step [1610/1751], Loss: 1.2816\n",
      "Epoch [21/100], Step [1620/1751], Loss: 1.2569\n",
      "Epoch [21/100], Step [1630/1751], Loss: 1.3048\n",
      "Epoch [21/100], Step [1640/1751], Loss: 1.3795\n",
      "Epoch [21/100], Step [1650/1751], Loss: 1.2052\n",
      "Epoch [21/100], Step [1660/1751], Loss: 1.2520\n",
      "Epoch [21/100], Step [1670/1751], Loss: 1.2319\n",
      "Epoch [21/100], Step [1680/1751], Loss: 1.2432\n",
      "Epoch [21/100], Step [1690/1751], Loss: 1.3343\n",
      "Epoch [21/100], Step [1700/1751], Loss: 1.2275\n",
      "Epoch [21/100], Step [1710/1751], Loss: 1.2816\n",
      "Epoch [21/100], Step [1720/1751], Loss: 1.3619\n",
      "Epoch [21/100], Step [1730/1751], Loss: 1.4105\n",
      "Epoch [21/100], Step [1740/1751], Loss: 1.1828\n",
      "Epoch [21/100], Step [1750/1751], Loss: 1.4042\n",
      "Epoch [21/100], Average Loss: 1.2780, Time: 1637.4232s\n",
      "Epoch [22/100], Step [10/1751], Loss: 1.1899\n",
      "Epoch [22/100], Step [20/1751], Loss: 1.2854\n",
      "Epoch [22/100], Step [30/1751], Loss: 1.3538\n",
      "Epoch [22/100], Step [40/1751], Loss: 1.3737\n",
      "Epoch [22/100], Step [50/1751], Loss: 1.2680\n",
      "Epoch [22/100], Step [60/1751], Loss: 1.2561\n",
      "Epoch [22/100], Step [70/1751], Loss: 1.1219\n",
      "Epoch [22/100], Step [80/1751], Loss: 1.3245\n",
      "Epoch [22/100], Step [90/1751], Loss: 1.2851\n",
      "Epoch [22/100], Step [100/1751], Loss: 1.1660\n",
      "Epoch [22/100], Step [110/1751], Loss: 1.2836\n",
      "Epoch [22/100], Step [120/1751], Loss: 1.2323\n",
      "Epoch [22/100], Step [130/1751], Loss: 1.3691\n",
      "Epoch [22/100], Step [140/1751], Loss: 1.2548\n",
      "Epoch [22/100], Step [150/1751], Loss: 1.3031\n",
      "Epoch [22/100], Step [160/1751], Loss: 1.3699\n",
      "Epoch [22/100], Step [170/1751], Loss: 1.2321\n",
      "Epoch [22/100], Step [180/1751], Loss: 1.1482\n",
      "Epoch [22/100], Step [190/1751], Loss: 1.1659\n",
      "Epoch [22/100], Step [200/1751], Loss: 1.2271\n",
      "Epoch [22/100], Step [210/1751], Loss: 1.2170\n",
      "Epoch [22/100], Step [220/1751], Loss: 1.4171\n",
      "Epoch [22/100], Step [230/1751], Loss: 1.2893\n",
      "Epoch [22/100], Step [240/1751], Loss: 1.1522\n",
      "Epoch [22/100], Step [250/1751], Loss: 1.2352\n",
      "Epoch [22/100], Step [260/1751], Loss: 1.1603\n",
      "Epoch [22/100], Step [270/1751], Loss: 1.3494\n",
      "Epoch [22/100], Step [280/1751], Loss: 1.1799\n",
      "Epoch [22/100], Step [290/1751], Loss: 1.2968\n",
      "Epoch [22/100], Step [300/1751], Loss: 1.2081\n",
      "Epoch [22/100], Step [310/1751], Loss: 1.2396\n",
      "Epoch [22/100], Step [320/1751], Loss: 1.3600\n",
      "Epoch [22/100], Step [330/1751], Loss: 1.2642\n",
      "Epoch [22/100], Step [340/1751], Loss: 1.2000\n",
      "Epoch [22/100], Step [350/1751], Loss: 1.1298\n",
      "Epoch [22/100], Step [360/1751], Loss: 1.2110\n",
      "Epoch [22/100], Step [370/1751], Loss: 1.2618\n",
      "Epoch [22/100], Step [380/1751], Loss: 1.1875\n",
      "Epoch [22/100], Step [390/1751], Loss: 0.9422\n",
      "Epoch [22/100], Step [400/1751], Loss: 1.2584\n",
      "Epoch [22/100], Step [410/1751], Loss: 1.2118\n",
      "Epoch [22/100], Step [420/1751], Loss: 1.2743\n",
      "Epoch [22/100], Step [430/1751], Loss: 1.4143\n",
      "Epoch [22/100], Step [440/1751], Loss: 1.1803\n",
      "Epoch [22/100], Step [450/1751], Loss: 1.2426\n",
      "Epoch [22/100], Step [460/1751], Loss: 1.4325\n",
      "Epoch [22/100], Step [470/1751], Loss: 1.1640\n",
      "Epoch [22/100], Step [480/1751], Loss: 1.1984\n",
      "Epoch [22/100], Step [490/1751], Loss: 1.1571\n",
      "Epoch [22/100], Step [500/1751], Loss: 1.3099\n",
      "Epoch [22/100], Step [510/1751], Loss: 1.1330\n",
      "Epoch [22/100], Step [520/1751], Loss: 1.2307\n",
      "Epoch [22/100], Step [530/1751], Loss: 1.3373\n",
      "Epoch [22/100], Step [540/1751], Loss: 1.2929\n",
      "Epoch [22/100], Step [550/1751], Loss: 1.3472\n",
      "Epoch [22/100], Step [560/1751], Loss: 1.4721\n",
      "Epoch [22/100], Step [570/1751], Loss: 1.3972\n",
      "Epoch [22/100], Step [580/1751], Loss: 1.3909\n",
      "Epoch [22/100], Step [590/1751], Loss: 1.3282\n",
      "Epoch [22/100], Step [600/1751], Loss: 1.1481\n",
      "Epoch [22/100], Step [610/1751], Loss: 1.3738\n",
      "Epoch [22/100], Step [620/1751], Loss: 1.2577\n",
      "Epoch [22/100], Step [630/1751], Loss: 1.3557\n",
      "Epoch [22/100], Step [640/1751], Loss: 1.3001\n",
      "Epoch [22/100], Step [650/1751], Loss: 1.2724\n",
      "Epoch [22/100], Step [660/1751], Loss: 1.3365\n",
      "Epoch [22/100], Step [670/1751], Loss: 1.2771\n",
      "Epoch [22/100], Step [680/1751], Loss: 1.2444\n",
      "Epoch [22/100], Step [690/1751], Loss: 1.4945\n",
      "Epoch [22/100], Step [700/1751], Loss: 1.2421\n",
      "Epoch [22/100], Step [710/1751], Loss: 1.4237\n",
      "Epoch [22/100], Step [720/1751], Loss: 1.4213\n",
      "Epoch [22/100], Step [730/1751], Loss: 1.2853\n",
      "Epoch [22/100], Step [740/1751], Loss: 1.4437\n",
      "Epoch [22/100], Step [750/1751], Loss: 1.4053\n",
      "Epoch [22/100], Step [760/1751], Loss: 1.2629\n",
      "Epoch [22/100], Step [770/1751], Loss: 1.3787\n",
      "Epoch [22/100], Step [780/1751], Loss: 1.2229\n",
      "Epoch [22/100], Step [790/1751], Loss: 1.2790\n",
      "Epoch [22/100], Step [800/1751], Loss: 1.2003\n",
      "Epoch [22/100], Step [810/1751], Loss: 1.2858\n",
      "Epoch [22/100], Step [820/1751], Loss: 1.2013\n",
      "Epoch [22/100], Step [830/1751], Loss: 1.1751\n",
      "Epoch [22/100], Step [840/1751], Loss: 1.2116\n",
      "Epoch [22/100], Step [850/1751], Loss: 1.2601\n",
      "Epoch [22/100], Step [860/1751], Loss: 1.3292\n",
      "Epoch [22/100], Step [870/1751], Loss: 1.3484\n",
      "Epoch [22/100], Step [880/1751], Loss: 1.3467\n",
      "Epoch [22/100], Step [890/1751], Loss: 1.2553\n",
      "Epoch [22/100], Step [900/1751], Loss: 1.1892\n",
      "Epoch [22/100], Step [910/1751], Loss: 1.3267\n",
      "Epoch [22/100], Step [920/1751], Loss: 1.1840\n",
      "Epoch [22/100], Step [930/1751], Loss: 1.1995\n",
      "Epoch [22/100], Step [940/1751], Loss: 1.3396\n",
      "Epoch [22/100], Step [950/1751], Loss: 1.2043\n",
      "Epoch [22/100], Step [960/1751], Loss: 1.3809\n",
      "Epoch [22/100], Step [970/1751], Loss: 1.4206\n",
      "Epoch [22/100], Step [980/1751], Loss: 1.3634\n",
      "Epoch [22/100], Step [990/1751], Loss: 1.4953\n",
      "Epoch [22/100], Step [1000/1751], Loss: 1.4152\n",
      "Epoch [22/100], Step [1010/1751], Loss: 1.0941\n",
      "Epoch [22/100], Step [1020/1751], Loss: 1.2081\n",
      "Epoch [22/100], Step [1030/1751], Loss: 1.2185\n",
      "Epoch [22/100], Step [1040/1751], Loss: 1.1960\n",
      "Epoch [22/100], Step [1050/1751], Loss: 1.3343\n",
      "Epoch [22/100], Step [1060/1751], Loss: 1.3492\n",
      "Epoch [22/100], Step [1070/1751], Loss: 1.2835\n",
      "Epoch [22/100], Step [1080/1751], Loss: 1.3619\n",
      "Epoch [22/100], Step [1090/1751], Loss: 1.3498\n",
      "Epoch [22/100], Step [1100/1751], Loss: 1.3194\n",
      "Epoch [22/100], Step [1110/1751], Loss: 1.2654\n",
      "Epoch [22/100], Step [1120/1751], Loss: 1.2794\n",
      "Epoch [22/100], Step [1130/1751], Loss: 1.2508\n",
      "Epoch [22/100], Step [1140/1751], Loss: 1.3103\n",
      "Epoch [22/100], Step [1150/1751], Loss: 1.2856\n",
      "Epoch [22/100], Step [1160/1751], Loss: 1.2917\n",
      "Epoch [22/100], Step [1170/1751], Loss: 1.4430\n",
      "Epoch [22/100], Step [1180/1751], Loss: 1.3499\n",
      "Epoch [22/100], Step [1190/1751], Loss: 1.2420\n",
      "Epoch [22/100], Step [1200/1751], Loss: 1.2139\n",
      "Epoch [22/100], Step [1210/1751], Loss: 1.3080\n",
      "Epoch [22/100], Step [1220/1751], Loss: 1.3111\n",
      "Epoch [22/100], Step [1230/1751], Loss: 1.1745\n",
      "Epoch [22/100], Step [1240/1751], Loss: 1.3516\n",
      "Epoch [22/100], Step [1250/1751], Loss: 1.3076\n",
      "Epoch [22/100], Step [1260/1751], Loss: 1.3654\n",
      "Epoch [22/100], Step [1270/1751], Loss: 1.2437\n",
      "Epoch [22/100], Step [1280/1751], Loss: 1.1343\n",
      "Epoch [22/100], Step [1290/1751], Loss: 1.2075\n",
      "Epoch [22/100], Step [1300/1751], Loss: 1.1407\n",
      "Epoch [22/100], Step [1310/1751], Loss: 1.5251\n",
      "Epoch [22/100], Step [1320/1751], Loss: 1.2493\n",
      "Epoch [22/100], Step [1330/1751], Loss: 1.2876\n",
      "Epoch [22/100], Step [1340/1751], Loss: 1.2988\n",
      "Epoch [22/100], Step [1350/1751], Loss: 1.4315\n",
      "Epoch [22/100], Step [1360/1751], Loss: 1.2382\n",
      "Epoch [22/100], Step [1370/1751], Loss: 1.4007\n",
      "Epoch [22/100], Step [1380/1751], Loss: 1.3496\n",
      "Epoch [22/100], Step [1390/1751], Loss: 1.4188\n",
      "Epoch [22/100], Step [1400/1751], Loss: 1.2248\n",
      "Epoch [22/100], Step [1410/1751], Loss: 1.3022\n",
      "Epoch [22/100], Step [1420/1751], Loss: 1.3544\n",
      "Epoch [22/100], Step [1430/1751], Loss: 1.2338\n",
      "Epoch [22/100], Step [1440/1751], Loss: 1.2460\n",
      "Epoch [22/100], Step [1450/1751], Loss: 1.1654\n",
      "Epoch [22/100], Step [1460/1751], Loss: 1.2724\n",
      "Epoch [22/100], Step [1470/1751], Loss: 1.2973\n",
      "Epoch [22/100], Step [1480/1751], Loss: 1.2033\n",
      "Epoch [22/100], Step [1490/1751], Loss: 1.3013\n",
      "Epoch [22/100], Step [1500/1751], Loss: 1.2836\n",
      "Epoch [22/100], Step [1510/1751], Loss: 1.3027\n",
      "Epoch [22/100], Step [1520/1751], Loss: 1.0860\n",
      "Epoch [22/100], Step [1530/1751], Loss: 1.2343\n",
      "Epoch [22/100], Step [1540/1751], Loss: 1.2862\n",
      "Epoch [22/100], Step [1550/1751], Loss: 1.1682\n",
      "Epoch [22/100], Step [1560/1751], Loss: 1.0815\n",
      "Epoch [22/100], Step [1570/1751], Loss: 1.1681\n",
      "Epoch [22/100], Step [1580/1751], Loss: 1.2936\n",
      "Epoch [22/100], Step [1590/1751], Loss: 1.2014\n",
      "Epoch [22/100], Step [1600/1751], Loss: 1.4544\n",
      "Epoch [22/100], Step [1610/1751], Loss: 1.3266\n",
      "Epoch [22/100], Step [1620/1751], Loss: 1.1785\n",
      "Epoch [22/100], Step [1630/1751], Loss: 1.3729\n",
      "Epoch [22/100], Step [1640/1751], Loss: 1.1388\n",
      "Epoch [22/100], Step [1650/1751], Loss: 1.1632\n",
      "Epoch [22/100], Step [1660/1751], Loss: 1.1899\n",
      "Epoch [22/100], Step [1670/1751], Loss: 1.2626\n",
      "Epoch [22/100], Step [1680/1751], Loss: 1.1588\n",
      "Epoch [22/100], Step [1690/1751], Loss: 1.2261\n",
      "Epoch [22/100], Step [1700/1751], Loss: 1.1708\n",
      "Epoch [22/100], Step [1710/1751], Loss: 1.2759\n",
      "Epoch [22/100], Step [1720/1751], Loss: 1.2292\n",
      "Epoch [22/100], Step [1730/1751], Loss: 1.3044\n",
      "Epoch [22/100], Step [1740/1751], Loss: 1.3914\n",
      "Epoch [22/100], Step [1750/1751], Loss: 1.2289\n",
      "Epoch [22/100], Average Loss: 1.2719, Time: 1638.2835s\n",
      "Epoch [23/100], Step [10/1751], Loss: 1.2451\n",
      "Epoch [23/100], Step [20/1751], Loss: 1.3997\n",
      "Epoch [23/100], Step [30/1751], Loss: 1.2328\n",
      "Epoch [23/100], Step [40/1751], Loss: 1.2614\n",
      "Epoch [23/100], Step [50/1751], Loss: 1.1860\n",
      "Epoch [23/100], Step [60/1751], Loss: 1.2518\n",
      "Epoch [23/100], Step [70/1751], Loss: 1.3788\n",
      "Epoch [23/100], Step [80/1751], Loss: 1.1668\n",
      "Epoch [23/100], Step [90/1751], Loss: 1.1998\n",
      "Epoch [23/100], Step [100/1751], Loss: 1.2788\n",
      "Epoch [23/100], Step [110/1751], Loss: 1.0989\n",
      "Epoch [23/100], Step [120/1751], Loss: 1.3048\n",
      "Epoch [23/100], Step [130/1751], Loss: 1.3464\n",
      "Epoch [23/100], Step [140/1751], Loss: 1.3114\n",
      "Epoch [23/100], Step [150/1751], Loss: 1.0808\n",
      "Epoch [23/100], Step [160/1751], Loss: 1.2282\n",
      "Epoch [23/100], Step [170/1751], Loss: 1.2935\n",
      "Epoch [23/100], Step [180/1751], Loss: 1.4154\n",
      "Epoch [23/100], Step [190/1751], Loss: 1.3423\n",
      "Epoch [23/100], Step [200/1751], Loss: 1.0621\n",
      "Epoch [23/100], Step [210/1751], Loss: 1.3918\n",
      "Epoch [23/100], Step [220/1751], Loss: 1.3152\n",
      "Epoch [23/100], Step [230/1751], Loss: 1.2789\n",
      "Epoch [23/100], Step [240/1751], Loss: 1.1715\n",
      "Epoch [23/100], Step [250/1751], Loss: 1.1170\n",
      "Epoch [23/100], Step [260/1751], Loss: 1.1915\n",
      "Epoch [23/100], Step [270/1751], Loss: 1.4089\n",
      "Epoch [23/100], Step [280/1751], Loss: 1.1877\n",
      "Epoch [23/100], Step [290/1751], Loss: 1.2602\n",
      "Epoch [23/100], Step [300/1751], Loss: 1.3646\n",
      "Epoch [23/100], Step [310/1751], Loss: 1.0837\n",
      "Epoch [23/100], Step [320/1751], Loss: 1.4044\n",
      "Epoch [23/100], Step [330/1751], Loss: 1.3416\n",
      "Epoch [23/100], Step [340/1751], Loss: 1.2807\n",
      "Epoch [23/100], Step [350/1751], Loss: 1.1870\n",
      "Epoch [23/100], Step [360/1751], Loss: 1.3872\n",
      "Epoch [23/100], Step [370/1751], Loss: 1.1598\n",
      "Epoch [23/100], Step [380/1751], Loss: 1.3229\n",
      "Epoch [23/100], Step [390/1751], Loss: 1.3791\n",
      "Epoch [23/100], Step [400/1751], Loss: 1.3478\n",
      "Epoch [23/100], Step [410/1751], Loss: 1.2861\n",
      "Epoch [23/100], Step [420/1751], Loss: 1.2823\n",
      "Epoch [23/100], Step [430/1751], Loss: 1.2582\n",
      "Epoch [23/100], Step [440/1751], Loss: 1.1905\n",
      "Epoch [23/100], Step [450/1751], Loss: 1.2745\n",
      "Epoch [23/100], Step [460/1751], Loss: 1.2273\n",
      "Epoch [23/100], Step [470/1751], Loss: 1.2411\n",
      "Epoch [23/100], Step [480/1751], Loss: 1.2536\n",
      "Epoch [23/100], Step [490/1751], Loss: 1.2554\n",
      "Epoch [23/100], Step [500/1751], Loss: 1.4114\n",
      "Epoch [23/100], Step [510/1751], Loss: 1.2992\n",
      "Epoch [23/100], Step [520/1751], Loss: 1.4690\n",
      "Epoch [23/100], Step [530/1751], Loss: 1.1488\n",
      "Epoch [23/100], Step [540/1751], Loss: 1.2831\n",
      "Epoch [23/100], Step [550/1751], Loss: 1.3210\n",
      "Epoch [23/100], Step [560/1751], Loss: 1.1797\n",
      "Epoch [23/100], Step [570/1751], Loss: 1.1407\n",
      "Epoch [23/100], Step [580/1751], Loss: 1.2491\n",
      "Epoch [23/100], Step [590/1751], Loss: 1.2315\n",
      "Epoch [23/100], Step [600/1751], Loss: 1.2573\n",
      "Epoch [23/100], Step [610/1751], Loss: 1.4156\n",
      "Epoch [23/100], Step [620/1751], Loss: 1.3393\n",
      "Epoch [23/100], Step [630/1751], Loss: 1.2490\n",
      "Epoch [23/100], Step [640/1751], Loss: 1.1157\n",
      "Epoch [23/100], Step [650/1751], Loss: 1.3216\n",
      "Epoch [23/100], Step [660/1751], Loss: 1.3766\n",
      "Epoch [23/100], Step [670/1751], Loss: 1.0630\n",
      "Epoch [23/100], Step [680/1751], Loss: 1.1433\n",
      "Epoch [23/100], Step [690/1751], Loss: 1.1958\n",
      "Epoch [23/100], Step [700/1751], Loss: 1.2546\n",
      "Epoch [23/100], Step [710/1751], Loss: 1.2578\n",
      "Epoch [23/100], Step [720/1751], Loss: 1.2396\n",
      "Epoch [23/100], Step [730/1751], Loss: 1.3745\n",
      "Epoch [23/100], Step [740/1751], Loss: 1.2330\n",
      "Epoch [23/100], Step [750/1751], Loss: 1.3460\n",
      "Epoch [23/100], Step [760/1751], Loss: 1.2727\n",
      "Epoch [23/100], Step [770/1751], Loss: 1.2540\n",
      "Epoch [23/100], Step [780/1751], Loss: 1.2341\n",
      "Epoch [23/100], Step [790/1751], Loss: 1.0882\n",
      "Epoch [23/100], Step [800/1751], Loss: 1.2467\n",
      "Epoch [23/100], Step [810/1751], Loss: 1.2652\n",
      "Epoch [23/100], Step [820/1751], Loss: 1.2120\n",
      "Epoch [23/100], Step [830/1751], Loss: 1.2257\n",
      "Epoch [23/100], Step [840/1751], Loss: 1.2429\n",
      "Epoch [23/100], Step [850/1751], Loss: 1.2643\n",
      "Epoch [23/100], Step [860/1751], Loss: 1.1892\n",
      "Epoch [23/100], Step [870/1751], Loss: 1.4386\n",
      "Epoch [23/100], Step [880/1751], Loss: 1.2534\n",
      "Epoch [23/100], Step [890/1751], Loss: 1.4045\n",
      "Epoch [23/100], Step [900/1751], Loss: 1.3447\n",
      "Epoch [23/100], Step [910/1751], Loss: 1.2492\n",
      "Epoch [23/100], Step [920/1751], Loss: 1.2372\n",
      "Epoch [23/100], Step [930/1751], Loss: 1.3584\n",
      "Epoch [23/100], Step [940/1751], Loss: 1.2476\n",
      "Epoch [23/100], Step [950/1751], Loss: 1.1959\n",
      "Epoch [23/100], Step [960/1751], Loss: 1.2583\n",
      "Epoch [23/100], Step [970/1751], Loss: 1.1765\n",
      "Epoch [23/100], Step [980/1751], Loss: 1.1402\n",
      "Epoch [23/100], Step [990/1751], Loss: 1.2394\n",
      "Epoch [23/100], Step [1000/1751], Loss: 1.2467\n",
      "Epoch [23/100], Step [1010/1751], Loss: 1.2287\n",
      "Epoch [23/100], Step [1020/1751], Loss: 1.1992\n",
      "Epoch [23/100], Step [1030/1751], Loss: 1.2122\n",
      "Epoch [23/100], Step [1040/1751], Loss: 1.2654\n",
      "Epoch [23/100], Step [1050/1751], Loss: 1.4178\n",
      "Epoch [23/100], Step [1060/1751], Loss: 1.2555\n",
      "Epoch [23/100], Step [1070/1751], Loss: 1.1931\n",
      "Epoch [23/100], Step [1080/1751], Loss: 1.2720\n",
      "Epoch [23/100], Step [1090/1751], Loss: 1.3725\n",
      "Epoch [23/100], Step [1100/1751], Loss: 1.3204\n",
      "Epoch [23/100], Step [1110/1751], Loss: 1.3425\n",
      "Epoch [23/100], Step [1120/1751], Loss: 1.2275\n",
      "Epoch [23/100], Step [1130/1751], Loss: 1.1754\n",
      "Epoch [23/100], Step [1140/1751], Loss: 1.2481\n",
      "Epoch [23/100], Step [1150/1751], Loss: 1.1921\n",
      "Epoch [23/100], Step [1160/1751], Loss: 1.2299\n",
      "Epoch [23/100], Step [1170/1751], Loss: 1.1646\n",
      "Epoch [23/100], Step [1180/1751], Loss: 1.3281\n",
      "Epoch [23/100], Step [1190/1751], Loss: 1.3060\n",
      "Epoch [23/100], Step [1200/1751], Loss: 1.3978\n",
      "Epoch [23/100], Step [1210/1751], Loss: 1.3334\n",
      "Epoch [23/100], Step [1220/1751], Loss: 1.2783\n",
      "Epoch [23/100], Step [1230/1751], Loss: 1.2194\n",
      "Epoch [23/100], Step [1240/1751], Loss: 1.3214\n",
      "Epoch [23/100], Step [1250/1751], Loss: 1.3183\n",
      "Epoch [23/100], Step [1260/1751], Loss: 1.4284\n",
      "Epoch [23/100], Step [1270/1751], Loss: 1.2841\n",
      "Epoch [23/100], Step [1280/1751], Loss: 1.3878\n",
      "Epoch [23/100], Step [1290/1751], Loss: 1.2531\n",
      "Epoch [23/100], Step [1300/1751], Loss: 1.2983\n",
      "Epoch [23/100], Step [1310/1751], Loss: 1.4769\n",
      "Epoch [23/100], Step [1320/1751], Loss: 1.2742\n",
      "Epoch [23/100], Step [1330/1751], Loss: 1.1381\n",
      "Epoch [23/100], Step [1340/1751], Loss: 1.2437\n",
      "Epoch [23/100], Step [1350/1751], Loss: 1.3289\n",
      "Epoch [23/100], Step [1360/1751], Loss: 1.3178\n",
      "Epoch [23/100], Step [1370/1751], Loss: 1.4029\n",
      "Epoch [23/100], Step [1380/1751], Loss: 1.2384\n",
      "Epoch [23/100], Step [1390/1751], Loss: 1.4124\n",
      "Epoch [23/100], Step [1400/1751], Loss: 1.3907\n",
      "Epoch [23/100], Step [1410/1751], Loss: 1.1676\n",
      "Epoch [23/100], Step [1420/1751], Loss: 1.2186\n",
      "Epoch [23/100], Step [1430/1751], Loss: 1.2599\n",
      "Epoch [23/100], Step [1440/1751], Loss: 1.3222\n",
      "Epoch [23/100], Step [1450/1751], Loss: 1.3702\n",
      "Epoch [23/100], Step [1460/1751], Loss: 1.1887\n",
      "Epoch [23/100], Step [1470/1751], Loss: 1.3631\n",
      "Epoch [23/100], Step [1480/1751], Loss: 1.0077\n",
      "Epoch [23/100], Step [1490/1751], Loss: 1.2466\n",
      "Epoch [23/100], Step [1500/1751], Loss: 1.3108\n",
      "Epoch [23/100], Step [1510/1751], Loss: 1.2714\n",
      "Epoch [23/100], Step [1520/1751], Loss: 1.3889\n",
      "Epoch [23/100], Step [1530/1751], Loss: 1.3096\n",
      "Epoch [23/100], Step [1540/1751], Loss: 1.1023\n",
      "Epoch [23/100], Step [1550/1751], Loss: 1.3089\n",
      "Epoch [23/100], Step [1560/1751], Loss: 1.2722\n",
      "Epoch [23/100], Step [1570/1751], Loss: 1.2063\n",
      "Epoch [23/100], Step [1580/1751], Loss: 1.3320\n",
      "Epoch [23/100], Step [1590/1751], Loss: 1.3384\n",
      "Epoch [23/100], Step [1600/1751], Loss: 1.2182\n",
      "Epoch [23/100], Step [1610/1751], Loss: 1.2180\n",
      "Epoch [23/100], Step [1620/1751], Loss: 1.1851\n",
      "Epoch [23/100], Step [1630/1751], Loss: 1.2848\n",
      "Epoch [23/100], Step [1640/1751], Loss: 1.2366\n",
      "Epoch [23/100], Step [1650/1751], Loss: 1.1921\n",
      "Epoch [23/100], Step [1660/1751], Loss: 1.3916\n",
      "Epoch [23/100], Step [1670/1751], Loss: 1.3834\n",
      "Epoch [23/100], Step [1680/1751], Loss: 1.2718\n",
      "Epoch [23/100], Step [1690/1751], Loss: 1.3935\n",
      "Epoch [23/100], Step [1700/1751], Loss: 1.1833\n",
      "Epoch [23/100], Step [1710/1751], Loss: 1.3821\n",
      "Epoch [23/100], Step [1720/1751], Loss: 1.2882\n",
      "Epoch [23/100], Step [1730/1751], Loss: 1.3029\n",
      "Epoch [23/100], Step [1740/1751], Loss: 1.2919\n",
      "Epoch [23/100], Step [1750/1751], Loss: 1.2285\n",
      "Epoch [23/100], Average Loss: 1.2672, Time: 1637.1205s\n",
      "Epoch [24/100], Step [10/1751], Loss: 1.3445\n",
      "Epoch [24/100], Step [20/1751], Loss: 1.2950\n",
      "Epoch [24/100], Step [30/1751], Loss: 1.2803\n",
      "Epoch [24/100], Step [40/1751], Loss: 1.3800\n",
      "Epoch [24/100], Step [50/1751], Loss: 1.2529\n",
      "Epoch [24/100], Step [60/1751], Loss: 1.3810\n",
      "Epoch [24/100], Step [70/1751], Loss: 1.3718\n",
      "Epoch [24/100], Step [80/1751], Loss: 1.1596\n",
      "Epoch [24/100], Step [90/1751], Loss: 1.3711\n",
      "Epoch [24/100], Step [100/1751], Loss: 1.2266\n",
      "Epoch [24/100], Step [110/1751], Loss: 1.2077\n",
      "Epoch [24/100], Step [120/1751], Loss: 1.1794\n",
      "Epoch [24/100], Step [130/1751], Loss: 1.3325\n",
      "Epoch [24/100], Step [140/1751], Loss: 1.2460\n",
      "Epoch [24/100], Step [150/1751], Loss: 1.3434\n",
      "Epoch [24/100], Step [160/1751], Loss: 1.2580\n",
      "Epoch [24/100], Step [170/1751], Loss: 1.3759\n",
      "Epoch [24/100], Step [180/1751], Loss: 1.1534\n",
      "Epoch [24/100], Step [190/1751], Loss: 1.3021\n",
      "Epoch [24/100], Step [200/1751], Loss: 1.2347\n",
      "Epoch [24/100], Step [210/1751], Loss: 1.1458\n",
      "Epoch [24/100], Step [220/1751], Loss: 1.1713\n",
      "Epoch [24/100], Step [230/1751], Loss: 1.2000\n",
      "Epoch [24/100], Step [240/1751], Loss: 1.3327\n",
      "Epoch [24/100], Step [250/1751], Loss: 1.2879\n",
      "Epoch [24/100], Step [260/1751], Loss: 1.2320\n",
      "Epoch [24/100], Step [270/1751], Loss: 1.2287\n",
      "Epoch [24/100], Step [280/1751], Loss: 1.3842\n",
      "Epoch [24/100], Step [290/1751], Loss: 1.2870\n",
      "Epoch [24/100], Step [300/1751], Loss: 1.3598\n",
      "Epoch [24/100], Step [310/1751], Loss: 1.1335\n",
      "Epoch [24/100], Step [320/1751], Loss: 1.1955\n",
      "Epoch [24/100], Step [330/1751], Loss: 1.1625\n",
      "Epoch [24/100], Step [340/1751], Loss: 1.3533\n",
      "Epoch [24/100], Step [350/1751], Loss: 1.2884\n",
      "Epoch [24/100], Step [360/1751], Loss: 1.3689\n",
      "Epoch [24/100], Step [370/1751], Loss: 1.2722\n",
      "Epoch [24/100], Step [380/1751], Loss: 1.3356\n",
      "Epoch [24/100], Step [390/1751], Loss: 1.1328\n",
      "Epoch [24/100], Step [400/1751], Loss: 1.1664\n",
      "Epoch [24/100], Step [410/1751], Loss: 1.2404\n",
      "Epoch [24/100], Step [420/1751], Loss: 1.1203\n",
      "Epoch [24/100], Step [430/1751], Loss: 1.1997\n",
      "Epoch [24/100], Step [440/1751], Loss: 1.1907\n",
      "Epoch [24/100], Step [450/1751], Loss: 1.2313\n",
      "Epoch [24/100], Step [460/1751], Loss: 1.2403\n",
      "Epoch [24/100], Step [470/1751], Loss: 1.1394\n",
      "Epoch [24/100], Step [480/1751], Loss: 1.2682\n",
      "Epoch [24/100], Step [490/1751], Loss: 1.2291\n",
      "Epoch [24/100], Step [500/1751], Loss: 1.2544\n",
      "Epoch [24/100], Step [510/1751], Loss: 1.2126\n",
      "Epoch [24/100], Step [520/1751], Loss: 1.1032\n",
      "Epoch [24/100], Step [530/1751], Loss: 1.2293\n",
      "Epoch [24/100], Step [540/1751], Loss: 1.2887\n",
      "Epoch [24/100], Step [550/1751], Loss: 1.3743\n",
      "Epoch [24/100], Step [560/1751], Loss: 1.3052\n",
      "Epoch [24/100], Step [570/1751], Loss: 1.2999\n",
      "Epoch [24/100], Step [580/1751], Loss: 1.3247\n",
      "Epoch [24/100], Step [590/1751], Loss: 1.1420\n",
      "Epoch [24/100], Step [600/1751], Loss: 1.4409\n",
      "Epoch [24/100], Step [610/1751], Loss: 1.4513\n",
      "Epoch [24/100], Step [620/1751], Loss: 1.1308\n",
      "Epoch [24/100], Step [630/1751], Loss: 1.2692\n",
      "Epoch [24/100], Step [640/1751], Loss: 1.3037\n",
      "Epoch [24/100], Step [650/1751], Loss: 1.3285\n",
      "Epoch [24/100], Step [660/1751], Loss: 1.4011\n",
      "Epoch [24/100], Step [670/1751], Loss: 1.1896\n",
      "Epoch [24/100], Step [680/1751], Loss: 1.3266\n",
      "Epoch [24/100], Step [690/1751], Loss: 1.3043\n",
      "Epoch [24/100], Step [700/1751], Loss: 1.2093\n",
      "Epoch [24/100], Step [710/1751], Loss: 1.3849\n",
      "Epoch [24/100], Step [720/1751], Loss: 1.5253\n",
      "Epoch [24/100], Step [730/1751], Loss: 1.2713\n",
      "Epoch [24/100], Step [740/1751], Loss: 1.2456\n",
      "Epoch [24/100], Step [750/1751], Loss: 1.2701\n",
      "Epoch [24/100], Step [760/1751], Loss: 1.3321\n",
      "Epoch [24/100], Step [770/1751], Loss: 1.2689\n",
      "Epoch [24/100], Step [780/1751], Loss: 1.2503\n",
      "Epoch [24/100], Step [790/1751], Loss: 1.2679\n",
      "Epoch [24/100], Step [800/1751], Loss: 1.3704\n",
      "Epoch [24/100], Step [810/1751], Loss: 1.3570\n",
      "Epoch [24/100], Step [820/1751], Loss: 1.2438\n",
      "Epoch [24/100], Step [830/1751], Loss: 1.3224\n",
      "Epoch [24/100], Step [840/1751], Loss: 1.2072\n",
      "Epoch [24/100], Step [850/1751], Loss: 1.2774\n",
      "Epoch [24/100], Step [860/1751], Loss: 1.0424\n",
      "Epoch [24/100], Step [870/1751], Loss: 1.3234\n",
      "Epoch [24/100], Step [880/1751], Loss: 1.3842\n",
      "Epoch [24/100], Step [890/1751], Loss: 1.1148\n",
      "Epoch [24/100], Step [900/1751], Loss: 1.1687\n",
      "Epoch [24/100], Step [910/1751], Loss: 1.3289\n",
      "Epoch [24/100], Step [920/1751], Loss: 1.2995\n",
      "Epoch [24/100], Step [930/1751], Loss: 1.2492\n",
      "Epoch [24/100], Step [940/1751], Loss: 1.2615\n",
      "Epoch [24/100], Step [950/1751], Loss: 1.2898\n",
      "Epoch [24/100], Step [960/1751], Loss: 1.3657\n",
      "Epoch [24/100], Step [970/1751], Loss: 1.1708\n",
      "Epoch [24/100], Step [980/1751], Loss: 1.1267\n",
      "Epoch [24/100], Step [990/1751], Loss: 1.3159\n",
      "Epoch [24/100], Step [1000/1751], Loss: 1.1586\n",
      "Epoch [24/100], Step [1010/1751], Loss: 1.1058\n",
      "Epoch [24/100], Step [1020/1751], Loss: 1.2817\n",
      "Epoch [24/100], Step [1030/1751], Loss: 1.2338\n",
      "Epoch [24/100], Step [1040/1751], Loss: 1.2804\n",
      "Epoch [24/100], Step [1050/1751], Loss: 1.3233\n",
      "Epoch [24/100], Step [1060/1751], Loss: 1.1205\n",
      "Epoch [24/100], Step [1070/1751], Loss: 1.2706\n",
      "Epoch [24/100], Step [1080/1751], Loss: 1.1881\n",
      "Epoch [24/100], Step [1090/1751], Loss: 1.2783\n",
      "Epoch [24/100], Step [1100/1751], Loss: 1.3466\n",
      "Epoch [24/100], Step [1110/1751], Loss: 1.2950\n",
      "Epoch [24/100], Step [1120/1751], Loss: 1.2842\n",
      "Epoch [24/100], Step [1130/1751], Loss: 1.2702\n",
      "Epoch [24/100], Step [1140/1751], Loss: 1.3763\n",
      "Epoch [24/100], Step [1150/1751], Loss: 1.2083\n",
      "Epoch [24/100], Step [1160/1751], Loss: 1.2708\n",
      "Epoch [24/100], Step [1170/1751], Loss: 1.3693\n",
      "Epoch [24/100], Step [1180/1751], Loss: 1.3389\n",
      "Epoch [24/100], Step [1190/1751], Loss: 1.3546\n",
      "Epoch [24/100], Step [1200/1751], Loss: 1.1133\n",
      "Epoch [24/100], Step [1210/1751], Loss: 1.2571\n",
      "Epoch [24/100], Step [1220/1751], Loss: 1.4052\n",
      "Epoch [24/100], Step [1230/1751], Loss: 1.2212\n",
      "Epoch [24/100], Step [1240/1751], Loss: 1.1492\n",
      "Epoch [24/100], Step [1250/1751], Loss: 1.3177\n",
      "Epoch [24/100], Step [1260/1751], Loss: 1.4649\n",
      "Epoch [24/100], Step [1270/1751], Loss: 1.1820\n",
      "Epoch [24/100], Step [1280/1751], Loss: 1.1389\n",
      "Epoch [24/100], Step [1290/1751], Loss: 1.2868\n",
      "Epoch [24/100], Step [1300/1751], Loss: 1.2346\n",
      "Epoch [24/100], Step [1310/1751], Loss: 1.2693\n",
      "Epoch [24/100], Step [1320/1751], Loss: 1.0876\n",
      "Epoch [24/100], Step [1330/1751], Loss: 1.1859\n",
      "Epoch [24/100], Step [1340/1751], Loss: 1.2697\n",
      "Epoch [24/100], Step [1350/1751], Loss: 1.2411\n",
      "Epoch [24/100], Step [1360/1751], Loss: 1.2025\n",
      "Epoch [24/100], Step [1370/1751], Loss: 1.1619\n",
      "Epoch [24/100], Step [1380/1751], Loss: 1.3280\n",
      "Epoch [24/100], Step [1390/1751], Loss: 1.3597\n",
      "Epoch [24/100], Step [1400/1751], Loss: 1.4303\n",
      "Epoch [24/100], Step [1410/1751], Loss: 1.2637\n",
      "Epoch [24/100], Step [1420/1751], Loss: 1.2537\n",
      "Epoch [24/100], Step [1430/1751], Loss: 1.3324\n",
      "Epoch [24/100], Step [1440/1751], Loss: 1.3086\n",
      "Epoch [24/100], Step [1450/1751], Loss: 1.2107\n",
      "Epoch [24/100], Step [1460/1751], Loss: 1.2104\n",
      "Epoch [24/100], Step [1470/1751], Loss: 1.3505\n",
      "Epoch [24/100], Step [1480/1751], Loss: 1.1958\n",
      "Epoch [24/100], Step [1490/1751], Loss: 1.1678\n",
      "Epoch [24/100], Step [1500/1751], Loss: 1.2395\n",
      "Epoch [24/100], Step [1510/1751], Loss: 1.2015\n",
      "Epoch [24/100], Step [1520/1751], Loss: 1.3964\n",
      "Epoch [24/100], Step [1530/1751], Loss: 1.0935\n",
      "Epoch [24/100], Step [1540/1751], Loss: 1.2812\n",
      "Epoch [24/100], Step [1550/1751], Loss: 1.2552\n",
      "Epoch [24/100], Step [1560/1751], Loss: 1.2826\n",
      "Epoch [24/100], Step [1570/1751], Loss: 1.1441\n",
      "Epoch [24/100], Step [1580/1751], Loss: 1.3778\n",
      "Epoch [24/100], Step [1590/1751], Loss: 1.4481\n",
      "Epoch [24/100], Step [1600/1751], Loss: 1.1964\n",
      "Epoch [24/100], Step [1610/1751], Loss: 1.2299\n",
      "Epoch [24/100], Step [1620/1751], Loss: 1.2834\n",
      "Epoch [24/100], Step [1630/1751], Loss: 1.2148\n",
      "Epoch [24/100], Step [1640/1751], Loss: 1.2215\n",
      "Epoch [24/100], Step [1650/1751], Loss: 1.1730\n",
      "Epoch [24/100], Step [1660/1751], Loss: 1.2529\n",
      "Epoch [24/100], Step [1670/1751], Loss: 1.1853\n",
      "Epoch [24/100], Step [1680/1751], Loss: 1.2730\n",
      "Epoch [24/100], Step [1690/1751], Loss: 1.3039\n",
      "Epoch [24/100], Step [1700/1751], Loss: 1.3310\n",
      "Epoch [24/100], Step [1710/1751], Loss: 1.0053\n",
      "Epoch [24/100], Step [1720/1751], Loss: 1.3161\n",
      "Epoch [24/100], Step [1730/1751], Loss: 1.2249\n",
      "Epoch [24/100], Step [1740/1751], Loss: 1.0839\n",
      "Epoch [24/100], Step [1750/1751], Loss: 1.4348\n",
      "Epoch [24/100], Average Loss: 1.2624, Time: 1638.1449s\n",
      "Epoch [25/100], Step [10/1751], Loss: 1.4662\n",
      "Epoch [25/100], Step [20/1751], Loss: 1.3718\n",
      "Epoch [25/100], Step [30/1751], Loss: 1.3516\n",
      "Epoch [25/100], Step [40/1751], Loss: 1.2635\n",
      "Epoch [25/100], Step [50/1751], Loss: 1.3316\n",
      "Epoch [25/100], Step [60/1751], Loss: 1.2712\n",
      "Epoch [25/100], Step [70/1751], Loss: 1.2340\n",
      "Epoch [25/100], Step [80/1751], Loss: 1.3027\n",
      "Epoch [25/100], Step [90/1751], Loss: 1.2602\n",
      "Epoch [25/100], Step [100/1751], Loss: 1.2564\n",
      "Epoch [25/100], Step [110/1751], Loss: 1.2514\n",
      "Epoch [25/100], Step [120/1751], Loss: 1.3060\n",
      "Epoch [25/100], Step [130/1751], Loss: 1.1691\n",
      "Epoch [25/100], Step [140/1751], Loss: 1.3769\n",
      "Epoch [25/100], Step [150/1751], Loss: 1.0723\n",
      "Epoch [25/100], Step [160/1751], Loss: 1.2780\n",
      "Epoch [25/100], Step [170/1751], Loss: 1.2796\n",
      "Epoch [25/100], Step [180/1751], Loss: 1.3228\n",
      "Epoch [25/100], Step [190/1751], Loss: 1.3475\n",
      "Epoch [25/100], Step [200/1751], Loss: 1.2084\n",
      "Epoch [25/100], Step [210/1751], Loss: 1.2785\n",
      "Epoch [25/100], Step [220/1751], Loss: 1.2037\n",
      "Epoch [25/100], Step [230/1751], Loss: 1.2270\n",
      "Epoch [25/100], Step [240/1751], Loss: 1.4323\n",
      "Epoch [25/100], Step [250/1751], Loss: 1.3491\n",
      "Epoch [25/100], Step [260/1751], Loss: 1.1659\n",
      "Epoch [25/100], Step [270/1751], Loss: 1.2949\n",
      "Epoch [25/100], Step [280/1751], Loss: 1.2701\n",
      "Epoch [25/100], Step [290/1751], Loss: 1.2426\n",
      "Epoch [25/100], Step [300/1751], Loss: 1.0809\n",
      "Epoch [25/100], Step [310/1751], Loss: 1.2478\n",
      "Epoch [25/100], Step [320/1751], Loss: 1.2640\n",
      "Epoch [25/100], Step [330/1751], Loss: 1.2224\n",
      "Epoch [25/100], Step [340/1751], Loss: 1.2667\n",
      "Epoch [25/100], Step [350/1751], Loss: 1.0582\n",
      "Epoch [25/100], Step [360/1751], Loss: 1.1434\n",
      "Epoch [25/100], Step [370/1751], Loss: 1.2334\n",
      "Epoch [25/100], Step [380/1751], Loss: 1.3946\n",
      "Epoch [25/100], Step [390/1751], Loss: 1.2915\n",
      "Epoch [25/100], Step [400/1751], Loss: 1.2018\n",
      "Epoch [25/100], Step [410/1751], Loss: 1.1488\n",
      "Epoch [25/100], Step [420/1751], Loss: 1.2741\n",
      "Epoch [25/100], Step [430/1751], Loss: 1.2249\n",
      "Epoch [25/100], Step [440/1751], Loss: 1.2338\n",
      "Epoch [25/100], Step [450/1751], Loss: 1.0966\n",
      "Epoch [25/100], Step [460/1751], Loss: 1.1365\n",
      "Epoch [25/100], Step [470/1751], Loss: 1.2294\n",
      "Epoch [25/100], Step [480/1751], Loss: 1.4248\n",
      "Epoch [25/100], Step [490/1751], Loss: 1.1710\n",
      "Epoch [25/100], Step [500/1751], Loss: 1.2826\n",
      "Epoch [25/100], Step [510/1751], Loss: 1.2305\n",
      "Epoch [25/100], Step [520/1751], Loss: 1.3127\n",
      "Epoch [25/100], Step [530/1751], Loss: 1.2042\n",
      "Epoch [25/100], Step [540/1751], Loss: 1.2673\n",
      "Epoch [25/100], Step [550/1751], Loss: 1.2827\n",
      "Epoch [25/100], Step [560/1751], Loss: 1.2482\n",
      "Epoch [25/100], Step [570/1751], Loss: 1.2063\n",
      "Epoch [25/100], Step [580/1751], Loss: 1.4072\n",
      "Epoch [25/100], Step [590/1751], Loss: 1.3318\n",
      "Epoch [25/100], Step [600/1751], Loss: 1.2152\n",
      "Epoch [25/100], Step [610/1751], Loss: 1.1912\n",
      "Epoch [25/100], Step [620/1751], Loss: 1.3011\n",
      "Epoch [25/100], Step [630/1751], Loss: 1.2941\n",
      "Epoch [25/100], Step [640/1751], Loss: 1.2663\n",
      "Epoch [25/100], Step [650/1751], Loss: 1.1458\n",
      "Epoch [25/100], Step [660/1751], Loss: 1.2277\n",
      "Epoch [25/100], Step [670/1751], Loss: 1.3302\n",
      "Epoch [25/100], Step [680/1751], Loss: 1.3796\n",
      "Epoch [25/100], Step [690/1751], Loss: 1.2783\n",
      "Epoch [25/100], Step [700/1751], Loss: 1.1430\n",
      "Epoch [25/100], Step [710/1751], Loss: 1.2710\n",
      "Epoch [25/100], Step [720/1751], Loss: 1.2756\n",
      "Epoch [25/100], Step [730/1751], Loss: 1.3504\n",
      "Epoch [25/100], Step [740/1751], Loss: 1.1896\n",
      "Epoch [25/100], Step [750/1751], Loss: 1.2085\n",
      "Epoch [25/100], Step [760/1751], Loss: 1.3200\n",
      "Epoch [25/100], Step [770/1751], Loss: 1.4151\n",
      "Epoch [25/100], Step [780/1751], Loss: 1.2510\n",
      "Epoch [25/100], Step [790/1751], Loss: 1.2601\n",
      "Epoch [25/100], Step [800/1751], Loss: 1.3377\n",
      "Epoch [25/100], Step [810/1751], Loss: 1.3905\n",
      "Epoch [25/100], Step [820/1751], Loss: 1.2249\n",
      "Epoch [25/100], Step [830/1751], Loss: 1.1563\n",
      "Epoch [25/100], Step [840/1751], Loss: 1.3582\n",
      "Epoch [25/100], Step [850/1751], Loss: 1.0949\n",
      "Epoch [25/100], Step [860/1751], Loss: 1.2379\n",
      "Epoch [25/100], Step [870/1751], Loss: 1.2368\n",
      "Epoch [25/100], Step [880/1751], Loss: 1.2155\n",
      "Epoch [25/100], Step [890/1751], Loss: 1.3998\n",
      "Epoch [25/100], Step [900/1751], Loss: 1.1708\n",
      "Epoch [25/100], Step [910/1751], Loss: 1.2101\n",
      "Epoch [25/100], Step [920/1751], Loss: 1.2234\n",
      "Epoch [25/100], Step [930/1751], Loss: 1.2511\n",
      "Epoch [25/100], Step [940/1751], Loss: 1.3793\n",
      "Epoch [25/100], Step [950/1751], Loss: 1.3196\n",
      "Epoch [25/100], Step [960/1751], Loss: 1.3659\n",
      "Epoch [25/100], Step [970/1751], Loss: 1.3750\n",
      "Epoch [25/100], Step [980/1751], Loss: 1.1500\n",
      "Epoch [25/100], Step [990/1751], Loss: 1.2381\n",
      "Epoch [25/100], Step [1000/1751], Loss: 1.4176\n",
      "Epoch [25/100], Step [1010/1751], Loss: 1.3432\n",
      "Epoch [25/100], Step [1020/1751], Loss: 1.3246\n",
      "Epoch [25/100], Step [1030/1751], Loss: 1.2903\n",
      "Epoch [25/100], Step [1040/1751], Loss: 1.3318\n",
      "Epoch [25/100], Step [1050/1751], Loss: 1.2046\n",
      "Epoch [25/100], Step [1060/1751], Loss: 1.2597\n",
      "Epoch [25/100], Step [1070/1751], Loss: 1.3317\n",
      "Epoch [25/100], Step [1080/1751], Loss: 1.1619\n",
      "Epoch [25/100], Step [1090/1751], Loss: 1.2122\n",
      "Epoch [25/100], Step [1100/1751], Loss: 1.1493\n",
      "Epoch [25/100], Step [1110/1751], Loss: 1.1461\n",
      "Epoch [25/100], Step [1120/1751], Loss: 1.3629\n",
      "Epoch [25/100], Step [1130/1751], Loss: 1.3666\n",
      "Epoch [25/100], Step [1140/1751], Loss: 1.2940\n",
      "Epoch [25/100], Step [1150/1751], Loss: 1.1692\n",
      "Epoch [25/100], Step [1160/1751], Loss: 1.1253\n",
      "Epoch [25/100], Step [1170/1751], Loss: 1.3293\n",
      "Epoch [25/100], Step [1180/1751], Loss: 1.3252\n",
      "Epoch [25/100], Step [1190/1751], Loss: 1.2582\n",
      "Epoch [25/100], Step [1200/1751], Loss: 1.3208\n",
      "Epoch [25/100], Step [1210/1751], Loss: 1.2134\n",
      "Epoch [25/100], Step [1220/1751], Loss: 1.2472\n",
      "Epoch [25/100], Step [1230/1751], Loss: 1.3973\n",
      "Epoch [25/100], Step [1240/1751], Loss: 1.2774\n",
      "Epoch [25/100], Step [1250/1751], Loss: 1.1051\n",
      "Epoch [25/100], Step [1260/1751], Loss: 1.3226\n",
      "Epoch [25/100], Step [1270/1751], Loss: 1.1993\n",
      "Epoch [25/100], Step [1280/1751], Loss: 1.1594\n",
      "Epoch [25/100], Step [1290/1751], Loss: 1.1017\n",
      "Epoch [25/100], Step [1300/1751], Loss: 1.3037\n",
      "Epoch [25/100], Step [1310/1751], Loss: 1.2643\n",
      "Epoch [25/100], Step [1320/1751], Loss: 1.2221\n",
      "Epoch [25/100], Step [1330/1751], Loss: 1.1931\n",
      "Epoch [25/100], Step [1340/1751], Loss: 1.2505\n",
      "Epoch [25/100], Step [1350/1751], Loss: 1.1161\n",
      "Epoch [25/100], Step [1360/1751], Loss: 1.2760\n",
      "Epoch [25/100], Step [1370/1751], Loss: 1.2941\n",
      "Epoch [25/100], Step [1380/1751], Loss: 1.3057\n",
      "Epoch [25/100], Step [1390/1751], Loss: 1.2175\n",
      "Epoch [25/100], Step [1400/1751], Loss: 1.2853\n",
      "Epoch [25/100], Step [1410/1751], Loss: 1.1365\n",
      "Epoch [25/100], Step [1420/1751], Loss: 1.2591\n",
      "Epoch [25/100], Step [1430/1751], Loss: 1.3609\n",
      "Epoch [25/100], Step [1440/1751], Loss: 1.1496\n",
      "Epoch [25/100], Step [1450/1751], Loss: 1.3186\n",
      "Epoch [25/100], Step [1460/1751], Loss: 1.1836\n",
      "Epoch [25/100], Step [1470/1751], Loss: 1.4215\n",
      "Epoch [25/100], Step [1480/1751], Loss: 1.3307\n",
      "Epoch [25/100], Step [1490/1751], Loss: 1.1336\n",
      "Epoch [25/100], Step [1500/1751], Loss: 1.2966\n",
      "Epoch [25/100], Step [1510/1751], Loss: 1.3437\n",
      "Epoch [25/100], Step [1520/1751], Loss: 1.3032\n",
      "Epoch [25/100], Step [1530/1751], Loss: 1.2960\n",
      "Epoch [25/100], Step [1540/1751], Loss: 1.1716\n",
      "Epoch [25/100], Step [1550/1751], Loss: 1.2511\n",
      "Epoch [25/100], Step [1560/1751], Loss: 1.2500\n",
      "Epoch [25/100], Step [1570/1751], Loss: 1.2692\n",
      "Epoch [25/100], Step [1580/1751], Loss: 1.1946\n",
      "Epoch [25/100], Step [1590/1751], Loss: 1.3835\n",
      "Epoch [25/100], Step [1600/1751], Loss: 1.0951\n",
      "Epoch [25/100], Step [1610/1751], Loss: 1.2897\n",
      "Epoch [25/100], Step [1620/1751], Loss: 1.2362\n",
      "Epoch [25/100], Step [1630/1751], Loss: 1.1942\n",
      "Epoch [25/100], Step [1640/1751], Loss: 1.3971\n",
      "Epoch [25/100], Step [1650/1751], Loss: 1.3590\n",
      "Epoch [25/100], Step [1660/1751], Loss: 1.2090\n",
      "Epoch [25/100], Step [1670/1751], Loss: 1.1122\n",
      "Epoch [25/100], Step [1680/1751], Loss: 1.1651\n",
      "Epoch [25/100], Step [1690/1751], Loss: 1.2219\n",
      "Epoch [25/100], Step [1700/1751], Loss: 1.3225\n",
      "Epoch [25/100], Step [1710/1751], Loss: 1.2005\n",
      "Epoch [25/100], Step [1720/1751], Loss: 1.2433\n",
      "Epoch [25/100], Step [1730/1751], Loss: 1.1667\n",
      "Epoch [25/100], Step [1740/1751], Loss: 1.1935\n",
      "Epoch [25/100], Step [1750/1751], Loss: 1.4241\n",
      "Epoch [25/100], Average Loss: 1.2588, Time: 1637.9406s\n",
      "Epoch [26/100], Step [10/1751], Loss: 1.2798\n",
      "Epoch [26/100], Step [20/1751], Loss: 1.3449\n",
      "Epoch [26/100], Step [30/1751], Loss: 1.2617\n",
      "Epoch [26/100], Step [40/1751], Loss: 1.3733\n",
      "Epoch [26/100], Step [50/1751], Loss: 1.4430\n",
      "Epoch [26/100], Step [60/1751], Loss: 1.3065\n",
      "Epoch [26/100], Step [70/1751], Loss: 1.2914\n",
      "Epoch [26/100], Step [80/1751], Loss: 1.2551\n",
      "Epoch [26/100], Step [90/1751], Loss: 1.1615\n",
      "Epoch [26/100], Step [100/1751], Loss: 1.2119\n",
      "Epoch [26/100], Step [110/1751], Loss: 1.3979\n",
      "Epoch [26/100], Step [120/1751], Loss: 1.2056\n",
      "Epoch [26/100], Step [130/1751], Loss: 1.2642\n",
      "Epoch [26/100], Step [140/1751], Loss: 1.2496\n",
      "Epoch [26/100], Step [150/1751], Loss: 1.2059\n",
      "Epoch [26/100], Step [160/1751], Loss: 1.2406\n",
      "Epoch [26/100], Step [170/1751], Loss: 1.0163\n",
      "Epoch [26/100], Step [180/1751], Loss: 1.2292\n",
      "Epoch [26/100], Step [190/1751], Loss: 1.2107\n",
      "Epoch [26/100], Step [200/1751], Loss: 1.1089\n",
      "Epoch [26/100], Step [210/1751], Loss: 1.4804\n",
      "Epoch [26/100], Step [220/1751], Loss: 1.3501\n",
      "Epoch [26/100], Step [230/1751], Loss: 1.3508\n",
      "Epoch [26/100], Step [240/1751], Loss: 1.2857\n",
      "Epoch [26/100], Step [250/1751], Loss: 1.2895\n",
      "Epoch [26/100], Step [260/1751], Loss: 1.1802\n",
      "Epoch [26/100], Step [270/1751], Loss: 1.3132\n",
      "Epoch [26/100], Step [280/1751], Loss: 1.2841\n",
      "Epoch [26/100], Step [290/1751], Loss: 1.2207\n",
      "Epoch [26/100], Step [300/1751], Loss: 1.2039\n",
      "Epoch [26/100], Step [310/1751], Loss: 1.2169\n",
      "Epoch [26/100], Step [320/1751], Loss: 1.2655\n",
      "Epoch [26/100], Step [330/1751], Loss: 1.4139\n",
      "Epoch [26/100], Step [340/1751], Loss: 1.2859\n",
      "Epoch [26/100], Step [350/1751], Loss: 1.3585\n",
      "Epoch [26/100], Step [360/1751], Loss: 1.0988\n",
      "Epoch [26/100], Step [370/1751], Loss: 1.3100\n",
      "Epoch [26/100], Step [380/1751], Loss: 1.1104\n",
      "Epoch [26/100], Step [390/1751], Loss: 1.2043\n",
      "Epoch [26/100], Step [400/1751], Loss: 1.1639\n",
      "Epoch [26/100], Step [410/1751], Loss: 1.2580\n",
      "Epoch [26/100], Step [420/1751], Loss: 1.3021\n",
      "Epoch [26/100], Step [430/1751], Loss: 1.3694\n",
      "Epoch [26/100], Step [440/1751], Loss: 1.1958\n",
      "Epoch [26/100], Step [450/1751], Loss: 1.2766\n",
      "Epoch [26/100], Step [460/1751], Loss: 1.1757\n",
      "Epoch [26/100], Step [470/1751], Loss: 1.2106\n",
      "Epoch [26/100], Step [480/1751], Loss: 1.2307\n",
      "Epoch [26/100], Step [490/1751], Loss: 1.3577\n",
      "Epoch [26/100], Step [500/1751], Loss: 1.2145\n",
      "Epoch [26/100], Step [510/1751], Loss: 1.4353\n",
      "Epoch [26/100], Step [520/1751], Loss: 1.2590\n",
      "Epoch [26/100], Step [530/1751], Loss: 1.1833\n",
      "Epoch [26/100], Step [540/1751], Loss: 1.4443\n",
      "Epoch [26/100], Step [550/1751], Loss: 1.3282\n",
      "Epoch [26/100], Step [560/1751], Loss: 1.1733\n",
      "Epoch [26/100], Step [570/1751], Loss: 1.2882\n",
      "Epoch [26/100], Step [580/1751], Loss: 1.2375\n",
      "Epoch [26/100], Step [590/1751], Loss: 1.2498\n",
      "Epoch [26/100], Step [600/1751], Loss: 1.2620\n",
      "Epoch [26/100], Step [610/1751], Loss: 1.2965\n",
      "Epoch [26/100], Step [620/1751], Loss: 1.3207\n",
      "Epoch [26/100], Step [630/1751], Loss: 1.0727\n",
      "Epoch [26/100], Step [640/1751], Loss: 1.3219\n",
      "Epoch [26/100], Step [650/1751], Loss: 1.2377\n",
      "Epoch [26/100], Step [660/1751], Loss: 1.1697\n",
      "Epoch [26/100], Step [670/1751], Loss: 1.1403\n",
      "Epoch [26/100], Step [680/1751], Loss: 1.1656\n",
      "Epoch [26/100], Step [690/1751], Loss: 1.1481\n",
      "Epoch [26/100], Step [700/1751], Loss: 1.3273\n",
      "Epoch [26/100], Step [710/1751], Loss: 1.2175\n",
      "Epoch [26/100], Step [720/1751], Loss: 1.3556\n",
      "Epoch [26/100], Step [730/1751], Loss: 1.2809\n",
      "Epoch [26/100], Step [740/1751], Loss: 1.1115\n",
      "Epoch [26/100], Step [750/1751], Loss: 1.4032\n",
      "Epoch [26/100], Step [760/1751], Loss: 1.3097\n",
      "Epoch [26/100], Step [770/1751], Loss: 1.3098\n",
      "Epoch [26/100], Step [780/1751], Loss: 1.1392\n",
      "Epoch [26/100], Step [790/1751], Loss: 1.2584\n",
      "Epoch [26/100], Step [800/1751], Loss: 1.2213\n",
      "Epoch [26/100], Step [810/1751], Loss: 1.4537\n",
      "Epoch [26/100], Step [820/1751], Loss: 1.3818\n",
      "Epoch [26/100], Step [830/1751], Loss: 1.3157\n",
      "Epoch [26/100], Step [840/1751], Loss: 1.0874\n",
      "Epoch [26/100], Step [850/1751], Loss: 1.3011\n",
      "Epoch [26/100], Step [860/1751], Loss: 1.1293\n",
      "Epoch [26/100], Step [870/1751], Loss: 1.1526\n",
      "Epoch [26/100], Step [880/1751], Loss: 1.2949\n",
      "Epoch [26/100], Step [890/1751], Loss: 1.3348\n",
      "Epoch [26/100], Step [900/1751], Loss: 1.2994\n",
      "Epoch [26/100], Step [910/1751], Loss: 1.3440\n",
      "Epoch [26/100], Step [920/1751], Loss: 1.2114\n",
      "Epoch [26/100], Step [930/1751], Loss: 1.1939\n",
      "Epoch [26/100], Step [940/1751], Loss: 1.1790\n",
      "Epoch [26/100], Step [950/1751], Loss: 1.0838\n",
      "Epoch [26/100], Step [960/1751], Loss: 1.3016\n",
      "Epoch [26/100], Step [970/1751], Loss: 1.2666\n",
      "Epoch [26/100], Step [980/1751], Loss: 1.2121\n",
      "Epoch [26/100], Step [990/1751], Loss: 1.1512\n",
      "Epoch [26/100], Step [1000/1751], Loss: 1.1916\n",
      "Epoch [26/100], Step [1010/1751], Loss: 1.2531\n",
      "Epoch [26/100], Step [1020/1751], Loss: 1.3075\n",
      "Epoch [26/100], Step [1030/1751], Loss: 1.1733\n",
      "Epoch [26/100], Step [1040/1751], Loss: 1.3843\n",
      "Epoch [26/100], Step [1050/1751], Loss: 1.3577\n",
      "Epoch [26/100], Step [1060/1751], Loss: 1.3569\n",
      "Epoch [26/100], Step [1070/1751], Loss: 1.2299\n",
      "Epoch [26/100], Step [1080/1751], Loss: 1.1658\n",
      "Epoch [26/100], Step [1090/1751], Loss: 1.2394\n",
      "Epoch [26/100], Step [1100/1751], Loss: 1.2910\n",
      "Epoch [26/100], Step [1110/1751], Loss: 1.2589\n",
      "Epoch [26/100], Step [1120/1751], Loss: 1.2979\n",
      "Epoch [26/100], Step [1130/1751], Loss: 1.2564\n",
      "Epoch [26/100], Step [1140/1751], Loss: 1.3003\n",
      "Epoch [26/100], Step [1150/1751], Loss: 1.2680\n",
      "Epoch [26/100], Step [1160/1751], Loss: 1.3259\n",
      "Epoch [26/100], Step [1170/1751], Loss: 1.3440\n",
      "Epoch [26/100], Step [1180/1751], Loss: 1.0374\n",
      "Epoch [26/100], Step [1190/1751], Loss: 1.2324\n",
      "Epoch [26/100], Step [1200/1751], Loss: 1.3460\n",
      "Epoch [26/100], Step [1210/1751], Loss: 1.2479\n",
      "Epoch [26/100], Step [1220/1751], Loss: 1.2844\n",
      "Epoch [26/100], Step [1230/1751], Loss: 1.2717\n",
      "Epoch [26/100], Step [1240/1751], Loss: 1.2864\n",
      "Epoch [26/100], Step [1250/1751], Loss: 1.2056\n",
      "Epoch [26/100], Step [1260/1751], Loss: 1.0806\n",
      "Epoch [26/100], Step [1270/1751], Loss: 1.3550\n",
      "Epoch [26/100], Step [1280/1751], Loss: 1.3017\n",
      "Epoch [26/100], Step [1290/1751], Loss: 1.2403\n",
      "Epoch [26/100], Step [1300/1751], Loss: 1.3191\n",
      "Epoch [26/100], Step [1310/1751], Loss: 1.3777\n",
      "Epoch [26/100], Step [1320/1751], Loss: 1.1869\n",
      "Epoch [26/100], Step [1330/1751], Loss: 1.3039\n",
      "Epoch [26/100], Step [1340/1751], Loss: 1.3092\n",
      "Epoch [26/100], Step [1350/1751], Loss: 1.2075\n",
      "Epoch [26/100], Step [1360/1751], Loss: 1.3101\n",
      "Epoch [26/100], Step [1370/1751], Loss: 1.3862\n",
      "Epoch [26/100], Step [1380/1751], Loss: 1.2521\n",
      "Epoch [26/100], Step [1390/1751], Loss: 1.3414\n",
      "Epoch [26/100], Step [1400/1751], Loss: 1.3530\n",
      "Epoch [26/100], Step [1410/1751], Loss: 1.2798\n",
      "Epoch [26/100], Step [1420/1751], Loss: 1.1967\n",
      "Epoch [26/100], Step [1430/1751], Loss: 1.2640\n",
      "Epoch [26/100], Step [1440/1751], Loss: 1.1266\n",
      "Epoch [26/100], Step [1450/1751], Loss: 1.1594\n",
      "Epoch [26/100], Step [1460/1751], Loss: 1.2554\n",
      "Epoch [26/100], Step [1470/1751], Loss: 1.3195\n",
      "Epoch [26/100], Step [1480/1751], Loss: 1.2287\n",
      "Epoch [26/100], Step [1490/1751], Loss: 1.1462\n",
      "Epoch [26/100], Step [1500/1751], Loss: 1.2811\n",
      "Epoch [26/100], Step [1510/1751], Loss: 1.2309\n",
      "Epoch [26/100], Step [1520/1751], Loss: 1.2440\n",
      "Epoch [26/100], Step [1530/1751], Loss: 1.1209\n",
      "Epoch [26/100], Step [1540/1751], Loss: 1.0910\n",
      "Epoch [26/100], Step [1550/1751], Loss: 1.1985\n",
      "Epoch [26/100], Step [1560/1751], Loss: 1.3722\n",
      "Epoch [26/100], Step [1570/1751], Loss: 1.4464\n",
      "Epoch [26/100], Step [1580/1751], Loss: 1.2149\n",
      "Epoch [26/100], Step [1590/1751], Loss: 1.1575\n",
      "Epoch [26/100], Step [1600/1751], Loss: 1.3336\n",
      "Epoch [26/100], Step [1610/1751], Loss: 1.1435\n",
      "Epoch [26/100], Step [1620/1751], Loss: 1.2193\n",
      "Epoch [26/100], Step [1630/1751], Loss: 1.3147\n",
      "Epoch [26/100], Step [1640/1751], Loss: 1.2955\n",
      "Epoch [26/100], Step [1650/1751], Loss: 1.2297\n",
      "Epoch [26/100], Step [1660/1751], Loss: 1.2915\n",
      "Epoch [26/100], Step [1670/1751], Loss: 1.4176\n",
      "Epoch [26/100], Step [1680/1751], Loss: 1.1549\n",
      "Epoch [26/100], Step [1690/1751], Loss: 1.3985\n",
      "Epoch [26/100], Step [1700/1751], Loss: 1.2577\n",
      "Epoch [26/100], Step [1710/1751], Loss: 1.0652\n",
      "Epoch [26/100], Step [1720/1751], Loss: 1.1912\n",
      "Epoch [26/100], Step [1730/1751], Loss: 1.2455\n",
      "Epoch [26/100], Step [1740/1751], Loss: 1.2178\n",
      "Epoch [26/100], Step [1750/1751], Loss: 1.2368\n",
      "Epoch [26/100], Average Loss: 1.2557, Time: 1639.2969s\n",
      "Epoch [27/100], Step [10/1751], Loss: 1.3006\n",
      "Epoch [27/100], Step [20/1751], Loss: 1.3023\n",
      "Epoch [27/100], Step [30/1751], Loss: 1.3029\n",
      "Epoch [27/100], Step [40/1751], Loss: 1.2541\n",
      "Epoch [27/100], Step [50/1751], Loss: 1.2582\n",
      "Epoch [27/100], Step [60/1751], Loss: 1.2339\n",
      "Epoch [27/100], Step [70/1751], Loss: 1.2845\n",
      "Epoch [27/100], Step [80/1751], Loss: 1.4421\n",
      "Epoch [27/100], Step [90/1751], Loss: 1.3232\n",
      "Epoch [27/100], Step [100/1751], Loss: 1.2659\n",
      "Epoch [27/100], Step [110/1751], Loss: 1.1722\n",
      "Epoch [27/100], Step [120/1751], Loss: 1.2309\n",
      "Epoch [27/100], Step [130/1751], Loss: 1.1758\n",
      "Epoch [27/100], Step [140/1751], Loss: 1.3271\n",
      "Epoch [27/100], Step [150/1751], Loss: 1.2808\n",
      "Epoch [27/100], Step [160/1751], Loss: 1.3428\n",
      "Epoch [27/100], Step [170/1751], Loss: 1.3312\n",
      "Epoch [27/100], Step [180/1751], Loss: 1.2471\n",
      "Epoch [27/100], Step [190/1751], Loss: 1.2597\n",
      "Epoch [27/100], Step [200/1751], Loss: 1.3267\n",
      "Epoch [27/100], Step [210/1751], Loss: 1.1044\n",
      "Epoch [27/100], Step [220/1751], Loss: 1.3230\n",
      "Epoch [27/100], Step [230/1751], Loss: 1.2759\n",
      "Epoch [27/100], Step [240/1751], Loss: 1.2444\n",
      "Epoch [27/100], Step [250/1751], Loss: 1.2186\n",
      "Epoch [27/100], Step [260/1751], Loss: 1.3009\n",
      "Epoch [27/100], Step [270/1751], Loss: 1.2027\n",
      "Epoch [27/100], Step [280/1751], Loss: 1.1568\n",
      "Epoch [27/100], Step [290/1751], Loss: 1.3623\n",
      "Epoch [27/100], Step [300/1751], Loss: 1.3107\n",
      "Epoch [27/100], Step [310/1751], Loss: 1.1879\n",
      "Epoch [27/100], Step [320/1751], Loss: 1.3515\n",
      "Epoch [27/100], Step [330/1751], Loss: 1.3572\n",
      "Epoch [27/100], Step [340/1751], Loss: 1.1469\n",
      "Epoch [27/100], Step [350/1751], Loss: 1.2856\n",
      "Epoch [27/100], Step [360/1751], Loss: 1.3922\n",
      "Epoch [27/100], Step [370/1751], Loss: 1.2276\n",
      "Epoch [27/100], Step [380/1751], Loss: 1.2241\n",
      "Epoch [27/100], Step [390/1751], Loss: 1.3065\n",
      "Epoch [27/100], Step [400/1751], Loss: 1.4457\n",
      "Epoch [27/100], Step [410/1751], Loss: 1.3897\n",
      "Epoch [27/100], Step [420/1751], Loss: 1.3426\n",
      "Epoch [27/100], Step [430/1751], Loss: 1.2512\n",
      "Epoch [27/100], Step [440/1751], Loss: 1.2187\n",
      "Epoch [27/100], Step [450/1751], Loss: 1.0420\n",
      "Epoch [27/100], Step [460/1751], Loss: 1.3758\n",
      "Epoch [27/100], Step [470/1751], Loss: 1.2584\n",
      "Epoch [27/100], Step [480/1751], Loss: 1.1705\n",
      "Epoch [27/100], Step [490/1751], Loss: 1.2383\n",
      "Epoch [27/100], Step [500/1751], Loss: 1.1489\n",
      "Epoch [27/100], Step [510/1751], Loss: 1.3026\n",
      "Epoch [27/100], Step [520/1751], Loss: 1.2485\n",
      "Epoch [27/100], Step [530/1751], Loss: 1.2333\n",
      "Epoch [27/100], Step [540/1751], Loss: 1.1542\n",
      "Epoch [27/100], Step [550/1751], Loss: 1.1992\n",
      "Epoch [27/100], Step [560/1751], Loss: 1.2549\n",
      "Epoch [27/100], Step [570/1751], Loss: 1.2109\n",
      "Epoch [27/100], Step [580/1751], Loss: 1.2228\n",
      "Epoch [27/100], Step [590/1751], Loss: 1.2029\n",
      "Epoch [27/100], Step [600/1751], Loss: 1.4157\n",
      "Epoch [27/100], Step [610/1751], Loss: 1.2047\n",
      "Epoch [27/100], Step [620/1751], Loss: 1.3408\n",
      "Epoch [27/100], Step [630/1751], Loss: 1.2431\n",
      "Epoch [27/100], Step [640/1751], Loss: 1.2850\n",
      "Epoch [27/100], Step [650/1751], Loss: 1.4388\n",
      "Epoch [27/100], Step [660/1751], Loss: 1.3527\n",
      "Epoch [27/100], Step [670/1751], Loss: 1.1215\n",
      "Epoch [27/100], Step [680/1751], Loss: 1.2233\n",
      "Epoch [27/100], Step [690/1751], Loss: 1.2320\n",
      "Epoch [27/100], Step [700/1751], Loss: 1.3297\n",
      "Epoch [27/100], Step [710/1751], Loss: 1.0742\n",
      "Epoch [27/100], Step [720/1751], Loss: 1.1890\n",
      "Epoch [27/100], Step [730/1751], Loss: 1.2478\n",
      "Epoch [27/100], Step [740/1751], Loss: 1.2871\n",
      "Epoch [27/100], Step [750/1751], Loss: 1.1563\n",
      "Epoch [27/100], Step [760/1751], Loss: 1.1650\n",
      "Epoch [27/100], Step [770/1751], Loss: 1.1598\n",
      "Epoch [27/100], Step [780/1751], Loss: 1.4213\n",
      "Epoch [27/100], Step [790/1751], Loss: 1.2540\n",
      "Epoch [27/100], Step [800/1751], Loss: 1.1686\n",
      "Epoch [27/100], Step [810/1751], Loss: 1.1469\n",
      "Epoch [27/100], Step [820/1751], Loss: 1.1826\n",
      "Epoch [27/100], Step [830/1751], Loss: 1.2937\n",
      "Epoch [27/100], Step [840/1751], Loss: 1.1510\n",
      "Epoch [27/100], Step [850/1751], Loss: 1.2357\n",
      "Epoch [27/100], Step [860/1751], Loss: 1.1503\n",
      "Epoch [27/100], Step [870/1751], Loss: 1.2364\n",
      "Epoch [27/100], Step [880/1751], Loss: 1.1696\n",
      "Epoch [27/100], Step [890/1751], Loss: 1.2337\n",
      "Epoch [27/100], Step [900/1751], Loss: 1.3704\n",
      "Epoch [27/100], Step [910/1751], Loss: 1.1466\n",
      "Epoch [27/100], Step [920/1751], Loss: 1.2537\n",
      "Epoch [27/100], Step [930/1751], Loss: 1.2071\n",
      "Epoch [27/100], Step [940/1751], Loss: 1.2672\n",
      "Epoch [27/100], Step [950/1751], Loss: 1.2999\n",
      "Epoch [27/100], Step [960/1751], Loss: 1.2629\n",
      "Epoch [27/100], Step [970/1751], Loss: 1.3054\n",
      "Epoch [27/100], Step [980/1751], Loss: 1.0952\n",
      "Epoch [27/100], Step [990/1751], Loss: 1.4147\n",
      "Epoch [27/100], Step [1000/1751], Loss: 1.2940\n",
      "Epoch [27/100], Step [1010/1751], Loss: 1.1922\n",
      "Epoch [27/100], Step [1020/1751], Loss: 1.2915\n",
      "Epoch [27/100], Step [1030/1751], Loss: 1.1905\n",
      "Epoch [27/100], Step [1040/1751], Loss: 1.1721\n",
      "Epoch [27/100], Step [1050/1751], Loss: 1.4455\n",
      "Epoch [27/100], Step [1060/1751], Loss: 1.2135\n",
      "Epoch [27/100], Step [1070/1751], Loss: 1.3396\n",
      "Epoch [27/100], Step [1080/1751], Loss: 1.2977\n",
      "Epoch [27/100], Step [1090/1751], Loss: 1.3322\n",
      "Epoch [27/100], Step [1100/1751], Loss: 1.3529\n",
      "Epoch [27/100], Step [1110/1751], Loss: 1.2383\n",
      "Epoch [27/100], Step [1120/1751], Loss: 1.3044\n",
      "Epoch [27/100], Step [1130/1751], Loss: 1.3557\n",
      "Epoch [27/100], Step [1140/1751], Loss: 1.2080\n",
      "Epoch [27/100], Step [1150/1751], Loss: 1.2908\n",
      "Epoch [27/100], Step [1160/1751], Loss: 1.2190\n",
      "Epoch [27/100], Step [1170/1751], Loss: 1.0141\n",
      "Epoch [27/100], Step [1180/1751], Loss: 1.2661\n",
      "Epoch [27/100], Step [1190/1751], Loss: 1.3374\n",
      "Epoch [27/100], Step [1200/1751], Loss: 1.2376\n",
      "Epoch [27/100], Step [1210/1751], Loss: 1.1573\n",
      "Epoch [27/100], Step [1220/1751], Loss: 1.2525\n",
      "Epoch [27/100], Step [1230/1751], Loss: 1.2130\n",
      "Epoch [27/100], Step [1240/1751], Loss: 1.2717\n",
      "Epoch [27/100], Step [1250/1751], Loss: 1.1558\n",
      "Epoch [27/100], Step [1260/1751], Loss: 1.2195\n",
      "Epoch [27/100], Step [1270/1751], Loss: 1.2067\n",
      "Epoch [27/100], Step [1280/1751], Loss: 1.3032\n",
      "Epoch [27/100], Step [1290/1751], Loss: 1.2841\n",
      "Epoch [27/100], Step [1300/1751], Loss: 1.2075\n",
      "Epoch [27/100], Step [1310/1751], Loss: 1.2481\n",
      "Epoch [27/100], Step [1320/1751], Loss: 1.2258\n",
      "Epoch [27/100], Step [1330/1751], Loss: 1.3096\n",
      "Epoch [27/100], Step [1340/1751], Loss: 1.3752\n",
      "Epoch [27/100], Step [1350/1751], Loss: 1.2548\n",
      "Epoch [27/100], Step [1360/1751], Loss: 1.2631\n",
      "Epoch [27/100], Step [1370/1751], Loss: 1.3307\n",
      "Epoch [27/100], Step [1380/1751], Loss: 1.3581\n",
      "Epoch [27/100], Step [1390/1751], Loss: 1.2327\n",
      "Epoch [27/100], Step [1400/1751], Loss: 1.3779\n",
      "Epoch [27/100], Step [1410/1751], Loss: 1.2845\n",
      "Epoch [27/100], Step [1420/1751], Loss: 1.1468\n",
      "Epoch [27/100], Step [1430/1751], Loss: 1.3878\n",
      "Epoch [27/100], Step [1440/1751], Loss: 1.2182\n",
      "Epoch [27/100], Step [1450/1751], Loss: 1.3650\n",
      "Epoch [27/100], Step [1460/1751], Loss: 1.2219\n",
      "Epoch [27/100], Step [1470/1751], Loss: 1.2582\n",
      "Epoch [27/100], Step [1480/1751], Loss: 1.2544\n",
      "Epoch [27/100], Step [1490/1751], Loss: 1.0657\n",
      "Epoch [27/100], Step [1500/1751], Loss: 1.1780\n",
      "Epoch [27/100], Step [1510/1751], Loss: 1.2174\n",
      "Epoch [27/100], Step [1520/1751], Loss: 1.0648\n",
      "Epoch [27/100], Step [1530/1751], Loss: 1.3085\n",
      "Epoch [27/100], Step [1540/1751], Loss: 1.2475\n",
      "Epoch [27/100], Step [1550/1751], Loss: 1.0927\n",
      "Epoch [27/100], Step [1560/1751], Loss: 1.2033\n",
      "Epoch [27/100], Step [1570/1751], Loss: 1.3250\n",
      "Epoch [27/100], Step [1580/1751], Loss: 1.3126\n",
      "Epoch [27/100], Step [1590/1751], Loss: 1.0898\n",
      "Epoch [27/100], Step [1600/1751], Loss: 1.3887\n",
      "Epoch [27/100], Step [1610/1751], Loss: 1.3221\n",
      "Epoch [27/100], Step [1620/1751], Loss: 1.2760\n",
      "Epoch [27/100], Step [1630/1751], Loss: 1.2480\n",
      "Epoch [27/100], Step [1640/1751], Loss: 1.2771\n",
      "Epoch [27/100], Step [1650/1751], Loss: 1.3831\n",
      "Epoch [27/100], Step [1660/1751], Loss: 1.2922\n",
      "Epoch [27/100], Step [1670/1751], Loss: 1.2892\n",
      "Epoch [27/100], Step [1680/1751], Loss: 1.2053\n",
      "Epoch [27/100], Step [1690/1751], Loss: 1.1719\n",
      "Epoch [27/100], Step [1700/1751], Loss: 1.1767\n",
      "Epoch [27/100], Step [1710/1751], Loss: 1.2119\n",
      "Epoch [27/100], Step [1720/1751], Loss: 1.2735\n",
      "Epoch [27/100], Step [1730/1751], Loss: 1.3493\n",
      "Epoch [27/100], Step [1740/1751], Loss: 1.3564\n",
      "Epoch [27/100], Step [1750/1751], Loss: 1.2369\n",
      "Epoch [27/100], Average Loss: 1.2515, Time: 1650.8649s\n",
      "Epoch [28/100], Step [10/1751], Loss: 1.4108\n",
      "Epoch [28/100], Step [20/1751], Loss: 1.5041\n",
      "Epoch [28/100], Step [30/1751], Loss: 1.2277\n",
      "Epoch [28/100], Step [40/1751], Loss: 1.4332\n",
      "Epoch [28/100], Step [50/1751], Loss: 1.2326\n",
      "Epoch [28/100], Step [60/1751], Loss: 1.4332\n",
      "Epoch [28/100], Step [70/1751], Loss: 1.2012\n",
      "Epoch [28/100], Step [80/1751], Loss: 1.4102\n",
      "Epoch [28/100], Step [90/1751], Loss: 1.3747\n",
      "Epoch [28/100], Step [100/1751], Loss: 1.2366\n",
      "Epoch [28/100], Step [110/1751], Loss: 1.2872\n",
      "Epoch [28/100], Step [120/1751], Loss: 1.3436\n",
      "Epoch [28/100], Step [130/1751], Loss: 1.1920\n",
      "Epoch [28/100], Step [140/1751], Loss: 1.1973\n",
      "Epoch [28/100], Step [150/1751], Loss: 1.3350\n",
      "Epoch [28/100], Step [160/1751], Loss: 1.3135\n",
      "Epoch [28/100], Step [170/1751], Loss: 1.0602\n",
      "Epoch [28/100], Step [180/1751], Loss: 1.4551\n",
      "Epoch [28/100], Step [190/1751], Loss: 1.1617\n",
      "Epoch [28/100], Step [200/1751], Loss: 1.2419\n",
      "Epoch [28/100], Step [210/1751], Loss: 1.2935\n",
      "Epoch [28/100], Step [220/1751], Loss: 1.1284\n",
      "Epoch [28/100], Step [230/1751], Loss: 1.2558\n",
      "Epoch [28/100], Step [240/1751], Loss: 1.1763\n",
      "Epoch [28/100], Step [250/1751], Loss: 1.2849\n",
      "Epoch [28/100], Step [260/1751], Loss: 1.2060\n",
      "Epoch [28/100], Step [270/1751], Loss: 1.4298\n",
      "Epoch [28/100], Step [280/1751], Loss: 1.2011\n",
      "Epoch [28/100], Step [290/1751], Loss: 1.1289\n",
      "Epoch [28/100], Step [300/1751], Loss: 1.1953\n",
      "Epoch [28/100], Step [310/1751], Loss: 1.3287\n",
      "Epoch [28/100], Step [320/1751], Loss: 1.2736\n",
      "Epoch [28/100], Step [330/1751], Loss: 1.2728\n",
      "Epoch [28/100], Step [340/1751], Loss: 1.1545\n",
      "Epoch [28/100], Step [350/1751], Loss: 1.1212\n",
      "Epoch [28/100], Step [360/1751], Loss: 1.2056\n",
      "Epoch [28/100], Step [370/1751], Loss: 1.1795\n",
      "Epoch [28/100], Step [380/1751], Loss: 1.2720\n",
      "Epoch [28/100], Step [390/1751], Loss: 1.3019\n",
      "Epoch [28/100], Step [400/1751], Loss: 1.1523\n",
      "Epoch [28/100], Step [410/1751], Loss: 1.1749\n",
      "Epoch [28/100], Step [420/1751], Loss: 1.1285\n",
      "Epoch [28/100], Step [430/1751], Loss: 1.2763\n",
      "Epoch [28/100], Step [440/1751], Loss: 1.1364\n",
      "Epoch [28/100], Step [450/1751], Loss: 1.2073\n",
      "Epoch [28/100], Step [460/1751], Loss: 1.2275\n",
      "Epoch [28/100], Step [470/1751], Loss: 1.3457\n",
      "Epoch [28/100], Step [480/1751], Loss: 1.2786\n",
      "Epoch [28/100], Step [490/1751], Loss: 1.1554\n",
      "Epoch [28/100], Step [500/1751], Loss: 1.1078\n",
      "Epoch [28/100], Step [510/1751], Loss: 1.2459\n",
      "Epoch [28/100], Step [520/1751], Loss: 1.2906\n",
      "Epoch [28/100], Step [530/1751], Loss: 1.3103\n",
      "Epoch [28/100], Step [540/1751], Loss: 1.4300\n",
      "Epoch [28/100], Step [550/1751], Loss: 1.2614\n",
      "Epoch [28/100], Step [560/1751], Loss: 1.2320\n",
      "Epoch [28/100], Step [570/1751], Loss: 1.2161\n",
      "Epoch [28/100], Step [580/1751], Loss: 1.2072\n",
      "Epoch [28/100], Step [590/1751], Loss: 1.3465\n",
      "Epoch [28/100], Step [600/1751], Loss: 1.2800\n",
      "Epoch [28/100], Step [610/1751], Loss: 1.3854\n",
      "Epoch [28/100], Step [620/1751], Loss: 1.4063\n",
      "Epoch [28/100], Step [630/1751], Loss: 1.2330\n",
      "Epoch [28/100], Step [640/1751], Loss: 1.1379\n",
      "Epoch [28/100], Step [650/1751], Loss: 1.2844\n",
      "Epoch [28/100], Step [660/1751], Loss: 1.2985\n",
      "Epoch [28/100], Step [670/1751], Loss: 1.3119\n",
      "Epoch [28/100], Step [680/1751], Loss: 1.2508\n",
      "Epoch [28/100], Step [690/1751], Loss: 1.3478\n",
      "Epoch [28/100], Step [700/1751], Loss: 1.2918\n",
      "Epoch [28/100], Step [710/1751], Loss: 1.1324\n",
      "Epoch [28/100], Step [720/1751], Loss: 1.2109\n",
      "Epoch [28/100], Step [730/1751], Loss: 1.2156\n",
      "Epoch [28/100], Step [740/1751], Loss: 1.2138\n",
      "Epoch [28/100], Step [750/1751], Loss: 1.1400\n",
      "Epoch [28/100], Step [760/1751], Loss: 1.2266\n",
      "Epoch [28/100], Step [770/1751], Loss: 1.2590\n",
      "Epoch [28/100], Step [780/1751], Loss: 1.3689\n",
      "Epoch [28/100], Step [790/1751], Loss: 1.2011\n",
      "Epoch [28/100], Step [800/1751], Loss: 1.3015\n",
      "Epoch [28/100], Step [810/1751], Loss: 1.2092\n",
      "Epoch [28/100], Step [820/1751], Loss: 1.2324\n",
      "Epoch [28/100], Step [830/1751], Loss: 1.2635\n",
      "Epoch [28/100], Step [840/1751], Loss: 1.3533\n",
      "Epoch [28/100], Step [850/1751], Loss: 1.2806\n",
      "Epoch [28/100], Step [860/1751], Loss: 1.1013\n",
      "Epoch [28/100], Step [870/1751], Loss: 1.2694\n",
      "Epoch [28/100], Step [880/1751], Loss: 1.1828\n",
      "Epoch [28/100], Step [890/1751], Loss: 1.0831\n",
      "Epoch [28/100], Step [900/1751], Loss: 1.1194\n",
      "Epoch [28/100], Step [910/1751], Loss: 1.3967\n",
      "Epoch [28/100], Step [920/1751], Loss: 1.1778\n",
      "Epoch [28/100], Step [930/1751], Loss: 1.4513\n",
      "Epoch [28/100], Step [940/1751], Loss: 1.2941\n",
      "Epoch [28/100], Step [950/1751], Loss: 1.2377\n",
      "Epoch [28/100], Step [960/1751], Loss: 1.2103\n",
      "Epoch [28/100], Step [970/1751], Loss: 1.1979\n",
      "Epoch [28/100], Step [980/1751], Loss: 1.2724\n",
      "Epoch [28/100], Step [990/1751], Loss: 1.2783\n",
      "Epoch [28/100], Step [1000/1751], Loss: 1.3109\n",
      "Epoch [28/100], Step [1010/1751], Loss: 1.1250\n",
      "Epoch [28/100], Step [1020/1751], Loss: 1.2232\n",
      "Epoch [28/100], Step [1030/1751], Loss: 1.2356\n",
      "Epoch [28/100], Step [1040/1751], Loss: 1.2269\n",
      "Epoch [28/100], Step [1050/1751], Loss: 1.4287\n",
      "Epoch [28/100], Step [1060/1751], Loss: 1.1792\n",
      "Epoch [28/100], Step [1070/1751], Loss: 1.2512\n",
      "Epoch [28/100], Step [1080/1751], Loss: 1.2446\n",
      "Epoch [28/100], Step [1090/1751], Loss: 1.3507\n",
      "Epoch [28/100], Step [1100/1751], Loss: 1.2652\n",
      "Epoch [28/100], Step [1110/1751], Loss: 1.2512\n",
      "Epoch [28/100], Step [1120/1751], Loss: 1.2118\n",
      "Epoch [28/100], Step [1130/1751], Loss: 1.2410\n",
      "Epoch [28/100], Step [1140/1751], Loss: 1.1637\n",
      "Epoch [28/100], Step [1150/1751], Loss: 1.2108\n",
      "Epoch [28/100], Step [1160/1751], Loss: 1.3045\n",
      "Epoch [28/100], Step [1170/1751], Loss: 1.3235\n",
      "Epoch [28/100], Step [1180/1751], Loss: 1.2518\n",
      "Epoch [28/100], Step [1190/1751], Loss: 1.2486\n",
      "Epoch [28/100], Step [1200/1751], Loss: 1.3445\n",
      "Epoch [28/100], Step [1210/1751], Loss: 1.3281\n",
      "Epoch [28/100], Step [1220/1751], Loss: 1.1263\n",
      "Epoch [28/100], Step [1230/1751], Loss: 1.2712\n",
      "Epoch [28/100], Step [1240/1751], Loss: 1.3208\n",
      "Epoch [28/100], Step [1250/1751], Loss: 1.1990\n",
      "Epoch [28/100], Step [1260/1751], Loss: 1.3432\n",
      "Epoch [28/100], Step [1270/1751], Loss: 1.3243\n",
      "Epoch [28/100], Step [1280/1751], Loss: 1.3832\n",
      "Epoch [28/100], Step [1290/1751], Loss: 1.1724\n",
      "Epoch [28/100], Step [1300/1751], Loss: 1.4705\n",
      "Epoch [28/100], Step [1310/1751], Loss: 1.1476\n",
      "Epoch [28/100], Step [1320/1751], Loss: 1.1741\n",
      "Epoch [28/100], Step [1330/1751], Loss: 1.3750\n",
      "Epoch [28/100], Step [1340/1751], Loss: 1.0842\n",
      "Epoch [28/100], Step [1350/1751], Loss: 1.1179\n",
      "Epoch [28/100], Step [1360/1751], Loss: 1.1736\n",
      "Epoch [28/100], Step [1370/1751], Loss: 1.2680\n",
      "Epoch [28/100], Step [1380/1751], Loss: 1.2915\n",
      "Epoch [28/100], Step [1390/1751], Loss: 1.2445\n",
      "Epoch [28/100], Step [1400/1751], Loss: 1.4489\n",
      "Epoch [28/100], Step [1410/1751], Loss: 1.3139\n",
      "Epoch [28/100], Step [1420/1751], Loss: 1.1975\n",
      "Epoch [28/100], Step [1430/1751], Loss: 1.2644\n",
      "Epoch [28/100], Step [1440/1751], Loss: 1.0627\n",
      "Epoch [28/100], Step [1450/1751], Loss: 1.1531\n",
      "Epoch [28/100], Step [1460/1751], Loss: 1.2747\n",
      "Epoch [28/100], Step [1470/1751], Loss: 1.1649\n",
      "Epoch [28/100], Step [1480/1751], Loss: 1.2466\n",
      "Epoch [28/100], Step [1490/1751], Loss: 1.2399\n",
      "Epoch [28/100], Step [1500/1751], Loss: 1.4336\n",
      "Epoch [28/100], Step [1510/1751], Loss: 1.4525\n",
      "Epoch [28/100], Step [1520/1751], Loss: 1.3507\n",
      "Epoch [28/100], Step [1530/1751], Loss: 1.2858\n",
      "Epoch [28/100], Step [1540/1751], Loss: 1.3832\n",
      "Epoch [28/100], Step [1550/1751], Loss: 1.0492\n",
      "Epoch [28/100], Step [1560/1751], Loss: 1.2501\n",
      "Epoch [28/100], Step [1570/1751], Loss: 1.4929\n",
      "Epoch [28/100], Step [1580/1751], Loss: 1.3618\n",
      "Epoch [28/100], Step [1590/1751], Loss: 1.1189\n",
      "Epoch [28/100], Step [1600/1751], Loss: 1.3520\n",
      "Epoch [28/100], Step [1610/1751], Loss: 1.2843\n",
      "Epoch [28/100], Step [1620/1751], Loss: 1.1722\n",
      "Epoch [28/100], Step [1630/1751], Loss: 1.3028\n",
      "Epoch [28/100], Step [1640/1751], Loss: 1.3268\n",
      "Epoch [28/100], Step [1650/1751], Loss: 1.3082\n",
      "Epoch [28/100], Step [1660/1751], Loss: 1.1657\n",
      "Epoch [28/100], Step [1670/1751], Loss: 1.2416\n",
      "Epoch [28/100], Step [1680/1751], Loss: 1.2880\n",
      "Epoch [28/100], Step [1690/1751], Loss: 1.0784\n",
      "Epoch [28/100], Step [1700/1751], Loss: 1.2213\n",
      "Epoch [28/100], Step [1710/1751], Loss: 1.3100\n",
      "Epoch [28/100], Step [1720/1751], Loss: 1.3973\n",
      "Epoch [28/100], Step [1730/1751], Loss: 1.2234\n",
      "Epoch [28/100], Step [1740/1751], Loss: 1.1640\n",
      "Epoch [28/100], Step [1750/1751], Loss: 1.3295\n",
      "Epoch [28/100], Average Loss: 1.2472, Time: 1649.9170s\n",
      "Epoch [29/100], Step [10/1751], Loss: 1.2206\n",
      "Epoch [29/100], Step [20/1751], Loss: 1.1055\n",
      "Epoch [29/100], Step [30/1751], Loss: 1.3896\n",
      "Epoch [29/100], Step [40/1751], Loss: 1.3641\n",
      "Epoch [29/100], Step [50/1751], Loss: 1.2775\n",
      "Epoch [29/100], Step [60/1751], Loss: 1.0174\n",
      "Epoch [29/100], Step [70/1751], Loss: 1.1556\n",
      "Epoch [29/100], Step [80/1751], Loss: 1.3744\n",
      "Epoch [29/100], Step [90/1751], Loss: 1.4068\n",
      "Epoch [29/100], Step [100/1751], Loss: 1.1813\n",
      "Epoch [29/100], Step [110/1751], Loss: 1.2211\n",
      "Epoch [29/100], Step [120/1751], Loss: 1.2511\n",
      "Epoch [29/100], Step [130/1751], Loss: 1.2678\n",
      "Epoch [29/100], Step [140/1751], Loss: 1.1939\n",
      "Epoch [29/100], Step [150/1751], Loss: 1.2388\n",
      "Epoch [29/100], Step [160/1751], Loss: 1.1769\n",
      "Epoch [29/100], Step [170/1751], Loss: 1.1810\n",
      "Epoch [29/100], Step [180/1751], Loss: 1.2586\n",
      "Epoch [29/100], Step [190/1751], Loss: 1.1993\n",
      "Epoch [29/100], Step [200/1751], Loss: 1.4374\n",
      "Epoch [29/100], Step [210/1751], Loss: 1.2775\n",
      "Epoch [29/100], Step [220/1751], Loss: 1.2473\n",
      "Epoch [29/100], Step [230/1751], Loss: 1.2126\n",
      "Epoch [29/100], Step [240/1751], Loss: 1.1751\n",
      "Epoch [29/100], Step [250/1751], Loss: 1.3709\n",
      "Epoch [29/100], Step [260/1751], Loss: 1.3266\n",
      "Epoch [29/100], Step [270/1751], Loss: 1.3116\n",
      "Epoch [29/100], Step [280/1751], Loss: 1.0672\n",
      "Epoch [29/100], Step [290/1751], Loss: 1.2314\n",
      "Epoch [29/100], Step [300/1751], Loss: 1.4593\n",
      "Epoch [29/100], Step [310/1751], Loss: 1.3733\n",
      "Epoch [29/100], Step [320/1751], Loss: 1.3036\n",
      "Epoch [29/100], Step [330/1751], Loss: 1.3020\n",
      "Epoch [29/100], Step [340/1751], Loss: 1.3388\n",
      "Epoch [29/100], Step [350/1751], Loss: 1.3518\n",
      "Epoch [29/100], Step [360/1751], Loss: 1.2087\n",
      "Epoch [29/100], Step [370/1751], Loss: 1.1795\n",
      "Epoch [29/100], Step [380/1751], Loss: 1.5288\n",
      "Epoch [29/100], Step [390/1751], Loss: 1.2699\n",
      "Epoch [29/100], Step [400/1751], Loss: 1.2463\n",
      "Epoch [29/100], Step [410/1751], Loss: 1.3007\n",
      "Epoch [29/100], Step [420/1751], Loss: 1.3437\n",
      "Epoch [29/100], Step [430/1751], Loss: 1.2202\n",
      "Epoch [29/100], Step [440/1751], Loss: 1.0497\n",
      "Epoch [29/100], Step [450/1751], Loss: 1.1055\n",
      "Epoch [29/100], Step [460/1751], Loss: 1.2369\n",
      "Epoch [29/100], Step [470/1751], Loss: 1.2193\n",
      "Epoch [29/100], Step [480/1751], Loss: 1.1678\n",
      "Epoch [29/100], Step [490/1751], Loss: 1.4022\n",
      "Epoch [29/100], Step [500/1751], Loss: 1.1399\n",
      "Epoch [29/100], Step [510/1751], Loss: 1.1978\n",
      "Epoch [29/100], Step [520/1751], Loss: 1.2583\n",
      "Epoch [29/100], Step [530/1751], Loss: 1.1484\n",
      "Epoch [29/100], Step [540/1751], Loss: 1.0867\n",
      "Epoch [29/100], Step [550/1751], Loss: 1.1936\n",
      "Epoch [29/100], Step [560/1751], Loss: 1.2231\n",
      "Epoch [29/100], Step [570/1751], Loss: 1.2717\n",
      "Epoch [29/100], Step [580/1751], Loss: 1.2485\n",
      "Epoch [29/100], Step [590/1751], Loss: 1.2197\n",
      "Epoch [29/100], Step [600/1751], Loss: 1.2576\n",
      "Epoch [29/100], Step [610/1751], Loss: 1.3038\n",
      "Epoch [29/100], Step [620/1751], Loss: 1.1312\n",
      "Epoch [29/100], Step [630/1751], Loss: 1.2461\n",
      "Epoch [29/100], Step [640/1751], Loss: 1.1778\n",
      "Epoch [29/100], Step [650/1751], Loss: 1.1250\n",
      "Epoch [29/100], Step [660/1751], Loss: 1.1959\n",
      "Epoch [29/100], Step [670/1751], Loss: 1.2652\n",
      "Epoch [29/100], Step [680/1751], Loss: 1.2210\n",
      "Epoch [29/100], Step [690/1751], Loss: 1.1693\n",
      "Epoch [29/100], Step [700/1751], Loss: 1.3175\n",
      "Epoch [29/100], Step [710/1751], Loss: 1.2500\n",
      "Epoch [29/100], Step [720/1751], Loss: 1.0872\n",
      "Epoch [29/100], Step [730/1751], Loss: 1.4053\n",
      "Epoch [29/100], Step [740/1751], Loss: 1.1939\n",
      "Epoch [29/100], Step [750/1751], Loss: 1.2110\n",
      "Epoch [29/100], Step [760/1751], Loss: 1.2922\n",
      "Epoch [29/100], Step [770/1751], Loss: 1.2480\n",
      "Epoch [29/100], Step [780/1751], Loss: 1.1642\n",
      "Epoch [29/100], Step [790/1751], Loss: 1.1658\n",
      "Epoch [29/100], Step [800/1751], Loss: 1.2265\n",
      "Epoch [29/100], Step [810/1751], Loss: 1.2340\n",
      "Epoch [29/100], Step [820/1751], Loss: 1.3210\n",
      "Epoch [29/100], Step [830/1751], Loss: 1.2944\n",
      "Epoch [29/100], Step [840/1751], Loss: 1.1687\n",
      "Epoch [29/100], Step [850/1751], Loss: 1.2319\n",
      "Epoch [29/100], Step [860/1751], Loss: 1.2525\n",
      "Epoch [29/100], Step [870/1751], Loss: 1.2120\n",
      "Epoch [29/100], Step [880/1751], Loss: 1.2545\n",
      "Epoch [29/100], Step [890/1751], Loss: 1.2485\n",
      "Epoch [29/100], Step [900/1751], Loss: 1.1930\n",
      "Epoch [29/100], Step [910/1751], Loss: 1.1843\n",
      "Epoch [29/100], Step [920/1751], Loss: 1.3655\n",
      "Epoch [29/100], Step [930/1751], Loss: 1.2202\n",
      "Epoch [29/100], Step [940/1751], Loss: 1.2653\n",
      "Epoch [29/100], Step [950/1751], Loss: 1.2536\n",
      "Epoch [29/100], Step [960/1751], Loss: 1.2495\n",
      "Epoch [29/100], Step [970/1751], Loss: 1.3189\n",
      "Epoch [29/100], Step [980/1751], Loss: 1.1584\n",
      "Epoch [29/100], Step [990/1751], Loss: 1.2112\n",
      "Epoch [29/100], Step [1000/1751], Loss: 1.3023\n",
      "Epoch [29/100], Step [1010/1751], Loss: 1.2250\n",
      "Epoch [29/100], Step [1020/1751], Loss: 1.2262\n",
      "Epoch [29/100], Step [1030/1751], Loss: 1.0612\n",
      "Epoch [29/100], Step [1040/1751], Loss: 1.3514\n",
      "Epoch [29/100], Step [1050/1751], Loss: 1.1330\n",
      "Epoch [29/100], Step [1060/1751], Loss: 1.2359\n",
      "Epoch [29/100], Step [1070/1751], Loss: 1.0752\n",
      "Epoch [29/100], Step [1080/1751], Loss: 1.2847\n",
      "Epoch [29/100], Step [1090/1751], Loss: 1.2458\n",
      "Epoch [29/100], Step [1100/1751], Loss: 1.1071\n",
      "Epoch [29/100], Step [1110/1751], Loss: 1.3682\n",
      "Epoch [29/100], Step [1120/1751], Loss: 1.2357\n",
      "Epoch [29/100], Step [1130/1751], Loss: 1.3466\n",
      "Epoch [29/100], Step [1140/1751], Loss: 1.1593\n",
      "Epoch [29/100], Step [1150/1751], Loss: 1.2127\n",
      "Epoch [29/100], Step [1160/1751], Loss: 1.3226\n",
      "Epoch [29/100], Step [1170/1751], Loss: 1.2535\n",
      "Epoch [29/100], Step [1180/1751], Loss: 1.1025\n",
      "Epoch [29/100], Step [1190/1751], Loss: 1.1318\n",
      "Epoch [29/100], Step [1200/1751], Loss: 1.3901\n",
      "Epoch [29/100], Step [1210/1751], Loss: 1.1694\n",
      "Epoch [29/100], Step [1220/1751], Loss: 1.4578\n",
      "Epoch [29/100], Step [1230/1751], Loss: 1.2737\n",
      "Epoch [29/100], Step [1240/1751], Loss: 1.2729\n",
      "Epoch [29/100], Step [1250/1751], Loss: 1.2103\n",
      "Epoch [29/100], Step [1260/1751], Loss: 1.1809\n",
      "Epoch [29/100], Step [1270/1751], Loss: 1.2484\n",
      "Epoch [29/100], Step [1280/1751], Loss: 1.2965\n",
      "Epoch [29/100], Step [1290/1751], Loss: 1.2266\n",
      "Epoch [29/100], Step [1300/1751], Loss: 1.2231\n",
      "Epoch [29/100], Step [1310/1751], Loss: 1.3228\n",
      "Epoch [29/100], Step [1320/1751], Loss: 1.2584\n",
      "Epoch [29/100], Step [1330/1751], Loss: 1.1328\n",
      "Epoch [29/100], Step [1340/1751], Loss: 1.1352\n",
      "Epoch [29/100], Step [1350/1751], Loss: 1.3698\n",
      "Epoch [29/100], Step [1360/1751], Loss: 1.2712\n",
      "Epoch [29/100], Step [1370/1751], Loss: 1.2383\n",
      "Epoch [29/100], Step [1380/1751], Loss: 1.2243\n",
      "Epoch [29/100], Step [1390/1751], Loss: 1.2352\n",
      "Epoch [29/100], Step [1400/1751], Loss: 1.1278\n",
      "Epoch [29/100], Step [1410/1751], Loss: 1.2727\n",
      "Epoch [29/100], Step [1420/1751], Loss: 1.1670\n",
      "Epoch [29/100], Step [1430/1751], Loss: 1.1865\n",
      "Epoch [29/100], Step [1440/1751], Loss: 1.2520\n",
      "Epoch [29/100], Step [1450/1751], Loss: 1.2001\n",
      "Epoch [29/100], Step [1460/1751], Loss: 1.1673\n",
      "Epoch [29/100], Step [1470/1751], Loss: 1.2567\n",
      "Epoch [29/100], Step [1480/1751], Loss: 1.2803\n",
      "Epoch [29/100], Step [1490/1751], Loss: 1.2572\n",
      "Epoch [29/100], Step [1500/1751], Loss: 1.1116\n",
      "Epoch [29/100], Step [1510/1751], Loss: 1.3532\n",
      "Epoch [29/100], Step [1520/1751], Loss: 1.3315\n",
      "Epoch [29/100], Step [1530/1751], Loss: 1.1867\n",
      "Epoch [29/100], Step [1540/1751], Loss: 1.2064\n",
      "Epoch [29/100], Step [1550/1751], Loss: 1.3585\n",
      "Epoch [29/100], Step [1560/1751], Loss: 1.1648\n",
      "Epoch [29/100], Step [1570/1751], Loss: 1.2856\n",
      "Epoch [29/100], Step [1580/1751], Loss: 1.0824\n",
      "Epoch [29/100], Step [1590/1751], Loss: 1.3348\n",
      "Epoch [29/100], Step [1600/1751], Loss: 1.1434\n",
      "Epoch [29/100], Step [1610/1751], Loss: 1.1909\n",
      "Epoch [29/100], Step [1620/1751], Loss: 1.3826\n",
      "Epoch [29/100], Step [1630/1751], Loss: 1.2824\n",
      "Epoch [29/100], Step [1640/1751], Loss: 1.4474\n",
      "Epoch [29/100], Step [1650/1751], Loss: 1.1563\n",
      "Epoch [29/100], Step [1660/1751], Loss: 1.3513\n",
      "Epoch [29/100], Step [1670/1751], Loss: 1.2492\n",
      "Epoch [29/100], Step [1680/1751], Loss: 1.1253\n",
      "Epoch [29/100], Step [1690/1751], Loss: 1.2691\n",
      "Epoch [29/100], Step [1700/1751], Loss: 1.3517\n",
      "Epoch [29/100], Step [1710/1751], Loss: 1.2152\n",
      "Epoch [29/100], Step [1720/1751], Loss: 1.1863\n",
      "Epoch [29/100], Step [1730/1751], Loss: 1.1294\n",
      "Epoch [29/100], Step [1740/1751], Loss: 1.0336\n",
      "Epoch [29/100], Step [1750/1751], Loss: 1.1547\n",
      "Epoch [29/100], Average Loss: 1.2440, Time: 1649.8742s\n",
      "Epoch [30/100], Step [10/1751], Loss: 1.3354\n",
      "Epoch [30/100], Step [20/1751], Loss: 1.4162\n",
      "Epoch [30/100], Step [30/1751], Loss: 1.3204\n",
      "Epoch [30/100], Step [40/1751], Loss: 1.1661\n",
      "Epoch [30/100], Step [50/1751], Loss: 1.0233\n",
      "Epoch [30/100], Step [60/1751], Loss: 1.1395\n",
      "Epoch [30/100], Step [70/1751], Loss: 1.3296\n",
      "Epoch [30/100], Step [80/1751], Loss: 1.1563\n",
      "Epoch [30/100], Step [90/1751], Loss: 1.2616\n",
      "Epoch [30/100], Step [100/1751], Loss: 1.1485\n",
      "Epoch [30/100], Step [110/1751], Loss: 1.0901\n",
      "Epoch [30/100], Step [120/1751], Loss: 1.3084\n",
      "Epoch [30/100], Step [130/1751], Loss: 1.1913\n",
      "Epoch [30/100], Step [140/1751], Loss: 1.0997\n",
      "Epoch [30/100], Step [150/1751], Loss: 1.2049\n",
      "Epoch [30/100], Step [160/1751], Loss: 1.3082\n",
      "Epoch [30/100], Step [170/1751], Loss: 1.1330\n",
      "Epoch [30/100], Step [180/1751], Loss: 1.3365\n",
      "Epoch [30/100], Step [190/1751], Loss: 1.0534\n",
      "Epoch [30/100], Step [200/1751], Loss: 1.2032\n",
      "Epoch [30/100], Step [210/1751], Loss: 1.3179\n",
      "Epoch [30/100], Step [220/1751], Loss: 1.0840\n",
      "Epoch [30/100], Step [230/1751], Loss: 1.2666\n",
      "Epoch [30/100], Step [240/1751], Loss: 1.1692\n",
      "Epoch [30/100], Step [250/1751], Loss: 1.2471\n",
      "Epoch [30/100], Step [260/1751], Loss: 1.4241\n",
      "Epoch [30/100], Step [270/1751], Loss: 1.2971\n",
      "Epoch [30/100], Step [280/1751], Loss: 1.2923\n",
      "Epoch [30/100], Step [290/1751], Loss: 1.2066\n",
      "Epoch [30/100], Step [300/1751], Loss: 1.2424\n",
      "Epoch [30/100], Step [310/1751], Loss: 1.2788\n",
      "Epoch [30/100], Step [320/1751], Loss: 1.1609\n",
      "Epoch [30/100], Step [330/1751], Loss: 1.1309\n",
      "Epoch [30/100], Step [340/1751], Loss: 1.1264\n",
      "Epoch [30/100], Step [350/1751], Loss: 1.2141\n",
      "Epoch [30/100], Step [360/1751], Loss: 1.0416\n",
      "Epoch [30/100], Step [370/1751], Loss: 1.1671\n",
      "Epoch [30/100], Step [380/1751], Loss: 1.2401\n",
      "Epoch [30/100], Step [390/1751], Loss: 1.3824\n",
      "Epoch [30/100], Step [400/1751], Loss: 1.2247\n",
      "Epoch [30/100], Step [410/1751], Loss: 1.1665\n",
      "Epoch [30/100], Step [420/1751], Loss: 1.2560\n",
      "Epoch [30/100], Step [430/1751], Loss: 1.1623\n",
      "Epoch [30/100], Step [440/1751], Loss: 1.2192\n",
      "Epoch [30/100], Step [450/1751], Loss: 1.2696\n",
      "Epoch [30/100], Step [460/1751], Loss: 1.1760\n",
      "Epoch [30/100], Step [470/1751], Loss: 1.3846\n",
      "Epoch [30/100], Step [480/1751], Loss: 1.3308\n",
      "Epoch [30/100], Step [490/1751], Loss: 1.3816\n",
      "Epoch [30/100], Step [500/1751], Loss: 1.2871\n",
      "Epoch [30/100], Step [510/1751], Loss: 1.1913\n",
      "Epoch [30/100], Step [520/1751], Loss: 1.2247\n",
      "Epoch [30/100], Step [530/1751], Loss: 1.2519\n",
      "Epoch [30/100], Step [540/1751], Loss: 1.0714\n",
      "Epoch [30/100], Step [550/1751], Loss: 1.3074\n",
      "Epoch [30/100], Step [560/1751], Loss: 1.2910\n",
      "Epoch [30/100], Step [570/1751], Loss: 1.2717\n",
      "Epoch [30/100], Step [580/1751], Loss: 1.4085\n",
      "Epoch [30/100], Step [590/1751], Loss: 1.3047\n",
      "Epoch [30/100], Step [600/1751], Loss: 1.2411\n",
      "Epoch [30/100], Step [610/1751], Loss: 1.2029\n",
      "Epoch [30/100], Step [620/1751], Loss: 1.2026\n",
      "Epoch [30/100], Step [630/1751], Loss: 1.2415\n",
      "Epoch [30/100], Step [640/1751], Loss: 1.3106\n",
      "Epoch [30/100], Step [650/1751], Loss: 1.3752\n",
      "Epoch [30/100], Step [660/1751], Loss: 1.2803\n",
      "Epoch [30/100], Step [670/1751], Loss: 1.2652\n",
      "Epoch [30/100], Step [680/1751], Loss: 1.2645\n",
      "Epoch [30/100], Step [690/1751], Loss: 1.1362\n",
      "Epoch [30/100], Step [700/1751], Loss: 1.2562\n",
      "Epoch [30/100], Step [710/1751], Loss: 1.1979\n",
      "Epoch [30/100], Step [720/1751], Loss: 1.2554\n",
      "Epoch [30/100], Step [730/1751], Loss: 1.3439\n",
      "Epoch [30/100], Step [740/1751], Loss: 1.3514\n",
      "Epoch [30/100], Step [750/1751], Loss: 1.1153\n",
      "Epoch [30/100], Step [760/1751], Loss: 1.2609\n",
      "Epoch [30/100], Step [770/1751], Loss: 1.4599\n",
      "Epoch [30/100], Step [780/1751], Loss: 1.2568\n",
      "Epoch [30/100], Step [790/1751], Loss: 1.1479\n",
      "Epoch [30/100], Step [800/1751], Loss: 1.0915\n",
      "Epoch [30/100], Step [810/1751], Loss: 1.4806\n",
      "Epoch [30/100], Step [820/1751], Loss: 1.2269\n",
      "Epoch [30/100], Step [830/1751], Loss: 1.3449\n",
      "Epoch [30/100], Step [840/1751], Loss: 1.1748\n",
      "Epoch [30/100], Step [850/1751], Loss: 1.3681\n",
      "Epoch [30/100], Step [860/1751], Loss: 1.2078\n",
      "Epoch [30/100], Step [870/1751], Loss: 1.0961\n",
      "Epoch [30/100], Step [880/1751], Loss: 1.2096\n",
      "Epoch [30/100], Step [890/1751], Loss: 1.1950\n",
      "Epoch [30/100], Step [900/1751], Loss: 1.0666\n",
      "Epoch [30/100], Step [910/1751], Loss: 1.1269\n",
      "Epoch [30/100], Step [920/1751], Loss: 1.2416\n",
      "Epoch [30/100], Step [930/1751], Loss: 1.3363\n",
      "Epoch [30/100], Step [940/1751], Loss: 1.1880\n",
      "Epoch [30/100], Step [950/1751], Loss: 1.3267\n",
      "Epoch [30/100], Step [960/1751], Loss: 1.2467\n",
      "Epoch [30/100], Step [970/1751], Loss: 1.2237\n",
      "Epoch [30/100], Step [980/1751], Loss: 1.2303\n",
      "Epoch [30/100], Step [990/1751], Loss: 1.2857\n",
      "Epoch [30/100], Step [1000/1751], Loss: 1.3216\n",
      "Epoch [30/100], Step [1010/1751], Loss: 1.2592\n",
      "Epoch [30/100], Step [1020/1751], Loss: 1.3552\n",
      "Epoch [30/100], Step [1030/1751], Loss: 1.3730\n",
      "Epoch [30/100], Step [1040/1751], Loss: 1.3741\n",
      "Epoch [30/100], Step [1050/1751], Loss: 1.3802\n",
      "Epoch [30/100], Step [1060/1751], Loss: 1.2572\n",
      "Epoch [30/100], Step [1070/1751], Loss: 1.2482\n",
      "Epoch [30/100], Step [1080/1751], Loss: 1.3460\n",
      "Epoch [30/100], Step [1090/1751], Loss: 1.2557\n",
      "Epoch [30/100], Step [1100/1751], Loss: 1.2025\n",
      "Epoch [30/100], Step [1110/1751], Loss: 1.1170\n",
      "Epoch [30/100], Step [1120/1751], Loss: 1.2427\n",
      "Epoch [30/100], Step [1130/1751], Loss: 1.2335\n",
      "Epoch [30/100], Step [1140/1751], Loss: 1.2096\n",
      "Epoch [30/100], Step [1150/1751], Loss: 1.1960\n",
      "Epoch [30/100], Step [1160/1751], Loss: 1.2427\n",
      "Epoch [30/100], Step [1170/1751], Loss: 1.2452\n",
      "Epoch [30/100], Step [1180/1751], Loss: 1.2621\n",
      "Epoch [30/100], Step [1190/1751], Loss: 1.1637\n",
      "Epoch [30/100], Step [1200/1751], Loss: 1.1651\n",
      "Epoch [30/100], Step [1210/1751], Loss: 1.0601\n",
      "Epoch [30/100], Step [1220/1751], Loss: 1.2664\n",
      "Epoch [30/100], Step [1230/1751], Loss: 1.1514\n",
      "Epoch [30/100], Step [1240/1751], Loss: 1.2211\n",
      "Epoch [30/100], Step [1250/1751], Loss: 1.1734\n",
      "Epoch [30/100], Step [1260/1751], Loss: 1.2703\n",
      "Epoch [30/100], Step [1270/1751], Loss: 1.3334\n",
      "Epoch [30/100], Step [1280/1751], Loss: 1.1023\n",
      "Epoch [30/100], Step [1290/1751], Loss: 1.2774\n",
      "Epoch [30/100], Step [1300/1751], Loss: 1.0917\n",
      "Epoch [30/100], Step [1310/1751], Loss: 1.1611\n",
      "Epoch [30/100], Step [1320/1751], Loss: 1.3630\n",
      "Epoch [30/100], Step [1330/1751], Loss: 1.2548\n",
      "Epoch [30/100], Step [1340/1751], Loss: 1.0761\n",
      "Epoch [30/100], Step [1350/1751], Loss: 1.2183\n",
      "Epoch [30/100], Step [1360/1751], Loss: 1.1366\n",
      "Epoch [30/100], Step [1370/1751], Loss: 1.1476\n",
      "Epoch [30/100], Step [1380/1751], Loss: 1.3123\n",
      "Epoch [30/100], Step [1390/1751], Loss: 1.3125\n",
      "Epoch [30/100], Step [1400/1751], Loss: 1.2235\n",
      "Epoch [30/100], Step [1410/1751], Loss: 1.1341\n",
      "Epoch [30/100], Step [1420/1751], Loss: 1.2863\n",
      "Epoch [30/100], Step [1430/1751], Loss: 1.3333\n",
      "Epoch [30/100], Step [1440/1751], Loss: 1.1781\n",
      "Epoch [30/100], Step [1450/1751], Loss: 1.1052\n",
      "Epoch [30/100], Step [1460/1751], Loss: 1.1757\n",
      "Epoch [30/100], Step [1470/1751], Loss: 1.1457\n",
      "Epoch [30/100], Step [1480/1751], Loss: 1.3253\n",
      "Epoch [30/100], Step [1490/1751], Loss: 1.1461\n",
      "Epoch [30/100], Step [1500/1751], Loss: 1.1690\n",
      "Epoch [30/100], Step [1510/1751], Loss: 1.1991\n",
      "Epoch [30/100], Step [1520/1751], Loss: 1.2955\n",
      "Epoch [30/100], Step [1530/1751], Loss: 1.3352\n",
      "Epoch [30/100], Step [1540/1751], Loss: 1.1945\n",
      "Epoch [30/100], Step [1550/1751], Loss: 1.2199\n",
      "Epoch [30/100], Step [1560/1751], Loss: 1.2673\n",
      "Epoch [30/100], Step [1570/1751], Loss: 1.2538\n",
      "Epoch [30/100], Step [1580/1751], Loss: 1.2421\n",
      "Epoch [30/100], Step [1590/1751], Loss: 1.3664\n",
      "Epoch [30/100], Step [1600/1751], Loss: 1.2477\n",
      "Epoch [30/100], Step [1610/1751], Loss: 1.2387\n",
      "Epoch [30/100], Step [1620/1751], Loss: 1.2414\n",
      "Epoch [30/100], Step [1630/1751], Loss: 1.2236\n",
      "Epoch [30/100], Step [1640/1751], Loss: 1.3215\n",
      "Epoch [30/100], Step [1650/1751], Loss: 1.1629\n",
      "Epoch [30/100], Step [1660/1751], Loss: 1.2771\n",
      "Epoch [30/100], Step [1670/1751], Loss: 1.1471\n",
      "Epoch [30/100], Step [1680/1751], Loss: 1.2968\n",
      "Epoch [30/100], Step [1690/1751], Loss: 1.4254\n",
      "Epoch [30/100], Step [1700/1751], Loss: 1.2443\n",
      "Epoch [30/100], Step [1710/1751], Loss: 1.3144\n",
      "Epoch [30/100], Step [1720/1751], Loss: 1.2831\n",
      "Epoch [30/100], Step [1730/1751], Loss: 1.2698\n",
      "Epoch [30/100], Step [1740/1751], Loss: 1.2460\n",
      "Epoch [30/100], Step [1750/1751], Loss: 1.3511\n",
      "Epoch [30/100], Average Loss: 1.2426, Time: 1648.6137s\n",
      "Epoch [31/100], Step [10/1751], Loss: 1.2565\n",
      "Epoch [31/100], Step [20/1751], Loss: 1.3235\n",
      "Epoch [31/100], Step [30/1751], Loss: 1.4263\n",
      "Epoch [31/100], Step [40/1751], Loss: 1.3288\n",
      "Epoch [31/100], Step [50/1751], Loss: 1.1935\n",
      "Epoch [31/100], Step [60/1751], Loss: 1.1818\n",
      "Epoch [31/100], Step [70/1751], Loss: 1.1690\n",
      "Epoch [31/100], Step [80/1751], Loss: 1.1244\n",
      "Epoch [31/100], Step [90/1751], Loss: 1.2094\n",
      "Epoch [31/100], Step [100/1751], Loss: 1.2647\n",
      "Epoch [31/100], Step [110/1751], Loss: 1.3287\n",
      "Epoch [31/100], Step [120/1751], Loss: 1.2994\n",
      "Epoch [31/100], Step [130/1751], Loss: 1.3445\n",
      "Epoch [31/100], Step [140/1751], Loss: 1.3288\n",
      "Epoch [31/100], Step [150/1751], Loss: 1.2739\n",
      "Epoch [31/100], Step [160/1751], Loss: 1.2756\n",
      "Epoch [31/100], Step [170/1751], Loss: 1.1466\n",
      "Epoch [31/100], Step [180/1751], Loss: 1.2331\n",
      "Epoch [31/100], Step [190/1751], Loss: 1.1622\n",
      "Epoch [31/100], Step [200/1751], Loss: 1.3247\n",
      "Epoch [31/100], Step [210/1751], Loss: 1.2605\n",
      "Epoch [31/100], Step [220/1751], Loss: 1.1488\n",
      "Epoch [31/100], Step [230/1751], Loss: 1.0308\n",
      "Epoch [31/100], Step [240/1751], Loss: 1.3057\n",
      "Epoch [31/100], Step [250/1751], Loss: 1.1931\n",
      "Epoch [31/100], Step [260/1751], Loss: 1.2214\n",
      "Epoch [31/100], Step [270/1751], Loss: 1.2190\n",
      "Epoch [31/100], Step [280/1751], Loss: 1.3492\n",
      "Epoch [31/100], Step [290/1751], Loss: 1.2769\n",
      "Epoch [31/100], Step [300/1751], Loss: 1.3045\n",
      "Epoch [31/100], Step [310/1751], Loss: 1.3437\n",
      "Epoch [31/100], Step [320/1751], Loss: 1.1409\n",
      "Epoch [31/100], Step [330/1751], Loss: 1.1035\n",
      "Epoch [31/100], Step [340/1751], Loss: 1.3729\n",
      "Epoch [31/100], Step [350/1751], Loss: 1.4560\n",
      "Epoch [31/100], Step [360/1751], Loss: 1.3059\n",
      "Epoch [31/100], Step [370/1751], Loss: 1.1090\n",
      "Epoch [31/100], Step [380/1751], Loss: 1.1810\n",
      "Epoch [31/100], Step [390/1751], Loss: 1.1955\n",
      "Epoch [31/100], Step [400/1751], Loss: 1.1492\n",
      "Epoch [31/100], Step [410/1751], Loss: 1.3083\n",
      "Epoch [31/100], Step [420/1751], Loss: 1.1529\n",
      "Epoch [31/100], Step [430/1751], Loss: 1.2901\n",
      "Epoch [31/100], Step [440/1751], Loss: 1.1049\n",
      "Epoch [31/100], Step [450/1751], Loss: 1.2260\n",
      "Epoch [31/100], Step [460/1751], Loss: 1.2918\n",
      "Epoch [31/100], Step [470/1751], Loss: 1.2165\n",
      "Epoch [31/100], Step [480/1751], Loss: 1.1955\n",
      "Epoch [31/100], Step [490/1751], Loss: 1.2637\n",
      "Epoch [31/100], Step [500/1751], Loss: 1.2006\n",
      "Epoch [31/100], Step [510/1751], Loss: 1.1452\n",
      "Epoch [31/100], Step [520/1751], Loss: 1.3204\n",
      "Epoch [31/100], Step [530/1751], Loss: 1.1500\n",
      "Epoch [31/100], Step [540/1751], Loss: 1.3600\n",
      "Epoch [31/100], Step [550/1751], Loss: 1.3850\n",
      "Epoch [31/100], Step [560/1751], Loss: 1.3348\n",
      "Epoch [31/100], Step [570/1751], Loss: 1.1498\n",
      "Epoch [31/100], Step [580/1751], Loss: 1.2363\n",
      "Epoch [31/100], Step [590/1751], Loss: 1.2209\n",
      "Epoch [31/100], Step [600/1751], Loss: 1.3887\n",
      "Epoch [31/100], Step [610/1751], Loss: 1.1204\n",
      "Epoch [31/100], Step [620/1751], Loss: 1.0686\n",
      "Epoch [31/100], Step [630/1751], Loss: 1.2415\n",
      "Epoch [31/100], Step [640/1751], Loss: 1.1967\n",
      "Epoch [31/100], Step [650/1751], Loss: 1.1679\n",
      "Epoch [31/100], Step [660/1751], Loss: 1.3317\n",
      "Epoch [31/100], Step [670/1751], Loss: 1.2507\n",
      "Epoch [31/100], Step [680/1751], Loss: 1.3200\n",
      "Epoch [31/100], Step [690/1751], Loss: 1.1507\n",
      "Epoch [31/100], Step [700/1751], Loss: 1.3465\n",
      "Epoch [31/100], Step [710/1751], Loss: 1.2795\n",
      "Epoch [31/100], Step [720/1751], Loss: 1.3962\n",
      "Epoch [31/100], Step [730/1751], Loss: 1.2443\n",
      "Epoch [31/100], Step [740/1751], Loss: 1.1309\n",
      "Epoch [31/100], Step [750/1751], Loss: 1.1060\n",
      "Epoch [31/100], Step [760/1751], Loss: 1.1787\n",
      "Epoch [31/100], Step [770/1751], Loss: 1.3966\n",
      "Epoch [31/100], Step [780/1751], Loss: 1.3123\n",
      "Epoch [31/100], Step [790/1751], Loss: 1.1576\n",
      "Epoch [31/100], Step [800/1751], Loss: 1.2569\n",
      "Epoch [31/100], Step [810/1751], Loss: 1.1080\n",
      "Epoch [31/100], Step [820/1751], Loss: 1.1830\n",
      "Epoch [31/100], Step [830/1751], Loss: 1.1960\n",
      "Epoch [31/100], Step [840/1751], Loss: 1.1756\n",
      "Epoch [31/100], Step [850/1751], Loss: 1.1787\n",
      "Epoch [31/100], Step [860/1751], Loss: 1.2019\n",
      "Epoch [31/100], Step [870/1751], Loss: 1.0718\n",
      "Epoch [31/100], Step [880/1751], Loss: 1.1655\n",
      "Epoch [31/100], Step [890/1751], Loss: 1.2163\n",
      "Epoch [31/100], Step [900/1751], Loss: 1.3016\n",
      "Epoch [31/100], Step [910/1751], Loss: 1.1575\n",
      "Epoch [31/100], Step [920/1751], Loss: 1.1331\n",
      "Epoch [31/100], Step [930/1751], Loss: 1.0573\n",
      "Epoch [31/100], Step [940/1751], Loss: 1.2076\n",
      "Epoch [31/100], Step [950/1751], Loss: 1.3846\n",
      "Epoch [31/100], Step [960/1751], Loss: 1.2617\n",
      "Epoch [31/100], Step [970/1751], Loss: 1.2154\n",
      "Epoch [31/100], Step [980/1751], Loss: 1.2440\n",
      "Epoch [31/100], Step [990/1751], Loss: 1.1392\n",
      "Epoch [31/100], Step [1000/1751], Loss: 1.2342\n",
      "Epoch [31/100], Step [1010/1751], Loss: 1.2130\n",
      "Epoch [31/100], Step [1020/1751], Loss: 1.2722\n",
      "Epoch [31/100], Step [1030/1751], Loss: 1.2472\n",
      "Epoch [31/100], Step [1040/1751], Loss: 1.0992\n",
      "Epoch [31/100], Step [1050/1751], Loss: 1.2605\n",
      "Epoch [31/100], Step [1060/1751], Loss: 1.2607\n",
      "Epoch [31/100], Step [1070/1751], Loss: 1.1306\n",
      "Epoch [31/100], Step [1080/1751], Loss: 1.3388\n",
      "Epoch [31/100], Step [1090/1751], Loss: 1.2727\n",
      "Epoch [31/100], Step [1100/1751], Loss: 1.1544\n",
      "Epoch [31/100], Step [1110/1751], Loss: 1.1463\n",
      "Epoch [31/100], Step [1120/1751], Loss: 1.3129\n",
      "Epoch [31/100], Step [1130/1751], Loss: 1.2999\n",
      "Epoch [31/100], Step [1140/1751], Loss: 1.3488\n",
      "Epoch [31/100], Step [1150/1751], Loss: 1.2601\n",
      "Epoch [31/100], Step [1160/1751], Loss: 1.1193\n",
      "Epoch [31/100], Step [1170/1751], Loss: 1.2232\n",
      "Epoch [31/100], Step [1180/1751], Loss: 1.2375\n",
      "Epoch [31/100], Step [1190/1751], Loss: 1.2262\n",
      "Epoch [31/100], Step [1200/1751], Loss: 1.3005\n",
      "Epoch [31/100], Step [1210/1751], Loss: 1.2545\n",
      "Epoch [31/100], Step [1220/1751], Loss: 1.2561\n",
      "Epoch [31/100], Step [1230/1751], Loss: 1.2329\n",
      "Epoch [31/100], Step [1240/1751], Loss: 1.2103\n",
      "Epoch [31/100], Step [1250/1751], Loss: 1.3223\n",
      "Epoch [31/100], Step [1260/1751], Loss: 1.4559\n",
      "Epoch [31/100], Step [1270/1751], Loss: 1.1516\n",
      "Epoch [31/100], Step [1280/1751], Loss: 1.1793\n",
      "Epoch [31/100], Step [1290/1751], Loss: 1.4520\n",
      "Epoch [31/100], Step [1300/1751], Loss: 1.2439\n",
      "Epoch [31/100], Step [1310/1751], Loss: 1.3430\n",
      "Epoch [31/100], Step [1320/1751], Loss: 1.1886\n",
      "Epoch [31/100], Step [1330/1751], Loss: 1.2258\n",
      "Epoch [31/100], Step [1340/1751], Loss: 1.1831\n",
      "Epoch [31/100], Step [1350/1751], Loss: 1.2394\n",
      "Epoch [31/100], Step [1360/1751], Loss: 1.2974\n",
      "Epoch [31/100], Step [1370/1751], Loss: 1.2579\n",
      "Epoch [31/100], Step [1380/1751], Loss: 1.2962\n",
      "Epoch [31/100], Step [1390/1751], Loss: 1.1313\n",
      "Epoch [31/100], Step [1400/1751], Loss: 1.3745\n",
      "Epoch [31/100], Step [1410/1751], Loss: 1.3937\n",
      "Epoch [31/100], Step [1420/1751], Loss: 1.2497\n",
      "Epoch [31/100], Step [1430/1751], Loss: 1.3122\n",
      "Epoch [31/100], Step [1440/1751], Loss: 1.2946\n",
      "Epoch [31/100], Step [1450/1751], Loss: 1.2290\n",
      "Epoch [31/100], Step [1460/1751], Loss: 1.2070\n",
      "Epoch [31/100], Step [1470/1751], Loss: 1.2055\n",
      "Epoch [31/100], Step [1480/1751], Loss: 1.4189\n",
      "Epoch [31/100], Step [1490/1751], Loss: 1.2316\n",
      "Epoch [31/100], Step [1500/1751], Loss: 1.2706\n",
      "Epoch [31/100], Step [1510/1751], Loss: 1.2910\n",
      "Epoch [31/100], Step [1520/1751], Loss: 1.3358\n",
      "Epoch [31/100], Step [1530/1751], Loss: 1.4280\n",
      "Epoch [31/100], Step [1540/1751], Loss: 1.1687\n",
      "Epoch [31/100], Step [1550/1751], Loss: 1.3148\n",
      "Epoch [31/100], Step [1560/1751], Loss: 1.2271\n",
      "Epoch [31/100], Step [1570/1751], Loss: 1.3168\n",
      "Epoch [31/100], Step [1580/1751], Loss: 1.2204\n",
      "Epoch [31/100], Step [1590/1751], Loss: 1.3486\n",
      "Epoch [31/100], Step [1600/1751], Loss: 1.3327\n",
      "Epoch [31/100], Step [1610/1751], Loss: 1.2191\n",
      "Epoch [31/100], Step [1620/1751], Loss: 1.2095\n",
      "Epoch [31/100], Step [1630/1751], Loss: 1.1159\n",
      "Epoch [31/100], Step [1640/1751], Loss: 1.1505\n",
      "Epoch [31/100], Step [1650/1751], Loss: 1.3018\n",
      "Epoch [31/100], Step [1660/1751], Loss: 1.2938\n",
      "Epoch [31/100], Step [1670/1751], Loss: 1.4052\n",
      "Epoch [31/100], Step [1680/1751], Loss: 1.3458\n",
      "Epoch [31/100], Step [1690/1751], Loss: 1.2218\n",
      "Epoch [31/100], Step [1700/1751], Loss: 1.3030\n",
      "Epoch [31/100], Step [1710/1751], Loss: 1.3127\n",
      "Epoch [31/100], Step [1720/1751], Loss: 1.1711\n",
      "Epoch [31/100], Step [1730/1751], Loss: 1.1753\n",
      "Epoch [31/100], Step [1740/1751], Loss: 1.1706\n",
      "Epoch [31/100], Step [1750/1751], Loss: 1.3169\n",
      "Epoch [31/100], Average Loss: 1.2394, Time: 1649.8380s\n",
      "Epoch [32/100], Step [10/1751], Loss: 1.2869\n",
      "Epoch [32/100], Step [20/1751], Loss: 1.2286\n",
      "Epoch [32/100], Step [30/1751], Loss: 1.3382\n",
      "Epoch [32/100], Step [40/1751], Loss: 1.1863\n",
      "Epoch [32/100], Step [50/1751], Loss: 1.3102\n",
      "Epoch [32/100], Step [60/1751], Loss: 1.1784\n",
      "Epoch [32/100], Step [70/1751], Loss: 1.2715\n",
      "Epoch [32/100], Step [80/1751], Loss: 1.3451\n",
      "Epoch [32/100], Step [90/1751], Loss: 1.3317\n",
      "Epoch [32/100], Step [100/1751], Loss: 1.3295\n",
      "Epoch [32/100], Step [110/1751], Loss: 1.2500\n",
      "Epoch [32/100], Step [120/1751], Loss: 1.1034\n",
      "Epoch [32/100], Step [130/1751], Loss: 1.2258\n",
      "Epoch [32/100], Step [140/1751], Loss: 1.2602\n",
      "Epoch [32/100], Step [150/1751], Loss: 1.2083\n",
      "Epoch [32/100], Step [160/1751], Loss: 1.2362\n",
      "Epoch [32/100], Step [170/1751], Loss: 1.1591\n",
      "Epoch [32/100], Step [180/1751], Loss: 1.2689\n",
      "Epoch [32/100], Step [190/1751], Loss: 1.2706\n",
      "Epoch [32/100], Step [200/1751], Loss: 1.2272\n",
      "Epoch [32/100], Step [210/1751], Loss: 1.1839\n",
      "Epoch [32/100], Step [220/1751], Loss: 1.2761\n",
      "Epoch [32/100], Step [230/1751], Loss: 1.3017\n",
      "Epoch [32/100], Step [240/1751], Loss: 1.1870\n",
      "Epoch [32/100], Step [250/1751], Loss: 1.3251\n",
      "Epoch [32/100], Step [260/1751], Loss: 1.0700\n",
      "Epoch [32/100], Step [270/1751], Loss: 1.2279\n",
      "Epoch [32/100], Step [280/1751], Loss: 1.1939\n",
      "Epoch [32/100], Step [290/1751], Loss: 1.1632\n",
      "Epoch [32/100], Step [300/1751], Loss: 1.3241\n",
      "Epoch [32/100], Step [310/1751], Loss: 1.2338\n",
      "Epoch [32/100], Step [320/1751], Loss: 1.2384\n",
      "Epoch [32/100], Step [330/1751], Loss: 1.2735\n",
      "Epoch [32/100], Step [340/1751], Loss: 1.1758\n",
      "Epoch [32/100], Step [350/1751], Loss: 1.1629\n",
      "Epoch [32/100], Step [360/1751], Loss: 1.3638\n",
      "Epoch [32/100], Step [370/1751], Loss: 1.2927\n",
      "Epoch [32/100], Step [380/1751], Loss: 1.1245\n",
      "Epoch [32/100], Step [390/1751], Loss: 1.1403\n",
      "Epoch [32/100], Step [400/1751], Loss: 1.3338\n",
      "Epoch [32/100], Step [410/1751], Loss: 1.2108\n",
      "Epoch [32/100], Step [420/1751], Loss: 1.1864\n",
      "Epoch [32/100], Step [430/1751], Loss: 1.2472\n",
      "Epoch [32/100], Step [440/1751], Loss: 1.2818\n",
      "Epoch [32/100], Step [450/1751], Loss: 1.1879\n",
      "Epoch [32/100], Step [460/1751], Loss: 1.2684\n",
      "Epoch [32/100], Step [470/1751], Loss: 1.2607\n",
      "Epoch [32/100], Step [480/1751], Loss: 1.2495\n",
      "Epoch [32/100], Step [490/1751], Loss: 1.0738\n",
      "Epoch [32/100], Step [500/1751], Loss: 1.2023\n",
      "Epoch [32/100], Step [510/1751], Loss: 1.3275\n",
      "Epoch [32/100], Step [520/1751], Loss: 1.2097\n",
      "Epoch [32/100], Step [530/1751], Loss: 1.1746\n",
      "Epoch [32/100], Step [540/1751], Loss: 1.1416\n",
      "Epoch [32/100], Step [550/1751], Loss: 1.1916\n",
      "Epoch [32/100], Step [560/1751], Loss: 1.3445\n",
      "Epoch [32/100], Step [570/1751], Loss: 1.2548\n",
      "Epoch [32/100], Step [580/1751], Loss: 1.1921\n",
      "Epoch [32/100], Step [590/1751], Loss: 1.3864\n",
      "Epoch [32/100], Step [600/1751], Loss: 1.3207\n",
      "Epoch [32/100], Step [610/1751], Loss: 1.2906\n",
      "Epoch [32/100], Step [620/1751], Loss: 1.2985\n",
      "Epoch [32/100], Step [630/1751], Loss: 1.2339\n",
      "Epoch [32/100], Step [640/1751], Loss: 1.2090\n",
      "Epoch [32/100], Step [650/1751], Loss: 1.1905\n",
      "Epoch [32/100], Step [660/1751], Loss: 1.2607\n",
      "Epoch [32/100], Step [670/1751], Loss: 1.4296\n",
      "Epoch [32/100], Step [680/1751], Loss: 1.2224\n",
      "Epoch [32/100], Step [690/1751], Loss: 1.3341\n",
      "Epoch [32/100], Step [700/1751], Loss: 1.4221\n",
      "Epoch [32/100], Step [710/1751], Loss: 1.2446\n",
      "Epoch [32/100], Step [720/1751], Loss: 1.1374\n",
      "Epoch [32/100], Step [730/1751], Loss: 1.1757\n",
      "Epoch [32/100], Step [740/1751], Loss: 1.3379\n",
      "Epoch [32/100], Step [750/1751], Loss: 1.2391\n",
      "Epoch [32/100], Step [760/1751], Loss: 1.2850\n",
      "Epoch [32/100], Step [770/1751], Loss: 1.2313\n",
      "Epoch [32/100], Step [780/1751], Loss: 1.2538\n",
      "Epoch [32/100], Step [790/1751], Loss: 1.2813\n",
      "Epoch [32/100], Step [800/1751], Loss: 1.3274\n",
      "Epoch [32/100], Step [810/1751], Loss: 1.1499\n",
      "Epoch [32/100], Step [820/1751], Loss: 1.3171\n",
      "Epoch [32/100], Step [830/1751], Loss: 1.1587\n",
      "Epoch [32/100], Step [840/1751], Loss: 1.1861\n",
      "Epoch [32/100], Step [850/1751], Loss: 1.3495\n",
      "Epoch [32/100], Step [860/1751], Loss: 1.2858\n",
      "Epoch [32/100], Step [870/1751], Loss: 1.3085\n",
      "Epoch [32/100], Step [880/1751], Loss: 1.0573\n",
      "Epoch [32/100], Step [890/1751], Loss: 1.1692\n",
      "Epoch [32/100], Step [900/1751], Loss: 1.1932\n",
      "Epoch [32/100], Step [910/1751], Loss: 1.2726\n",
      "Epoch [32/100], Step [920/1751], Loss: 1.2255\n",
      "Epoch [32/100], Step [930/1751], Loss: 1.3124\n",
      "Epoch [32/100], Step [940/1751], Loss: 1.3496\n",
      "Epoch [32/100], Step [950/1751], Loss: 1.1104\n",
      "Epoch [32/100], Step [960/1751], Loss: 1.3122\n",
      "Epoch [32/100], Step [970/1751], Loss: 1.1636\n",
      "Epoch [32/100], Step [980/1751], Loss: 1.3842\n",
      "Epoch [32/100], Step [990/1751], Loss: 1.1676\n",
      "Epoch [32/100], Step [1000/1751], Loss: 1.1771\n",
      "Epoch [32/100], Step [1010/1751], Loss: 1.2855\n",
      "Epoch [32/100], Step [1020/1751], Loss: 1.2777\n",
      "Epoch [32/100], Step [1030/1751], Loss: 1.2619\n",
      "Epoch [32/100], Step [1040/1751], Loss: 1.2604\n",
      "Epoch [32/100], Step [1050/1751], Loss: 1.2479\n",
      "Epoch [32/100], Step [1060/1751], Loss: 1.2443\n",
      "Epoch [32/100], Step [1070/1751], Loss: 1.3593\n",
      "Epoch [32/100], Step [1080/1751], Loss: 1.1479\n",
      "Epoch [32/100], Step [1090/1751], Loss: 1.1758\n",
      "Epoch [32/100], Step [1100/1751], Loss: 1.1893\n",
      "Epoch [32/100], Step [1110/1751], Loss: 1.2054\n",
      "Epoch [32/100], Step [1120/1751], Loss: 1.3869\n",
      "Epoch [32/100], Step [1130/1751], Loss: 1.3376\n",
      "Epoch [32/100], Step [1140/1751], Loss: 1.1756\n",
      "Epoch [32/100], Step [1150/1751], Loss: 1.2145\n",
      "Epoch [32/100], Step [1160/1751], Loss: 1.2660\n",
      "Epoch [32/100], Step [1170/1751], Loss: 1.2080\n",
      "Epoch [32/100], Step [1180/1751], Loss: 1.1184\n",
      "Epoch [32/100], Step [1190/1751], Loss: 1.3459\n",
      "Epoch [32/100], Step [1200/1751], Loss: 1.2921\n",
      "Epoch [32/100], Step [1210/1751], Loss: 1.2733\n",
      "Epoch [32/100], Step [1220/1751], Loss: 1.1019\n",
      "Epoch [32/100], Step [1230/1751], Loss: 1.2499\n",
      "Epoch [32/100], Step [1240/1751], Loss: 1.3691\n",
      "Epoch [32/100], Step [1250/1751], Loss: 1.1588\n",
      "Epoch [32/100], Step [1260/1751], Loss: 1.2084\n",
      "Epoch [32/100], Step [1270/1751], Loss: 1.2070\n",
      "Epoch [32/100], Step [1280/1751], Loss: 1.3999\n",
      "Epoch [32/100], Step [1290/1751], Loss: 1.2801\n",
      "Epoch [32/100], Step [1300/1751], Loss: 1.1261\n",
      "Epoch [32/100], Step [1310/1751], Loss: 1.2711\n",
      "Epoch [32/100], Step [1320/1751], Loss: 1.0927\n",
      "Epoch [32/100], Step [1330/1751], Loss: 1.2958\n",
      "Epoch [32/100], Step [1340/1751], Loss: 1.2227\n",
      "Epoch [32/100], Step [1350/1751], Loss: 1.1280\n",
      "Epoch [32/100], Step [1360/1751], Loss: 1.2751\n",
      "Epoch [32/100], Step [1370/1751], Loss: 1.2119\n",
      "Epoch [32/100], Step [1380/1751], Loss: 1.2155\n",
      "Epoch [32/100], Step [1390/1751], Loss: 1.3590\n",
      "Epoch [32/100], Step [1400/1751], Loss: 1.3804\n",
      "Epoch [32/100], Step [1410/1751], Loss: 1.3101\n",
      "Epoch [32/100], Step [1420/1751], Loss: 1.1582\n",
      "Epoch [32/100], Step [1430/1751], Loss: 1.2746\n",
      "Epoch [32/100], Step [1440/1751], Loss: 1.3492\n",
      "Epoch [32/100], Step [1450/1751], Loss: 1.2494\n",
      "Epoch [32/100], Step [1460/1751], Loss: 1.2841\n",
      "Epoch [32/100], Step [1470/1751], Loss: 1.1829\n",
      "Epoch [32/100], Step [1480/1751], Loss: 1.3453\n",
      "Epoch [32/100], Step [1490/1751], Loss: 1.3243\n",
      "Epoch [32/100], Step [1500/1751], Loss: 1.2141\n",
      "Epoch [32/100], Step [1510/1751], Loss: 1.2010\n",
      "Epoch [32/100], Step [1520/1751], Loss: 1.3555\n",
      "Epoch [32/100], Step [1530/1751], Loss: 1.2732\n",
      "Epoch [32/100], Step [1540/1751], Loss: 1.0842\n",
      "Epoch [32/100], Step [1550/1751], Loss: 1.3629\n",
      "Epoch [32/100], Step [1560/1751], Loss: 1.0869\n",
      "Epoch [32/100], Step [1570/1751], Loss: 1.2630\n",
      "Epoch [32/100], Step [1580/1751], Loss: 1.1807\n",
      "Epoch [32/100], Step [1590/1751], Loss: 1.1335\n",
      "Epoch [32/100], Step [1600/1751], Loss: 1.2016\n",
      "Epoch [32/100], Step [1610/1751], Loss: 1.3036\n",
      "Epoch [32/100], Step [1620/1751], Loss: 1.2165\n",
      "Epoch [32/100], Step [1630/1751], Loss: 1.3005\n",
      "Epoch [32/100], Step [1640/1751], Loss: 1.2646\n",
      "Epoch [32/100], Step [1650/1751], Loss: 1.1570\n",
      "Epoch [32/100], Step [1660/1751], Loss: 1.3212\n",
      "Epoch [32/100], Step [1670/1751], Loss: 1.2110\n",
      "Epoch [32/100], Step [1680/1751], Loss: 1.2575\n",
      "Epoch [32/100], Step [1690/1751], Loss: 1.1289\n",
      "Epoch [32/100], Step [1700/1751], Loss: 1.1424\n",
      "Epoch [32/100], Step [1710/1751], Loss: 1.3853\n",
      "Epoch [32/100], Step [1720/1751], Loss: 1.3178\n",
      "Epoch [32/100], Step [1730/1751], Loss: 1.2410\n",
      "Epoch [32/100], Step [1740/1751], Loss: 1.3854\n",
      "Epoch [32/100], Step [1750/1751], Loss: 1.2755\n",
      "Epoch [32/100], Average Loss: 1.2364, Time: 1649.9711s\n",
      "Epoch [33/100], Step [10/1751], Loss: 1.2842\n",
      "Epoch [33/100], Step [20/1751], Loss: 1.2781\n",
      "Epoch [33/100], Step [30/1751], Loss: 1.2589\n",
      "Epoch [33/100], Step [40/1751], Loss: 1.2174\n",
      "Epoch [33/100], Step [50/1751], Loss: 1.3643\n",
      "Epoch [33/100], Step [60/1751], Loss: 1.2445\n",
      "Epoch [33/100], Step [70/1751], Loss: 1.1763\n",
      "Epoch [33/100], Step [80/1751], Loss: 1.0927\n",
      "Epoch [33/100], Step [90/1751], Loss: 1.1740\n",
      "Epoch [33/100], Step [100/1751], Loss: 1.3847\n",
      "Epoch [33/100], Step [110/1751], Loss: 1.2852\n",
      "Epoch [33/100], Step [120/1751], Loss: 1.3341\n",
      "Epoch [33/100], Step [130/1751], Loss: 1.0692\n",
      "Epoch [33/100], Step [140/1751], Loss: 1.2870\n",
      "Epoch [33/100], Step [150/1751], Loss: 1.1005\n",
      "Epoch [33/100], Step [160/1751], Loss: 1.0684\n",
      "Epoch [33/100], Step [170/1751], Loss: 1.1868\n",
      "Epoch [33/100], Step [180/1751], Loss: 1.1795\n",
      "Epoch [33/100], Step [190/1751], Loss: 1.1769\n",
      "Epoch [33/100], Step [200/1751], Loss: 1.2142\n",
      "Epoch [33/100], Step [210/1751], Loss: 1.2258\n",
      "Epoch [33/100], Step [220/1751], Loss: 1.3430\n",
      "Epoch [33/100], Step [230/1751], Loss: 1.1201\n",
      "Epoch [33/100], Step [240/1751], Loss: 1.2931\n",
      "Epoch [33/100], Step [250/1751], Loss: 1.3723\n",
      "Epoch [33/100], Step [260/1751], Loss: 1.2612\n",
      "Epoch [33/100], Step [270/1751], Loss: 1.2275\n",
      "Epoch [33/100], Step [280/1751], Loss: 1.3074\n",
      "Epoch [33/100], Step [290/1751], Loss: 1.1014\n",
      "Epoch [33/100], Step [300/1751], Loss: 1.1360\n",
      "Epoch [33/100], Step [310/1751], Loss: 1.1519\n",
      "Epoch [33/100], Step [320/1751], Loss: 1.2795\n",
      "Epoch [33/100], Step [330/1751], Loss: 1.2335\n",
      "Epoch [33/100], Step [340/1751], Loss: 1.2883\n",
      "Epoch [33/100], Step [350/1751], Loss: 1.3057\n",
      "Epoch [33/100], Step [360/1751], Loss: 1.2850\n",
      "Epoch [33/100], Step [370/1751], Loss: 1.4146\n",
      "Epoch [33/100], Step [380/1751], Loss: 1.2159\n",
      "Epoch [33/100], Step [390/1751], Loss: 1.1716\n",
      "Epoch [33/100], Step [400/1751], Loss: 1.2146\n",
      "Epoch [33/100], Step [410/1751], Loss: 1.3194\n",
      "Epoch [33/100], Step [420/1751], Loss: 1.1113\n",
      "Epoch [33/100], Step [430/1751], Loss: 1.1118\n",
      "Epoch [33/100], Step [440/1751], Loss: 1.1733\n",
      "Epoch [33/100], Step [450/1751], Loss: 1.3244\n",
      "Epoch [33/100], Step [460/1751], Loss: 1.0343\n",
      "Epoch [33/100], Step [470/1751], Loss: 1.1707\n",
      "Epoch [33/100], Step [480/1751], Loss: 1.0999\n",
      "Epoch [33/100], Step [490/1751], Loss: 1.2551\n",
      "Epoch [33/100], Step [500/1751], Loss: 1.1918\n",
      "Epoch [33/100], Step [510/1751], Loss: 1.1078\n",
      "Epoch [33/100], Step [520/1751], Loss: 1.2867\n",
      "Epoch [33/100], Step [530/1751], Loss: 1.1572\n",
      "Epoch [33/100], Step [540/1751], Loss: 1.3367\n",
      "Epoch [33/100], Step [550/1751], Loss: 1.2250\n",
      "Epoch [33/100], Step [560/1751], Loss: 1.3486\n",
      "Epoch [33/100], Step [570/1751], Loss: 1.2639\n",
      "Epoch [33/100], Step [580/1751], Loss: 1.1715\n",
      "Epoch [33/100], Step [590/1751], Loss: 1.3238\n",
      "Epoch [33/100], Step [600/1751], Loss: 1.2928\n",
      "Epoch [33/100], Step [610/1751], Loss: 1.2588\n",
      "Epoch [33/100], Step [620/1751], Loss: 1.2221\n",
      "Epoch [33/100], Step [630/1751], Loss: 1.2142\n",
      "Epoch [33/100], Step [640/1751], Loss: 1.4465\n",
      "Epoch [33/100], Step [650/1751], Loss: 1.2240\n",
      "Epoch [33/100], Step [660/1751], Loss: 1.2272\n",
      "Epoch [33/100], Step [670/1751], Loss: 1.0235\n",
      "Epoch [33/100], Step [680/1751], Loss: 1.2458\n",
      "Epoch [33/100], Step [690/1751], Loss: 1.2985\n",
      "Epoch [33/100], Step [700/1751], Loss: 1.1955\n",
      "Epoch [33/100], Step [710/1751], Loss: 1.2707\n",
      "Epoch [33/100], Step [720/1751], Loss: 1.2652\n",
      "Epoch [33/100], Step [730/1751], Loss: 1.1684\n",
      "Epoch [33/100], Step [740/1751], Loss: 1.2292\n",
      "Epoch [33/100], Step [750/1751], Loss: 1.3142\n",
      "Epoch [33/100], Step [760/1751], Loss: 1.2131\n",
      "Epoch [33/100], Step [770/1751], Loss: 1.1916\n",
      "Epoch [33/100], Step [780/1751], Loss: 1.2391\n",
      "Epoch [33/100], Step [790/1751], Loss: 1.2759\n",
      "Epoch [33/100], Step [800/1751], Loss: 1.1619\n",
      "Epoch [33/100], Step [810/1751], Loss: 1.3612\n",
      "Epoch [33/100], Step [820/1751], Loss: 1.2260\n",
      "Epoch [33/100], Step [830/1751], Loss: 1.3611\n",
      "Epoch [33/100], Step [840/1751], Loss: 1.2287\n",
      "Epoch [33/100], Step [850/1751], Loss: 1.2974\n",
      "Epoch [33/100], Step [860/1751], Loss: 1.2750\n",
      "Epoch [33/100], Step [870/1751], Loss: 1.3116\n",
      "Epoch [33/100], Step [880/1751], Loss: 1.2043\n",
      "Epoch [33/100], Step [890/1751], Loss: 1.1994\n",
      "Epoch [33/100], Step [900/1751], Loss: 1.2017\n",
      "Epoch [33/100], Step [910/1751], Loss: 1.1418\n",
      "Epoch [33/100], Step [920/1751], Loss: 1.1032\n",
      "Epoch [33/100], Step [930/1751], Loss: 1.1708\n",
      "Epoch [33/100], Step [940/1751], Loss: 1.2955\n",
      "Epoch [33/100], Step [950/1751], Loss: 1.2921\n",
      "Epoch [33/100], Step [960/1751], Loss: 1.1238\n",
      "Epoch [33/100], Step [970/1751], Loss: 1.2448\n",
      "Epoch [33/100], Step [980/1751], Loss: 1.3001\n",
      "Epoch [33/100], Step [990/1751], Loss: 1.2051\n",
      "Epoch [33/100], Step [1000/1751], Loss: 1.2725\n",
      "Epoch [33/100], Step [1010/1751], Loss: 1.2624\n",
      "Epoch [33/100], Step [1020/1751], Loss: 1.1673\n",
      "Epoch [33/100], Step [1030/1751], Loss: 1.2433\n",
      "Epoch [33/100], Step [1040/1751], Loss: 1.2707\n",
      "Epoch [33/100], Step [1050/1751], Loss: 1.2211\n",
      "Epoch [33/100], Step [1060/1751], Loss: 1.1840\n",
      "Epoch [33/100], Step [1070/1751], Loss: 1.2374\n",
      "Epoch [33/100], Step [1080/1751], Loss: 1.1424\n",
      "Epoch [33/100], Step [1090/1751], Loss: 1.2557\n",
      "Epoch [33/100], Step [1100/1751], Loss: 1.3345\n",
      "Epoch [33/100], Step [1110/1751], Loss: 1.2884\n",
      "Epoch [33/100], Step [1120/1751], Loss: 1.1064\n",
      "Epoch [33/100], Step [1130/1751], Loss: 1.2933\n",
      "Epoch [33/100], Step [1140/1751], Loss: 1.1313\n",
      "Epoch [33/100], Step [1150/1751], Loss: 1.4784\n",
      "Epoch [33/100], Step [1160/1751], Loss: 1.0882\n",
      "Epoch [33/100], Step [1170/1751], Loss: 1.1059\n",
      "Epoch [33/100], Step [1180/1751], Loss: 1.1826\n",
      "Epoch [33/100], Step [1190/1751], Loss: 1.2798\n",
      "Epoch [33/100], Step [1200/1751], Loss: 1.1518\n",
      "Epoch [33/100], Step [1210/1751], Loss: 1.3065\n",
      "Epoch [33/100], Step [1220/1751], Loss: 1.2535\n",
      "Epoch [33/100], Step [1230/1751], Loss: 1.2225\n",
      "Epoch [33/100], Step [1240/1751], Loss: 1.1971\n",
      "Epoch [33/100], Step [1250/1751], Loss: 1.2841\n",
      "Epoch [33/100], Step [1260/1751], Loss: 1.1922\n",
      "Epoch [33/100], Step [1270/1751], Loss: 1.3017\n",
      "Epoch [33/100], Step [1280/1751], Loss: 1.2332\n",
      "Epoch [33/100], Step [1290/1751], Loss: 1.1236\n",
      "Epoch [33/100], Step [1300/1751], Loss: 1.1154\n",
      "Epoch [33/100], Step [1310/1751], Loss: 1.2139\n",
      "Epoch [33/100], Step [1320/1751], Loss: 1.2449\n",
      "Epoch [33/100], Step [1330/1751], Loss: 1.2026\n",
      "Epoch [33/100], Step [1340/1751], Loss: 1.1106\n",
      "Epoch [33/100], Step [1350/1751], Loss: 1.0447\n",
      "Epoch [33/100], Step [1360/1751], Loss: 1.3638\n",
      "Epoch [33/100], Step [1370/1751], Loss: 1.1632\n",
      "Epoch [33/100], Step [1380/1751], Loss: 1.2304\n",
      "Epoch [33/100], Step [1390/1751], Loss: 1.3436\n",
      "Epoch [33/100], Step [1400/1751], Loss: 1.2681\n",
      "Epoch [33/100], Step [1410/1751], Loss: 1.2740\n",
      "Epoch [33/100], Step [1420/1751], Loss: 1.3274\n",
      "Epoch [33/100], Step [1430/1751], Loss: 1.3647\n",
      "Epoch [33/100], Step [1440/1751], Loss: 1.2292\n",
      "Epoch [33/100], Step [1450/1751], Loss: 1.3486\n",
      "Epoch [33/100], Step [1460/1751], Loss: 1.1506\n",
      "Epoch [33/100], Step [1470/1751], Loss: 1.3026\n",
      "Epoch [33/100], Step [1480/1751], Loss: 1.1056\n",
      "Epoch [33/100], Step [1490/1751], Loss: 1.0982\n",
      "Epoch [33/100], Step [1500/1751], Loss: 1.1540\n",
      "Epoch [33/100], Step [1510/1751], Loss: 1.3147\n",
      "Epoch [33/100], Step [1520/1751], Loss: 1.0948\n",
      "Epoch [33/100], Step [1530/1751], Loss: 1.3349\n",
      "Epoch [33/100], Step [1540/1751], Loss: 1.3977\n",
      "Epoch [33/100], Step [1550/1751], Loss: 1.3274\n",
      "Epoch [33/100], Step [1560/1751], Loss: 1.2298\n",
      "Epoch [33/100], Step [1570/1751], Loss: 1.3267\n",
      "Epoch [33/100], Step [1580/1751], Loss: 1.2213\n",
      "Epoch [33/100], Step [1590/1751], Loss: 1.2634\n",
      "Epoch [33/100], Step [1600/1751], Loss: 1.1808\n",
      "Epoch [33/100], Step [1610/1751], Loss: 1.2584\n",
      "Epoch [33/100], Step [1620/1751], Loss: 1.2556\n",
      "Epoch [33/100], Step [1630/1751], Loss: 1.1986\n",
      "Epoch [33/100], Step [1640/1751], Loss: 1.3310\n",
      "Epoch [33/100], Step [1650/1751], Loss: 1.2443\n",
      "Epoch [33/100], Step [1660/1751], Loss: 1.2321\n",
      "Epoch [33/100], Step [1670/1751], Loss: 1.2580\n",
      "Epoch [33/100], Step [1680/1751], Loss: 1.0210\n",
      "Epoch [33/100], Step [1690/1751], Loss: 1.1438\n",
      "Epoch [33/100], Step [1700/1751], Loss: 1.2287\n",
      "Epoch [33/100], Step [1710/1751], Loss: 1.2717\n",
      "Epoch [33/100], Step [1720/1751], Loss: 1.1705\n",
      "Epoch [33/100], Step [1730/1751], Loss: 1.3201\n",
      "Epoch [33/100], Step [1740/1751], Loss: 1.1701\n",
      "Epoch [33/100], Step [1750/1751], Loss: 1.3515\n",
      "Epoch [33/100], Average Loss: 1.2348, Time: 1649.4037s\n",
      "Epoch [34/100], Step [10/1751], Loss: 1.2562\n",
      "Epoch [34/100], Step [20/1751], Loss: 1.1886\n",
      "Epoch [34/100], Step [30/1751], Loss: 1.0559\n",
      "Epoch [34/100], Step [40/1751], Loss: 1.3286\n",
      "Epoch [34/100], Step [50/1751], Loss: 1.3229\n",
      "Epoch [34/100], Step [60/1751], Loss: 1.2927\n",
      "Epoch [34/100], Step [70/1751], Loss: 1.2509\n",
      "Epoch [34/100], Step [80/1751], Loss: 1.0795\n",
      "Epoch [34/100], Step [90/1751], Loss: 1.2930\n",
      "Epoch [34/100], Step [100/1751], Loss: 1.2776\n",
      "Epoch [34/100], Step [110/1751], Loss: 1.1098\n",
      "Epoch [34/100], Step [120/1751], Loss: 1.3268\n",
      "Epoch [34/100], Step [130/1751], Loss: 1.1332\n",
      "Epoch [34/100], Step [140/1751], Loss: 1.2839\n",
      "Epoch [34/100], Step [150/1751], Loss: 1.0319\n",
      "Epoch [34/100], Step [160/1751], Loss: 1.1191\n",
      "Epoch [34/100], Step [170/1751], Loss: 1.1213\n",
      "Epoch [34/100], Step [180/1751], Loss: 1.2218\n",
      "Epoch [34/100], Step [190/1751], Loss: 1.1269\n",
      "Epoch [34/100], Step [200/1751], Loss: 1.1563\n",
      "Epoch [34/100], Step [210/1751], Loss: 1.1915\n",
      "Epoch [34/100], Step [220/1751], Loss: 1.1601\n",
      "Epoch [34/100], Step [230/1751], Loss: 1.1785\n",
      "Epoch [34/100], Step [240/1751], Loss: 1.2684\n",
      "Epoch [34/100], Step [250/1751], Loss: 1.1786\n",
      "Epoch [34/100], Step [260/1751], Loss: 1.1517\n",
      "Epoch [34/100], Step [270/1751], Loss: 1.1880\n",
      "Epoch [34/100], Step [280/1751], Loss: 1.3556\n",
      "Epoch [34/100], Step [290/1751], Loss: 1.2779\n",
      "Epoch [34/100], Step [300/1751], Loss: 1.2319\n",
      "Epoch [34/100], Step [310/1751], Loss: 1.1373\n",
      "Epoch [34/100], Step [320/1751], Loss: 1.1792\n",
      "Epoch [34/100], Step [330/1751], Loss: 1.0652\n",
      "Epoch [34/100], Step [340/1751], Loss: 1.3271\n",
      "Epoch [34/100], Step [350/1751], Loss: 1.2687\n",
      "Epoch [34/100], Step [360/1751], Loss: 1.2470\n",
      "Epoch [34/100], Step [370/1751], Loss: 1.2369\n",
      "Epoch [34/100], Step [380/1751], Loss: 1.1566\n",
      "Epoch [34/100], Step [390/1751], Loss: 1.1740\n",
      "Epoch [34/100], Step [400/1751], Loss: 1.1139\n",
      "Epoch [34/100], Step [410/1751], Loss: 1.2087\n",
      "Epoch [34/100], Step [420/1751], Loss: 1.1892\n",
      "Epoch [34/100], Step [430/1751], Loss: 0.9947\n",
      "Epoch [34/100], Step [440/1751], Loss: 1.1744\n",
      "Epoch [34/100], Step [450/1751], Loss: 1.3112\n",
      "Epoch [34/100], Step [460/1751], Loss: 1.0729\n",
      "Epoch [34/100], Step [470/1751], Loss: 1.2581\n",
      "Epoch [34/100], Step [480/1751], Loss: 1.2166\n",
      "Epoch [34/100], Step [490/1751], Loss: 1.2945\n",
      "Epoch [34/100], Step [500/1751], Loss: 1.2238\n",
      "Epoch [34/100], Step [510/1751], Loss: 1.2073\n",
      "Epoch [34/100], Step [520/1751], Loss: 1.2845\n",
      "Epoch [34/100], Step [530/1751], Loss: 1.2445\n",
      "Epoch [34/100], Step [540/1751], Loss: 1.2907\n",
      "Epoch [34/100], Step [550/1751], Loss: 1.2688\n",
      "Epoch [34/100], Step [560/1751], Loss: 1.2607\n",
      "Epoch [34/100], Step [570/1751], Loss: 1.2874\n",
      "Epoch [34/100], Step [580/1751], Loss: 1.1843\n",
      "Epoch [34/100], Step [590/1751], Loss: 1.2934\n",
      "Epoch [34/100], Step [600/1751], Loss: 1.2546\n",
      "Epoch [34/100], Step [610/1751], Loss: 1.1776\n",
      "Epoch [34/100], Step [620/1751], Loss: 1.2517\n",
      "Epoch [34/100], Step [630/1751], Loss: 1.2063\n",
      "Epoch [34/100], Step [640/1751], Loss: 1.3252\n",
      "Epoch [34/100], Step [650/1751], Loss: 1.0716\n",
      "Epoch [34/100], Step [660/1751], Loss: 1.2181\n",
      "Epoch [34/100], Step [670/1751], Loss: 1.2771\n",
      "Epoch [34/100], Step [680/1751], Loss: 1.2963\n",
      "Epoch [34/100], Step [690/1751], Loss: 1.3290\n",
      "Epoch [34/100], Step [700/1751], Loss: 1.1671\n",
      "Epoch [34/100], Step [710/1751], Loss: 1.1506\n",
      "Epoch [34/100], Step [720/1751], Loss: 1.2972\n",
      "Epoch [34/100], Step [730/1751], Loss: 1.0856\n",
      "Epoch [34/100], Step [740/1751], Loss: 1.2794\n",
      "Epoch [34/100], Step [750/1751], Loss: 1.2007\n",
      "Epoch [34/100], Step [760/1751], Loss: 1.1744\n",
      "Epoch [34/100], Step [770/1751], Loss: 1.2116\n",
      "Epoch [34/100], Step [780/1751], Loss: 1.1059\n",
      "Epoch [34/100], Step [790/1751], Loss: 1.2208\n",
      "Epoch [34/100], Step [800/1751], Loss: 1.0470\n",
      "Epoch [34/100], Step [810/1751], Loss: 1.1997\n",
      "Epoch [34/100], Step [820/1751], Loss: 1.2513\n",
      "Epoch [34/100], Step [830/1751], Loss: 1.2034\n",
      "Epoch [34/100], Step [840/1751], Loss: 1.3671\n",
      "Epoch [34/100], Step [850/1751], Loss: 1.1097\n",
      "Epoch [34/100], Step [860/1751], Loss: 1.2323\n",
      "Epoch [34/100], Step [870/1751], Loss: 1.2391\n",
      "Epoch [34/100], Step [880/1751], Loss: 1.2190\n",
      "Epoch [34/100], Step [890/1751], Loss: 1.1881\n",
      "Epoch [34/100], Step [900/1751], Loss: 1.1465\n",
      "Epoch [34/100], Step [910/1751], Loss: 1.3155\n",
      "Epoch [34/100], Step [920/1751], Loss: 1.2632\n",
      "Epoch [34/100], Step [930/1751], Loss: 1.2351\n",
      "Epoch [34/100], Step [940/1751], Loss: 1.2389\n",
      "Epoch [34/100], Step [950/1751], Loss: 1.2485\n",
      "Epoch [34/100], Step [960/1751], Loss: 1.2479\n",
      "Epoch [34/100], Step [970/1751], Loss: 1.1773\n",
      "Epoch [34/100], Step [980/1751], Loss: 1.3757\n",
      "Epoch [34/100], Step [990/1751], Loss: 1.1934\n",
      "Epoch [34/100], Step [1000/1751], Loss: 1.2649\n",
      "Epoch [34/100], Step [1010/1751], Loss: 1.3282\n",
      "Epoch [34/100], Step [1020/1751], Loss: 1.3405\n",
      "Epoch [34/100], Step [1030/1751], Loss: 1.2775\n",
      "Epoch [34/100], Step [1040/1751], Loss: 1.3372\n",
      "Epoch [34/100], Step [1050/1751], Loss: 1.0992\n",
      "Epoch [34/100], Step [1060/1751], Loss: 1.1420\n",
      "Epoch [34/100], Step [1070/1751], Loss: 1.2801\n",
      "Epoch [34/100], Step [1080/1751], Loss: 1.2428\n",
      "Epoch [34/100], Step [1090/1751], Loss: 1.0475\n",
      "Epoch [34/100], Step [1100/1751], Loss: 1.3249\n",
      "Epoch [34/100], Step [1110/1751], Loss: 1.2752\n",
      "Epoch [34/100], Step [1120/1751], Loss: 1.2552\n",
      "Epoch [34/100], Step [1130/1751], Loss: 1.3083\n",
      "Epoch [34/100], Step [1140/1751], Loss: 1.3579\n",
      "Epoch [34/100], Step [1150/1751], Loss: 1.2097\n",
      "Epoch [34/100], Step [1160/1751], Loss: 1.2400\n",
      "Epoch [34/100], Step [1170/1751], Loss: 1.4772\n",
      "Epoch [34/100], Step [1180/1751], Loss: 1.1975\n",
      "Epoch [34/100], Step [1190/1751], Loss: 1.1931\n",
      "Epoch [34/100], Step [1200/1751], Loss: 1.3120\n",
      "Epoch [34/100], Step [1210/1751], Loss: 1.1758\n",
      "Epoch [34/100], Step [1220/1751], Loss: 1.1541\n",
      "Epoch [34/100], Step [1230/1751], Loss: 1.2476\n",
      "Epoch [34/100], Step [1240/1751], Loss: 1.2139\n",
      "Epoch [34/100], Step [1250/1751], Loss: 1.0640\n",
      "Epoch [34/100], Step [1260/1751], Loss: 1.2728\n",
      "Epoch [34/100], Step [1270/1751], Loss: 1.2996\n",
      "Epoch [34/100], Step [1280/1751], Loss: 1.2070\n",
      "Epoch [34/100], Step [1290/1751], Loss: 1.1007\n",
      "Epoch [34/100], Step [1300/1751], Loss: 1.1101\n",
      "Epoch [34/100], Step [1310/1751], Loss: 1.2040\n",
      "Epoch [34/100], Step [1320/1751], Loss: 1.3558\n",
      "Epoch [34/100], Step [1330/1751], Loss: 1.3245\n",
      "Epoch [34/100], Step [1340/1751], Loss: 1.3008\n",
      "Epoch [34/100], Step [1350/1751], Loss: 1.2958\n",
      "Epoch [34/100], Step [1360/1751], Loss: 1.3793\n",
      "Epoch [34/100], Step [1370/1751], Loss: 1.0932\n",
      "Epoch [34/100], Step [1380/1751], Loss: 1.2287\n",
      "Epoch [34/100], Step [1390/1751], Loss: 1.3270\n",
      "Epoch [34/100], Step [1400/1751], Loss: 1.3310\n",
      "Epoch [34/100], Step [1410/1751], Loss: 1.2973\n",
      "Epoch [34/100], Step [1420/1751], Loss: 1.2787\n",
      "Epoch [34/100], Step [1430/1751], Loss: 1.2004\n",
      "Epoch [34/100], Step [1440/1751], Loss: 1.1890\n",
      "Epoch [34/100], Step [1450/1751], Loss: 1.3178\n",
      "Epoch [34/100], Step [1460/1751], Loss: 1.2790\n",
      "Epoch [34/100], Step [1470/1751], Loss: 1.4052\n",
      "Epoch [34/100], Step [1480/1751], Loss: 1.3038\n",
      "Epoch [34/100], Step [1490/1751], Loss: 1.1820\n",
      "Epoch [34/100], Step [1500/1751], Loss: 1.1776\n",
      "Epoch [34/100], Step [1510/1751], Loss: 1.2592\n",
      "Epoch [34/100], Step [1520/1751], Loss: 1.3367\n",
      "Epoch [34/100], Step [1530/1751], Loss: 1.3982\n",
      "Epoch [34/100], Step [1540/1751], Loss: 1.2200\n",
      "Epoch [34/100], Step [1550/1751], Loss: 1.3660\n",
      "Epoch [34/100], Step [1560/1751], Loss: 1.3038\n",
      "Epoch [34/100], Step [1570/1751], Loss: 1.1470\n",
      "Epoch [34/100], Step [1580/1751], Loss: 1.2231\n",
      "Epoch [34/100], Step [1590/1751], Loss: 1.2358\n",
      "Epoch [34/100], Step [1600/1751], Loss: 1.1546\n",
      "Epoch [34/100], Step [1610/1751], Loss: 1.2791\n",
      "Epoch [34/100], Step [1620/1751], Loss: 1.4037\n",
      "Epoch [34/100], Step [1630/1751], Loss: 1.2800\n",
      "Epoch [34/100], Step [1640/1751], Loss: 1.1037\n",
      "Epoch [34/100], Step [1650/1751], Loss: 1.1651\n",
      "Epoch [34/100], Step [1660/1751], Loss: 1.1567\n",
      "Epoch [34/100], Step [1670/1751], Loss: 1.3038\n",
      "Epoch [34/100], Step [1680/1751], Loss: 1.2332\n",
      "Epoch [34/100], Step [1690/1751], Loss: 1.1451\n",
      "Epoch [34/100], Step [1700/1751], Loss: 1.2192\n",
      "Epoch [34/100], Step [1710/1751], Loss: 1.1289\n",
      "Epoch [34/100], Step [1720/1751], Loss: 1.4594\n",
      "Epoch [34/100], Step [1730/1751], Loss: 1.2187\n",
      "Epoch [34/100], Step [1740/1751], Loss: 1.3416\n",
      "Epoch [34/100], Step [1750/1751], Loss: 1.1182\n",
      "Epoch [34/100], Average Loss: 1.2332, Time: 1650.1769s\n",
      "Epoch [35/100], Step [10/1751], Loss: 1.2475\n",
      "Epoch [35/100], Step [20/1751], Loss: 1.2021\n",
      "Epoch [35/100], Step [30/1751], Loss: 1.1917\n",
      "Epoch [35/100], Step [40/1751], Loss: 1.1997\n",
      "Epoch [35/100], Step [50/1751], Loss: 1.3478\n",
      "Epoch [35/100], Step [60/1751], Loss: 1.2482\n",
      "Epoch [35/100], Step [70/1751], Loss: 1.1970\n",
      "Epoch [35/100], Step [80/1751], Loss: 1.2755\n",
      "Epoch [35/100], Step [90/1751], Loss: 1.2557\n",
      "Epoch [35/100], Step [100/1751], Loss: 1.2832\n",
      "Epoch [35/100], Step [110/1751], Loss: 1.2054\n",
      "Epoch [35/100], Step [120/1751], Loss: 1.2771\n",
      "Epoch [35/100], Step [130/1751], Loss: 1.1955\n",
      "Epoch [35/100], Step [140/1751], Loss: 1.3252\n",
      "Epoch [35/100], Step [150/1751], Loss: 1.3307\n",
      "Epoch [35/100], Step [160/1751], Loss: 1.3577\n",
      "Epoch [35/100], Step [170/1751], Loss: 1.4011\n",
      "Epoch [35/100], Step [180/1751], Loss: 1.0293\n",
      "Epoch [35/100], Step [190/1751], Loss: 1.1056\n",
      "Epoch [35/100], Step [200/1751], Loss: 1.2275\n",
      "Epoch [35/100], Step [210/1751], Loss: 1.1970\n",
      "Epoch [35/100], Step [220/1751], Loss: 1.4705\n",
      "Epoch [35/100], Step [230/1751], Loss: 1.3210\n",
      "Epoch [35/100], Step [240/1751], Loss: 1.2559\n",
      "Epoch [35/100], Step [250/1751], Loss: 1.2298\n",
      "Epoch [35/100], Step [260/1751], Loss: 1.2418\n",
      "Epoch [35/100], Step [270/1751], Loss: 1.1979\n",
      "Epoch [35/100], Step [280/1751], Loss: 1.3806\n",
      "Epoch [35/100], Step [290/1751], Loss: 1.3169\n",
      "Epoch [35/100], Step [300/1751], Loss: 1.1895\n",
      "Epoch [35/100], Step [310/1751], Loss: 1.0951\n",
      "Epoch [35/100], Step [320/1751], Loss: 1.2156\n",
      "Epoch [35/100], Step [330/1751], Loss: 1.2218\n",
      "Epoch [35/100], Step [340/1751], Loss: 1.0659\n",
      "Epoch [35/100], Step [350/1751], Loss: 1.2404\n",
      "Epoch [35/100], Step [360/1751], Loss: 1.1561\n",
      "Epoch [35/100], Step [370/1751], Loss: 1.1231\n",
      "Epoch [35/100], Step [380/1751], Loss: 1.2275\n",
      "Epoch [35/100], Step [390/1751], Loss: 1.1691\n",
      "Epoch [35/100], Step [400/1751], Loss: 1.3984\n",
      "Epoch [35/100], Step [410/1751], Loss: 1.1396\n",
      "Epoch [35/100], Step [420/1751], Loss: 1.1497\n",
      "Epoch [35/100], Step [430/1751], Loss: 1.2697\n",
      "Epoch [35/100], Step [440/1751], Loss: 1.1515\n",
      "Epoch [35/100], Step [450/1751], Loss: 1.2942\n",
      "Epoch [35/100], Step [460/1751], Loss: 1.4006\n",
      "Epoch [35/100], Step [470/1751], Loss: 1.0871\n",
      "Epoch [35/100], Step [480/1751], Loss: 1.1118\n",
      "Epoch [35/100], Step [490/1751], Loss: 1.1486\n",
      "Epoch [35/100], Step [500/1751], Loss: 1.3332\n",
      "Epoch [35/100], Step [510/1751], Loss: 1.1490\n",
      "Epoch [35/100], Step [520/1751], Loss: 1.1342\n",
      "Epoch [35/100], Step [530/1751], Loss: 1.1342\n",
      "Epoch [35/100], Step [540/1751], Loss: 1.0909\n",
      "Epoch [35/100], Step [550/1751], Loss: 1.2834\n",
      "Epoch [35/100], Step [560/1751], Loss: 1.2127\n",
      "Epoch [35/100], Step [570/1751], Loss: 1.1237\n",
      "Epoch [35/100], Step [580/1751], Loss: 1.2228\n",
      "Epoch [35/100], Step [590/1751], Loss: 1.3929\n",
      "Epoch [35/100], Step [600/1751], Loss: 1.2823\n",
      "Epoch [35/100], Step [610/1751], Loss: 1.1600\n",
      "Epoch [35/100], Step [620/1751], Loss: 1.1849\n",
      "Epoch [35/100], Step [630/1751], Loss: 1.3432\n",
      "Epoch [35/100], Step [640/1751], Loss: 1.2484\n",
      "Epoch [35/100], Step [650/1751], Loss: 1.2278\n",
      "Epoch [35/100], Step [660/1751], Loss: 1.2578\n",
      "Epoch [35/100], Step [670/1751], Loss: 1.1851\n",
      "Epoch [35/100], Step [680/1751], Loss: 1.2435\n",
      "Epoch [35/100], Step [690/1751], Loss: 1.2508\n",
      "Epoch [35/100], Step [700/1751], Loss: 1.0863\n",
      "Epoch [35/100], Step [710/1751], Loss: 1.1631\n",
      "Epoch [35/100], Step [720/1751], Loss: 1.2874\n",
      "Epoch [35/100], Step [730/1751], Loss: 1.1417\n",
      "Epoch [35/100], Step [740/1751], Loss: 1.2258\n",
      "Epoch [35/100], Step [750/1751], Loss: 1.0692\n",
      "Epoch [35/100], Step [760/1751], Loss: 1.2498\n",
      "Epoch [35/100], Step [770/1751], Loss: 1.2633\n",
      "Epoch [35/100], Step [780/1751], Loss: 1.3542\n",
      "Epoch [35/100], Step [790/1751], Loss: 1.3359\n",
      "Epoch [35/100], Step [800/1751], Loss: 1.2359\n",
      "Epoch [35/100], Step [810/1751], Loss: 1.1237\n",
      "Epoch [35/100], Step [820/1751], Loss: 1.2587\n",
      "Epoch [35/100], Step [830/1751], Loss: 1.3048\n",
      "Epoch [35/100], Step [840/1751], Loss: 1.1842\n",
      "Epoch [35/100], Step [850/1751], Loss: 1.1457\n",
      "Epoch [35/100], Step [860/1751], Loss: 1.3342\n",
      "Epoch [35/100], Step [870/1751], Loss: 1.2294\n",
      "Epoch [35/100], Step [880/1751], Loss: 1.2221\n",
      "Epoch [35/100], Step [890/1751], Loss: 1.2879\n",
      "Epoch [35/100], Step [900/1751], Loss: 1.2993\n",
      "Epoch [35/100], Step [910/1751], Loss: 1.3309\n",
      "Epoch [35/100], Step [920/1751], Loss: 1.1929\n",
      "Epoch [35/100], Step [930/1751], Loss: 1.1528\n",
      "Epoch [35/100], Step [940/1751], Loss: 1.2452\n",
      "Epoch [35/100], Step [950/1751], Loss: 1.2052\n",
      "Epoch [35/100], Step [960/1751], Loss: 1.2259\n",
      "Epoch [35/100], Step [970/1751], Loss: 1.2527\n",
      "Epoch [35/100], Step [980/1751], Loss: 0.9875\n",
      "Epoch [35/100], Step [990/1751], Loss: 1.3478\n",
      "Epoch [35/100], Step [1000/1751], Loss: 1.3199\n",
      "Epoch [35/100], Step [1010/1751], Loss: 1.1379\n",
      "Epoch [35/100], Step [1020/1751], Loss: 1.1131\n",
      "Epoch [35/100], Step [1030/1751], Loss: 1.1389\n",
      "Epoch [35/100], Step [1040/1751], Loss: 1.2830\n",
      "Epoch [35/100], Step [1050/1751], Loss: 1.3002\n",
      "Epoch [35/100], Step [1060/1751], Loss: 1.3661\n",
      "Epoch [35/100], Step [1070/1751], Loss: 1.2599\n",
      "Epoch [35/100], Step [1080/1751], Loss: 1.2613\n",
      "Epoch [35/100], Step [1090/1751], Loss: 1.1360\n",
      "Epoch [35/100], Step [1100/1751], Loss: 1.2821\n",
      "Epoch [35/100], Step [1110/1751], Loss: 1.3917\n",
      "Epoch [35/100], Step [1120/1751], Loss: 1.2089\n",
      "Epoch [35/100], Step [1130/1751], Loss: 1.2361\n",
      "Epoch [35/100], Step [1140/1751], Loss: 1.1760\n",
      "Epoch [35/100], Step [1150/1751], Loss: 1.1908\n",
      "Epoch [35/100], Step [1160/1751], Loss: 1.1689\n",
      "Epoch [35/100], Step [1170/1751], Loss: 1.2659\n",
      "Epoch [35/100], Step [1180/1751], Loss: 1.2388\n",
      "Epoch [35/100], Step [1190/1751], Loss: 1.3290\n",
      "Epoch [35/100], Step [1200/1751], Loss: 1.2194\n",
      "Epoch [35/100], Step [1210/1751], Loss: 1.3020\n",
      "Epoch [35/100], Step [1220/1751], Loss: 1.2508\n",
      "Epoch [35/100], Step [1230/1751], Loss: 1.2000\n",
      "Epoch [35/100], Step [1240/1751], Loss: 1.2481\n",
      "Epoch [35/100], Step [1250/1751], Loss: 1.2991\n",
      "Epoch [35/100], Step [1260/1751], Loss: 1.0049\n",
      "Epoch [35/100], Step [1270/1751], Loss: 1.3268\n",
      "Epoch [35/100], Step [1280/1751], Loss: 1.2227\n",
      "Epoch [35/100], Step [1290/1751], Loss: 1.2477\n",
      "Epoch [35/100], Step [1300/1751], Loss: 1.2683\n",
      "Epoch [35/100], Step [1310/1751], Loss: 1.2642\n",
      "Epoch [35/100], Step [1320/1751], Loss: 1.2773\n",
      "Epoch [35/100], Step [1330/1751], Loss: 1.1859\n",
      "Epoch [35/100], Step [1340/1751], Loss: 1.3538\n",
      "Epoch [35/100], Step [1350/1751], Loss: 1.2206\n",
      "Epoch [35/100], Step [1360/1751], Loss: 1.2272\n",
      "Epoch [35/100], Step [1370/1751], Loss: 1.0939\n",
      "Epoch [35/100], Step [1380/1751], Loss: 1.2142\n",
      "Epoch [35/100], Step [1390/1751], Loss: 1.2955\n",
      "Epoch [35/100], Step [1400/1751], Loss: 1.1099\n",
      "Epoch [35/100], Step [1410/1751], Loss: 1.3031\n",
      "Epoch [35/100], Step [1420/1751], Loss: 1.1840\n",
      "Epoch [35/100], Step [1430/1751], Loss: 1.2936\n",
      "Epoch [35/100], Step [1440/1751], Loss: 1.2039\n",
      "Epoch [35/100], Step [1450/1751], Loss: 1.1771\n",
      "Epoch [35/100], Step [1460/1751], Loss: 1.3014\n",
      "Epoch [35/100], Step [1470/1751], Loss: 1.3928\n",
      "Epoch [35/100], Step [1480/1751], Loss: 1.1274\n",
      "Epoch [35/100], Step [1490/1751], Loss: 1.3474\n",
      "Epoch [35/100], Step [1500/1751], Loss: 1.1734\n",
      "Epoch [35/100], Step [1510/1751], Loss: 1.2702\n",
      "Epoch [35/100], Step [1520/1751], Loss: 1.1491\n",
      "Epoch [35/100], Step [1530/1751], Loss: 1.1445\n",
      "Epoch [35/100], Step [1540/1751], Loss: 1.0959\n",
      "Epoch [35/100], Step [1550/1751], Loss: 1.2078\n",
      "Epoch [35/100], Step [1560/1751], Loss: 1.2275\n",
      "Epoch [35/100], Step [1570/1751], Loss: 1.1991\n",
      "Epoch [35/100], Step [1580/1751], Loss: 1.1307\n",
      "Epoch [35/100], Step [1590/1751], Loss: 1.2250\n",
      "Epoch [35/100], Step [1600/1751], Loss: 1.1829\n",
      "Epoch [35/100], Step [1610/1751], Loss: 1.3223\n",
      "Epoch [35/100], Step [1620/1751], Loss: 1.3512\n",
      "Epoch [35/100], Step [1630/1751], Loss: 1.3146\n",
      "Epoch [35/100], Step [1640/1751], Loss: 1.1442\n",
      "Epoch [35/100], Step [1650/1751], Loss: 1.2046\n",
      "Epoch [35/100], Step [1660/1751], Loss: 1.2994\n",
      "Epoch [35/100], Step [1670/1751], Loss: 1.4033\n",
      "Epoch [35/100], Step [1680/1751], Loss: 1.1861\n",
      "Epoch [35/100], Step [1690/1751], Loss: 1.1601\n",
      "Epoch [35/100], Step [1700/1751], Loss: 1.1666\n",
      "Epoch [35/100], Step [1710/1751], Loss: 1.2396\n",
      "Epoch [35/100], Step [1720/1751], Loss: 1.3135\n",
      "Epoch [35/100], Step [1730/1751], Loss: 1.2727\n",
      "Epoch [35/100], Step [1740/1751], Loss: 1.3347\n",
      "Epoch [35/100], Step [1750/1751], Loss: 1.1795\n",
      "Epoch [35/100], Average Loss: 1.2303, Time: 1649.5121s\n",
      "Epoch [36/100], Step [10/1751], Loss: 1.1349\n",
      "Epoch [36/100], Step [20/1751], Loss: 1.1659\n",
      "Epoch [36/100], Step [30/1751], Loss: 1.1624\n",
      "Epoch [36/100], Step [40/1751], Loss: 1.2420\n",
      "Epoch [36/100], Step [50/1751], Loss: 1.0891\n",
      "Epoch [36/100], Step [60/1751], Loss: 1.2038\n",
      "Epoch [36/100], Step [70/1751], Loss: 1.2273\n",
      "Epoch [36/100], Step [80/1751], Loss: 1.3956\n",
      "Epoch [36/100], Step [90/1751], Loss: 1.0952\n",
      "Epoch [36/100], Step [100/1751], Loss: 1.0066\n",
      "Epoch [36/100], Step [110/1751], Loss: 1.2211\n",
      "Epoch [36/100], Step [120/1751], Loss: 1.1113\n",
      "Epoch [36/100], Step [130/1751], Loss: 1.2311\n",
      "Epoch [36/100], Step [140/1751], Loss: 1.1952\n",
      "Epoch [36/100], Step [150/1751], Loss: 1.3213\n",
      "Epoch [36/100], Step [160/1751], Loss: 1.3723\n",
      "Epoch [36/100], Step [170/1751], Loss: 1.3039\n",
      "Epoch [36/100], Step [180/1751], Loss: 1.2189\n",
      "Epoch [36/100], Step [190/1751], Loss: 1.1565\n",
      "Epoch [36/100], Step [200/1751], Loss: 1.2109\n",
      "Epoch [36/100], Step [210/1751], Loss: 1.1498\n",
      "Epoch [36/100], Step [220/1751], Loss: 1.1894\n",
      "Epoch [36/100], Step [230/1751], Loss: 1.2983\n",
      "Epoch [36/100], Step [240/1751], Loss: 1.3085\n",
      "Epoch [36/100], Step [250/1751], Loss: 1.3256\n",
      "Epoch [36/100], Step [260/1751], Loss: 1.2201\n",
      "Epoch [36/100], Step [270/1751], Loss: 1.0988\n",
      "Epoch [36/100], Step [280/1751], Loss: 1.2192\n",
      "Epoch [36/100], Step [290/1751], Loss: 1.2058\n",
      "Epoch [36/100], Step [300/1751], Loss: 1.2333\n",
      "Epoch [36/100], Step [310/1751], Loss: 1.1685\n",
      "Epoch [36/100], Step [320/1751], Loss: 1.3010\n",
      "Epoch [36/100], Step [330/1751], Loss: 1.3538\n",
      "Epoch [36/100], Step [340/1751], Loss: 1.4586\n",
      "Epoch [36/100], Step [350/1751], Loss: 1.2466\n",
      "Epoch [36/100], Step [360/1751], Loss: 1.2261\n",
      "Epoch [36/100], Step [370/1751], Loss: 1.2910\n",
      "Epoch [36/100], Step [380/1751], Loss: 1.2260\n",
      "Epoch [36/100], Step [390/1751], Loss: 1.1978\n",
      "Epoch [36/100], Step [400/1751], Loss: 1.2892\n",
      "Epoch [36/100], Step [410/1751], Loss: 1.2325\n",
      "Epoch [36/100], Step [420/1751], Loss: 1.2677\n",
      "Epoch [36/100], Step [430/1751], Loss: 1.3081\n",
      "Epoch [36/100], Step [440/1751], Loss: 1.1417\n",
      "Epoch [36/100], Step [450/1751], Loss: 1.2456\n",
      "Epoch [36/100], Step [460/1751], Loss: 1.4010\n",
      "Epoch [36/100], Step [470/1751], Loss: 1.1957\n",
      "Epoch [36/100], Step [480/1751], Loss: 1.1333\n",
      "Epoch [36/100], Step [490/1751], Loss: 1.1576\n",
      "Epoch [36/100], Step [500/1751], Loss: 1.0808\n",
      "Epoch [36/100], Step [510/1751], Loss: 1.3387\n",
      "Epoch [36/100], Step [520/1751], Loss: 1.1588\n",
      "Epoch [36/100], Step [530/1751], Loss: 1.3692\n",
      "Epoch [36/100], Step [540/1751], Loss: 1.2830\n",
      "Epoch [36/100], Step [550/1751], Loss: 1.2013\n",
      "Epoch [36/100], Step [560/1751], Loss: 1.3247\n",
      "Epoch [36/100], Step [570/1751], Loss: 1.2311\n",
      "Epoch [36/100], Step [580/1751], Loss: 1.4135\n",
      "Epoch [36/100], Step [590/1751], Loss: 1.1349\n",
      "Epoch [36/100], Step [600/1751], Loss: 1.1430\n",
      "Epoch [36/100], Step [610/1751], Loss: 1.2135\n",
      "Epoch [36/100], Step [620/1751], Loss: 1.1917\n",
      "Epoch [36/100], Step [630/1751], Loss: 1.3378\n",
      "Epoch [36/100], Step [640/1751], Loss: 1.2034\n",
      "Epoch [36/100], Step [650/1751], Loss: 1.2070\n",
      "Epoch [36/100], Step [660/1751], Loss: 1.2231\n",
      "Epoch [36/100], Step [670/1751], Loss: 1.4216\n",
      "Epoch [36/100], Step [680/1751], Loss: 1.2747\n",
      "Epoch [36/100], Step [690/1751], Loss: 1.1471\n",
      "Epoch [36/100], Step [700/1751], Loss: 1.2673\n",
      "Epoch [36/100], Step [710/1751], Loss: 1.3096\n",
      "Epoch [36/100], Step [720/1751], Loss: 1.3788\n",
      "Epoch [36/100], Step [730/1751], Loss: 1.1292\n",
      "Epoch [36/100], Step [740/1751], Loss: 1.2676\n",
      "Epoch [36/100], Step [750/1751], Loss: 1.1164\n",
      "Epoch [36/100], Step [760/1751], Loss: 1.1915\n",
      "Epoch [36/100], Step [770/1751], Loss: 1.2015\n",
      "Epoch [36/100], Step [780/1751], Loss: 1.3088\n",
      "Epoch [36/100], Step [790/1751], Loss: 1.0557\n",
      "Epoch [36/100], Step [800/1751], Loss: 1.2602\n",
      "Epoch [36/100], Step [810/1751], Loss: 1.1957\n",
      "Epoch [36/100], Step [820/1751], Loss: 1.2715\n",
      "Epoch [36/100], Step [830/1751], Loss: 1.2668\n",
      "Epoch [36/100], Step [840/1751], Loss: 1.2917\n",
      "Epoch [36/100], Step [850/1751], Loss: 1.2821\n",
      "Epoch [36/100], Step [860/1751], Loss: 1.3274\n",
      "Epoch [36/100], Step [870/1751], Loss: 1.1511\n",
      "Epoch [36/100], Step [880/1751], Loss: 1.3181\n",
      "Epoch [36/100], Step [890/1751], Loss: 1.1908\n",
      "Epoch [36/100], Step [900/1751], Loss: 1.2129\n",
      "Epoch [36/100], Step [910/1751], Loss: 1.2520\n",
      "Epoch [36/100], Step [920/1751], Loss: 1.2754\n",
      "Epoch [36/100], Step [930/1751], Loss: 1.2669\n",
      "Epoch [36/100], Step [940/1751], Loss: 1.1875\n",
      "Epoch [36/100], Step [950/1751], Loss: 1.1937\n",
      "Epoch [36/100], Step [960/1751], Loss: 1.2075\n",
      "Epoch [36/100], Step [970/1751], Loss: 1.2809\n",
      "Epoch [36/100], Step [980/1751], Loss: 1.4846\n",
      "Epoch [36/100], Step [990/1751], Loss: 1.1757\n",
      "Epoch [36/100], Step [1000/1751], Loss: 1.1079\n",
      "Epoch [36/100], Step [1010/1751], Loss: 1.1979\n",
      "Epoch [36/100], Step [1020/1751], Loss: 1.2452\n",
      "Epoch [36/100], Step [1030/1751], Loss: 1.1341\n",
      "Epoch [36/100], Step [1040/1751], Loss: 1.3279\n",
      "Epoch [36/100], Step [1050/1751], Loss: 1.0626\n",
      "Epoch [36/100], Step [1060/1751], Loss: 1.1936\n",
      "Epoch [36/100], Step [1070/1751], Loss: 1.1305\n",
      "Epoch [36/100], Step [1080/1751], Loss: 1.0762\n",
      "Epoch [36/100], Step [1090/1751], Loss: 1.1927\n",
      "Epoch [36/100], Step [1100/1751], Loss: 1.3058\n",
      "Epoch [36/100], Step [1110/1751], Loss: 1.1586\n",
      "Epoch [36/100], Step [1120/1751], Loss: 1.1631\n",
      "Epoch [36/100], Step [1130/1751], Loss: 1.1548\n",
      "Epoch [36/100], Step [1140/1751], Loss: 1.1502\n",
      "Epoch [36/100], Step [1150/1751], Loss: 1.2017\n",
      "Epoch [36/100], Step [1160/1751], Loss: 1.1513\n",
      "Epoch [36/100], Step [1170/1751], Loss: 1.3040\n",
      "Epoch [36/100], Step [1180/1751], Loss: 1.1244\n",
      "Epoch [36/100], Step [1190/1751], Loss: 1.1702\n",
      "Epoch [36/100], Step [1200/1751], Loss: 1.1737\n",
      "Epoch [36/100], Step [1210/1751], Loss: 1.3169\n",
      "Epoch [36/100], Step [1220/1751], Loss: 1.2904\n",
      "Epoch [36/100], Step [1230/1751], Loss: 1.1318\n",
      "Epoch [36/100], Step [1240/1751], Loss: 1.0666\n",
      "Epoch [36/100], Step [1250/1751], Loss: 1.1526\n",
      "Epoch [36/100], Step [1260/1751], Loss: 1.3016\n",
      "Epoch [36/100], Step [1270/1751], Loss: 1.1355\n",
      "Epoch [36/100], Step [1280/1751], Loss: 1.4235\n",
      "Epoch [36/100], Step [1290/1751], Loss: 1.3010\n",
      "Epoch [36/100], Step [1300/1751], Loss: 1.1990\n",
      "Epoch [36/100], Step [1310/1751], Loss: 1.2870\n",
      "Epoch [36/100], Step [1320/1751], Loss: 1.3282\n",
      "Epoch [36/100], Step [1330/1751], Loss: 1.1454\n",
      "Epoch [36/100], Step [1340/1751], Loss: 1.3088\n",
      "Epoch [36/100], Step [1350/1751], Loss: 1.1859\n",
      "Epoch [36/100], Step [1360/1751], Loss: 1.2021\n",
      "Epoch [36/100], Step [1370/1751], Loss: 1.4510\n",
      "Epoch [36/100], Step [1380/1751], Loss: 1.2457\n",
      "Epoch [36/100], Step [1390/1751], Loss: 1.2602\n",
      "Epoch [36/100], Step [1400/1751], Loss: 1.2938\n",
      "Epoch [36/100], Step [1410/1751], Loss: 1.2343\n",
      "Epoch [36/100], Step [1420/1751], Loss: 1.3230\n",
      "Epoch [36/100], Step [1430/1751], Loss: 1.2242\n",
      "Epoch [36/100], Step [1440/1751], Loss: 1.3133\n",
      "Epoch [36/100], Step [1450/1751], Loss: 1.3516\n",
      "Epoch [36/100], Step [1460/1751], Loss: 1.1310\n",
      "Epoch [36/100], Step [1470/1751], Loss: 1.1878\n",
      "Epoch [36/100], Step [1480/1751], Loss: 1.2128\n",
      "Epoch [36/100], Step [1490/1751], Loss: 1.1829\n",
      "Epoch [36/100], Step [1500/1751], Loss: 1.2038\n",
      "Epoch [36/100], Step [1510/1751], Loss: 1.1451\n",
      "Epoch [36/100], Step [1520/1751], Loss: 1.0850\n",
      "Epoch [36/100], Step [1530/1751], Loss: 1.1621\n",
      "Epoch [36/100], Step [1540/1751], Loss: 1.1875\n",
      "Epoch [36/100], Step [1550/1751], Loss: 1.1330\n",
      "Epoch [36/100], Step [1560/1751], Loss: 1.2089\n",
      "Epoch [36/100], Step [1570/1751], Loss: 1.2686\n",
      "Epoch [36/100], Step [1580/1751], Loss: 1.4150\n",
      "Epoch [36/100], Step [1590/1751], Loss: 1.2175\n",
      "Epoch [36/100], Step [1600/1751], Loss: 1.1720\n",
      "Epoch [36/100], Step [1610/1751], Loss: 1.3727\n",
      "Epoch [36/100], Step [1620/1751], Loss: 1.0883\n",
      "Epoch [36/100], Step [1630/1751], Loss: 1.1547\n",
      "Epoch [36/100], Step [1640/1751], Loss: 1.2420\n",
      "Epoch [36/100], Step [1650/1751], Loss: 1.2024\n",
      "Epoch [36/100], Step [1660/1751], Loss: 1.1771\n",
      "Epoch [36/100], Step [1670/1751], Loss: 1.3180\n",
      "Epoch [36/100], Step [1680/1751], Loss: 1.2535\n",
      "Epoch [36/100], Step [1690/1751], Loss: 1.2397\n",
      "Epoch [36/100], Step [1700/1751], Loss: 1.2238\n",
      "Epoch [36/100], Step [1710/1751], Loss: 1.3212\n",
      "Epoch [36/100], Step [1720/1751], Loss: 1.2580\n",
      "Epoch [36/100], Step [1730/1751], Loss: 1.2297\n",
      "Epoch [36/100], Step [1740/1751], Loss: 1.1162\n",
      "Epoch [36/100], Step [1750/1751], Loss: 1.3121\n",
      "Epoch [36/100], Average Loss: 1.2293, Time: 1649.2956s\n",
      "Epoch [37/100], Step [10/1751], Loss: 1.2104\n",
      "Epoch [37/100], Step [20/1751], Loss: 1.1954\n",
      "Epoch [37/100], Step [30/1751], Loss: 1.3807\n",
      "Epoch [37/100], Step [40/1751], Loss: 1.1590\n",
      "Epoch [37/100], Step [50/1751], Loss: 1.2965\n",
      "Epoch [37/100], Step [60/1751], Loss: 1.2058\n",
      "Epoch [37/100], Step [70/1751], Loss: 1.3197\n",
      "Epoch [37/100], Step [80/1751], Loss: 1.2135\n",
      "Epoch [37/100], Step [90/1751], Loss: 1.2018\n",
      "Epoch [37/100], Step [100/1751], Loss: 1.2782\n",
      "Epoch [37/100], Step [110/1751], Loss: 1.2081\n",
      "Epoch [37/100], Step [120/1751], Loss: 1.1982\n",
      "Epoch [37/100], Step [130/1751], Loss: 1.4172\n",
      "Epoch [37/100], Step [140/1751], Loss: 1.0745\n",
      "Epoch [37/100], Step [150/1751], Loss: 1.2342\n",
      "Epoch [37/100], Step [160/1751], Loss: 1.1388\n",
      "Epoch [37/100], Step [170/1751], Loss: 1.0990\n",
      "Epoch [37/100], Step [180/1751], Loss: 1.0879\n",
      "Epoch [37/100], Step [190/1751], Loss: 1.1916\n",
      "Epoch [37/100], Step [200/1751], Loss: 1.2586\n",
      "Epoch [37/100], Step [210/1751], Loss: 1.0957\n",
      "Epoch [37/100], Step [220/1751], Loss: 1.2480\n",
      "Epoch [37/100], Step [230/1751], Loss: 1.2117\n",
      "Epoch [37/100], Step [240/1751], Loss: 1.2002\n",
      "Epoch [37/100], Step [250/1751], Loss: 1.2925\n",
      "Epoch [37/100], Step [260/1751], Loss: 1.3006\n",
      "Epoch [37/100], Step [270/1751], Loss: 1.2826\n",
      "Epoch [37/100], Step [280/1751], Loss: 1.2689\n",
      "Epoch [37/100], Step [290/1751], Loss: 1.2263\n",
      "Epoch [37/100], Step [300/1751], Loss: 1.2622\n",
      "Epoch [37/100], Step [310/1751], Loss: 1.1681\n",
      "Epoch [37/100], Step [320/1751], Loss: 1.1153\n",
      "Epoch [37/100], Step [330/1751], Loss: 1.2688\n",
      "Epoch [37/100], Step [340/1751], Loss: 1.2688\n",
      "Epoch [37/100], Step [350/1751], Loss: 1.0489\n",
      "Epoch [37/100], Step [360/1751], Loss: 1.2298\n",
      "Epoch [37/100], Step [370/1751], Loss: 1.2289\n",
      "Epoch [37/100], Step [380/1751], Loss: 1.2189\n",
      "Epoch [37/100], Step [390/1751], Loss: 1.2212\n",
      "Epoch [37/100], Step [400/1751], Loss: 1.2568\n",
      "Epoch [37/100], Step [410/1751], Loss: 1.2756\n",
      "Epoch [37/100], Step [420/1751], Loss: 1.0700\n",
      "Epoch [37/100], Step [430/1751], Loss: 1.3416\n",
      "Epoch [37/100], Step [440/1751], Loss: 1.4239\n",
      "Epoch [37/100], Step [450/1751], Loss: 1.3303\n",
      "Epoch [37/100], Step [460/1751], Loss: 1.1446\n",
      "Epoch [37/100], Step [470/1751], Loss: 1.2086\n",
      "Epoch [37/100], Step [480/1751], Loss: 1.2734\n",
      "Epoch [37/100], Step [490/1751], Loss: 1.2650\n",
      "Epoch [37/100], Step [500/1751], Loss: 1.2756\n",
      "Epoch [37/100], Step [510/1751], Loss: 1.1449\n",
      "Epoch [37/100], Step [520/1751], Loss: 1.2529\n",
      "Epoch [37/100], Step [530/1751], Loss: 1.2778\n",
      "Epoch [37/100], Step [540/1751], Loss: 1.0610\n",
      "Epoch [37/100], Step [550/1751], Loss: 1.1658\n",
      "Epoch [37/100], Step [560/1751], Loss: 1.1848\n",
      "Epoch [37/100], Step [570/1751], Loss: 1.3017\n",
      "Epoch [37/100], Step [580/1751], Loss: 1.1494\n",
      "Epoch [37/100], Step [590/1751], Loss: 1.2982\n",
      "Epoch [37/100], Step [600/1751], Loss: 1.2308\n",
      "Epoch [37/100], Step [610/1751], Loss: 1.3049\n",
      "Epoch [37/100], Step [620/1751], Loss: 1.1082\n",
      "Epoch [37/100], Step [630/1751], Loss: 1.1879\n",
      "Epoch [37/100], Step [640/1751], Loss: 1.3520\n",
      "Epoch [37/100], Step [650/1751], Loss: 1.2315\n",
      "Epoch [37/100], Step [660/1751], Loss: 1.3646\n",
      "Epoch [37/100], Step [670/1751], Loss: 1.1865\n",
      "Epoch [37/100], Step [680/1751], Loss: 1.1324\n",
      "Epoch [37/100], Step [690/1751], Loss: 1.3734\n",
      "Epoch [37/100], Step [700/1751], Loss: 1.2736\n",
      "Epoch [37/100], Step [710/1751], Loss: 1.1149\n",
      "Epoch [37/100], Step [720/1751], Loss: 1.3334\n",
      "Epoch [37/100], Step [730/1751], Loss: 1.1002\n",
      "Epoch [37/100], Step [740/1751], Loss: 1.3853\n",
      "Epoch [37/100], Step [750/1751], Loss: 1.1775\n",
      "Epoch [37/100], Step [760/1751], Loss: 1.2598\n",
      "Epoch [37/100], Step [770/1751], Loss: 1.2493\n",
      "Epoch [37/100], Step [780/1751], Loss: 1.3414\n",
      "Epoch [37/100], Step [790/1751], Loss: 1.3725\n",
      "Epoch [37/100], Step [800/1751], Loss: 1.3352\n",
      "Epoch [37/100], Step [810/1751], Loss: 1.2718\n",
      "Epoch [37/100], Step [820/1751], Loss: 1.3407\n",
      "Epoch [37/100], Step [830/1751], Loss: 1.3458\n",
      "Epoch [37/100], Step [840/1751], Loss: 1.2934\n",
      "Epoch [37/100], Step [850/1751], Loss: 1.2409\n",
      "Epoch [37/100], Step [860/1751], Loss: 1.1053\n",
      "Epoch [37/100], Step [870/1751], Loss: 1.2336\n",
      "Epoch [37/100], Step [880/1751], Loss: 1.1727\n",
      "Epoch [37/100], Step [890/1751], Loss: 1.1728\n",
      "Epoch [37/100], Step [900/1751], Loss: 1.2426\n",
      "Epoch [37/100], Step [910/1751], Loss: 1.1150\n",
      "Epoch [37/100], Step [920/1751], Loss: 1.2757\n",
      "Epoch [37/100], Step [930/1751], Loss: 1.2738\n",
      "Epoch [37/100], Step [940/1751], Loss: 1.2021\n",
      "Epoch [37/100], Step [950/1751], Loss: 1.2683\n",
      "Epoch [37/100], Step [960/1751], Loss: 1.1838\n",
      "Epoch [37/100], Step [970/1751], Loss: 1.1269\n",
      "Epoch [37/100], Step [980/1751], Loss: 1.1250\n",
      "Epoch [37/100], Step [990/1751], Loss: 1.1582\n",
      "Epoch [37/100], Step [1000/1751], Loss: 1.2725\n",
      "Epoch [37/100], Step [1010/1751], Loss: 1.2418\n",
      "Epoch [37/100], Step [1020/1751], Loss: 1.2162\n",
      "Epoch [37/100], Step [1030/1751], Loss: 1.2882\n",
      "Epoch [37/100], Step [1040/1751], Loss: 1.1687\n",
      "Epoch [37/100], Step [1050/1751], Loss: 1.3101\n",
      "Epoch [37/100], Step [1060/1751], Loss: 1.1587\n",
      "Epoch [37/100], Step [1070/1751], Loss: 1.3351\n",
      "Epoch [37/100], Step [1080/1751], Loss: 1.3141\n",
      "Epoch [37/100], Step [1090/1751], Loss: 1.1677\n",
      "Epoch [37/100], Step [1100/1751], Loss: 1.1573\n",
      "Epoch [37/100], Step [1110/1751], Loss: 1.1465\n",
      "Epoch [37/100], Step [1120/1751], Loss: 1.3230\n",
      "Epoch [37/100], Step [1130/1751], Loss: 1.2085\n",
      "Epoch [37/100], Step [1140/1751], Loss: 1.2923\n",
      "Epoch [37/100], Step [1150/1751], Loss: 1.1945\n",
      "Epoch [37/100], Step [1160/1751], Loss: 1.2684\n",
      "Epoch [37/100], Step [1170/1751], Loss: 1.1618\n",
      "Epoch [37/100], Step [1180/1751], Loss: 1.1777\n",
      "Epoch [37/100], Step [1190/1751], Loss: 1.2657\n",
      "Epoch [37/100], Step [1200/1751], Loss: 1.1836\n",
      "Epoch [37/100], Step [1210/1751], Loss: 1.3074\n",
      "Epoch [37/100], Step [1220/1751], Loss: 1.1656\n",
      "Epoch [37/100], Step [1230/1751], Loss: 1.0457\n",
      "Epoch [37/100], Step [1240/1751], Loss: 1.1514\n",
      "Epoch [37/100], Step [1250/1751], Loss: 1.0935\n",
      "Epoch [37/100], Step [1260/1751], Loss: 1.0264\n",
      "Epoch [37/100], Step [1270/1751], Loss: 1.2291\n",
      "Epoch [37/100], Step [1280/1751], Loss: 1.1387\n",
      "Epoch [37/100], Step [1290/1751], Loss: 1.1990\n",
      "Epoch [37/100], Step [1300/1751], Loss: 1.1748\n",
      "Epoch [37/100], Step [1310/1751], Loss: 0.9862\n",
      "Epoch [37/100], Step [1320/1751], Loss: 1.3093\n",
      "Epoch [37/100], Step [1330/1751], Loss: 1.3093\n",
      "Epoch [37/100], Step [1340/1751], Loss: 1.1225\n",
      "Epoch [37/100], Step [1350/1751], Loss: 1.2458\n",
      "Epoch [37/100], Step [1360/1751], Loss: 1.3046\n",
      "Epoch [37/100], Step [1370/1751], Loss: 1.2177\n",
      "Epoch [37/100], Step [1380/1751], Loss: 1.2854\n",
      "Epoch [37/100], Step [1390/1751], Loss: 1.1319\n",
      "Epoch [37/100], Step [1400/1751], Loss: 1.4100\n",
      "Epoch [37/100], Step [1410/1751], Loss: 1.0319\n",
      "Epoch [37/100], Step [1420/1751], Loss: 1.1699\n",
      "Epoch [37/100], Step [1430/1751], Loss: 1.3008\n",
      "Epoch [37/100], Step [1440/1751], Loss: 1.2805\n",
      "Epoch [37/100], Step [1450/1751], Loss: 1.2786\n",
      "Epoch [37/100], Step [1460/1751], Loss: 1.2480\n",
      "Epoch [37/100], Step [1470/1751], Loss: 1.1840\n",
      "Epoch [37/100], Step [1480/1751], Loss: 1.1912\n",
      "Epoch [37/100], Step [1490/1751], Loss: 1.2046\n",
      "Epoch [37/100], Step [1500/1751], Loss: 1.3625\n",
      "Epoch [37/100], Step [1510/1751], Loss: 1.2148\n",
      "Epoch [37/100], Step [1520/1751], Loss: 1.3562\n",
      "Epoch [37/100], Step [1530/1751], Loss: 1.0641\n",
      "Epoch [37/100], Step [1540/1751], Loss: 1.2243\n",
      "Epoch [37/100], Step [1550/1751], Loss: 1.2510\n",
      "Epoch [37/100], Step [1560/1751], Loss: 1.1747\n",
      "Epoch [37/100], Step [1570/1751], Loss: 1.2562\n",
      "Epoch [37/100], Step [1580/1751], Loss: 1.1624\n",
      "Epoch [37/100], Step [1590/1751], Loss: 1.1515\n",
      "Epoch [37/100], Step [1600/1751], Loss: 1.2915\n",
      "Epoch [37/100], Step [1610/1751], Loss: 1.2400\n",
      "Epoch [37/100], Step [1620/1751], Loss: 1.0855\n",
      "Epoch [37/100], Step [1630/1751], Loss: 1.2707\n",
      "Epoch [37/100], Step [1640/1751], Loss: 1.3240\n",
      "Epoch [37/100], Step [1650/1751], Loss: 1.3885\n",
      "Epoch [37/100], Step [1660/1751], Loss: 1.2796\n",
      "Epoch [37/100], Step [1670/1751], Loss: 1.4400\n",
      "Epoch [37/100], Step [1680/1751], Loss: 1.3923\n",
      "Epoch [37/100], Step [1690/1751], Loss: 1.3417\n",
      "Epoch [37/100], Step [1700/1751], Loss: 1.3121\n",
      "Epoch [37/100], Step [1710/1751], Loss: 1.2237\n",
      "Epoch [37/100], Step [1720/1751], Loss: 1.2213\n",
      "Epoch [37/100], Step [1730/1751], Loss: 1.3423\n",
      "Epoch [37/100], Step [1740/1751], Loss: 1.2041\n",
      "Epoch [37/100], Step [1750/1751], Loss: 1.4022\n",
      "Epoch [37/100], Average Loss: 1.2270, Time: 1649.4249s\n",
      "Epoch [38/100], Step [10/1751], Loss: 1.1940\n",
      "Epoch [38/100], Step [20/1751], Loss: 1.2845\n",
      "Epoch [38/100], Step [30/1751], Loss: 1.1346\n",
      "Epoch [38/100], Step [40/1751], Loss: 1.1431\n",
      "Epoch [38/100], Step [50/1751], Loss: 1.3874\n",
      "Epoch [38/100], Step [60/1751], Loss: 1.1405\n",
      "Epoch [38/100], Step [70/1751], Loss: 1.1981\n",
      "Epoch [38/100], Step [80/1751], Loss: 1.2904\n",
      "Epoch [38/100], Step [90/1751], Loss: 1.1262\n",
      "Epoch [38/100], Step [100/1751], Loss: 1.1521\n",
      "Epoch [38/100], Step [110/1751], Loss: 1.1764\n",
      "Epoch [38/100], Step [120/1751], Loss: 1.2067\n",
      "Epoch [38/100], Step [130/1751], Loss: 1.1849\n",
      "Epoch [38/100], Step [140/1751], Loss: 1.3559\n",
      "Epoch [38/100], Step [150/1751], Loss: 0.9987\n",
      "Epoch [38/100], Step [160/1751], Loss: 1.2055\n",
      "Epoch [38/100], Step [170/1751], Loss: 1.1099\n",
      "Epoch [38/100], Step [180/1751], Loss: 1.3163\n",
      "Epoch [38/100], Step [190/1751], Loss: 1.0945\n",
      "Epoch [38/100], Step [200/1751], Loss: 1.2417\n",
      "Epoch [38/100], Step [210/1751], Loss: 1.2234\n",
      "Epoch [38/100], Step [220/1751], Loss: 1.1205\n",
      "Epoch [38/100], Step [230/1751], Loss: 1.0550\n",
      "Epoch [38/100], Step [240/1751], Loss: 1.1286\n",
      "Epoch [38/100], Step [250/1751], Loss: 1.2112\n",
      "Epoch [38/100], Step [260/1751], Loss: 1.4045\n",
      "Epoch [38/100], Step [270/1751], Loss: 1.0840\n",
      "Epoch [38/100], Step [280/1751], Loss: 1.1684\n",
      "Epoch [38/100], Step [290/1751], Loss: 1.2683\n",
      "Epoch [38/100], Step [300/1751], Loss: 1.1768\n",
      "Epoch [38/100], Step [310/1751], Loss: 1.3108\n",
      "Epoch [38/100], Step [320/1751], Loss: 1.4482\n",
      "Epoch [38/100], Step [330/1751], Loss: 1.2159\n",
      "Epoch [38/100], Step [340/1751], Loss: 1.0668\n",
      "Epoch [38/100], Step [350/1751], Loss: 1.3142\n",
      "Epoch [38/100], Step [360/1751], Loss: 1.1475\n",
      "Epoch [38/100], Step [370/1751], Loss: 1.2520\n",
      "Epoch [38/100], Step [380/1751], Loss: 1.3381\n",
      "Epoch [38/100], Step [390/1751], Loss: 1.0537\n",
      "Epoch [38/100], Step [400/1751], Loss: 1.3850\n",
      "Epoch [38/100], Step [410/1751], Loss: 1.1781\n",
      "Epoch [38/100], Step [420/1751], Loss: 1.2166\n",
      "Epoch [38/100], Step [430/1751], Loss: 1.2124\n",
      "Epoch [38/100], Step [440/1751], Loss: 1.3248\n",
      "Epoch [38/100], Step [450/1751], Loss: 1.1477\n",
      "Epoch [38/100], Step [460/1751], Loss: 1.1068\n",
      "Epoch [38/100], Step [470/1751], Loss: 1.1279\n",
      "Epoch [38/100], Step [480/1751], Loss: 1.2156\n",
      "Epoch [38/100], Step [490/1751], Loss: 1.1303\n",
      "Epoch [38/100], Step [500/1751], Loss: 1.2798\n",
      "Epoch [38/100], Step [510/1751], Loss: 1.1675\n",
      "Epoch [38/100], Step [520/1751], Loss: 1.2500\n",
      "Epoch [38/100], Step [530/1751], Loss: 1.2020\n",
      "Epoch [38/100], Step [540/1751], Loss: 1.3539\n",
      "Epoch [38/100], Step [550/1751], Loss: 1.1509\n",
      "Epoch [38/100], Step [560/1751], Loss: 1.1895\n",
      "Epoch [38/100], Step [570/1751], Loss: 1.3083\n",
      "Epoch [38/100], Step [580/1751], Loss: 1.2723\n",
      "Epoch [38/100], Step [590/1751], Loss: 1.0883\n",
      "Epoch [38/100], Step [600/1751], Loss: 1.1351\n",
      "Epoch [38/100], Step [610/1751], Loss: 1.2527\n",
      "Epoch [38/100], Step [620/1751], Loss: 1.2779\n",
      "Epoch [38/100], Step [630/1751], Loss: 1.2616\n",
      "Epoch [38/100], Step [640/1751], Loss: 1.4071\n",
      "Epoch [38/100], Step [650/1751], Loss: 1.3054\n",
      "Epoch [38/100], Step [660/1751], Loss: 1.1563\n",
      "Epoch [38/100], Step [670/1751], Loss: 1.2015\n",
      "Epoch [38/100], Step [680/1751], Loss: 1.1948\n",
      "Epoch [38/100], Step [690/1751], Loss: 1.2934\n",
      "Epoch [38/100], Step [700/1751], Loss: 1.1525\n",
      "Epoch [38/100], Step [710/1751], Loss: 1.2663\n",
      "Epoch [38/100], Step [720/1751], Loss: 1.2138\n",
      "Epoch [38/100], Step [730/1751], Loss: 1.1307\n",
      "Epoch [38/100], Step [740/1751], Loss: 1.2882\n",
      "Epoch [38/100], Step [750/1751], Loss: 1.1853\n",
      "Epoch [38/100], Step [760/1751], Loss: 1.0861\n",
      "Epoch [38/100], Step [770/1751], Loss: 1.1981\n",
      "Epoch [38/100], Step [780/1751], Loss: 1.1875\n",
      "Epoch [38/100], Step [790/1751], Loss: 1.2727\n",
      "Epoch [38/100], Step [800/1751], Loss: 1.1431\n",
      "Epoch [38/100], Step [810/1751], Loss: 1.2482\n",
      "Epoch [38/100], Step [820/1751], Loss: 1.1341\n",
      "Epoch [38/100], Step [830/1751], Loss: 1.2746\n",
      "Epoch [38/100], Step [840/1751], Loss: 1.1636\n",
      "Epoch [38/100], Step [850/1751], Loss: 1.1881\n",
      "Epoch [38/100], Step [860/1751], Loss: 1.2487\n",
      "Epoch [38/100], Step [870/1751], Loss: 1.2994\n",
      "Epoch [38/100], Step [880/1751], Loss: 1.3204\n",
      "Epoch [38/100], Step [890/1751], Loss: 1.3116\n",
      "Epoch [38/100], Step [900/1751], Loss: 1.1523\n",
      "Epoch [38/100], Step [910/1751], Loss: 1.1818\n",
      "Epoch [38/100], Step [920/1751], Loss: 1.1569\n",
      "Epoch [38/100], Step [930/1751], Loss: 1.2089\n",
      "Epoch [38/100], Step [940/1751], Loss: 1.2015\n",
      "Epoch [38/100], Step [950/1751], Loss: 1.3202\n",
      "Epoch [38/100], Step [960/1751], Loss: 1.4033\n",
      "Epoch [38/100], Step [970/1751], Loss: 1.3053\n",
      "Epoch [38/100], Step [980/1751], Loss: 1.2380\n",
      "Epoch [38/100], Step [990/1751], Loss: 1.1979\n",
      "Epoch [38/100], Step [1000/1751], Loss: 1.1354\n",
      "Epoch [38/100], Step [1010/1751], Loss: 1.1923\n",
      "Epoch [38/100], Step [1020/1751], Loss: 1.4254\n",
      "Epoch [38/100], Step [1030/1751], Loss: 1.2997\n",
      "Epoch [38/100], Step [1040/1751], Loss: 1.2337\n",
      "Epoch [38/100], Step [1050/1751], Loss: 1.1023\n",
      "Epoch [38/100], Step [1060/1751], Loss: 1.2684\n",
      "Epoch [38/100], Step [1070/1751], Loss: 1.3475\n",
      "Epoch [38/100], Step [1080/1751], Loss: 1.2242\n",
      "Epoch [38/100], Step [1090/1751], Loss: 1.1834\n",
      "Epoch [38/100], Step [1100/1751], Loss: 1.3509\n",
      "Epoch [38/100], Step [1110/1751], Loss: 1.1520\n",
      "Epoch [38/100], Step [1120/1751], Loss: 1.2541\n",
      "Epoch [38/100], Step [1130/1751], Loss: 1.2066\n",
      "Epoch [38/100], Step [1140/1751], Loss: 1.2642\n",
      "Epoch [38/100], Step [1150/1751], Loss: 1.1166\n",
      "Epoch [38/100], Step [1160/1751], Loss: 1.0459\n",
      "Epoch [38/100], Step [1170/1751], Loss: 1.3048\n",
      "Epoch [38/100], Step [1180/1751], Loss: 1.1199\n",
      "Epoch [38/100], Step [1190/1751], Loss: 1.2468\n",
      "Epoch [38/100], Step [1200/1751], Loss: 1.2530\n",
      "Epoch [38/100], Step [1210/1751], Loss: 1.0816\n",
      "Epoch [38/100], Step [1220/1751], Loss: 1.2178\n",
      "Epoch [38/100], Step [1230/1751], Loss: 1.0580\n",
      "Epoch [38/100], Step [1240/1751], Loss: 1.2530\n",
      "Epoch [38/100], Step [1250/1751], Loss: 1.2504\n",
      "Epoch [38/100], Step [1260/1751], Loss: 1.2386\n",
      "Epoch [38/100], Step [1270/1751], Loss: 1.1699\n",
      "Epoch [38/100], Step [1280/1751], Loss: 1.2036\n",
      "Epoch [38/100], Step [1290/1751], Loss: 1.1436\n",
      "Epoch [38/100], Step [1300/1751], Loss: 1.1755\n",
      "Epoch [38/100], Step [1310/1751], Loss: 1.1736\n",
      "Epoch [38/100], Step [1320/1751], Loss: 1.1947\n",
      "Epoch [38/100], Step [1330/1751], Loss: 1.1668\n",
      "Epoch [38/100], Step [1340/1751], Loss: 1.3826\n",
      "Epoch [38/100], Step [1350/1751], Loss: 1.3177\n",
      "Epoch [38/100], Step [1360/1751], Loss: 1.2829\n",
      "Epoch [38/100], Step [1370/1751], Loss: 1.2117\n",
      "Epoch [38/100], Step [1380/1751], Loss: 1.3361\n",
      "Epoch [38/100], Step [1390/1751], Loss: 1.1987\n",
      "Epoch [38/100], Step [1400/1751], Loss: 1.1905\n",
      "Epoch [38/100], Step [1410/1751], Loss: 1.1835\n",
      "Epoch [38/100], Step [1420/1751], Loss: 1.1582\n",
      "Epoch [38/100], Step [1430/1751], Loss: 1.1733\n",
      "Epoch [38/100], Step [1440/1751], Loss: 1.2183\n",
      "Epoch [38/100], Step [1450/1751], Loss: 1.2085\n",
      "Epoch [38/100], Step [1460/1751], Loss: 1.2362\n",
      "Epoch [38/100], Step [1470/1751], Loss: 1.2733\n",
      "Epoch [38/100], Step [1480/1751], Loss: 1.3012\n",
      "Epoch [38/100], Step [1490/1751], Loss: 1.2410\n",
      "Epoch [38/100], Step [1500/1751], Loss: 1.2511\n",
      "Epoch [38/100], Step [1510/1751], Loss: 1.2126\n",
      "Epoch [38/100], Step [1520/1751], Loss: 1.1514\n",
      "Epoch [38/100], Step [1530/1751], Loss: 1.4217\n",
      "Epoch [38/100], Step [1540/1751], Loss: 1.3908\n",
      "Epoch [38/100], Step [1550/1751], Loss: 1.3492\n",
      "Epoch [38/100], Step [1560/1751], Loss: 1.1703\n",
      "Epoch [38/100], Step [1570/1751], Loss: 1.4027\n",
      "Epoch [38/100], Step [1580/1751], Loss: 1.3884\n",
      "Epoch [38/100], Step [1590/1751], Loss: 1.3116\n",
      "Epoch [38/100], Step [1600/1751], Loss: 1.2331\n",
      "Epoch [38/100], Step [1610/1751], Loss: 1.1872\n",
      "Epoch [38/100], Step [1620/1751], Loss: 1.1238\n",
      "Epoch [38/100], Step [1630/1751], Loss: 1.2243\n",
      "Epoch [38/100], Step [1640/1751], Loss: 1.3055\n",
      "Epoch [38/100], Step [1650/1751], Loss: 1.2020\n",
      "Epoch [38/100], Step [1660/1751], Loss: 1.1770\n",
      "Epoch [38/100], Step [1670/1751], Loss: 1.2645\n",
      "Epoch [38/100], Step [1680/1751], Loss: 1.1788\n",
      "Epoch [38/100], Step [1690/1751], Loss: 1.2298\n",
      "Epoch [38/100], Step [1700/1751], Loss: 1.0342\n",
      "Epoch [38/100], Step [1710/1751], Loss: 1.3469\n",
      "Epoch [38/100], Step [1720/1751], Loss: 1.1836\n",
      "Epoch [38/100], Step [1730/1751], Loss: 1.1613\n",
      "Epoch [38/100], Step [1740/1751], Loss: 1.1004\n",
      "Epoch [38/100], Step [1750/1751], Loss: 1.1307\n",
      "Epoch [38/100], Average Loss: 1.2249, Time: 1650.0911s\n",
      "Epoch [39/100], Step [10/1751], Loss: 1.2669\n",
      "Epoch [39/100], Step [20/1751], Loss: 1.0912\n",
      "Epoch [39/100], Step [30/1751], Loss: 1.2772\n",
      "Epoch [39/100], Step [40/1751], Loss: 1.3245\n",
      "Epoch [39/100], Step [50/1751], Loss: 1.1876\n",
      "Epoch [39/100], Step [60/1751], Loss: 1.2849\n",
      "Epoch [39/100], Step [70/1751], Loss: 1.0891\n",
      "Epoch [39/100], Step [80/1751], Loss: 1.1989\n",
      "Epoch [39/100], Step [90/1751], Loss: 1.1294\n",
      "Epoch [39/100], Step [100/1751], Loss: 1.1543\n",
      "Epoch [39/100], Step [110/1751], Loss: 1.1340\n",
      "Epoch [39/100], Step [120/1751], Loss: 1.1684\n",
      "Epoch [39/100], Step [130/1751], Loss: 1.1815\n",
      "Epoch [39/100], Step [140/1751], Loss: 1.2675\n",
      "Epoch [39/100], Step [150/1751], Loss: 1.1200\n",
      "Epoch [39/100], Step [160/1751], Loss: 1.1836\n",
      "Epoch [39/100], Step [170/1751], Loss: 1.1150\n",
      "Epoch [39/100], Step [180/1751], Loss: 1.1742\n",
      "Epoch [39/100], Step [190/1751], Loss: 1.2927\n",
      "Epoch [39/100], Step [200/1751], Loss: 1.2931\n",
      "Epoch [39/100], Step [210/1751], Loss: 1.2196\n",
      "Epoch [39/100], Step [220/1751], Loss: 1.1913\n",
      "Epoch [39/100], Step [230/1751], Loss: 1.2156\n",
      "Epoch [39/100], Step [240/1751], Loss: 1.1702\n",
      "Epoch [39/100], Step [250/1751], Loss: 1.4336\n",
      "Epoch [39/100], Step [260/1751], Loss: 1.2727\n",
      "Epoch [39/100], Step [270/1751], Loss: 1.1136\n",
      "Epoch [39/100], Step [280/1751], Loss: 1.2417\n",
      "Epoch [39/100], Step [290/1751], Loss: 1.2604\n",
      "Epoch [39/100], Step [300/1751], Loss: 1.0775\n",
      "Epoch [39/100], Step [310/1751], Loss: 1.3253\n",
      "Epoch [39/100], Step [320/1751], Loss: 1.3781\n",
      "Epoch [39/100], Step [330/1751], Loss: 1.1216\n",
      "Epoch [39/100], Step [340/1751], Loss: 1.3536\n",
      "Epoch [39/100], Step [350/1751], Loss: 1.2550\n",
      "Epoch [39/100], Step [360/1751], Loss: 1.1560\n",
      "Epoch [39/100], Step [370/1751], Loss: 1.0812\n",
      "Epoch [39/100], Step [380/1751], Loss: 1.3562\n",
      "Epoch [39/100], Step [390/1751], Loss: 1.2308\n",
      "Epoch [39/100], Step [400/1751], Loss: 1.0676\n",
      "Epoch [39/100], Step [410/1751], Loss: 1.3480\n",
      "Epoch [39/100], Step [420/1751], Loss: 1.2191\n",
      "Epoch [39/100], Step [430/1751], Loss: 1.3233\n",
      "Epoch [39/100], Step [440/1751], Loss: 1.3322\n",
      "Epoch [39/100], Step [450/1751], Loss: 1.2633\n",
      "Epoch [39/100], Step [460/1751], Loss: 1.2036\n",
      "Epoch [39/100], Step [470/1751], Loss: 1.0551\n",
      "Epoch [39/100], Step [480/1751], Loss: 1.1474\n",
      "Epoch [39/100], Step [490/1751], Loss: 1.3583\n",
      "Epoch [39/100], Step [500/1751], Loss: 1.1857\n",
      "Epoch [39/100], Step [510/1751], Loss: 1.2667\n",
      "Epoch [39/100], Step [520/1751], Loss: 1.2401\n",
      "Epoch [39/100], Step [530/1751], Loss: 1.2636\n",
      "Epoch [39/100], Step [540/1751], Loss: 1.2692\n",
      "Epoch [39/100], Step [550/1751], Loss: 1.1843\n",
      "Epoch [39/100], Step [560/1751], Loss: 1.2279\n",
      "Epoch [39/100], Step [570/1751], Loss: 1.3622\n",
      "Epoch [39/100], Step [580/1751], Loss: 1.3822\n",
      "Epoch [39/100], Step [590/1751], Loss: 1.2480\n",
      "Epoch [39/100], Step [600/1751], Loss: 1.3187\n",
      "Epoch [39/100], Step [610/1751], Loss: 1.3929\n",
      "Epoch [39/100], Step [620/1751], Loss: 1.2209\n",
      "Epoch [39/100], Step [630/1751], Loss: 1.2370\n",
      "Epoch [39/100], Step [640/1751], Loss: 1.2391\n",
      "Epoch [39/100], Step [650/1751], Loss: 1.2503\n",
      "Epoch [39/100], Step [660/1751], Loss: 1.3726\n",
      "Epoch [39/100], Step [670/1751], Loss: 1.1980\n",
      "Epoch [39/100], Step [680/1751], Loss: 1.2710\n",
      "Epoch [39/100], Step [690/1751], Loss: 1.0305\n",
      "Epoch [39/100], Step [700/1751], Loss: 1.2069\n",
      "Epoch [39/100], Step [710/1751], Loss: 1.2064\n",
      "Epoch [39/100], Step [720/1751], Loss: 1.1799\n",
      "Epoch [39/100], Step [730/1751], Loss: 1.3423\n",
      "Epoch [39/100], Step [740/1751], Loss: 1.1917\n",
      "Epoch [39/100], Step [750/1751], Loss: 1.1044\n",
      "Epoch [39/100], Step [760/1751], Loss: 1.2125\n",
      "Epoch [39/100], Step [770/1751], Loss: 1.2689\n",
      "Epoch [39/100], Step [780/1751], Loss: 1.1649\n",
      "Epoch [39/100], Step [790/1751], Loss: 1.2863\n",
      "Epoch [39/100], Step [800/1751], Loss: 1.3492\n",
      "Epoch [39/100], Step [810/1751], Loss: 1.2708\n",
      "Epoch [39/100], Step [820/1751], Loss: 1.1207\n",
      "Epoch [39/100], Step [830/1751], Loss: 1.1424\n",
      "Epoch [39/100], Step [840/1751], Loss: 1.2538\n",
      "Epoch [39/100], Step [850/1751], Loss: 1.3080\n",
      "Epoch [39/100], Step [860/1751], Loss: 1.0517\n",
      "Epoch [39/100], Step [870/1751], Loss: 1.1567\n",
      "Epoch [39/100], Step [880/1751], Loss: 1.1511\n",
      "Epoch [39/100], Step [890/1751], Loss: 1.2561\n",
      "Epoch [39/100], Step [900/1751], Loss: 1.2765\n",
      "Epoch [39/100], Step [910/1751], Loss: 1.1580\n",
      "Epoch [39/100], Step [920/1751], Loss: 1.2094\n",
      "Epoch [39/100], Step [930/1751], Loss: 1.2381\n",
      "Epoch [39/100], Step [940/1751], Loss: 1.3130\n",
      "Epoch [39/100], Step [950/1751], Loss: 1.2013\n",
      "Epoch [39/100], Step [960/1751], Loss: 1.2357\n",
      "Epoch [39/100], Step [970/1751], Loss: 1.2310\n",
      "Epoch [39/100], Step [980/1751], Loss: 1.2085\n",
      "Epoch [39/100], Step [990/1751], Loss: 1.2733\n",
      "Epoch [39/100], Step [1000/1751], Loss: 1.2316\n",
      "Epoch [39/100], Step [1010/1751], Loss: 1.2742\n",
      "Epoch [39/100], Step [1020/1751], Loss: 1.2968\n",
      "Epoch [39/100], Step [1030/1751], Loss: 1.3972\n",
      "Epoch [39/100], Step [1040/1751], Loss: 1.1799\n",
      "Epoch [39/100], Step [1050/1751], Loss: 1.1654\n",
      "Epoch [39/100], Step [1060/1751], Loss: 1.1826\n",
      "Epoch [39/100], Step [1070/1751], Loss: 1.3497\n",
      "Epoch [39/100], Step [1080/1751], Loss: 1.2625\n",
      "Epoch [39/100], Step [1090/1751], Loss: 1.2142\n",
      "Epoch [39/100], Step [1100/1751], Loss: 1.2890\n",
      "Epoch [39/100], Step [1110/1751], Loss: 1.2595\n",
      "Epoch [39/100], Step [1120/1751], Loss: 1.1850\n",
      "Epoch [39/100], Step [1130/1751], Loss: 1.1762\n",
      "Epoch [39/100], Step [1140/1751], Loss: 1.2535\n",
      "Epoch [39/100], Step [1150/1751], Loss: 1.2176\n",
      "Epoch [39/100], Step [1160/1751], Loss: 1.3160\n",
      "Epoch [39/100], Step [1170/1751], Loss: 1.1130\n",
      "Epoch [39/100], Step [1180/1751], Loss: 1.3089\n",
      "Epoch [39/100], Step [1190/1751], Loss: 1.1658\n",
      "Epoch [39/100], Step [1200/1751], Loss: 1.2595\n",
      "Epoch [39/100], Step [1210/1751], Loss: 1.2332\n",
      "Epoch [39/100], Step [1220/1751], Loss: 1.2012\n",
      "Epoch [39/100], Step [1230/1751], Loss: 1.0505\n",
      "Epoch [39/100], Step [1240/1751], Loss: 1.0761\n",
      "Epoch [39/100], Step [1250/1751], Loss: 1.2116\n",
      "Epoch [39/100], Step [1260/1751], Loss: 1.3927\n",
      "Epoch [39/100], Step [1270/1751], Loss: 1.0843\n",
      "Epoch [39/100], Step [1280/1751], Loss: 1.1105\n",
      "Epoch [39/100], Step [1290/1751], Loss: 1.2136\n",
      "Epoch [39/100], Step [1300/1751], Loss: 1.1276\n",
      "Epoch [39/100], Step [1310/1751], Loss: 1.3574\n",
      "Epoch [39/100], Step [1320/1751], Loss: 1.3492\n",
      "Epoch [39/100], Step [1330/1751], Loss: 1.1836\n",
      "Epoch [39/100], Step [1340/1751], Loss: 1.3977\n",
      "Epoch [39/100], Step [1350/1751], Loss: 1.1401\n",
      "Epoch [39/100], Step [1360/1751], Loss: 1.2575\n",
      "Epoch [39/100], Step [1370/1751], Loss: 1.1656\n",
      "Epoch [39/100], Step [1380/1751], Loss: 1.2376\n",
      "Epoch [39/100], Step [1390/1751], Loss: 1.4510\n",
      "Epoch [39/100], Step [1400/1751], Loss: 1.2513\n",
      "Epoch [39/100], Step [1410/1751], Loss: 1.0931\n",
      "Epoch [39/100], Step [1420/1751], Loss: 1.2729\n",
      "Epoch [39/100], Step [1430/1751], Loss: 1.2676\n",
      "Epoch [39/100], Step [1440/1751], Loss: 1.1441\n",
      "Epoch [39/100], Step [1450/1751], Loss: 1.1410\n",
      "Epoch [39/100], Step [1460/1751], Loss: 1.2849\n",
      "Epoch [39/100], Step [1470/1751], Loss: 1.1796\n",
      "Epoch [39/100], Step [1480/1751], Loss: 1.2014\n",
      "Epoch [39/100], Step [1490/1751], Loss: 1.2084\n",
      "Epoch [39/100], Step [1500/1751], Loss: 1.2331\n",
      "Epoch [39/100], Step [1510/1751], Loss: 1.2745\n",
      "Epoch [39/100], Step [1520/1751], Loss: 1.2770\n",
      "Epoch [39/100], Step [1530/1751], Loss: 1.0739\n",
      "Epoch [39/100], Step [1540/1751], Loss: 1.2450\n",
      "Epoch [39/100], Step [1550/1751], Loss: 1.1359\n",
      "Epoch [39/100], Step [1560/1751], Loss: 1.2748\n",
      "Epoch [39/100], Step [1570/1751], Loss: 1.2215\n",
      "Epoch [39/100], Step [1580/1751], Loss: 1.3033\n",
      "Epoch [39/100], Step [1590/1751], Loss: 1.2636\n",
      "Epoch [39/100], Step [1600/1751], Loss: 1.0933\n",
      "Epoch [39/100], Step [1610/1751], Loss: 1.3616\n",
      "Epoch [39/100], Step [1620/1751], Loss: 1.4209\n",
      "Epoch [39/100], Step [1630/1751], Loss: 1.2484\n",
      "Epoch [39/100], Step [1640/1751], Loss: 1.1220\n",
      "Epoch [39/100], Step [1650/1751], Loss: 1.1292\n",
      "Epoch [39/100], Step [1660/1751], Loss: 1.1744\n",
      "Epoch [39/100], Step [1670/1751], Loss: 1.1660\n",
      "Epoch [39/100], Step [1680/1751], Loss: 1.1782\n",
      "Epoch [39/100], Step [1690/1751], Loss: 1.3236\n",
      "Epoch [39/100], Step [1700/1751], Loss: 1.2723\n",
      "Epoch [39/100], Step [1710/1751], Loss: 1.1800\n",
      "Epoch [39/100], Step [1720/1751], Loss: 1.3174\n",
      "Epoch [39/100], Step [1730/1751], Loss: 1.1949\n",
      "Epoch [39/100], Step [1740/1751], Loss: 1.2700\n",
      "Epoch [39/100], Step [1750/1751], Loss: 1.1683\n",
      "Epoch [39/100], Average Loss: 1.2241, Time: 1649.9929s\n",
      "Epoch [40/100], Step [10/1751], Loss: 1.2312\n",
      "Epoch [40/100], Step [20/1751], Loss: 1.3064\n",
      "Epoch [40/100], Step [30/1751], Loss: 1.1139\n",
      "Epoch [40/100], Step [40/1751], Loss: 1.1977\n",
      "Epoch [40/100], Step [50/1751], Loss: 1.2048\n",
      "Epoch [40/100], Step [60/1751], Loss: 1.1620\n",
      "Epoch [40/100], Step [70/1751], Loss: 1.4201\n",
      "Epoch [40/100], Step [80/1751], Loss: 1.2453\n",
      "Epoch [40/100], Step [90/1751], Loss: 1.1929\n",
      "Epoch [40/100], Step [100/1751], Loss: 1.2091\n",
      "Epoch [40/100], Step [110/1751], Loss: 1.1058\n",
      "Epoch [40/100], Step [120/1751], Loss: 1.1965\n",
      "Epoch [40/100], Step [130/1751], Loss: 1.3396\n",
      "Epoch [40/100], Step [140/1751], Loss: 1.3444\n",
      "Epoch [40/100], Step [150/1751], Loss: 1.1327\n",
      "Epoch [40/100], Step [160/1751], Loss: 1.2101\n",
      "Epoch [40/100], Step [170/1751], Loss: 1.1120\n",
      "Epoch [40/100], Step [180/1751], Loss: 1.1400\n",
      "Epoch [40/100], Step [190/1751], Loss: 1.1246\n",
      "Epoch [40/100], Step [200/1751], Loss: 1.3725\n",
      "Epoch [40/100], Step [210/1751], Loss: 1.0620\n",
      "Epoch [40/100], Step [220/1751], Loss: 1.2373\n",
      "Epoch [40/100], Step [230/1751], Loss: 1.2050\n",
      "Epoch [40/100], Step [240/1751], Loss: 1.3175\n",
      "Epoch [40/100], Step [250/1751], Loss: 1.2442\n",
      "Epoch [40/100], Step [260/1751], Loss: 1.0875\n",
      "Epoch [40/100], Step [270/1751], Loss: 1.3019\n",
      "Epoch [40/100], Step [280/1751], Loss: 1.2882\n",
      "Epoch [40/100], Step [290/1751], Loss: 1.2989\n",
      "Epoch [40/100], Step [300/1751], Loss: 1.2800\n",
      "Epoch [40/100], Step [310/1751], Loss: 1.0349\n",
      "Epoch [40/100], Step [320/1751], Loss: 1.2454\n",
      "Epoch [40/100], Step [330/1751], Loss: 1.2825\n",
      "Epoch [40/100], Step [340/1751], Loss: 1.1861\n",
      "Epoch [40/100], Step [350/1751], Loss: 1.2154\n",
      "Epoch [40/100], Step [360/1751], Loss: 1.2087\n",
      "Epoch [40/100], Step [370/1751], Loss: 1.1111\n",
      "Epoch [40/100], Step [380/1751], Loss: 1.1869\n",
      "Epoch [40/100], Step [390/1751], Loss: 1.1852\n",
      "Epoch [40/100], Step [400/1751], Loss: 1.1207\n",
      "Epoch [40/100], Step [410/1751], Loss: 1.2348\n",
      "Epoch [40/100], Step [420/1751], Loss: 1.4239\n",
      "Epoch [40/100], Step [430/1751], Loss: 1.0800\n",
      "Epoch [40/100], Step [440/1751], Loss: 1.4481\n",
      "Epoch [40/100], Step [450/1751], Loss: 1.2171\n",
      "Epoch [40/100], Step [460/1751], Loss: 1.2911\n",
      "Epoch [40/100], Step [470/1751], Loss: 1.2531\n",
      "Epoch [40/100], Step [480/1751], Loss: 1.1791\n",
      "Epoch [40/100], Step [490/1751], Loss: 1.1222\n",
      "Epoch [40/100], Step [500/1751], Loss: 1.1964\n",
      "Epoch [40/100], Step [510/1751], Loss: 1.2611\n",
      "Epoch [40/100], Step [520/1751], Loss: 1.1533\n",
      "Epoch [40/100], Step [530/1751], Loss: 1.0999\n",
      "Epoch [40/100], Step [540/1751], Loss: 1.2293\n",
      "Epoch [40/100], Step [550/1751], Loss: 1.3312\n",
      "Epoch [40/100], Step [560/1751], Loss: 1.2005\n",
      "Epoch [40/100], Step [570/1751], Loss: 1.3296\n",
      "Epoch [40/100], Step [580/1751], Loss: 1.2565\n",
      "Epoch [40/100], Step [590/1751], Loss: 1.1255\n",
      "Epoch [40/100], Step [600/1751], Loss: 1.1538\n",
      "Epoch [40/100], Step [610/1751], Loss: 1.1589\n",
      "Epoch [40/100], Step [620/1751], Loss: 1.2779\n",
      "Epoch [40/100], Step [630/1751], Loss: 1.2704\n",
      "Epoch [40/100], Step [640/1751], Loss: 1.1623\n",
      "Epoch [40/100], Step [650/1751], Loss: 1.1815\n",
      "Epoch [40/100], Step [660/1751], Loss: 1.1469\n",
      "Epoch [40/100], Step [670/1751], Loss: 1.1946\n",
      "Epoch [40/100], Step [680/1751], Loss: 1.0693\n",
      "Epoch [40/100], Step [690/1751], Loss: 1.1140\n",
      "Epoch [40/100], Step [700/1751], Loss: 1.2812\n",
      "Epoch [40/100], Step [710/1751], Loss: 1.1017\n",
      "Epoch [40/100], Step [720/1751], Loss: 1.1600\n",
      "Epoch [40/100], Step [730/1751], Loss: 1.0512\n",
      "Epoch [40/100], Step [740/1751], Loss: 0.9987\n",
      "Epoch [40/100], Step [750/1751], Loss: 1.2804\n",
      "Epoch [40/100], Step [760/1751], Loss: 1.1365\n",
      "Epoch [40/100], Step [770/1751], Loss: 1.1154\n",
      "Epoch [40/100], Step [780/1751], Loss: 1.1636\n",
      "Epoch [40/100], Step [790/1751], Loss: 1.2737\n",
      "Epoch [40/100], Step [800/1751], Loss: 1.1154\n",
      "Epoch [40/100], Step [810/1751], Loss: 1.1905\n",
      "Epoch [40/100], Step [820/1751], Loss: 1.2197\n",
      "Epoch [40/100], Step [830/1751], Loss: 1.2742\n",
      "Epoch [40/100], Step [840/1751], Loss: 1.3969\n",
      "Epoch [40/100], Step [850/1751], Loss: 1.4396\n",
      "Epoch [40/100], Step [860/1751], Loss: 1.1305\n",
      "Epoch [40/100], Step [870/1751], Loss: 1.2073\n",
      "Epoch [40/100], Step [880/1751], Loss: 1.3957\n",
      "Epoch [40/100], Step [890/1751], Loss: 1.3025\n",
      "Epoch [40/100], Step [900/1751], Loss: 1.3357\n",
      "Epoch [40/100], Step [910/1751], Loss: 1.1641\n",
      "Epoch [40/100], Step [920/1751], Loss: 1.1577\n",
      "Epoch [40/100], Step [930/1751], Loss: 1.3519\n",
      "Epoch [40/100], Step [940/1751], Loss: 1.2532\n",
      "Epoch [40/100], Step [950/1751], Loss: 1.3681\n",
      "Epoch [40/100], Step [960/1751], Loss: 1.1101\n",
      "Epoch [40/100], Step [970/1751], Loss: 0.9799\n",
      "Epoch [40/100], Step [980/1751], Loss: 1.0268\n",
      "Epoch [40/100], Step [990/1751], Loss: 1.1741\n",
      "Epoch [40/100], Step [1000/1751], Loss: 1.2308\n",
      "Epoch [40/100], Step [1010/1751], Loss: 1.1985\n",
      "Epoch [40/100], Step [1020/1751], Loss: 1.2504\n",
      "Epoch [40/100], Step [1030/1751], Loss: 1.3534\n",
      "Epoch [40/100], Step [1040/1751], Loss: 1.1072\n",
      "Epoch [40/100], Step [1050/1751], Loss: 1.2222\n",
      "Epoch [40/100], Step [1060/1751], Loss: 1.2652\n",
      "Epoch [40/100], Step [1070/1751], Loss: 1.2001\n",
      "Epoch [40/100], Step [1080/1751], Loss: 1.2707\n",
      "Epoch [40/100], Step [1090/1751], Loss: 1.1687\n",
      "Epoch [40/100], Step [1100/1751], Loss: 1.2177\n",
      "Epoch [40/100], Step [1110/1751], Loss: 1.1925\n",
      "Epoch [40/100], Step [1120/1751], Loss: 1.0740\n",
      "Epoch [40/100], Step [1130/1751], Loss: 1.2309\n",
      "Epoch [40/100], Step [1140/1751], Loss: 1.1904\n",
      "Epoch [40/100], Step [1150/1751], Loss: 1.1379\n",
      "Epoch [40/100], Step [1160/1751], Loss: 1.2198\n",
      "Epoch [40/100], Step [1170/1751], Loss: 1.1973\n",
      "Epoch [40/100], Step [1180/1751], Loss: 1.2250\n",
      "Epoch [40/100], Step [1190/1751], Loss: 1.2034\n",
      "Epoch [40/100], Step [1200/1751], Loss: 1.2450\n",
      "Epoch [40/100], Step [1210/1751], Loss: 1.2815\n",
      "Epoch [40/100], Step [1220/1751], Loss: 1.1986\n",
      "Epoch [40/100], Step [1230/1751], Loss: 1.2448\n",
      "Epoch [40/100], Step [1240/1751], Loss: 1.2710\n",
      "Epoch [40/100], Step [1250/1751], Loss: 1.3008\n",
      "Epoch [40/100], Step [1260/1751], Loss: 1.2905\n",
      "Epoch [40/100], Step [1270/1751], Loss: 1.3032\n",
      "Epoch [40/100], Step [1280/1751], Loss: 1.3623\n",
      "Epoch [40/100], Step [1290/1751], Loss: 1.1282\n",
      "Epoch [40/100], Step [1300/1751], Loss: 1.2041\n",
      "Epoch [40/100], Step [1310/1751], Loss: 1.2174\n",
      "Epoch [40/100], Step [1320/1751], Loss: 1.4272\n",
      "Epoch [40/100], Step [1330/1751], Loss: 1.1439\n",
      "Epoch [40/100], Step [1340/1751], Loss: 1.0131\n",
      "Epoch [40/100], Step [1350/1751], Loss: 1.1071\n",
      "Epoch [40/100], Step [1360/1751], Loss: 1.1861\n",
      "Epoch [40/100], Step [1370/1751], Loss: 1.3030\n",
      "Epoch [40/100], Step [1380/1751], Loss: 1.1928\n",
      "Epoch [40/100], Step [1390/1751], Loss: 1.2583\n",
      "Epoch [40/100], Step [1400/1751], Loss: 1.4441\n",
      "Epoch [40/100], Step [1410/1751], Loss: 1.1678\n",
      "Epoch [40/100], Step [1420/1751], Loss: 1.2662\n",
      "Epoch [40/100], Step [1430/1751], Loss: 1.2678\n",
      "Epoch [40/100], Step [1440/1751], Loss: 1.2078\n",
      "Epoch [40/100], Step [1450/1751], Loss: 1.2749\n",
      "Epoch [40/100], Step [1460/1751], Loss: 1.3044\n",
      "Epoch [40/100], Step [1470/1751], Loss: 1.3104\n",
      "Epoch [40/100], Step [1480/1751], Loss: 1.3511\n",
      "Epoch [40/100], Step [1490/1751], Loss: 1.2420\n",
      "Epoch [40/100], Step [1500/1751], Loss: 1.2503\n",
      "Epoch [40/100], Step [1510/1751], Loss: 1.1958\n",
      "Epoch [40/100], Step [1520/1751], Loss: 1.2869\n",
      "Epoch [40/100], Step [1530/1751], Loss: 1.0532\n",
      "Epoch [40/100], Step [1540/1751], Loss: 1.2666\n",
      "Epoch [40/100], Step [1550/1751], Loss: 1.1055\n",
      "Epoch [40/100], Step [1560/1751], Loss: 1.1554\n",
      "Epoch [40/100], Step [1570/1751], Loss: 1.2375\n",
      "Epoch [40/100], Step [1580/1751], Loss: 1.3668\n",
      "Epoch [40/100], Step [1590/1751], Loss: 1.0882\n",
      "Epoch [40/100], Step [1600/1751], Loss: 1.3130\n",
      "Epoch [40/100], Step [1610/1751], Loss: 1.2964\n",
      "Epoch [40/100], Step [1620/1751], Loss: 1.2992\n",
      "Epoch [40/100], Step [1630/1751], Loss: 1.1068\n",
      "Epoch [40/100], Step [1640/1751], Loss: 1.1532\n",
      "Epoch [40/100], Step [1650/1751], Loss: 1.2861\n",
      "Epoch [40/100], Step [1660/1751], Loss: 1.2210\n",
      "Epoch [40/100], Step [1670/1751], Loss: 1.1801\n",
      "Epoch [40/100], Step [1680/1751], Loss: 1.2010\n",
      "Epoch [40/100], Step [1690/1751], Loss: 1.2101\n",
      "Epoch [40/100], Step [1700/1751], Loss: 1.2322\n",
      "Epoch [40/100], Step [1710/1751], Loss: 1.1001\n",
      "Epoch [40/100], Step [1720/1751], Loss: 1.1744\n",
      "Epoch [40/100], Step [1730/1751], Loss: 1.4195\n",
      "Epoch [40/100], Step [1740/1751], Loss: 1.1620\n",
      "Epoch [40/100], Step [1750/1751], Loss: 1.1264\n",
      "Epoch [40/100], Average Loss: 1.2224, Time: 1649.4044s\n",
      "Epoch [41/100], Step [10/1751], Loss: 1.0847\n",
      "Epoch [41/100], Step [20/1751], Loss: 1.3889\n",
      "Epoch [41/100], Step [30/1751], Loss: 1.3408\n",
      "Epoch [41/100], Step [40/1751], Loss: 1.3437\n",
      "Epoch [41/100], Step [50/1751], Loss: 1.3216\n",
      "Epoch [41/100], Step [60/1751], Loss: 1.1662\n",
      "Epoch [41/100], Step [70/1751], Loss: 1.3673\n",
      "Epoch [41/100], Step [80/1751], Loss: 1.3200\n",
      "Epoch [41/100], Step [90/1751], Loss: 1.1185\n",
      "Epoch [41/100], Step [100/1751], Loss: 1.2121\n",
      "Epoch [41/100], Step [110/1751], Loss: 1.1874\n",
      "Epoch [41/100], Step [120/1751], Loss: 1.3311\n",
      "Epoch [41/100], Step [130/1751], Loss: 1.1605\n",
      "Epoch [41/100], Step [140/1751], Loss: 1.1134\n",
      "Epoch [41/100], Step [150/1751], Loss: 1.1340\n",
      "Epoch [41/100], Step [160/1751], Loss: 1.1614\n",
      "Epoch [41/100], Step [170/1751], Loss: 1.3745\n",
      "Epoch [41/100], Step [180/1751], Loss: 1.1561\n",
      "Epoch [41/100], Step [190/1751], Loss: 1.2112\n",
      "Epoch [41/100], Step [200/1751], Loss: 1.1982\n",
      "Epoch [41/100], Step [210/1751], Loss: 1.1737\n",
      "Epoch [41/100], Step [220/1751], Loss: 1.1187\n",
      "Epoch [41/100], Step [230/1751], Loss: 1.2477\n",
      "Epoch [41/100], Step [240/1751], Loss: 1.1966\n",
      "Epoch [41/100], Step [250/1751], Loss: 1.0349\n",
      "Epoch [41/100], Step [260/1751], Loss: 1.1338\n",
      "Epoch [41/100], Step [270/1751], Loss: 1.2360\n",
      "Epoch [41/100], Step [280/1751], Loss: 1.1976\n",
      "Epoch [41/100], Step [290/1751], Loss: 1.1588\n",
      "Epoch [41/100], Step [300/1751], Loss: 1.4012\n",
      "Epoch [41/100], Step [310/1751], Loss: 1.0466\n",
      "Epoch [41/100], Step [320/1751], Loss: 1.1250\n",
      "Epoch [41/100], Step [330/1751], Loss: 1.1823\n",
      "Epoch [41/100], Step [340/1751], Loss: 1.3342\n",
      "Epoch [41/100], Step [350/1751], Loss: 1.2133\n",
      "Epoch [41/100], Step [360/1751], Loss: 1.1548\n",
      "Epoch [41/100], Step [370/1751], Loss: 1.3389\n",
      "Epoch [41/100], Step [380/1751], Loss: 1.0657\n",
      "Epoch [41/100], Step [390/1751], Loss: 1.2460\n",
      "Epoch [41/100], Step [400/1751], Loss: 1.1537\n",
      "Epoch [41/100], Step [410/1751], Loss: 1.2684\n",
      "Epoch [41/100], Step [420/1751], Loss: 1.2977\n",
      "Epoch [41/100], Step [430/1751], Loss: 1.1141\n",
      "Epoch [41/100], Step [440/1751], Loss: 1.2804\n",
      "Epoch [41/100], Step [450/1751], Loss: 1.2525\n",
      "Epoch [41/100], Step [460/1751], Loss: 1.3006\n",
      "Epoch [41/100], Step [470/1751], Loss: 1.3575\n",
      "Epoch [41/100], Step [480/1751], Loss: 1.3570\n",
      "Epoch [41/100], Step [490/1751], Loss: 1.1898\n",
      "Epoch [41/100], Step [500/1751], Loss: 1.2785\n",
      "Epoch [41/100], Step [510/1751], Loss: 1.2328\n",
      "Epoch [41/100], Step [520/1751], Loss: 1.2235\n",
      "Epoch [41/100], Step [530/1751], Loss: 1.2303\n",
      "Epoch [41/100], Step [540/1751], Loss: 1.1728\n",
      "Epoch [41/100], Step [550/1751], Loss: 1.1673\n",
      "Epoch [41/100], Step [560/1751], Loss: 1.1821\n",
      "Epoch [41/100], Step [570/1751], Loss: 1.1446\n",
      "Epoch [41/100], Step [580/1751], Loss: 1.2148\n",
      "Epoch [41/100], Step [590/1751], Loss: 1.2930\n",
      "Epoch [41/100], Step [600/1751], Loss: 1.0927\n",
      "Epoch [41/100], Step [610/1751], Loss: 1.1152\n",
      "Epoch [41/100], Step [620/1751], Loss: 1.3087\n",
      "Epoch [41/100], Step [630/1751], Loss: 1.2274\n",
      "Epoch [41/100], Step [640/1751], Loss: 1.1308\n",
      "Epoch [41/100], Step [650/1751], Loss: 1.1329\n",
      "Epoch [41/100], Step [660/1751], Loss: 1.2626\n",
      "Epoch [41/100], Step [670/1751], Loss: 1.3318\n",
      "Epoch [41/100], Step [680/1751], Loss: 1.1923\n",
      "Epoch [41/100], Step [690/1751], Loss: 1.2334\n",
      "Epoch [41/100], Step [700/1751], Loss: 1.3358\n",
      "Epoch [41/100], Step [710/1751], Loss: 1.2232\n",
      "Epoch [41/100], Step [720/1751], Loss: 1.2141\n",
      "Epoch [41/100], Step [730/1751], Loss: 1.2870\n",
      "Epoch [41/100], Step [740/1751], Loss: 1.3479\n",
      "Epoch [41/100], Step [750/1751], Loss: 1.2275\n",
      "Epoch [41/100], Step [760/1751], Loss: 1.2199\n",
      "Epoch [41/100], Step [770/1751], Loss: 1.2017\n",
      "Epoch [41/100], Step [780/1751], Loss: 1.2518\n",
      "Epoch [41/100], Step [790/1751], Loss: 1.2731\n",
      "Epoch [41/100], Step [800/1751], Loss: 1.1893\n",
      "Epoch [41/100], Step [810/1751], Loss: 1.3462\n",
      "Epoch [41/100], Step [820/1751], Loss: 1.2459\n",
      "Epoch [41/100], Step [830/1751], Loss: 1.3396\n",
      "Epoch [41/100], Step [840/1751], Loss: 1.3717\n",
      "Epoch [41/100], Step [850/1751], Loss: 1.1007\n",
      "Epoch [41/100], Step [860/1751], Loss: 1.2891\n",
      "Epoch [41/100], Step [870/1751], Loss: 1.0558\n",
      "Epoch [41/100], Step [880/1751], Loss: 1.1332\n",
      "Epoch [41/100], Step [890/1751], Loss: 1.1535\n",
      "Epoch [41/100], Step [900/1751], Loss: 1.0476\n",
      "Epoch [41/100], Step [910/1751], Loss: 1.2004\n",
      "Epoch [41/100], Step [920/1751], Loss: 1.1591\n",
      "Epoch [41/100], Step [930/1751], Loss: 1.1690\n",
      "Epoch [41/100], Step [940/1751], Loss: 1.1656\n",
      "Epoch [41/100], Step [950/1751], Loss: 1.1627\n",
      "Epoch [41/100], Step [960/1751], Loss: 1.1555\n",
      "Epoch [41/100], Step [970/1751], Loss: 1.2311\n",
      "Epoch [41/100], Step [980/1751], Loss: 1.4106\n",
      "Epoch [41/100], Step [990/1751], Loss: 1.1418\n",
      "Epoch [41/100], Step [1000/1751], Loss: 1.1732\n",
      "Epoch [41/100], Step [1010/1751], Loss: 1.2855\n",
      "Epoch [41/100], Step [1020/1751], Loss: 1.2615\n",
      "Epoch [41/100], Step [1030/1751], Loss: 1.2072\n",
      "Epoch [41/100], Step [1040/1751], Loss: 1.2391\n",
      "Epoch [41/100], Step [1050/1751], Loss: 1.1249\n",
      "Epoch [41/100], Step [1060/1751], Loss: 1.4056\n",
      "Epoch [41/100], Step [1070/1751], Loss: 1.1528\n",
      "Epoch [41/100], Step [1080/1751], Loss: 1.1562\n",
      "Epoch [41/100], Step [1090/1751], Loss: 1.2521\n",
      "Epoch [41/100], Step [1100/1751], Loss: 1.2371\n",
      "Epoch [41/100], Step [1110/1751], Loss: 1.3165\n",
      "Epoch [41/100], Step [1120/1751], Loss: 1.1121\n",
      "Epoch [41/100], Step [1130/1751], Loss: 1.2931\n",
      "Epoch [41/100], Step [1140/1751], Loss: 1.2276\n",
      "Epoch [41/100], Step [1150/1751], Loss: 1.1550\n",
      "Epoch [41/100], Step [1160/1751], Loss: 1.3454\n",
      "Epoch [41/100], Step [1170/1751], Loss: 1.1324\n",
      "Epoch [41/100], Step [1180/1751], Loss: 1.2189\n",
      "Epoch [41/100], Step [1190/1751], Loss: 1.1308\n",
      "Epoch [41/100], Step [1200/1751], Loss: 1.3253\n",
      "Epoch [41/100], Step [1210/1751], Loss: 1.3807\n",
      "Epoch [41/100], Step [1220/1751], Loss: 1.1423\n",
      "Epoch [41/100], Step [1230/1751], Loss: 1.2281\n",
      "Epoch [41/100], Step [1240/1751], Loss: 1.3317\n",
      "Epoch [41/100], Step [1250/1751], Loss: 1.2263\n",
      "Epoch [41/100], Step [1260/1751], Loss: 1.1984\n",
      "Epoch [41/100], Step [1270/1751], Loss: 1.3538\n",
      "Epoch [41/100], Step [1280/1751], Loss: 1.2906\n",
      "Epoch [41/100], Step [1290/1751], Loss: 1.1607\n",
      "Epoch [41/100], Step [1300/1751], Loss: 1.1444\n",
      "Epoch [41/100], Step [1310/1751], Loss: 1.2539\n",
      "Epoch [41/100], Step [1320/1751], Loss: 1.2423\n",
      "Epoch [41/100], Step [1330/1751], Loss: 1.2276\n",
      "Epoch [41/100], Step [1340/1751], Loss: 1.3220\n",
      "Epoch [41/100], Step [1350/1751], Loss: 1.2977\n",
      "Epoch [41/100], Step [1360/1751], Loss: 1.1437\n",
      "Epoch [41/100], Step [1370/1751], Loss: 1.2018\n",
      "Epoch [41/100], Step [1380/1751], Loss: 1.2292\n",
      "Epoch [41/100], Step [1390/1751], Loss: 1.2002\n",
      "Epoch [41/100], Step [1400/1751], Loss: 1.1732\n",
      "Epoch [41/100], Step [1410/1751], Loss: 1.2699\n",
      "Epoch [41/100], Step [1420/1751], Loss: 1.1123\n",
      "Epoch [41/100], Step [1430/1751], Loss: 1.1074\n",
      "Epoch [41/100], Step [1440/1751], Loss: 1.2757\n",
      "Epoch [41/100], Step [1450/1751], Loss: 1.3632\n",
      "Epoch [41/100], Step [1460/1751], Loss: 1.1478\n",
      "Epoch [41/100], Step [1470/1751], Loss: 1.0181\n",
      "Epoch [41/100], Step [1480/1751], Loss: 1.2055\n",
      "Epoch [41/100], Step [1490/1751], Loss: 1.3457\n",
      "Epoch [41/100], Step [1500/1751], Loss: 1.3391\n",
      "Epoch [41/100], Step [1510/1751], Loss: 1.3451\n",
      "Epoch [41/100], Step [1520/1751], Loss: 1.2597\n",
      "Epoch [41/100], Step [1530/1751], Loss: 1.1750\n",
      "Epoch [41/100], Step [1540/1751], Loss: 1.1156\n",
      "Epoch [41/100], Step [1550/1751], Loss: 1.2839\n",
      "Epoch [41/100], Step [1560/1751], Loss: 1.2000\n",
      "Epoch [41/100], Step [1570/1751], Loss: 1.1137\n",
      "Epoch [41/100], Step [1580/1751], Loss: 1.3145\n",
      "Epoch [41/100], Step [1590/1751], Loss: 1.1042\n",
      "Epoch [41/100], Step [1600/1751], Loss: 1.2087\n",
      "Epoch [41/100], Step [1610/1751], Loss: 1.2070\n",
      "Epoch [41/100], Step [1620/1751], Loss: 1.2650\n",
      "Epoch [41/100], Step [1630/1751], Loss: 1.3198\n",
      "Epoch [41/100], Step [1640/1751], Loss: 1.2792\n",
      "Epoch [41/100], Step [1650/1751], Loss: 1.1764\n",
      "Epoch [41/100], Step [1660/1751], Loss: 1.1866\n",
      "Epoch [41/100], Step [1670/1751], Loss: 1.2333\n",
      "Epoch [41/100], Step [1680/1751], Loss: 1.2570\n",
      "Epoch [41/100], Step [1690/1751], Loss: 1.1866\n",
      "Epoch [41/100], Step [1700/1751], Loss: 1.0651\n",
      "Epoch [41/100], Step [1710/1751], Loss: 1.1860\n",
      "Epoch [41/100], Step [1720/1751], Loss: 1.1357\n",
      "Epoch [41/100], Step [1730/1751], Loss: 1.1687\n",
      "Epoch [41/100], Step [1740/1751], Loss: 1.0620\n",
      "Epoch [41/100], Step [1750/1751], Loss: 1.3192\n",
      "Epoch [41/100], Average Loss: 1.2199, Time: 1642.3599s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.00002\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[19], line 20\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, dataloader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 20\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Step [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataloader)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m], Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.00002)\n",
    "\n",
    "train_model(net, dataloader, criterion, optimizer, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 predictions for V3_Small_trained on :\n",
      "92 b'bee eater'          23.9%\n",
      "374 b'langur'              6.3%\n",
      "337 b'beaver'              5.9%\n",
      "334 b'porcupine'           5.1%\n",
      "21 b'kite'                4.7%\n",
      "377 b'marmoset'            3.0%\n",
      "82 b'ruffed grouse'       2.9%\n",
      "379 b'howler monkey'       2.5%\n",
      "380 b'titi'                2.1%\n",
      "90 b'lorikeet'            2.0%\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import skimage as ski\n",
    "from PIL import Image\n",
    "from utils.helper import get_imagenet_categories\n",
    "\n",
    "\n",
    "folderpath = \"/home/centar15-desktop1/Desktop/example_data/images-20250210T115939Z-001/images/\"\n",
    "\n",
    "classes = get_imagenet_categories()\n",
    "\n",
    "net = net.eval()\n",
    "\n",
    "transform2 = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.4435, 0.3968, 0.3221], std=[0.2266, 0.2126, 0.2013]),  \n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Lambda(lambda x: x.unsqueeze(0).to(device))\n",
    "])\n",
    "\n",
    "image = Image.open(folderpath + f\"{idx}.jpg\")\n",
    "\n",
    "if image.mode == 'RGBA':\n",
    "    # Convert the image to RGB (remove alpha channel)\n",
    "    image = image.convert('RGB')\n",
    "\n",
    "# image = ski.io.imread(folderpath + f\"{idx}.jpg\")\n",
    "\n",
    "# print(image.shape)\n",
    "\n",
    "# image = image[:,:, :3]\n",
    "# image2 = np.transpose(image, (2, 0, 1))\n",
    "\n",
    "# print(image.shape)\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "helper.print_probablities_from_output(net(transform2(image)), classes, 10, 'V3_Small_trained')\n",
    "\n",
    "idx = idx + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slika: 0\n",
      "Slika: 1000\n",
      "Slika: 2000\n",
      "Slika: 3000\n",
      "Slika: 4000\n",
      "Slika: 5000\n",
      "Slika: 6000\n",
      "Slika: 7000\n",
      "Slika: 8000\n",
      "Slika: 9000\n",
      "Slika: 10000\n",
      "Slika: 11000\n",
      "Slika: 12000\n",
      "Slika: 13000\n",
      "Slika: 14000\n",
      "Slika: 15000\n",
      "Slika: 16000\n",
      "Slika: 17000\n",
      "Slika: 18000\n",
      "Slika: 19000\n",
      "Slika: 20000\n",
      "Slika: 21000\n",
      "Slika: 22000\n",
      "Slika: 23000\n",
      "Accuracy: 0.5976218374343618\n"
     ]
    }
   ],
   "source": [
    "totalPost = 0\n",
    "accuracyPost = 0\n",
    "\n",
    "net = net.eval()\n",
    "\n",
    "dataset = DatasetReader.COCODataset(annotation_file='../../datasets/coco/annotations/instances_val2017.json',\n",
    "    image_dir= '../../datasets/coco/val2017',\n",
    "    target_classes=[s.lower() for s in utils.GLOBAL_CLASSES],\n",
    "    transform=transform)\n",
    "\n",
    "# batch_size = 256\n",
    "# dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=11, prefetch_factor=4, persistent_workers=True)\n",
    "\n",
    "\n",
    "for i in range(0, len(dataset)):\n",
    "    totalPost += 1\n",
    "    image, label = dataset[i]\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    label = torch.tensor([label]).to(device)\n",
    "    output = net(image)\n",
    "    _, predicted = torch.max(output, 1)\n",
    "    # print(f\"Predicted: {predicted.item()}, Actual: {label.item()}\")\n",
    "    if(i % 1000 == 0):\n",
    "        print(f\"Slika: {i}\")\n",
    "    if predicted.item() == label.item():\n",
    "        accuracyPost += 1\n",
    "    \n",
    "\n",
    "print(f\"Accuracy: {accuracyPost/totalPost}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
