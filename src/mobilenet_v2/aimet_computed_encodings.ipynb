{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.cuda\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-7ebf99e0.pth\" to /home/centar15-desktop1/.cache/torch/hub/checkpoints/mobilenet_v2-7ebf99e0.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 86.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2, MobileNet_V2_Weights\n",
    "\n",
    "model = mobilenet_v2(weights = MobileNet_V2_Weights.DEFAULT).cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 17:35:24,913 - root - INFO - AIMET\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "<frozen abc>:106: FutureWarning: `NLLLoss2d` has been deprecated. Please use `NLLLoss` instead as a drop-in replacement and see https://pytorch.org/docs/main/nn.html#torch.nn.NLLLoss for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 17:35:26,258 - Quant - INFO - No config file provided, defaulting to config file at /home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/aimet_common/quantsim_config/default_config.json\n",
      "2025-02-19 17:35:26,267 - Quant - INFO - Unsupported op type Squeeze\n",
      "2025-02-19 17:35:26,267 - Quant - INFO - Unsupported op type Mean\n",
      "2025-02-19 17:35:26,270 - Quant - INFO - Selecting DefaultOpInstanceConfigGenerator to compute the specialized config. hw_version:default\n"
     ]
    }
   ],
   "source": [
    "from aimet_common.defs import QuantScheme\n",
    "from aimet_common.quantsim_config.utils import get_path_for_per_channel_config\n",
    "from aimet_torch.quantsim import QuantizationSimModel\n",
    "\n",
    "input_shape = (1, 3, 224, 224)\n",
    "dummy_input = torch.randn(input_shape).cuda()\n",
    "\n",
    "sim = QuantizationSimModel(model,\n",
    "                           dummy_input,\n",
    "                           quant_scheme=QuantScheme.post_training_tf_enhanced,\n",
    "                           default_param_bw=8,\n",
    "                           default_output_bw=16,\n",
    "                           #config_file=get_path_for_per_channel_config())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): QuantizedConv2d(\n",
      "        3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (1): QuantizedBatchNorm2d(\n",
      "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): None\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (2): QuantizedReLU6(\n",
      "        inplace=True\n",
      "        (param_quantizers): ModuleDict()\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): QuantizedConv2d(\n",
      "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedBatchNorm2d(\n",
      "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): QuantizedConv2d(\n",
      "        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (1): QuantizedBatchNorm2d(\n",
      "        1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): None\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (2): QuantizedReLU6(\n",
      "        inplace=True\n",
      "        (param_quantizers): ModuleDict()\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): QuantizedDropout(\n",
      "      p=0.2, inplace=False\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizedLinear(\n",
      "      in_features=1280, out_features=1000, bias=True\n",
      "      (param_quantizers): ModuleDict(\n",
      "        (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "        (bias): None\n",
      "      )\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sim.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "QuantizedConv2d(\n",
       "  3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
       "  (param_quantizers): ModuleDict(\n",
       "    (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
       "  )\n",
       "  (input_quantizers): ModuleList(\n",
       "    (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
       "  )\n",
       "  (output_quantizers): ModuleList(\n",
       "    (0): None\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sim.model(dummy_input)\n",
    "sim.model.features[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.features[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(ROOT_DIR)\n",
    "\n",
    "from dataset.DatasetReader import COCODataset\n",
    "import dataset.utils as dsutils\n",
    "\n",
    "def get_calibration_data_loader():\n",
    "    transform = transforms.Compose([transforms.Resize(256),\n",
    "                                    transforms.CenterCrop(224),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    datasetCOCO = COCODataset(\n",
    "    annotation_file = r\"/home/centar15-desktop1/LPCV_2025_T1/datasets/coco/annotations/instances_val2017.json\", \n",
    "    image_dir= r'/home/centar15-desktop1/LPCV_2025_T1/datasets/coco/val2017',\n",
    "    target_classes=[s.lower() for s in dsutils.GLOBAL_CLASSES],\n",
    "    transform = transform)\n",
    "\n",
    "    dataloader = DataLoader(datasetCOCO, batch_size=16, shuffle=True)\n",
    "    return dataloader\n",
    "\n",
    "dataloader = get_calibration_data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pass_calibration_data(model: torch.nn.Module, dataloader):\n",
    "    num_batches = 32\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (input_data, _) in enumerate(dataloader):\n",
    "            if batch >= num_batches:\n",
    "                break\n",
    "            inputs_batch = input_data.to(\"cuda\")\n",
    "            asdf = model(inputs_batch)\n",
    "            print(asdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2864,  0.4086, -0.1682,  ..., -1.0524, -0.4447,  1.1467],\n",
      "        [ 0.1579, -0.5318, -0.4925,  ..., -0.3671, -0.0064, -1.6205],\n",
      "        [-0.2782,  0.1649, -0.2332,  ...,  0.5585,  0.2680, -0.8378],\n",
      "        ...,\n",
      "        [-0.5398,  0.6756, -0.5106,  ..., -0.8966, -0.3162,  0.6858],\n",
      "        [-0.1569,  0.0467, -0.2110,  ..., -0.3236,  0.4402, -0.7001],\n",
      "        [ 0.1008,  0.6660, -0.6845,  ..., -0.6017,  0.5578,  0.3483]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.4694,  0.0800, -0.0060,  ..., -0.7170, -1.2197, -1.2221],\n",
      "        [-0.0178, -1.0593, -0.6007,  ..., -0.5795,  0.5358, -0.0333],\n",
      "        [-0.4527, -0.7011, -0.3270,  ..., -0.4895,  1.6511, -0.4237],\n",
      "        ...,\n",
      "        [-0.7852, -0.3666, -0.0877,  ..., -0.1127, -0.2861, -0.0596],\n",
      "        [-0.5309, -0.1522, -0.5360,  ..., -0.8239,  0.9017, -0.5682],\n",
      "        [ 0.1828,  0.4876, -1.1630,  ..., -0.0969,  1.7014, -1.0652]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.2538,  0.2936, -0.9496,  ..., -0.2193,  2.4241, -0.6486],\n",
      "        [ 0.0823,  0.1066,  0.3661,  ..., -0.5493, -0.8957, -1.5684],\n",
      "        [ 0.3712, -0.1390, -0.6298,  ..., -0.1978,  0.8528, -0.4877],\n",
      "        ...,\n",
      "        [ 0.4286,  0.8782, -0.9041,  ..., -0.7116, -0.3434, -0.4461],\n",
      "        [-0.1727, -0.0886, -0.5620,  ..., -0.8153,  0.1777,  0.9677],\n",
      "        [ 0.3281, -0.1370, -0.2679,  ..., -0.0550, -0.5403,  1.7500]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0169, -0.4122, -0.8191,  ..., -1.2534,  0.9129,  0.6280],\n",
      "        [-0.4480, -0.2576,  0.0051,  ..., -0.3140, -0.3333,  0.0139],\n",
      "        [-0.4311,  0.3446, -0.6908,  ..., -0.5366, -0.4596, -1.0155],\n",
      "        ...,\n",
      "        [-0.5400, -0.4467, -0.0984,  ..., -0.6248, -0.5876,  0.6003],\n",
      "        [-0.6070,  0.2594, -0.5421,  ..., -0.5418, -0.7318,  0.3988],\n",
      "        [ 0.4962, -0.3594, -0.4016,  ..., -0.3979, -0.0570, -0.8692]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7058,  0.1248, -0.5035,  ..., -1.1705, -0.2676,  0.4127],\n",
      "        [-0.6758, -0.2396, -0.9365,  ..., -1.0096, -0.9972, -0.9624],\n",
      "        [-0.1698,  0.8613, -0.3411,  ..., -0.8434,  1.4134,  0.2153],\n",
      "        ...,\n",
      "        [-0.1451,  0.4856, -0.2331,  ..., -0.6189, -0.2874, -0.6092],\n",
      "        [-0.3613,  0.2340, -0.9889,  ..., -0.5069, -0.5855,  0.7467],\n",
      "        [ 0.8094,  1.5317, -0.7356,  ...,  0.8937,  0.5166,  0.6941]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.4301, -0.4531, -0.2586,  ..., -0.7782,  0.1460, -0.5834],\n",
      "        [-0.0358,  0.1222,  0.4155,  ..., -0.6853, -0.4859, -0.6657],\n",
      "        [ 0.1391,  2.5089,  0.0773,  ...,  0.1375, -0.0651, -0.6973],\n",
      "        ...,\n",
      "        [ 0.1980,  0.4692, -1.0175,  ...,  0.0379, -0.2885, -0.4858],\n",
      "        [ 0.2028, -0.3205, -0.0908,  ..., -0.1426,  0.7644,  0.9446],\n",
      "        [ 1.3663,  0.7115,  0.9895,  ..., -0.0200, -0.2618, -0.3034]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.6521,  0.1007, -0.5427,  ..., -0.3482,  0.5436, -0.4049],\n",
      "        [ 1.0052,  3.2517, -1.0842,  ...,  0.0113, -0.0999, -1.3673],\n",
      "        [ 0.0124, -0.1717, -0.4683,  ..., -0.8297, -1.1263, -0.6618],\n",
      "        ...,\n",
      "        [-0.0513,  0.6131, -1.0475,  ..., -0.6982,  0.1188,  0.6055],\n",
      "        [-0.0930,  0.6990,  0.1205,  ..., -0.0338, -0.2843, -0.2578],\n",
      "        [ 0.2403,  1.0703, -0.4753,  ...,  0.1704,  0.4763, -1.0372]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3519,  0.6153, -1.3081,  ...,  0.1167, -0.4885, -0.6733],\n",
      "        [ 0.7775, -0.8760,  0.3880,  ...,  0.8746,  3.1226, -0.0923],\n",
      "        [-0.5183,  1.1869, -1.1665,  ..., -0.6121, -0.5445, -0.2164],\n",
      "        ...,\n",
      "        [ 1.1935, -1.1132, -1.2861,  ...,  0.2852,  3.1105, -1.5863],\n",
      "        [ 0.1309,  0.3662, -0.9554,  ..., -0.8096, -0.5369,  0.0917],\n",
      "        [ 0.6809,  1.5282, -0.0845,  ...,  0.3472,  0.4072, -0.3880]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0991, -0.1140, -0.0752,  ..., -0.6755, -0.3932, -0.3955],\n",
      "        [-0.1090, -0.6014, -0.4901,  ..., -0.1880, -0.1313, -0.3048],\n",
      "        [-0.7840,  0.2174, -0.6171,  ..., -0.7261, -1.2058, -0.0602],\n",
      "        ...,\n",
      "        [-0.0087, -0.1859, -1.1595,  ...,  0.0559,  0.1513, -0.5530],\n",
      "        [ 0.2313,  0.9737, -0.2925,  ..., -0.3049, -0.0279, -0.3298],\n",
      "        [-0.6689,  0.1802, -0.5733,  ...,  0.0676, -0.3799,  1.5281]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3351,  0.7275, -0.6365,  ..., -0.6253,  0.0728,  0.0757],\n",
      "        [-0.1920,  0.0890,  0.1566,  ..., -0.7565,  0.0739,  0.3584],\n",
      "        [ 0.7577, -0.3410, -0.3836,  ...,  0.9097, -0.1354, -1.1311],\n",
      "        ...,\n",
      "        [ 1.2560,  0.0327, -0.4407,  ...,  0.2301,  0.3799,  0.4780],\n",
      "        [ 0.3500,  2.7087, -1.0177,  ...,  0.3040, -0.2852, -0.4239],\n",
      "        [ 1.5158,  0.7923, -1.1317,  ..., -0.0914,  1.6109, -0.7807]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1391,  0.1492,  0.4338,  ..., -0.9266,  0.3930, -0.3933],\n",
      "        [ 0.4472,  0.1115, -0.5263,  ...,  0.2881, -0.6169, -1.1747],\n",
      "        [-0.1646,  0.3958, -1.0715,  ..., -0.5044,  0.2339, -0.3993],\n",
      "        ...,\n",
      "        [-0.2038, -0.5974, -1.4923,  ..., -0.6578, -0.2988, -0.5794],\n",
      "        [-0.9179, -0.5288, -0.3169,  ...,  0.0812,  0.0174,  0.8686],\n",
      "        [ 0.2985,  0.5662, -1.7133,  ...,  0.5257,  0.3530, -0.5606]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.8631, -0.5838, -0.4406,  ...,  0.0107, -0.6775,  0.7085],\n",
      "        [-0.2344, -0.6824, -0.6445,  ..., -0.5191,  0.3970, -0.2635],\n",
      "        [-0.7891, -1.1784, -0.0162,  ..., -0.6524, -1.6515,  0.6417],\n",
      "        ...,\n",
      "        [-0.8679, -1.2287, -0.2209,  ..., -0.3457, -0.4172, -1.1103],\n",
      "        [ 0.3607,  1.1510, -0.8153,  ..., -1.1354,  2.4394, -1.1163],\n",
      "        [-0.2354, -0.5222, -1.3582,  ...,  0.0265,  0.4188, -0.8342]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.4215, -0.3537,  0.0761,  ..., -0.5676, -0.4039,  1.0850],\n",
      "        [-0.3399,  1.0691, -0.8195,  ..., -0.3329, -0.8236,  0.3036],\n",
      "        [-0.3290,  0.7858, -0.4348,  ..., -0.6290,  0.1211,  0.1602],\n",
      "        ...,\n",
      "        [-0.1068,  0.2908, -0.4150,  ..., -0.1929, -0.5843, -1.0335],\n",
      "        [ 0.3262,  0.2918, -0.0871,  ...,  0.1270, -0.2581, -0.9590],\n",
      "        [ 1.9514,  1.6890, -0.4784,  ..., -0.7343,  0.4142, -0.4540]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1312,  0.2800, -0.5166,  ..., -0.4303,  1.1472,  0.1287],\n",
      "        [-0.0272, -0.7175, -0.0365,  ...,  0.0683, -0.2833, -0.8944],\n",
      "        [ 1.2459,  1.0901, -0.5565,  ...,  0.1871, -0.1081, -0.8573],\n",
      "        ...,\n",
      "        [-0.9622,  0.1907, -0.5998,  ...,  0.0457, -0.1307,  1.1703],\n",
      "        [-0.2457,  0.8052, -0.3494,  ..., -0.6256, -0.1245, -0.5181],\n",
      "        [ 0.3721, -0.6452,  0.0512,  ...,  0.2001,  1.2053, -0.2996]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0675,  0.3126, -0.6878,  ..., -0.8231, -0.6693, -0.5463],\n",
      "        [ 1.0424,  1.6307, -0.9632,  ...,  0.3923, -0.1180, -0.9481],\n",
      "        [ 1.0781,  2.0154, -1.2726,  ..., -0.3023,  3.7828, -1.1631],\n",
      "        ...,\n",
      "        [ 0.7658, -0.5579, -0.6038,  ..., -0.8354,  0.7788,  0.4112],\n",
      "        [ 0.0769, -0.5592, -0.3494,  ..., -0.5077, -1.3535,  0.3355],\n",
      "        [-0.1187,  1.4869, -0.6364,  ..., -0.4917,  0.0931, -0.7344]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0948,  0.4896, -0.2879,  ..., -0.3509, -0.0554, -0.6159],\n",
      "        [-0.5036,  1.1674, -0.6414,  ..., -0.7545, -0.0282, -2.3274],\n",
      "        [-0.0656,  0.5786, -0.9362,  ..., -0.3337, -0.4131,  0.2622],\n",
      "        ...,\n",
      "        [-0.0652, -0.7979, -0.7305,  ..., -0.8791, -0.1402,  2.4155],\n",
      "        [-0.0901, -0.3292, -0.4808,  ..., -0.1515, -0.1625, -1.3264],\n",
      "        [-0.6844,  0.9930, -0.1802,  ..., -0.2613, -0.1641,  4.5173]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.4769,  3.1057, -1.0240,  ...,  0.2909,  1.8119, -0.5947],\n",
      "        [-0.6217, -0.2211, -1.6004,  ..., -0.4200,  1.2797,  1.7806],\n",
      "        [-0.6145, -0.6028, -0.1076,  ...,  0.5077,  0.0590, -0.4822],\n",
      "        ...,\n",
      "        [-0.6531,  0.2142, -1.5221,  ..., -1.3383, -0.3466,  0.0648],\n",
      "        [-0.6375, -0.1998,  0.6885,  ..., -1.2012, -0.5102,  1.5892],\n",
      "        [-0.4419, -0.5028, -1.0123,  ..., -0.7860, -0.4652, -0.9371]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7159, -0.2168,  0.0599,  ..., -1.4453, -0.4067, -0.2197],\n",
      "        [-0.3102,  1.2302, -0.0835,  ..., -1.1257,  0.7830,  0.5588],\n",
      "        [-0.2348,  1.2156, -0.9242,  ..., -1.0143, -0.2669, -0.1269],\n",
      "        ...,\n",
      "        [-0.3337,  0.2242, -0.1357,  ..., -1.0326, -0.4611, -1.1182],\n",
      "        [-0.1787,  0.0321,  1.0503,  ..., -0.6744, -0.6212, -0.0849],\n",
      "        [ 0.1107, -1.0284,  0.1506,  ...,  1.4313,  0.5369,  1.0336]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1416,  0.1933, -0.8348,  ..., -1.0136, -0.1506, -0.3321],\n",
      "        [-0.4919,  0.4425, -0.9269,  ..., -0.6939,  0.0673,  0.7093],\n",
      "        [ 0.0862,  1.0044, -1.3356,  ...,  0.0641, -0.7981, -0.7228],\n",
      "        ...,\n",
      "        [ 0.5114, -0.3846, -0.1614,  ..., -0.1575,  0.3768, -0.7715],\n",
      "        [-0.3516,  0.6059, -1.2326,  ..., -0.6458,  0.5471,  0.4179],\n",
      "        [ 0.8031,  0.4893, -0.5927,  ..., -0.9271, -0.1081, -0.5316]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.1450,  0.1926, -0.4171,  ..., -0.6314, -0.7341,  0.0968],\n",
      "        [ 0.5633,  0.8082, -1.3599,  ..., -0.0378,  0.0789, -0.3877],\n",
      "        [-0.0066,  0.8879, -1.0722,  ..., -0.5552,  1.8422, -0.8377],\n",
      "        ...,\n",
      "        [ 1.9884,  0.4120,  0.1961,  ..., -0.1626, -0.0599, -0.6798],\n",
      "        [-0.2411,  0.1123, -0.7363,  ..., -0.9349, -0.5663,  0.0491],\n",
      "        [ 0.2582, -0.0069, -0.9073,  ..., -0.3947,  0.0222,  0.3653]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.3000,  1.5114, -1.3022,  ...,  0.7783,  0.9523, -0.6521],\n",
      "        [-0.4582,  0.2923, -1.2309,  ..., -0.4237,  1.2365, -0.9257],\n",
      "        [ 0.4916, -0.0576, -0.3237,  ...,  0.2024, -0.6520, -0.4904],\n",
      "        ...,\n",
      "        [ 1.1389,  1.0748, -0.7469,  ..., -0.4453,  0.7261,  0.5939],\n",
      "        [-0.7409,  0.4395,  0.0325,  ..., -0.3895, -0.0065,  0.8282],\n",
      "        [-0.3689,  0.2512, -0.7763,  ..., -0.3354,  0.6284, -0.0638]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.4374,  0.2713, -0.9595,  ..., -0.3396, -0.9081, -1.1360],\n",
      "        [-0.1966, -0.0460, -0.0218,  ...,  1.0266, -0.4232,  3.5937],\n",
      "        [-0.7542, -0.9096, -0.8787,  ..., -0.3518,  0.1863,  0.4283],\n",
      "        ...,\n",
      "        [-0.7366, -0.3788, -0.5652,  ..., -0.6397, -0.1176,  1.5769],\n",
      "        [-0.3808,  0.7579, -0.7500,  ..., -0.4605, -0.7911, -0.2109],\n",
      "        [-0.8318,  1.0203,  0.3942,  ..., -0.3068,  0.9242,  1.2332]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.2413,  0.0833, -1.3865,  ..., -0.4202, -0.3873, -0.1495],\n",
      "        [ 0.5453, -0.3840, -0.1634,  ..., -0.7588, -0.2703,  0.2665],\n",
      "        [ 0.8326,  0.5189, -0.3118,  ..., -0.2491,  1.0768, -0.5814],\n",
      "        ...,\n",
      "        [-0.2943,  0.5628,  0.0518,  ..., -0.8585, -0.8461,  0.8678],\n",
      "        [-0.9672, -0.8609, -0.4903,  ..., -0.4135, -0.4679,  2.2986],\n",
      "        [-0.1239, -1.2342, -0.5469,  ...,  0.3871,  0.5994, -0.9541]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2.2665,  0.3871, -0.0628,  ..., -0.6014, -0.2167, -0.1308],\n",
      "        [ 0.5816,  0.1496, -1.0044,  ...,  1.0934,  0.6770, -0.6900],\n",
      "        [ 0.8654,  0.1119, -0.4466,  ..., -0.2591, -0.6119, -1.4732],\n",
      "        ...,\n",
      "        [-0.0634,  0.1908, -0.7916,  ..., -0.7315, -0.5752, -0.4556],\n",
      "        [ 0.7203,  0.5648, -0.3227,  ..., -0.2887, -0.0730, -0.2572],\n",
      "        [ 0.1370,  0.3526,  0.1820,  ..., -1.0788,  0.3403, -0.4109]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.6505, -0.4166,  0.0948,  ..., -0.4515,  0.3132, -0.0745],\n",
      "        [ 0.2176,  1.5371, -1.0625,  ..., -1.2032,  0.7447, -0.4157],\n",
      "        [-0.3888,  0.7955, -0.5778,  ..., -0.5090, -0.0519, -0.4334],\n",
      "        ...,\n",
      "        [-0.4654, -0.4092, -0.7091,  ..., -0.2555,  0.6881,  1.4668],\n",
      "        [ 0.2102,  1.1006, -0.8486,  ..., -0.7643, -0.5342, -1.5000],\n",
      "        [-0.2431, -0.6307, -0.0828,  ..., -0.2478,  0.7267,  1.6067]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3092, -0.1660,  0.4683,  ..., -0.4574,  0.4578,  0.2987],\n",
      "        [-0.3894,  0.6341, -0.9606,  ..., -1.0437,  0.0802,  0.7827],\n",
      "        [ 0.9080,  0.6622, -0.5562,  ..., -0.3273,  0.1502, -0.0242],\n",
      "        ...,\n",
      "        [-0.1480,  0.0023, -0.6038,  ..., -0.4181,  0.3722,  1.0631],\n",
      "        [ 0.5302, -1.0744, -1.1943,  ..., -0.4790,  0.5364, -0.6685],\n",
      "        [ 0.1953, -0.5080, -0.5857,  ..., -1.1481, -1.0591, -1.1812]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.0193,  0.7798, -0.8687,  ..., -0.8937,  0.3500, -0.2174],\n",
      "        [-0.9523, -0.0651, -0.2540,  ...,  0.3337,  0.1093,  0.0485],\n",
      "        [-0.8313, -0.3701, -0.0243,  ...,  1.3588,  0.3707,  0.3067],\n",
      "        ...,\n",
      "        [-0.0868,  1.4217, -1.3378,  ..., -0.5195,  0.6897, -0.8153],\n",
      "        [-0.0411,  1.9832, -0.9901,  ..., -0.7072,  0.5781, -0.7904],\n",
      "        [-0.1351,  0.2208, -0.6402,  ..., -0.8234, -0.0997, -0.8388]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.0394,  0.4862,  0.6498,  ...,  0.3945,  0.1520, -0.1497],\n",
      "        [ 0.9616, -0.3804, -0.0582,  ...,  0.0258,  0.6051, -1.3844],\n",
      "        [-0.0997, -1.1033, -0.7644,  ..., -0.4813, -0.7760, -0.9010],\n",
      "        ...,\n",
      "        [ 0.0290, -0.5765,  0.5179,  ..., -1.0061, -0.3060, -0.4618],\n",
      "        [-0.4168, -0.1264,  0.2603,  ..., -0.4953, -0.0280, -1.2764],\n",
      "        [-0.2966,  0.6158, -0.5019,  ..., -0.8819, -0.1936,  0.4837]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.3173,  0.5495, -1.0504,  ..., -0.2399, -0.6160, -0.3071],\n",
      "        [-0.3790,  0.2020, -1.0591,  ..., -0.7121, -0.2973, -0.2446],\n",
      "        [-0.2490,  0.9447, -0.7459,  ..., -0.6010, -0.4316, -0.0572],\n",
      "        ...,\n",
      "        [ 1.4887,  2.4641, -0.1486,  ..., -0.3361, -0.5766, -0.3615],\n",
      "        [-0.1448, -0.2977, -1.2732,  ..., -0.5192, -0.1926, -0.2534],\n",
      "        [ 1.2458, -0.0864, -1.4731,  ...,  1.2747,  3.2019, -1.0814]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 0.5757,  0.5269, -0.3532,  ...,  0.0680,  0.1506, -0.0310],\n",
      "        [-0.0682,  0.8038, -0.7943,  ..., -0.8803,  0.2434,  0.5050],\n",
      "        [-0.9090,  0.0457,  0.4839,  ...,  0.4913,  0.0475,  0.4646],\n",
      "        ...,\n",
      "        [ 0.1076,  1.3858, -1.1336,  ..., -0.0043,  0.4728, -0.6671],\n",
      "        [ 1.7331,  1.5132, -1.4195,  ..., -0.2387,  2.6852, -1.1114],\n",
      "        [-0.9058,  1.0397, -1.1154,  ..., -0.6935,  0.2681,  0.2739]],\n",
      "       device='cuda:0')\n",
      "tensor([[-0.7093,  0.2217, -0.6296,  ..., -0.8912,  0.0426,  2.2723],\n",
      "        [-0.5942,  0.6251, -1.0886,  ..., -1.0343,  0.0928,  0.5500],\n",
      "        [-0.8907, -0.1840,  0.0902,  ..., -0.7210,  0.3631, -1.4175],\n",
      "        ...,\n",
      "        [-0.7881,  0.2707,  0.2811,  ..., -0.8217, -0.6414,  0.9576],\n",
      "        [ 0.0067,  0.3907,  0.1335,  ..., -0.9270, -0.3917,  4.2840],\n",
      "        [-0.1327, -0.2818, -0.2926,  ...,  0.3917,  1.1050,  1.8739]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 1.9534,  0.6009, -1.0420,  ..., -0.1003, -0.4188, -0.4106],\n",
      "        [ 0.4268,  0.1526,  0.2171,  ..., -0.2442, -0.2032,  0.1069],\n",
      "        [-0.3696,  1.5870,  0.1974,  ..., -1.0657, -0.8184,  0.6125],\n",
      "        ...,\n",
      "        [ 1.1566,  0.4930, -0.5116,  ...,  0.3856, -0.0318,  2.1637],\n",
      "        [ 0.1941, -0.1289, -0.7746,  ..., -0.4360, -0.4194, -0.3603],\n",
      "        [-0.1920,  1.4403, -0.2183,  ...,  0.0359, -0.3479,  0.0339]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sim.compute_encodings(pass_calibration_data, forward_pass_callback_args=dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DequantizedTensor([[ 3.8063e-01,  9.4928e-02, -1.2205e-01, -6.0017e-01,\n",
      "                    -7.8252e-02, -1.8381e-01, -8.2650e-02,  2.8937e-01,\n",
      "                     4.7098e-02, -2.1845e-01, -2.2303e-01, -2.5308e-01,\n",
      "                    -2.6957e-01,  2.5950e-01, -2.9230e-01, -1.6127e-01,\n",
      "                    -3.0769e-01, -9.6578e-02,  5.3145e-03,  1.6530e-01,\n",
      "                    -2.5290e-02, -3.7055e-01, -1.7886e-01, -5.8038e-01,\n",
      "                    -4.9700e-01, -4.0170e-01, -3.4526e-01, -1.8583e-01,\n",
      "                    -3.9144e-01, -1.7758e-01, -3.5955e-01, -2.8314e-01,\n",
      "                    -5.3988e-01, -2.8075e-01, -6.5973e-03,  4.3616e-02,\n",
      "                     9.9143e-02,  1.0812e-02, -4.6273e-01, -5.2595e-02,\n",
      "                     2.1991e-03, -4.0335e-01, -2.9853e-01,  3.6652e-04,\n",
      "                    -1.8033e-01, -4.6218e-01, -2.4832e-01, -4.3377e-01,\n",
      "                    -3.3683e-01, -4.3158e-01, -2.1625e-01,  1.0189e-01,\n",
      "                    -7.3670e-02, -1.6493e-03, -2.9798e-01, -5.2046e-01,\n",
      "                    -9.4745e-02, -9.8227e-02,  6.7256e-02, -2.5656e-03,\n",
      "                     4.0299e-01,  1.1949e-01, -8.1001e-02, -9.1630e-04,\n",
      "                    -1.3561e-01,  3.3720e-02,  1.2828e-03, -3.2364e-01,\n",
      "                    -1.7373e-01,  1.8326e-04,  9.0164e-02, -1.1454e-01,\n",
      "                    -1.7849e-01,  1.7666e-01,  4.1233e-02,  6.7256e-02,\n",
      "                    -1.4844e-02,  1.7593e-01,  2.4538e-01, -2.8424e-01,\n",
      "                    -1.3066e-01, -3.7935e-01, -5.8460e-02, -1.0153e-01,\n",
      "                     6.1575e-02, -1.6420e-01, -1.0666e-01,  2.6976e-01,\n",
      "                    -1.7281e-01, -9.3646e-02, -3.5241e-01,  3.6652e-04,\n",
      "                    -2.3164e-01, -1.8601e-01,  5.5161e-02, -5.0946e-02,\n",
      "                    -7.3304e-02, -4.8380e-01, -3.4141e-01, -4.0757e-01,\n",
      "                    -2.0323e-01, -3.4838e-01, -2.8277e-01, -2.6463e-01,\n",
      "                     1.1784e-01, -4.6181e-01, -2.2816e-01, -1.5394e-01,\n",
      "                    -4.5210e-01, -3.2162e-01, -2.2248e-01, -5.6994e-02,\n",
      "                     4.8380e-01,  1.2883e-01,  6.3224e-02, -3.7440e-01,\n",
      "                    -6.2308e-02, -2.3732e-01,  2.2761e-01, -1.5357e-01,\n",
      "                    -1.1051e-01, -6.8539e-02,  2.9303e-01, -4.7501e-01,\n",
      "                     8.7598e-02,  2.8185e-01, -3.9034e-02, -1.1362e-01,\n",
      "                    -3.1924e-01, -3.2125e-01, -1.6622e-01, -1.8546e-01,\n",
      "                    -2.1918e-01, -3.2620e-01,  7.9351e-02, -2.6884e-01,\n",
      "                    -2.3219e-01, -2.8772e-01, -3.8228e-01, -4.7812e-01,\n",
      "                    -5.4831e-01, -1.4423e-01, -3.9053e-01, -3.3921e-01,\n",
      "                    -5.3219e-01, -1.6768e-01, -6.8887e-01, -3.4874e-01,\n",
      "                    -3.5021e-01, -5.2009e-01, -1.6438e-01,  3.9474e-01,\n",
      "                    -1.0427e-01,  2.3036e-01,  3.6744e-01,  5.3328e-02,\n",
      "                    -7.6786e-02, -3.4453e-02,  1.8509e-02, -1.2883e-01,\n",
      "                     2.4337e-01,  2.2468e-01,  1.3360e-01,  1.0922e-01,\n",
      "                    -5.2834e-01, -2.9945e-01, -4.6786e-01, -5.1606e-01,\n",
      "                    -5.2595e-02,  3.0623e-01, -3.3536e-02,  5.1642e-01,\n",
      "                     5.0763e-02,  4.7189e-01, -1.4514e-01, -8.5582e-02,\n",
      "                    -1.2572e-01, -1.1802e-01,  1.4148e-01,  6.4874e-02,\n",
      "                     1.4313e-01,  1.4697e-01, -1.3744e-02,  3.6304e-01,\n",
      "                     2.6683e-01,  3.6230e-01,  2.9670e-01,  1.7520e-01,\n",
      "                     1.4203e-01,  3.5222e-01, -1.2040e-01,  2.0745e-01,\n",
      "                     1.5357e-01,  3.5699e-01, -2.2852e-01,  3.4050e-01,\n",
      "                     1.5650e-01,  2.0159e-02,  9.4195e-02,  4.7446e-01,\n",
      "                    -1.7886e-01,  2.6059e-01,  3.7971e-01,  2.9615e-01,\n",
      "                     8.1001e-02, -1.0171e-01, -3.2950e-01,  7.6969e-02,\n",
      "                     4.1838e-01,  6.1392e-02, -1.9480e-01,  2.4282e-01,\n",
      "                    -7.2387e-02, -3.3042e-01,  4.4532e-02, -5.9559e-02,\n",
      "                     1.7611e-01, -2.2009e-01, -2.3329e-01,  1.4166e-01,\n",
      "                     3.3903e-02, -4.4899e-02,  2.3091e-02,  2.0763e-01,\n",
      "                    -1.3561e-01, -1.9462e-01,  2.5125e-01,  1.7373e-01,\n",
      "                     5.7727e-02,  3.0055e-02,  3.3427e-01,  2.4557e-02,\n",
      "                    -1.6860e-02,  9.6578e-02,  1.2058e-01, -8.8514e-02,\n",
      "                     1.0153e-01,  2.1661e-01,  1.6475e-01,  1.6347e-01,\n",
      "                    -1.7300e-01, -8.9980e-02,  3.0788e-02, -2.4923e-02,\n",
      "                    -2.3531e-01,  1.4734e-01, -6.7256e-02, -9.1446e-02,\n",
      "                     1.4477e-02,  1.3396e-01,  1.3433e-01,  4.0500e-02,\n",
      "                    -1.3983e-01,  1.9700e-01,  9.0530e-02,  1.0372e-01,\n",
      "                    -9.9327e-02, -6.5973e-03,  3.2712e-01, -8.2467e-02,\n",
      "                    -4.8930e-02, -3.5497e-01, -7.0372e-02,  2.7214e-01,\n",
      "                     2.7104e-01,  4.6749e-01,  4.5742e-01,  8.6315e-02,\n",
      "                    -4.2150e-01, -5.2449e-01, -1.9462e-01, -1.5962e-01,\n",
      "                    -2.5308e-01,  2.3640e-02, -3.1154e-02, -8.2980e-01,\n",
      "                    -5.9834e-01, -2.1185e-01, -1.6915e-01, -4.2571e-01,\n",
      "                    -3.1667e-01,  5.2247e-01,  4.6640e-01,  2.2962e-01,\n",
      "                    -7.1288e-02,  3.6102e-01, -1.3928e-01, -1.9975e-02,\n",
      "                    -4.2498e-01, -7.0005e-01, -5.4556e-01, -3.6780e-01,\n",
      "                    -1.0336e-01, -7.1618e-01, -4.3414e-01, -6.0036e-01,\n",
      "                    -7.9406e-01, -7.3872e-01, -1.3561e-02, -1.6603e-01,\n",
      "                    -2.9835e-01,  1.1106e-01, -7.2387e-02, -3.7605e-01,\n",
      "                    -3.6945e-01, -4.8875e-01,  6.9455e-02, -4.1801e-01,\n",
      "                     4.3982e-03, -2.5253e-01, -8.2467e-03, -2.5473e-02,\n",
      "                     3.0238e-01,  9.1813e-02,  2.7397e-01,  4.5870e-01,\n",
      "                     7.2754e-02, -2.6481e-01, -1.2370e-01, -1.6310e-01,\n",
      "                    -3.5919e-01, -1.3891e-01,  5.5344e-02, -2.2358e-01,\n",
      "                    -1.4789e-01, -2.3384e-01, -2.7324e-01,  7.6602e-02,\n",
      "                    -4.2883e-01, -1.5980e-01,  1.0721e-01, -8.6132e-02,\n",
      "                     1.4148e-01, -4.5632e-02, -4.0354e-01,  2.2211e-01,\n",
      "                    -1.8308e-01, -1.0959e-01,  3.9969e-01, -2.5216e-01,\n",
      "                    -3.1759e-01,  1.1600e-01, -2.0653e-01, -1.2975e-01,\n",
      "                    -3.4728e-01,  1.2187e-01, -2.2706e-01, -1.2865e-01,\n",
      "                    -3.1392e-01, -2.1625e-01, -2.1002e-01, -1.9994e-01,\n",
      "                    -2.7654e-01, -3.7238e-01,  2.0323e-01, -3.8338e-01,\n",
      "                     3.0256e-01,  8.3383e-02,  1.2462e-01,  4.4312e-01,\n",
      "                    -4.0225e-01,  2.3146e-01, -3.6890e-01, -2.0305e-01,\n",
      "                    -2.4520e-01, -1.3231e-01, -5.1239e-01, -9.5295e-02,\n",
      "                    -4.0739e-01, -4.6914e-01, -1.3964e-01,  1.9096e-01,\n",
      "                    -1.1142e-01,  1.4441e-01, -1.2682e-01, -6.8686e-01,\n",
      "                    -4.3432e-02,  1.4826e-01, -9.8227e-02, -6.4141e-01,\n",
      "                     2.9321e-03, -2.1790e-01,  1.6915e-01, -3.8814e-01,\n",
      "                    -4.4770e-01, -2.5107e-01, -5.1313e-02, -2.4355e-01,\n",
      "                    -5.1569e-01,  1.4844e-01, -3.4013e-01,  8.5582e-02,\n",
      "                    -1.9389e-01, -4.4019e-01,  2.8515e-01, -1.4423e-01,\n",
      "                    -3.0073e-01, -5.2376e-01, -6.7806e-02,  1.1215e-01,\n",
      "                     2.8863e-01,  3.4581e-01,  1.3946e-01, -3.9547e-01,\n",
      "                     3.3720e-02,  8.5032e-02, -1.3415e-01, -1.1967e-01,\n",
      "                     2.0837e-01,  2.4245e-01, -1.0684e-01, -9.3279e-02,\n",
      "                     7.7885e-02,  3.4966e-01,  1.3433e-01, -3.6652e-02,\n",
      "                     9.5661e-02, -2.0342e-02,  3.9218e-01,  2.1313e-01,\n",
      "                     4.8564e-01,  5.2192e-01,  3.8045e-01, -9.6394e-02,\n",
      "                     4.8930e-02, -1.9774e-01,  1.9022e-01,  6.2125e-02,\n",
      "                     3.0403e-01,  2.2211e-01,  1.4056e-01,  1.5962e-01,\n",
      "                     5.7727e-02,  3.6744e-01,  2.3054e-01,  4.6346e-01,\n",
      "                    -1.9316e-01, -1.8821e-01,  7.3487e-02, -2.6756e-02,\n",
      "                     1.4459e-01, -1.3176e-01,  7.1471e-03, -1.5559e-01,\n",
      "                     1.8289e-01,  3.4819e-02, -1.2682e-01,  5.9559e-02,\n",
      "                     2.1331e-01, -7.3120e-02,  2.9688e-01, -3.5003e-02,\n",
      "                     7.0921e-02, -2.2248e-01, -1.3928e-01,  5.4959e-01,\n",
      "                     6.5973e-03,  4.4385e-01, -1.0574e-01,  1.9059e-01,\n",
      "                    -1.7263e-01,  1.0043e-01, -1.9975e-01,  2.8882e-01,\n",
      "                     4.8545e-01, -1.9682e-01,  4.7647e-02,  3.7935e-02,\n",
      "                    -7.0188e-02,  2.0305e-01,  1.5247e-01,  3.0769e-01,\n",
      "                    -3.2180e-01,  9.1391e-01, -2.3274e-02, -8.1367e-02,\n",
      "                    -3.3976e-01, -1.1912e-02,  2.1423e-01, -2.0598e-01,\n",
      "                    -3.3628e-01,  2.5162e-01,  4.7977e-01, -3.4911e-01,\n",
      "                    -5.6554e-01,  2.4850e-01,  1.1600e-01,  2.0782e-01,\n",
      "                     4.8399e-01, -2.9321e-02, -2.3989e-01,  6.3463e-01,\n",
      "                    -4.4899e-02, -2.4905e-01, -3.2987e-03, -6.1612e-01,\n",
      "                     2.8955e-01, -1.1674e-01, -6.5240e-02,  3.3683e-01,\n",
      "                    -1.6585e-01,  2.3512e-01,  3.8283e-01, -6.0842e-02,\n",
      "                     9.9876e-02,  1.4184e-01, -3.2620e-02,  3.3555e-01,\n",
      "                     1.3836e-01, -2.8937e-01, -3.7092e-01, -1.6787e-01,\n",
      "                     2.5052e-01,  1.2682e-01,  5.2907e-01,  4.1032e-01,\n",
      "                     1.5412e-01,  1.6750e-01,  3.8356e-01,  1.4349e-01,\n",
      "                    -1.8949e-01,  2.4245e-01,  1.4148e-01,  3.5497e-01,\n",
      "                    -6.5057e-02, -4.4275e-01, -9.3646e-02,  1.5211e-02,\n",
      "                     4.5632e-02,  2.4373e-02,  4.6328e-01,  1.5980e-01,\n",
      "                    -1.0391e-01, -3.5516e-01,  3.5791e-01, -6.7989e-02,\n",
      "                    -1.0739e-01,  1.1124e-01, -5.9010e-02, -7.0738e-02,\n",
      "                    -2.1185e-01,  1.0043e-01,  3.5827e-01,  3.6890e-01,\n",
      "                     1.8436e-01,  3.0329e-01,  7.3872e-01, -1.6695e-01,\n",
      "                    -1.9279e-01,  2.9321e-02, -9.5295e-02,  1.2242e-01,\n",
      "                     5.6132e-01, -2.5345e-01, -5.0946e-02, -1.4294e-02,\n",
      "                    -2.4190e-02,  1.7171e-01,  1.4661e-01,  1.5027e-02,\n",
      "                    -1.0996e-03,  4.2974e-01,  1.5944e-01,  1.7465e-01,\n",
      "                    -4.9480e-02, -3.1007e-01,  6.4324e-02,  1.5889e-01,\n",
      "                     2.6206e-01,  1.0996e-01,  2.9157e-01, -1.3854e-01,\n",
      "                     1.8399e-01,  3.4013e-01,  2.7251e-01,  6.3958e-02,\n",
      "                    -1.1325e-01,  1.7226e-01,  6.0476e-02,  9.9693e-02,\n",
      "                    -8.4483e-02, -2.5638e-01,  1.2150e-01,  1.9554e-01,\n",
      "                     3.7751e-01,  2.8900e-01, -1.6365e-01,  3.6817e-01,\n",
      "                    -3.9474e-01,  5.7140e-01, -2.7489e-01,  1.1949e-01,\n",
      "                     2.4777e-01,  7.2772e-01,  1.6383e-01,  4.5265e-02,\n",
      "                    -8.6315e-02,  5.5528e-02, -6.0842e-02, -6.3518e-01,\n",
      "                     5.5986e-01, -1.3854e-01,  1.8234e-01,  2.5583e-01,\n",
      "                     1.7959e-01, -9.1630e-02,  4.0775e-01,  1.0061e-01,\n",
      "                     1.5944e-02,  1.0427e-01,  1.3341e-01,  1.5705e-01,\n",
      "                     5.0030e-02,  3.1887e-01,  2.4612e-01,  5.0763e-02,\n",
      "                     3.7715e-01,  8.1367e-02,  5.6755e-01, -4.4440e-01,\n",
      "                    -9.0164e-02,  4.1178e-01,  1.7336e-01,  2.2889e-01,\n",
      "                     2.4428e-01, -2.0195e-01,  2.1606e-01, -1.4129e-01,\n",
      "                    -2.7177e-01,  2.2797e-01,  3.7403e-01,  2.1441e-01,\n",
      "                     7.1471e-02,  4.9150e-01, -6.8356e-02,  2.2779e-01,\n",
      "                     8.0268e-02,  6.5607e-02,  1.4111e-01,  2.6261e-01,\n",
      "                    -3.9584e-01,  4.1765e-01,  1.1967e-01,  3.0604e-01,\n",
      "                     3.1557e-01, -2.3109e-01,  1.5394e-02,  1.4936e-01,\n",
      "                     1.6090e-01, -5.0048e-01,  2.5473e-01, -7.9718e-02,\n",
      "                     2.8588e-02, -2.4923e-02, -1.3195e-02,  7.9351e-02,\n",
      "                    -1.8216e-01,  4.1966e-02,  1.2645e-02, -1.2022e-01,\n",
      "                     7.6969e-02, -2.0837e-01,  1.4441e-01, -1.1124e-01,\n",
      "                    -2.6847e-01,  7.2754e-02, -9.2913e-02,  2.1845e-01,\n",
      "                    -4.9480e-02, -1.5302e-01,  9.7494e-02, -7.2571e-02,\n",
      "                    -2.1570e-01,  5.2815e-01,  5.9394e-01,  1.6475e-01,\n",
      "                     1.2022e-01,  5.6022e-01,  1.5046e-01, -2.3512e-01,\n",
      "                     2.9028e-01,  3.7751e-02, -4.9847e-02,  2.9963e-01,\n",
      "                     4.5210e-01, -4.0427e-01,  4.4660e-01, -6.2235e-01,\n",
      "                     1.5449e-01, -2.3402e-01, -2.4373e-02,  3.8558e-01,\n",
      "                     4.5558e-01,  1.6768e-01, -8.1917e-02, -8.6132e-03,\n",
      "                     3.4581e-01,  9.7494e-02, -6.2858e-02,  1.7886e-01,\n",
      "                     3.6395e-01, -1.5046e-01,  2.5326e-01, -1.0996e-02,\n",
      "                     1.3470e-01, -1.2517e-01, -3.6469e-02,  5.8826e-02,\n",
      "                    -4.3799e-02,  1.8326e-02,  3.3573e-01,  7.1288e-02,\n",
      "                    -1.2535e-01,  9.1630e-03,  2.1551e-01,  2.0708e-01,\n",
      "                     1.8088e-01, -1.9975e-02, -4.2516e-02,  2.4282e-01,\n",
      "                     1.5339e-01, -2.2504e-01,  7.7665e-01, -6.8356e-02,\n",
      "                    -2.0928e-01,  1.4954e-01,  3.9272e-01, -3.2437e-02,\n",
      "                     2.8808e-01,  3.7202e-02,  1.8308e-01,  5.4135e-01,\n",
      "                    -2.1808e-01,  1.6072e-01, -7.0921e-02, -1.1545e-02,\n",
      "                     6.2858e-02,  2.0653e-01, -1.0263e-01,  3.0641e-01,\n",
      "                     4.3139e-01, -2.6518e-01,  1.2187e-01, -2.2541e-02,\n",
      "                     1.4624e-01,  3.5571e-01,  2.2816e-01,  2.3347e-01,\n",
      "                     4.2131e-01,  3.3720e-01,  8.5399e-02, -2.0159e-03,\n",
      "                     3.0623e-01,  4.6420e-01, -9.9693e-02, -2.2688e-01,\n",
      "                    -5.0946e-02,  1.1857e-01,  4.5082e-02,  2.4502e-01,\n",
      "                     2.6957e-01,  4.3487e-01, -2.7251e-01,  2.7800e-01,\n",
      "                     2.3237e-01, -2.0653e-01, -6.1575e-02,  5.6261e-02,\n",
      "                     6.4874e-02,  5.6352e-01,  3.4929e-01,  4.4715e-02,\n",
      "                     3.4434e-01,  2.5785e-01,  1.2846e-01, -1.9975e-02,\n",
      "                     3.7751e-02,  1.0427e-01,  3.9566e-01, -6.0109e-02,\n",
      "                    -5.1991e-01, -3.0623e-01, -6.0842e-02,  7.5026e-01,\n",
      "                     7.8472e-01,  1.5595e-01,  3.2272e-01,  3.3536e-01,\n",
      "                     1.4697e-01, -4.0299e-01,  6.1575e-02,  6.0805e-01,\n",
      "                    -4.8380e-02,  3.5571e-01,  3.5552e-02,  1.9554e-01,\n",
      "                     2.7617e-01,  4.1435e-01,  3.1557e-01, -2.8039e-02,\n",
      "                    -2.1588e-01, -3.7568e-02,  1.0226e-01,  1.7483e-01,\n",
      "                     1.6933e-01,  5.7965e-01,  2.5950e-01, -2.3604e-01,\n",
      "                     2.1258e-01,  3.4819e-02,  1.0061e-01,  5.0121e-01,\n",
      "                    -7.9535e-02,  4.8271e-01, -4.3744e-01, -1.3561e-02,\n",
      "                     2.0342e-02, -2.4557e-02,  3.9547e-01,  1.2901e-01,\n",
      "                     4.6988e-01, -4.0647e-01,  2.5052e-01,  5.3420e-01,\n",
      "                     3.2693e-01, -7.1251e-01, -2.0892e-02,  3.3408e-01,\n",
      "                     3.1814e-01, -2.6316e-01,  4.4147e-01,  2.6976e-01,\n",
      "                    -4.2150e-02,  1.2297e-01,  2.4264e-01,  1.6878e-01,\n",
      "                     4.8380e-01,  2.8094e-01,  6.3591e-02,  9.2363e-02,\n",
      "                     3.5277e-01,  6.9639e-02, -1.5082e-01,  1.7886e-01,\n",
      "                     6.9932e-01,  4.9187e-01, -1.2938e-01,  7.9351e-02,\n",
      "                     3.0549e-01,  1.6328e-01,  4.4312e-01,  8.6132e-02,\n",
      "                     3.0714e-01, -1.9737e-01, -3.9566e-01,  4.1050e-02,\n",
      "                     2.7910e-01, -1.5449e-01, -3.0769e-01,  5.5857e-01,\n",
      "                    -8.4483e-02,  2.7342e-01,  3.8521e-01, -1.1362e-02,\n",
      "                     1.3689e-01, -1.4734e-01,  1.7978e-01,  3.9181e-01,\n",
      "                     2.0727e-01,  3.5003e-02,  2.3531e-01, -5.1771e-01,\n",
      "                     3.0916e-01, -6.6523e-02,  9.1630e-03,  3.2235e-01,\n",
      "                     3.6579e-01, -5.4611e-02,  2.1991e-03,  1.5394e-02,\n",
      "                     3.2144e-01, -9.8227e-02,  3.6579e-01,  1.8839e-01,\n",
      "                    -2.2101e-01,  2.3824e-01, -4.1820e-01,  1.7538e-01,\n",
      "                    -4.3194e-01,  1.3305e-01,  1.8637e-01,  2.2046e-01,\n",
      "                     6.2308e-02,  7.6419e-02,  1.2553e-01,  7.6969e-02,\n",
      "                     4.2131e-01,  1.8326e-01,  5.4776e-01,  3.6047e-01,\n",
      "                     5.8276e-02,  1.7776e-02,  3.9841e-01,  2.1771e-01,\n",
      "                    -4.3872e-01, -3.5607e-01,  1.3231e-01,  2.1899e-01,\n",
      "                    -3.8503e-01,  2.4557e-02,  3.6982e-01,  6.8539e-02,\n",
      "                    -3.6469e-02, -3.1960e-01, -5.9834e-01,  1.1655e-01,\n",
      "                    -3.2254e-02,  2.9761e-01,  3.1905e-01, -1.1692e-01,\n",
      "                     1.5357e-01,  2.3476e-01, -3.7513e-01,  2.9212e-01,\n",
      "                    -3.1960e-01,  9.5295e-02, -4.7281e-02,  8.5216e-02,\n",
      "                    -2.6444e-01,  2.2504e-01, -3.6927e-01, -2.8827e-01,\n",
      "                    -1.1454e-01, -5.4171e-01, -1.3726e-01, -2.6371e-01,\n",
      "                    -1.0904e-01, -4.9755e-01, -1.9939e-01, -1.1454e-01,\n",
      "                    -4.3872e-01, -1.9206e-01, -2.5730e-01, -2.5675e-01,\n",
      "                    -3.0256e-01, -4.1838e-01, -1.7336e-01, -2.4722e-01,\n",
      "                    -3.8210e-01, -5.7727e-02, -2.9816e-01, -4.5723e-01,\n",
      "                    -1.8564e-01, -6.3041e-02, -8.6132e-02, -2.6609e-01,\n",
      "                    -9.5478e-02, -1.1325e-01,  9.0530e-02, -1.6420e-01,\n",
      "                    -4.5815e-03, -2.1753e-01, -5.6627e-02, -6.5277e-01,\n",
      "                    -1.5944e-01, -6.4141e-02,  5.7562e-01,  6.3408e-02,\n",
      "                     1.2278e-01, -1.4001e-01, -2.9212e-01,  5.6499e-01,\n",
      "                    -4.8271e-01, -3.1356e-01, -1.5632e-01, -1.9920e-01,\n",
      "                    -3.9218e-01, -1.1564e-01, -2.5638e-01, -6.6560e-01,\n",
      "                    -2.1936e-01, -2.6206e-02, -1.0959e-01,  3.0788e-02,\n",
      "                    -2.2761e-01, -1.6347e-01, -1.9206e-01, -2.9193e-01,\n",
      "                    -1.9242e-01, -1.4294e-01, -1.0079e-01, -3.7147e-01,\n",
      "                    -3.0751e-01, -1.0556e-01, -3.4416e-01, -2.1057e-01,\n",
      "                    -1.4551e-01, -2.3769e-01,  4.2333e-02,  2.4923e-01]],\n",
      "                  device='cuda:0', grad_fn=<AliasBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(sim.model(dummy_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MobileNetV2(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2dNormActivation(\n",
      "      (0): QuantizedConv2d(\n",
      "        3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (1): QuantizedBatchNorm2d(\n",
      "        32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): None\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (2): QuantizedReLU6(\n",
      "        inplace=True\n",
      "        (param_quantizers): ModuleDict()\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): QuantizedConv2d(\n",
      "          32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedBatchNorm2d(\n",
      "          16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (4): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (6): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (7): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (8): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (9): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (10): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (11): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (12): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (13): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (14): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (15): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (16): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (17): InvertedResidual(\n",
      "      (conv): Sequential(\n",
      "        (0): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): Conv2dNormActivation(\n",
      "          (0): QuantizedConv2d(\n",
      "            960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (1): QuantizedBatchNorm2d(\n",
      "            960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "            (param_quantizers): ModuleDict(\n",
      "              (weight): None\n",
      "              (bias): None\n",
      "            )\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "          )\n",
      "          (2): QuantizedReLU6(\n",
      "            inplace=True\n",
      "            (param_quantizers): ModuleDict()\n",
      "            (input_quantizers): ModuleList(\n",
      "              (0): None\n",
      "            )\n",
      "            (output_quantizers): ModuleList(\n",
      "              (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): QuantizedConv2d(\n",
      "          960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "        )\n",
      "        (3): QuantizedBatchNorm2d(\n",
      "          320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "          (param_quantizers): ModuleDict(\n",
      "            (weight): None\n",
      "            (bias): None\n",
      "          )\n",
      "          (input_quantizers): ModuleList(\n",
      "            (0): None\n",
      "          )\n",
      "          (output_quantizers): ModuleList(\n",
      "            (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (18): Conv2dNormActivation(\n",
      "      (0): QuantizedConv2d(\n",
      "        320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (1): QuantizedBatchNorm2d(\n",
      "        1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True\n",
      "        (param_quantizers): ModuleDict(\n",
      "          (weight): None\n",
      "          (bias): None\n",
      "        )\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "      )\n",
      "      (2): QuantizedReLU6(\n",
      "        inplace=True\n",
      "        (param_quantizers): ModuleDict()\n",
      "        (input_quantizers): ModuleList(\n",
      "          (0): None\n",
      "        )\n",
      "        (output_quantizers): ModuleList(\n",
      "          (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): QuantizedDropout(\n",
      "      p=0.2, inplace=False\n",
      "      (param_quantizers): ModuleDict()\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "    )\n",
      "    (1): QuantizedLinear(\n",
      "      in_features=1280, out_features=1000, bias=True\n",
      "      (param_quantizers): ModuleDict(\n",
      "        (weight): QuantizeDequantize(shape=(), qmin=-128, qmax=127, symmetric=True)\n",
      "        (bias): None\n",
      "      )\n",
      "      (input_quantizers): ModuleList(\n",
      "        (0): None\n",
      "      )\n",
      "      (output_quantizers): ModuleList(\n",
      "        (0): QuantizeDequantize(shape=(), qmin=0, qmax=65535, symmetric=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(sim.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-19 17:37:29,436 - Utils - INFO - successfully created onnx model with 140/222 node names updated\n",
      "2025-02-19 17:37:29,482 - Quant - WARNING - The following layers were not found in the exported onnx model. Encodings for these layers will not appear in the exported encodings file, however it will continue to exist in torch encoding file:\n",
      "['classifier.0']\n",
      "This can be due to several reasons:\n",
      "\t- The layer is set to quantize with float datatype, but was not exercised in compute encodings. Not an issue if the layer is not meant to be run.\n",
      "\t- The layer has valid encodings but was not seen while exporting to onnx using the dummy input provided in sim.export(). Ensure that the dummy input covers all layers.\n",
      "2025-02-19 17:37:29,483 - Quant - INFO - Layers excluded from quantization: []\n",
      "2025-02-19 17:37:29,483 - Quant - WARNING - \u001b[31;21mQuantsim export will stop exporting encodings for saving and loading in a future AIMET release.\n",
      "To export encodings for saving and loading, use QuantizationSimModel's save_encodings_to_json() utility instead.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "sim.export(path='tmp', filename_prefix='quantized_mobilenet_v2', dummy_input=dummy_input.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: features.0.0.weight\n",
      "Weights: tensor([[[[-6.3108e-02, -1.8766e-01, -1.5188e-01],\n",
      "          [-4.9379e-01, -6.4248e-01, -5.8935e-01],\n",
      "          [-6.8005e-01, -9.7448e-01, -7.6317e-01]],\n",
      "\n",
      "         [[-1.6350e-02, -1.8482e-02,  6.2783e-02],\n",
      "          [ 3.5436e-02,  5.8980e-02,  1.0693e-01],\n",
      "          [ 1.6995e-01,  1.4699e-01,  1.8521e-01]],\n",
      "\n",
      "         [[ 1.1395e-01,  1.6316e-01,  1.0483e-01],\n",
      "          [ 4.0824e-01,  5.7489e-01,  4.7270e-01],\n",
      "          [ 5.7547e-01,  7.1503e-01,  5.3702e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9983e-03,  1.4297e-02,  5.9918e-02],\n",
      "          [ 5.5779e-03,  3.0330e-02, -4.5050e-02],\n",
      "          [ 1.2600e-01,  5.5075e-02, -9.2239e-01]],\n",
      "\n",
      "         [[ 4.2316e-03, -6.6995e-02, -7.4151e-02],\n",
      "          [ 1.4910e-02,  1.5604e-02, -6.8112e-02],\n",
      "          [ 2.4632e-02, -4.4099e-02, -7.3383e-01]],\n",
      "\n",
      "         [[-9.1925e-03, -3.3236e-02,  1.0019e-01],\n",
      "          [ 3.9586e-03,  5.4139e-02,  1.0663e-01],\n",
      "          [ 1.0968e-01,  3.5723e-02, -3.9510e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2649e-01, -1.5025e-01,  2.4107e-02],\n",
      "          [ 6.7298e-01, -7.3204e-01,  5.9724e-02],\n",
      "          [ 6.7486e-01, -7.4353e-01,  6.6735e-02]],\n",
      "\n",
      "         [[ 2.2576e-01, -2.8267e-01,  9.2581e-02],\n",
      "          [ 1.1130e+00, -1.1783e+00, -1.2675e-02],\n",
      "          [ 1.0229e+00, -1.0997e+00,  9.1427e-02]],\n",
      "\n",
      "         [[-1.0309e-03, -7.3701e-03,  1.4532e-02],\n",
      "          [ 3.5864e-01, -4.3105e-01,  4.8293e-02],\n",
      "          [ 3.4249e-01, -3.9095e-01,  6.2845e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9063e-01, -2.1703e-02,  2.1708e-01],\n",
      "          [-3.3194e-01,  8.8984e-02,  3.1595e-01],\n",
      "          [ 1.1153e-01, -2.0132e-02, -1.2743e-01]],\n",
      "\n",
      "         [[-4.1511e-01, -1.5042e-02,  3.6632e-01],\n",
      "          [-4.0987e-01,  1.4164e-01,  5.1298e-01],\n",
      "          [ 1.0206e-01, -1.4003e-01, -2.3454e-01]],\n",
      "\n",
      "         [[-1.2547e-01, -5.8624e-03,  1.6301e-01],\n",
      "          [-1.7890e-01,  2.7285e-02,  1.9681e-01],\n",
      "          [ 3.8072e-02, -1.1414e-02, -3.7176e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1460e-02, -1.5710e-01,  1.2891e-01],\n",
      "          [ 9.5111e-01, -1.0478e+00,  7.0390e-02],\n",
      "          [ 9.0578e-01, -9.9058e-01,  1.1389e-01]],\n",
      "\n",
      "         [[ 9.0173e-02, -2.4164e-01,  1.7184e-01],\n",
      "          [ 1.6654e+00, -1.8639e+00,  1.6213e-01],\n",
      "          [ 1.4305e+00, -1.6406e+00,  2.3614e-01]],\n",
      "\n",
      "         [[ 4.2059e-02, -9.9022e-02,  5.5216e-02],\n",
      "          [ 5.8131e-01, -6.1206e-01,  4.6993e-02],\n",
      "          [ 5.1095e-01, -5.6993e-01,  5.2198e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0025e-02, -8.9831e-02,  7.0567e-02],\n",
      "          [-6.2591e-02, -3.6622e-01, -7.4632e-02],\n",
      "          [ 3.9007e-02, -7.6280e-02,  5.9376e-01]],\n",
      "\n",
      "         [[ 5.3733e-04, -1.5370e-01,  7.3156e-02],\n",
      "          [-1.2556e-01, -8.1988e-01, -4.0643e-04],\n",
      "          [ 1.0827e-01, -1.8564e-01,  1.2043e+00]],\n",
      "\n",
      "         [[ 1.0083e-02, -6.6229e-02,  2.6713e-02],\n",
      "          [-6.2522e-02, -1.7091e-01, -3.7039e-02],\n",
      "          [ 3.3739e-03, -5.4554e-02,  3.1005e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2633e-01, -3.1430e-01, -8.0592e-02],\n",
      "          [ 6.3337e-02, -1.2931e-02,  9.8636e-03],\n",
      "          [ 4.4366e-02, -1.0503e-01, -1.3218e-01]],\n",
      "\n",
      "         [[-1.5831e-02,  2.9931e-02,  2.7480e-02],\n",
      "          [ 7.9076e-02,  3.1479e-01,  1.3513e-01],\n",
      "          [-1.0124e-01, -1.1418e-01, -1.7459e-01]],\n",
      "\n",
      "         [[ 5.7943e-02,  5.3078e-01,  1.7641e-01],\n",
      "          [ 8.4426e-02,  8.2810e-01,  3.6864e-01],\n",
      "          [-1.0976e-01,  1.2883e-01, -7.3352e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4989e-01,  1.5511e-01,  1.8277e-02],\n",
      "          [-7.5067e-02, -3.9095e-01, -2.2539e-01],\n",
      "          [ 5.3553e-02, -3.2975e-02,  2.2271e-03]],\n",
      "\n",
      "         [[ 8.8964e-01,  3.7630e-01,  1.6020e-01],\n",
      "          [-7.6890e-02, -8.8736e-01, -4.3854e-01],\n",
      "          [ 5.7299e-02, -5.7675e-02, -4.6108e-02]],\n",
      "\n",
      "         [[ 2.8124e-01,  6.8133e-02,  5.7941e-02],\n",
      "          [-4.4408e-02, -2.3539e-01, -1.0597e-01],\n",
      "          [ 2.8994e-02, -3.2856e-02,  7.8189e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.6281e-02, -5.7937e-02, -4.3937e-02],\n",
      "          [ 9.0735e-03,  1.3916e-01, -7.9150e-03],\n",
      "          [-3.8555e-02, -1.2932e-02, -9.1438e-02]],\n",
      "\n",
      "         [[ 1.3477e-01,  5.7015e-01,  6.1717e-01],\n",
      "          [ 3.3894e-01,  1.0945e+00,  1.0415e+00],\n",
      "          [-4.4605e-02,  3.2533e-01,  2.4988e-01]],\n",
      "\n",
      "         [[-1.3150e-01, -5.3689e-01, -5.7689e-01],\n",
      "          [-2.8067e-01, -8.9386e-01, -9.0974e-01],\n",
      "          [ 3.0480e-02, -3.5946e-01, -3.3129e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5202e-02,  6.7297e-02,  1.1581e-02],\n",
      "          [ 3.0848e-02, -2.2521e-01, -5.0964e-02],\n",
      "          [-2.1193e-02, -5.4927e-01, -2.2358e-01]],\n",
      "\n",
      "         [[ 3.6336e-02,  1.2003e-01,  1.0872e-01],\n",
      "          [ 3.4592e-02, -4.6312e-01, -1.8739e-01],\n",
      "          [-8.6748e-02, -8.6480e-01, -5.0257e-01]],\n",
      "\n",
      "         [[-3.2263e-02, -4.6266e-03, -4.2814e-02],\n",
      "          [ 4.0989e-03,  4.9871e-02, -1.6867e-02],\n",
      "          [-1.0984e-02, -1.5952e-02, -8.5527e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6813e-03, -2.0950e-02,  1.0321e-01],\n",
      "          [ 2.8623e-02, -1.0510e-01,  5.4155e-01],\n",
      "          [-8.7686e-02, -3.9274e-01, -7.4930e-02]],\n",
      "\n",
      "         [[ 2.1687e-02, -3.2457e-02,  2.5844e-01],\n",
      "          [ 9.3187e-02, -3.0333e-01,  1.1068e+00],\n",
      "          [-1.3829e-01, -8.3726e-01, -1.5081e-01]],\n",
      "\n",
      "         [[ 1.2504e-02, -3.1581e-02,  9.7049e-02],\n",
      "          [-6.8633e-03, -5.2405e-02,  2.7689e-01],\n",
      "          [-5.0215e-02, -1.9690e-01, -5.2774e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4322e-03, -7.7974e-02,  2.4713e-02],\n",
      "          [ 1.1972e-01, -5.5139e-02,  1.1026e-01],\n",
      "          [-4.9709e-01, -1.7255e-01,  8.3711e-02]],\n",
      "\n",
      "         [[ 2.4634e-02, -2.5033e-02,  6.3014e-02],\n",
      "          [ 1.0156e-01, -4.6482e-02,  4.3943e-02],\n",
      "          [-3.3659e-01, -6.3855e-02,  5.2790e-02]],\n",
      "\n",
      "         [[ 2.2542e-02, -3.1942e-02, -9.9265e-03],\n",
      "          [ 5.2683e-02, -2.3995e-02, -4.2422e-02],\n",
      "          [ 6.1511e-03,  1.0269e-01,  1.3343e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2030e-01, -4.2881e-03,  1.2525e-01],\n",
      "          [-9.6667e-03,  1.2808e-01,  1.6959e-01],\n",
      "          [ 6.4296e-02,  4.9177e-02, -1.4363e-01]],\n",
      "\n",
      "         [[ 9.3911e-02,  1.2769e-01,  6.7019e-02],\n",
      "          [ 9.2397e-02, -2.4380e-03, -2.1277e-01],\n",
      "          [ 2.4836e-01, -1.7409e-03, -4.7832e-01]],\n",
      "\n",
      "         [[-7.3533e-02, -8.3743e-02, -1.2825e-01],\n",
      "          [-4.9601e-02, -1.5993e-01, -4.0318e-01],\n",
      "          [ 1.4418e-02, -2.0640e-01, -6.8773e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9578e-17,  5.4964e-17,  4.0560e-17],\n",
      "          [ 3.4623e-17,  4.2001e-17,  2.8739e-17],\n",
      "          [ 1.5971e-17,  2.7824e-17,  2.8468e-17]],\n",
      "\n",
      "         [[ 1.7691e-17,  2.2488e-17, -4.6646e-18],\n",
      "          [ 1.7656e-17,  2.0812e-17,  6.3410e-18],\n",
      "          [ 3.1096e-18,  8.4611e-18, -8.3258e-18]],\n",
      "\n",
      "         [[ 6.7496e-19,  2.3360e-18, -8.8849e-18],\n",
      "          [-6.2217e-18, -5.7158e-18,  4.4253e-18],\n",
      "          [-8.3838e-18, -1.6980e-18, -2.4405e-18]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6187e-02, -5.9923e-02,  3.3357e-02],\n",
      "          [-8.6558e-02, -1.1710e-01, -1.5908e-01],\n",
      "          [-5.5892e-02,  2.0884e-01,  5.9444e-01]],\n",
      "\n",
      "         [[ 4.0159e-02, -9.3325e-02,  1.3166e-01],\n",
      "          [-2.1915e-01, -7.3873e-02, -3.8949e-03],\n",
      "          [-1.3423e-01,  2.9179e-01,  8.0891e-01]],\n",
      "\n",
      "         [[ 1.4765e-02, -7.1611e-02,  1.8672e-02],\n",
      "          [-5.5121e-02, -8.8543e-02, -7.8880e-02],\n",
      "          [-2.5229e-02,  1.3414e-01,  4.6638e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4690e-01,  2.1926e-01,  5.3029e-02],\n",
      "          [ 5.8891e-01,  8.2946e-01,  3.0994e-01],\n",
      "          [ 1.0423e+00,  1.1847e+00,  4.2832e-01]],\n",
      "\n",
      "         [[-1.2859e-01, -1.7304e-01, -4.1763e-02],\n",
      "          [-3.4404e-01, -4.6775e-01, -1.9919e-01],\n",
      "          [-4.0979e-01, -4.8466e-01, -2.0872e-01]],\n",
      "\n",
      "         [[-3.0979e-02, -7.4061e-02, -9.7713e-03],\n",
      "          [-2.6998e-01, -4.3212e-01, -8.2540e-02],\n",
      "          [-6.1460e-01, -6.7769e-01, -1.6677e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1805e-01, -9.6279e-01, -1.5261e-02],\n",
      "          [ 2.9034e-01,  1.0530e+00,  1.5144e-01],\n",
      "          [-1.8623e-01, -5.6081e-02, -1.4682e-01]],\n",
      "\n",
      "         [[-1.3622e-01, -1.4321e+00, -3.8721e-02],\n",
      "          [ 5.2778e-01,  1.6753e+00,  3.5717e-01],\n",
      "          [-4.2408e-01, -2.0844e-01, -3.2538e-01]],\n",
      "\n",
      "         [[-5.3212e-02, -5.5743e-01,  4.5195e-03],\n",
      "          [ 1.4686e-01,  6.4422e-01,  6.7543e-02],\n",
      "          [-1.0445e-01, -5.5421e-02, -9.3682e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0820e-01, -1.3018e-01,  4.6164e-02],\n",
      "          [ 2.3627e-02, -8.5943e-01,  7.7085e-01],\n",
      "          [ 7.0663e-02, -7.7828e-01,  7.5455e-01]],\n",
      "\n",
      "         [[ 2.2331e-01, -2.4350e-01,  7.9593e-02],\n",
      "          [ 3.4355e-02, -1.2878e+00,  1.0858e+00],\n",
      "          [ 1.4973e-01, -1.1448e+00,  1.0338e+00]],\n",
      "\n",
      "         [[ 8.6060e-02, -5.7519e-02, -3.8344e-02],\n",
      "          [ 1.9714e-03, -5.3869e-01,  5.3752e-01],\n",
      "          [ 1.9351e-03, -4.7707e-01,  4.5895e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9196e-02,  2.1047e-02,  1.6275e-01],\n",
      "          [ 1.2301e-01, -3.2168e-01, -2.9806e-01],\n",
      "          [ 1.7663e-01, -2.0355e-01, -2.5371e-01]],\n",
      "\n",
      "         [[-8.7093e-04,  5.2870e-02,  3.3130e-02],\n",
      "          [ 5.4699e-02, -3.7649e-01, -4.6097e-01],\n",
      "          [ 5.2894e-02, -3.7830e-01, -4.9596e-01]],\n",
      "\n",
      "         [[-3.8744e-02,  6.8300e-02,  5.4475e-02],\n",
      "          [ 7.0257e-02, -1.4492e-01, -2.4585e-01],\n",
      "          [ 5.4091e-02, -7.7883e-02, -1.5300e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.4538e-01, -9.2383e-01, -6.9041e-01],\n",
      "          [ 7.7942e-01,  1.6503e+00,  8.7853e-01],\n",
      "          [-2.7195e-01, -4.9448e-01, -3.3044e-01]],\n",
      "\n",
      "         [[-7.6631e-01, -1.3475e+00, -8.6426e-01],\n",
      "          [ 1.1050e+00,  2.2459e+00,  1.1861e+00],\n",
      "          [-3.6525e-01, -6.6076e-01, -3.9021e-01]],\n",
      "\n",
      "         [[-2.8621e-01, -5.4791e-01, -3.4948e-01],\n",
      "          [ 4.2653e-01,  1.0436e+00,  5.5337e-01],\n",
      "          [-1.5862e-01, -4.0578e-01, -2.2147e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8209e-03, -3.2519e-01, -2.8348e-01],\n",
      "          [ 3.3506e-01,  2.5524e-01,  1.1688e-02],\n",
      "          [ 3.6047e-02,  3.7303e-02, -1.7237e-02]],\n",
      "\n",
      "         [[-8.0229e-02, -7.2748e-01, -6.2011e-01],\n",
      "          [ 7.9651e-01,  6.2221e-01,  1.5411e-01],\n",
      "          [ 4.5067e-02, -3.5878e-02, -7.9207e-02]],\n",
      "\n",
      "         [[-1.9919e-02, -1.9552e-01, -1.5398e-01],\n",
      "          [ 2.3802e-01,  1.3166e-01,  5.4832e-03],\n",
      "          [-1.9837e-02,  3.2758e-02,  1.6308e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3067e-02, -1.6271e-01, -1.6606e-01],\n",
      "          [-2.8478e-01, -4.1181e-01, -3.3369e-01],\n",
      "          [-3.9702e-01, -5.2222e-01, -2.9572e-01]],\n",
      "\n",
      "         [[ 1.1121e-01,  3.4395e-01,  1.6040e-01],\n",
      "          [ 5.5069e-01,  9.8467e-01,  6.0292e-01],\n",
      "          [ 7.9991e-01,  1.2273e+00,  8.4450e-01]],\n",
      "\n",
      "         [[-4.6157e-02, -2.0538e-01,  4.1712e-06],\n",
      "          [-3.1632e-01, -6.3407e-01, -2.7254e-01],\n",
      "          [-3.8782e-01, -8.0559e-01, -5.0330e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4390e-02,  2.1508e-02,  1.1723e-02],\n",
      "          [-5.4224e-01, -1.1592e+00, -2.9346e-01],\n",
      "          [ 5.1555e-01,  1.1812e+00,  2.5774e-01]],\n",
      "\n",
      "         [[ 2.3498e-02, -4.4873e-02,  1.0335e-01],\n",
      "          [-8.1933e-01, -2.0528e+00, -4.9998e-01],\n",
      "          [ 7.6768e-01,  2.0742e+00,  4.2068e-01]],\n",
      "\n",
      "         [[ 1.4207e-02, -6.9347e-04,  1.2788e-02],\n",
      "          [-2.6861e-01, -6.2116e-01, -8.1165e-02],\n",
      "          [ 2.2904e-01,  6.0848e-01,  7.8574e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2633e-02,  2.2196e-01,  1.1862e-01],\n",
      "          [ 1.9674e-01,  3.6300e-01,  3.1765e-01],\n",
      "          [ 2.1826e-01,  4.0048e-01,  2.7987e-01]],\n",
      "\n",
      "         [[-2.1739e-01, -4.7843e-01, -2.5212e-01],\n",
      "          [-5.6329e-01, -9.9938e-01, -6.5538e-01],\n",
      "          [-6.8013e-01, -1.1713e+00, -8.6992e-01]],\n",
      "\n",
      "         [[ 1.1670e-01,  2.7000e-01,  1.9417e-01],\n",
      "          [ 3.5852e-01,  6.1727e-01,  4.1898e-01],\n",
      "          [ 5.2598e-01,  7.5598e-01,  4.6438e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1432e-02, -1.5728e-01,  5.9200e-02],\n",
      "          [ 6.8278e-01, -6.9446e-01,  1.2221e-02],\n",
      "          [ 6.4092e-01, -6.6526e-01,  5.0217e-02]],\n",
      "\n",
      "         [[ 1.9827e-01, -2.1453e-01,  3.2063e-02],\n",
      "          [ 1.1111e+00, -1.1431e+00,  5.5392e-02],\n",
      "          [ 9.3968e-01, -1.0102e+00,  5.1862e-02]],\n",
      "\n",
      "         [[-1.1294e-02, -7.6501e-03,  5.6847e-02],\n",
      "          [ 4.2223e-01, -5.3620e-01,  4.3200e-02],\n",
      "          [ 3.9580e-01, -4.2915e-01,  8.2356e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6184e-02,  7.2007e-01,  4.9063e-01],\n",
      "          [ 3.0464e-01,  1.4807e+00,  1.0120e+00],\n",
      "          [-1.2676e-01,  4.5031e-01,  2.0662e-01]],\n",
      "\n",
      "         [[-1.6664e-01, -6.7651e-01, -4.7091e-01],\n",
      "          [-2.4501e-01, -9.3582e-01, -7.6905e-01],\n",
      "          [ 4.0048e-02, -4.0938e-01, -3.6880e-01]],\n",
      "\n",
      "         [[ 4.9491e-02, -2.5192e-02,  1.6667e-02],\n",
      "          [ 1.5346e-02, -1.6299e-01, -4.1588e-02],\n",
      "          [ 2.2358e-02, -1.9023e-02, -5.6675e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2617e-03,  1.1628e-01, -1.4966e-01],\n",
      "          [-1.7737e-01,  9.0415e-01, -7.7968e-01],\n",
      "          [-1.2917e-01,  8.8658e-01, -6.3615e-01]],\n",
      "\n",
      "         [[ 7.1681e-02,  2.6763e-01, -2.2828e-01],\n",
      "          [-1.8326e-01,  1.3076e+00, -1.2497e+00],\n",
      "          [-1.0383e-01,  1.2653e+00, -1.0593e+00]],\n",
      "\n",
      "         [[ 4.8256e-02,  1.3945e-02, -3.2131e-02],\n",
      "          [-1.8211e-01,  6.4112e-01, -5.2627e-01],\n",
      "          [-1.4267e-01,  6.3035e-01, -4.1425e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0104e-02,  4.6287e-03, -1.2321e-02],\n",
      "          [-3.4887e-01, -4.1664e-01, -6.7217e-02],\n",
      "          [-1.1803e-02, -1.4742e-01, -4.2432e-02]],\n",
      "\n",
      "         [[-9.2254e-05,  9.4569e-03,  5.5899e-02],\n",
      "          [-6.3504e-01, -7.9261e-01, -1.6051e-01],\n",
      "          [-2.0672e-02, -2.8181e-01, -5.8319e-02]],\n",
      "\n",
      "         [[ 1.4462e-02, -1.9225e-02, -1.5334e-02],\n",
      "          [-2.2606e-01, -2.8504e-01, -5.6084e-02],\n",
      "          [ 9.0715e-02, -6.5981e-02, -2.1934e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9810e-01,  1.4182e-01,  6.7656e-02],\n",
      "          [ 4.3522e-02,  7.6264e-01, -7.9007e-01],\n",
      "          [-5.5130e-02,  7.2790e-01, -6.8250e-01]],\n",
      "\n",
      "         [[-2.4072e-01,  2.1072e-01,  3.7873e-02],\n",
      "          [ 6.7277e-03,  1.4432e+00, -1.4762e+00],\n",
      "          [-4.0121e-02,  1.2931e+00, -1.2528e+00]],\n",
      "\n",
      "         [[-8.5257e-02,  6.9258e-02,  3.1450e-02],\n",
      "          [-1.6972e-02,  4.7712e-01, -4.4024e-01],\n",
      "          [-4.7878e-02,  4.2231e-01, -4.0366e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6781e-19, -1.5936e-17,  6.2832e-18],\n",
      "          [ 1.0562e-16,  1.0140e-17, -9.6849e-18],\n",
      "          [ 4.2576e-17, -1.6736e-17, -1.5269e-17]],\n",
      "\n",
      "         [[-9.3665e-19, -2.0997e-17,  1.0625e-17],\n",
      "          [ 1.1059e-16, -8.5305e-18,  5.7360e-18],\n",
      "          [ 4.4472e-17, -1.4536e-18,  1.5525e-17]],\n",
      "\n",
      "         [[ 2.3261e-17, -1.2886e-17,  5.6310e-18],\n",
      "          [ 1.4525e-16,  3.6420e-17,  1.8129e-17],\n",
      "          [ 7.3362e-17,  3.9671e-18, -1.4386e-17]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2752e-02, -5.8898e-02,  1.4701e-02],\n",
      "          [-2.6580e-02,  7.0509e-04, -1.7290e-02],\n",
      "          [-4.4236e-02,  5.6697e-01, -4.2755e-02]],\n",
      "\n",
      "         [[ 4.0966e-02, -1.0857e-02,  3.7020e-02],\n",
      "          [ 4.2369e-02, -3.4714e-02, -7.8123e-03],\n",
      "          [ 1.3258e-02,  5.0397e-01,  1.8258e-02]],\n",
      "\n",
      "         [[-1.1556e-02, -5.2486e-02, -2.6202e-03],\n",
      "          [-1.2290e-02,  1.7760e-02, -2.3098e-02],\n",
      "          [-7.0463e-04,  6.2742e-01,  3.9530e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7271e-03,  2.0321e-02, -4.8876e-02],\n",
      "          [ 4.2461e-01,  1.2307e+00,  2.3159e-01],\n",
      "          [-4.4056e-01, -1.2695e+00, -1.7976e-01]],\n",
      "\n",
      "         [[ 1.6891e-02, -3.7882e-03,  7.2732e-03],\n",
      "          [ 7.8612e-01,  1.9440e+00,  4.1202e-01],\n",
      "          [-8.1143e-01, -2.0023e+00, -3.2891e-01]],\n",
      "\n",
      "         [[ 1.2426e-02, -4.7324e-03, -1.8188e-02],\n",
      "          [ 2.3214e-01,  7.2258e-01,  1.2125e-01],\n",
      "          [-2.5964e-01, -7.1867e-01, -9.1978e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 3, 3, 3])\n",
      "\n",
      "Layer: features.0.0.param_quantizers.weight.min\n",
      "Weights: -2.263631582260132\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.0.0.param_quantizers.weight.max\n",
      "Weights: 2.2459468841552734\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.0.0.input_quantizers.0.min\n",
      "Weights: -2.1179039478302\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.0.0.input_quantizers.0.max\n",
      "Weights: 2.640000104904175\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.0.1.weight\n",
      "Weights: tensor([1.0825, 4.8204, 1.4738, 0.6213, 2.9739, 1.3405, 0.8329, 1.5772, 0.4265,\n",
      "        1.1092, 1.2303, 0.4780, 3.4831, 0.3000, 1.1989, 0.8532, 3.5887, 1.0497,\n",
      "        1.2191, 1.1197, 1.2261, 0.8141, 1.6100, 1.0700, 1.3712, 0.3701, 0.9097,\n",
      "        1.1438, 1.5628, 0.4121, 3.2324, 1.5968], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.0.1.bias\n",
      "Weights: tensor([ 0.0590, -4.9566,  0.3007,  2.5982,  3.0160,  2.8810,  2.6893,  2.9803,\n",
      "         2.3208,  3.2837,  2.4797,  6.5129, -2.8342, -1.2568,  2.3335,  0.5338,\n",
      "         2.8048,  0.4600,  2.7009,  2.8078,  2.5135,  0.3663,  0.6951,  0.1422,\n",
      "         5.8098,  2.5753,  2.0864,  3.2367,  0.9298, -1.9115, -5.8667,  0.8266],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.0.0.weight\n",
      "Weights: tensor([[[[ 8.5443e-02,  1.0032e+00, -1.4700e-01],\n",
      "          [ 1.3916e-02,  6.7163e-01, -2.7953e-01],\n",
      "          [-3.1885e-01, -5.1679e-01, -4.9956e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0335e-01,  7.1423e-02, -2.9735e-01],\n",
      "          [ 8.8945e-01,  4.1716e-01, -2.2317e-01],\n",
      "          [-4.6418e-01, -1.6449e-01, -1.6234e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1001e-02, -3.0135e-01, -1.2470e-01],\n",
      "          [ 5.9850e-02,  1.2607e+00, -8.5826e-02],\n",
      "          [-3.7885e-02, -2.4390e-01, -1.2187e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1329e-02,  1.7918e-02,  6.9535e-03],\n",
      "          [ 1.1795e-01, -9.0861e-01, -7.9298e-02],\n",
      "          [-1.7618e-01,  8.6090e-01,  1.0088e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4295e-02, -1.5054e-01, -8.4380e-02],\n",
      "          [ 9.2268e-03,  1.3897e+00, -5.2309e-02],\n",
      "          [-4.9429e-02, -1.8494e-01, -1.0474e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4959e-02, -1.5435e-02,  2.7955e-02],\n",
      "          [ 1.1760e+00, -1.0571e+00, -6.1691e-02],\n",
      "          [-3.8607e-02, -6.7303e-02,  6.9350e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1566e-01,  7.1589e-02, -2.1001e-01],\n",
      "          [-1.4702e+00, -6.0055e-02,  1.4992e+00],\n",
      "          [-1.3169e+00, -1.3660e-01,  1.4259e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3407e-02, -7.2000e-02,  2.3293e-02],\n",
      "          [ 9.4520e-03, -1.1674e+00,  6.0358e-02],\n",
      "          [-3.5548e-02,  1.2426e+00, -9.4536e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8866e-01, -6.2938e-02,  1.6370e-01],\n",
      "          [ 1.4687e+00,  1.3162e-01, -1.4877e+00],\n",
      "          [ 9.0463e-01, -7.3324e-03, -9.3306e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6515e+00, -3.2295e-02,  1.5447e+00],\n",
      "          [-3.0276e+00,  1.3104e-02,  3.3229e+00],\n",
      "          [-9.2209e-01,  4.2776e-02,  7.8151e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8697e-02,  4.7429e-03, -4.0908e-02],\n",
      "          [-1.1504e+00,  1.0937e+00,  7.1639e-02],\n",
      "          [-1.3848e-02,  4.5822e-02, -6.1518e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7714e-01, -6.1111e-02, -4.6014e-01],\n",
      "          [ 4.2587e-01,  1.5969e-01, -2.0393e-01],\n",
      "          [-3.7848e-02, -9.5468e-02, -5.7780e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4411e-01,  1.7778e-01, -2.7842e-01],\n",
      "          [ 3.7785e-01,  2.2821e-01, -7.9396e-02],\n",
      "          [-3.8765e-01, -1.2349e-01, -1.0295e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2547e-17,  6.8476e-18, -2.3288e-17],\n",
      "          [ 5.3333e-17,  2.8721e-17, -3.7573e-17],\n",
      "          [ 1.7128e-17,  8.5286e-18, -3.2252e-17]]],\n",
      "\n",
      "\n",
      "        [[[-8.5163e-01, -1.6266e+00,  2.8374e-02],\n",
      "          [-2.1293e-01, -1.3969e-01,  1.7841e-01],\n",
      "          [ 1.1541e+00,  1.8968e+00, -2.3943e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4254e-01,  1.6161e+00, -1.3062e-01],\n",
      "          [-5.0432e-02,  5.3076e-01, -9.1056e-02],\n",
      "          [-1.8085e-01, -9.2565e-01, -2.8698e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2559e-02, -4.3727e-02,  2.0142e-02],\n",
      "          [ 2.8543e-01, -1.1714e+00,  3.0521e-01],\n",
      "          [ 2.2202e-01, -3.8132e-01,  2.6610e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5160e-01, -2.4966e-01, -6.2121e-02],\n",
      "          [ 1.1418e-01,  1.2268e+00, -1.7825e-02],\n",
      "          [-1.5606e-01, -2.1591e-01, -5.0242e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0871e-01,  1.4862e-01,  8.7118e-02],\n",
      "          [-8.8470e-01, -1.3666e+00,  3.2498e-01],\n",
      "          [ 4.7185e-01,  2.4698e-01,  8.9874e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3296e-02,  5.7612e-02, -2.1130e-02],\n",
      "          [-1.8302e-02, -7.3717e-02,  2.6013e-02],\n",
      "          [ 8.7581e-02, -1.5098e+00,  2.6878e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2006e-03, -5.2485e-02,  2.7674e-02],\n",
      "          [ 1.2416e-02, -1.2057e+00,  7.3873e-02],\n",
      "          [-2.2537e-03,  1.2654e+00, -1.0702e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9115e-01,  8.7886e-01, -9.9702e-02],\n",
      "          [ 2.0659e-01,  5.6930e-01, -1.7283e-01],\n",
      "          [-6.2056e-01, -4.3000e-01, -1.0813e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6553e-02, -1.0026e-01, -8.4674e-02],\n",
      "          [-1.9936e-01,  1.4638e+00, -2.4480e-01],\n",
      "          [-5.8807e-02, -4.9006e-02, -6.1104e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2019e-01,  7.6050e-01, -6.0416e-02],\n",
      "          [ 1.6566e-01,  5.8785e-01, -2.1086e-01],\n",
      "          [-6.0002e-01, -3.0928e-01, -1.5713e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5430e-02,  2.3638e-01,  7.0212e-02],\n",
      "          [ 1.1879e-01, -1.2487e+00,  2.3156e-02],\n",
      "          [ 9.3941e-02,  2.2081e-01,  4.8800e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1901e-01,  2.3382e-02,  2.5616e-01],\n",
      "          [ 2.0157e+00, -1.1292e-01, -1.8618e+00],\n",
      "          [ 1.1497e+00, -5.2672e-02, -1.1123e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.3321e-01, -5.2005e-02,  2.1991e-02],\n",
      "          [ 1.2610e+00, -1.7072e-01, -1.3929e-02],\n",
      "          [-1.2928e-01, -6.0996e-02, -2.2575e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0476e+00, -3.0978e+00, -2.0043e+00],\n",
      "          [ 1.8272e-01,  6.6250e-01, -2.2211e-02],\n",
      "          [ 8.8813e-01,  2.4166e+00,  1.9718e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.2871e-01, -1.8781e-01, -6.0284e-02],\n",
      "          [ 1.0912e-01,  1.3016e+00, -6.0392e-02],\n",
      "          [-1.4083e-01, -2.4574e-01, -5.4686e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2937e-17,  3.1581e-17,  4.4111e-17],\n",
      "          [-5.6233e-17,  1.7199e-16,  6.8477e-17],\n",
      "          [-7.8994e-18, -3.2047e-17, -7.7552e-17]]],\n",
      "\n",
      "\n",
      "        [[[-1.7230e-01,  2.2708e-01, -1.4950e-01],\n",
      "          [-9.7139e-02,  7.7846e-01, -8.8162e-02],\n",
      "          [-5.8989e-02, -1.9932e-01, -1.1193e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8591e-02,  5.4870e-02,  9.3470e-02],\n",
      "          [ 1.9068e-01, -1.4928e+00,  2.3316e-01],\n",
      "          [ 8.0642e-02,  1.0242e-01,  8.6321e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 1, 3, 3])\n",
      "\n",
      "Layer: features.1.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -3.3491125106811523\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 3.3229475021362305\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.0.1.weight\n",
      "Weights: tensor([0.6519, 0.4864, 0.9031, 0.9693, 2.3145, 6.2372, 1.7343, 7.2227, 3.7534,\n",
      "        6.2679, 6.5068, 3.1254, 0.4076, 0.6415, 2.0785, 0.7188, 1.2937, 0.7520,\n",
      "        0.8610, 0.8136, 8.8045, 0.7231, 1.1978, 0.5913, 0.8605, 2.9741, 0.8403,\n",
      "        8.2873, 1.3564, 0.8470, 0.3696, 1.2543], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.1.conv.0.1.bias\n",
      "Weights: tensor([ 0.1991,  0.4557,  0.2405,  2.9042,  3.0671,  2.8726,  3.1959,  3.1174,\n",
      "         2.6113,  2.3480,  3.1414,  0.6196,  0.5494, -0.9236,  3.1420,  0.6274,\n",
      "         2.7969,  0.4176,  2.9588,  3.1497,  2.4506,  0.4565,  0.5826,  0.3681,\n",
      "         0.1423,  2.4579,  2.4429,  3.2343,  0.9534, -0.9287,  1.0302,  5.3544],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.1.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.1.weight\n",
      "Weights: tensor([[[[ 6.5831e-02]],\n",
      "\n",
      "         [[ 2.2735e-01]],\n",
      "\n",
      "         [[ 3.0291e-02]],\n",
      "\n",
      "         [[ 4.3289e-01]],\n",
      "\n",
      "         [[-1.8641e-02]],\n",
      "\n",
      "         [[-1.1605e-01]],\n",
      "\n",
      "         [[-1.0227e-03]],\n",
      "\n",
      "         [[-3.0987e-01]],\n",
      "\n",
      "         [[-1.4409e-02]],\n",
      "\n",
      "         [[-5.8532e-03]],\n",
      "\n",
      "         [[ 3.0491e-02]],\n",
      "\n",
      "         [[ 1.6556e-01]],\n",
      "\n",
      "         [[-1.1043e-01]],\n",
      "\n",
      "         [[ 2.6296e-17]],\n",
      "\n",
      "         [[ 3.7170e-01]],\n",
      "\n",
      "         [[-8.8819e-04]],\n",
      "\n",
      "         [[ 8.8885e-01]],\n",
      "\n",
      "         [[ 2.4126e-01]],\n",
      "\n",
      "         [[-1.3078e-01]],\n",
      "\n",
      "         [[ 3.8163e-01]],\n",
      "\n",
      "         [[ 5.1393e-02]],\n",
      "\n",
      "         [[-1.3926e-02]],\n",
      "\n",
      "         [[-8.9247e-01]],\n",
      "\n",
      "         [[ 6.3301e-03]],\n",
      "\n",
      "         [[ 5.1762e-02]],\n",
      "\n",
      "         [[ 2.7626e-02]],\n",
      "\n",
      "         [[ 1.3687e-01]],\n",
      "\n",
      "         [[-6.8765e-02]],\n",
      "\n",
      "         [[-1.3766e-01]],\n",
      "\n",
      "         [[ 3.6874e-17]],\n",
      "\n",
      "         [[-2.1122e-01]],\n",
      "\n",
      "         [[-9.8416e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3083e-02]],\n",
      "\n",
      "         [[ 1.0636e-01]],\n",
      "\n",
      "         [[-5.5089e-01]],\n",
      "\n",
      "         [[-7.2518e-02]],\n",
      "\n",
      "         [[-2.4052e-01]],\n",
      "\n",
      "         [[-2.4511e-01]],\n",
      "\n",
      "         [[-1.1781e-01]],\n",
      "\n",
      "         [[-1.7814e-01]],\n",
      "\n",
      "         [[-1.6745e-01]],\n",
      "\n",
      "         [[ 9.5221e-02]],\n",
      "\n",
      "         [[ 5.9568e-02]],\n",
      "\n",
      "         [[-7.5988e-03]],\n",
      "\n",
      "         [[-6.1008e-02]],\n",
      "\n",
      "         [[ 9.7702e-18]],\n",
      "\n",
      "         [[ 2.3303e-01]],\n",
      "\n",
      "         [[-9.4494e-03]],\n",
      "\n",
      "         [[-9.3311e-01]],\n",
      "\n",
      "         [[ 3.6155e-01]],\n",
      "\n",
      "         [[-2.3905e-01]],\n",
      "\n",
      "         [[-2.1183e-01]],\n",
      "\n",
      "         [[-4.3778e-02]],\n",
      "\n",
      "         [[-2.8650e-02]],\n",
      "\n",
      "         [[-4.7581e-01]],\n",
      "\n",
      "         [[ 1.7237e-02]],\n",
      "\n",
      "         [[ 3.9299e-01]],\n",
      "\n",
      "         [[ 1.0936e-01]],\n",
      "\n",
      "         [[ 8.3376e-01]],\n",
      "\n",
      "         [[ 5.7835e-02]],\n",
      "\n",
      "         [[-3.7655e-01]],\n",
      "\n",
      "         [[-6.6484e-17]],\n",
      "\n",
      "         [[-2.0839e-01]],\n",
      "\n",
      "         [[-5.2253e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6309e-02]],\n",
      "\n",
      "         [[-1.2284e-01]],\n",
      "\n",
      "         [[-1.0494e-02]],\n",
      "\n",
      "         [[-3.1888e-02]],\n",
      "\n",
      "         [[-2.7149e-02]],\n",
      "\n",
      "         [[ 8.0823e-03]],\n",
      "\n",
      "         [[-6.1411e-02]],\n",
      "\n",
      "         [[-7.3772e-02]],\n",
      "\n",
      "         [[ 9.0169e-02]],\n",
      "\n",
      "         [[ 1.4061e-01]],\n",
      "\n",
      "         [[-1.0812e-03]],\n",
      "\n",
      "         [[ 1.8863e-01]],\n",
      "\n",
      "         [[-4.5377e-01]],\n",
      "\n",
      "         [[ 2.2029e-17]],\n",
      "\n",
      "         [[-3.2379e-01]],\n",
      "\n",
      "         [[ 1.0884e-01]],\n",
      "\n",
      "         [[ 7.0762e-02]],\n",
      "\n",
      "         [[-1.2901e-01]],\n",
      "\n",
      "         [[ 1.1202e+00]],\n",
      "\n",
      "         [[-7.3342e-02]],\n",
      "\n",
      "         [[ 6.2016e-02]],\n",
      "\n",
      "         [[-1.5451e+00]],\n",
      "\n",
      "         [[-1.9085e-01]],\n",
      "\n",
      "         [[ 1.4876e+00]],\n",
      "\n",
      "         [[-7.5468e-02]],\n",
      "\n",
      "         [[-6.0768e-02]],\n",
      "\n",
      "         [[-2.3226e-02]],\n",
      "\n",
      "         [[ 1.8126e-01]],\n",
      "\n",
      "         [[ 5.9385e-02]],\n",
      "\n",
      "         [[ 4.1560e-17]],\n",
      "\n",
      "         [[ 2.0230e-01]],\n",
      "\n",
      "         [[-2.3621e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6180e-02]],\n",
      "\n",
      "         [[-9.3069e-02]],\n",
      "\n",
      "         [[ 6.0585e-01]],\n",
      "\n",
      "         [[-2.4444e-01]],\n",
      "\n",
      "         [[ 4.2906e-01]],\n",
      "\n",
      "         [[ 9.6671e-02]],\n",
      "\n",
      "         [[ 2.3754e-01]],\n",
      "\n",
      "         [[-9.6197e-02]],\n",
      "\n",
      "         [[-2.4767e-02]],\n",
      "\n",
      "         [[-1.5549e-01]],\n",
      "\n",
      "         [[-6.3028e-02]],\n",
      "\n",
      "         [[-3.9198e-02]],\n",
      "\n",
      "         [[-1.0621e-02]],\n",
      "\n",
      "         [[-2.3131e-17]],\n",
      "\n",
      "         [[ 3.2039e-01]],\n",
      "\n",
      "         [[ 1.0602e-02]],\n",
      "\n",
      "         [[-3.4653e-01]],\n",
      "\n",
      "         [[-5.8286e-01]],\n",
      "\n",
      "         [[ 1.1895e-01]],\n",
      "\n",
      "         [[ 9.4472e-01]],\n",
      "\n",
      "         [[ 5.1004e-02]],\n",
      "\n",
      "         [[ 3.0067e-03]],\n",
      "\n",
      "         [[-8.4240e-02]],\n",
      "\n",
      "         [[ 1.5263e-02]],\n",
      "\n",
      "         [[-1.1991e+00]],\n",
      "\n",
      "         [[-3.6590e-02]],\n",
      "\n",
      "         [[-5.8643e-01]],\n",
      "\n",
      "         [[ 6.5958e-02]],\n",
      "\n",
      "         [[ 1.7309e-01]],\n",
      "\n",
      "         [[ 5.6598e-18]],\n",
      "\n",
      "         [[-2.2379e-01]],\n",
      "\n",
      "         [[ 2.1740e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9298e-01]],\n",
      "\n",
      "         [[-1.2348e-01]],\n",
      "\n",
      "         [[-4.1473e-01]],\n",
      "\n",
      "         [[-1.1678e-01]],\n",
      "\n",
      "         [[-2.1214e-01]],\n",
      "\n",
      "         [[-1.1894e-02]],\n",
      "\n",
      "         [[ 1.0823e+00]],\n",
      "\n",
      "         [[-1.2160e-01]],\n",
      "\n",
      "         [[ 1.4030e+00]],\n",
      "\n",
      "         [[-1.0360e-01]],\n",
      "\n",
      "         [[-3.2732e-02]],\n",
      "\n",
      "         [[-1.3039e-01]],\n",
      "\n",
      "         [[ 2.0993e-01]],\n",
      "\n",
      "         [[ 4.4375e-18]],\n",
      "\n",
      "         [[ 3.0142e-02]],\n",
      "\n",
      "         [[ 2.7108e-01]],\n",
      "\n",
      "         [[-6.7393e-02]],\n",
      "\n",
      "         [[ 2.6563e-01]],\n",
      "\n",
      "         [[-5.1977e-02]],\n",
      "\n",
      "         [[-9.6476e-02]],\n",
      "\n",
      "         [[ 1.0028e-01]],\n",
      "\n",
      "         [[ 1.1880e-01]],\n",
      "\n",
      "         [[ 1.1193e-01]],\n",
      "\n",
      "         [[-1.0816e-01]],\n",
      "\n",
      "         [[ 2.7673e-01]],\n",
      "\n",
      "         [[ 4.3108e-01]],\n",
      "\n",
      "         [[-1.7900e-02]],\n",
      "\n",
      "         [[ 7.1261e-02]],\n",
      "\n",
      "         [[-3.2291e-01]],\n",
      "\n",
      "         [[-3.6724e-18]],\n",
      "\n",
      "         [[-5.2534e-02]],\n",
      "\n",
      "         [[ 1.9412e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2302e-02]],\n",
      "\n",
      "         [[-1.0545e-01]],\n",
      "\n",
      "         [[-5.9359e-01]],\n",
      "\n",
      "         [[ 5.0745e-01]],\n",
      "\n",
      "         [[-2.2783e-01]],\n",
      "\n",
      "         [[-1.7745e-01]],\n",
      "\n",
      "         [[-1.4324e-01]],\n",
      "\n",
      "         [[-5.2423e-02]],\n",
      "\n",
      "         [[-8.1088e-02]],\n",
      "\n",
      "         [[ 8.1023e-02]],\n",
      "\n",
      "         [[-4.0820e-02]],\n",
      "\n",
      "         [[ 1.1068e-01]],\n",
      "\n",
      "         [[-2.7420e-02]],\n",
      "\n",
      "         [[ 2.4230e-17]],\n",
      "\n",
      "         [[ 1.7100e-02]],\n",
      "\n",
      "         [[-3.7814e-02]],\n",
      "\n",
      "         [[ 1.4872e-01]],\n",
      "\n",
      "         [[ 1.4240e-02]],\n",
      "\n",
      "         [[ 6.1679e-01]],\n",
      "\n",
      "         [[ 1.7158e+00]],\n",
      "\n",
      "         [[-1.1615e-01]],\n",
      "\n",
      "         [[-2.2048e-02]],\n",
      "\n",
      "         [[ 9.6844e-01]],\n",
      "\n",
      "         [[ 1.1223e-02]],\n",
      "\n",
      "         [[ 3.4682e-01]],\n",
      "\n",
      "         [[ 9.8144e-02]],\n",
      "\n",
      "         [[ 2.2866e-01]],\n",
      "\n",
      "         [[ 1.7796e-02]],\n",
      "\n",
      "         [[-1.7014e-01]],\n",
      "\n",
      "         [[-2.5076e-17]],\n",
      "\n",
      "         [[ 5.2268e-02]],\n",
      "\n",
      "         [[ 1.0250e+00]]],\n",
      "\n",
      "\n",
      "        [[[-5.2759e-02]],\n",
      "\n",
      "         [[-4.6772e-01]],\n",
      "\n",
      "         [[ 6.4227e-02]],\n",
      "\n",
      "         [[-2.2886e-01]],\n",
      "\n",
      "         [[-2.1504e-02]],\n",
      "\n",
      "         [[-7.6024e-02]],\n",
      "\n",
      "         [[ 1.4228e-01]],\n",
      "\n",
      "         [[-7.7604e-02]],\n",
      "\n",
      "         [[-2.0975e-02]],\n",
      "\n",
      "         [[-1.0114e-01]],\n",
      "\n",
      "         [[ 6.2361e-02]],\n",
      "\n",
      "         [[ 4.1426e-01]],\n",
      "\n",
      "         [[-1.0777e-01]],\n",
      "\n",
      "         [[-1.4988e-17]],\n",
      "\n",
      "         [[ 7.4858e-01]],\n",
      "\n",
      "         [[ 1.2785e-01]],\n",
      "\n",
      "         [[ 3.1075e-02]],\n",
      "\n",
      "         [[ 5.6224e-03]],\n",
      "\n",
      "         [[ 1.5875e+00]],\n",
      "\n",
      "         [[-5.2594e-01]],\n",
      "\n",
      "         [[-1.7869e-02]],\n",
      "\n",
      "         [[ 5.7994e-02]],\n",
      "\n",
      "         [[ 1.4741e-01]],\n",
      "\n",
      "         [[-1.2731e-02]],\n",
      "\n",
      "         [[-1.5030e-01]],\n",
      "\n",
      "         [[-1.0126e-02]],\n",
      "\n",
      "         [[ 5.6472e-02]],\n",
      "\n",
      "         [[-7.0164e-01]],\n",
      "\n",
      "         [[-2.6149e-02]],\n",
      "\n",
      "         [[-3.1055e-18]],\n",
      "\n",
      "         [[ 3.6672e-01]],\n",
      "\n",
      "         [[ 4.4243e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2085e-02]],\n",
      "\n",
      "         [[-1.7531e-01]],\n",
      "\n",
      "         [[-8.4010e-01]],\n",
      "\n",
      "         [[-4.7240e-01]],\n",
      "\n",
      "         [[-4.0943e-01]],\n",
      "\n",
      "         [[ 3.6342e-01]],\n",
      "\n",
      "         [[-3.4715e-01]],\n",
      "\n",
      "         [[ 6.4749e-02]],\n",
      "\n",
      "         [[-5.9481e-02]],\n",
      "\n",
      "         [[ 1.8594e-01]],\n",
      "\n",
      "         [[-2.0674e-01]],\n",
      "\n",
      "         [[ 1.0277e-01]],\n",
      "\n",
      "         [[-5.1262e-03]],\n",
      "\n",
      "         [[ 7.0312e-18]],\n",
      "\n",
      "         [[ 1.5137e-01]],\n",
      "\n",
      "         [[-6.7204e-02]],\n",
      "\n",
      "         [[ 9.5743e-03]],\n",
      "\n",
      "         [[ 2.5047e-01]],\n",
      "\n",
      "         [[ 1.7607e-01]],\n",
      "\n",
      "         [[ 2.4320e-01]],\n",
      "\n",
      "         [[ 7.2173e-02]],\n",
      "\n",
      "         [[ 3.5486e-02]],\n",
      "\n",
      "         [[-5.0573e-01]],\n",
      "\n",
      "         [[-3.6048e-02]],\n",
      "\n",
      "         [[ 4.2133e-01]],\n",
      "\n",
      "         [[ 1.9576e-01]],\n",
      "\n",
      "         [[-1.1449e+00]],\n",
      "\n",
      "         [[-3.1745e-02]],\n",
      "\n",
      "         [[-4.1712e-01]],\n",
      "\n",
      "         [[ 3.1579e-17]],\n",
      "\n",
      "         [[ 1.1915e-01]],\n",
      "\n",
      "         [[-2.8083e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4794e+00]],\n",
      "\n",
      "         [[ 3.8379e-01]],\n",
      "\n",
      "         [[ 1.2690e-01]],\n",
      "\n",
      "         [[-1.9931e-01]],\n",
      "\n",
      "         [[ 7.4906e-02]],\n",
      "\n",
      "         [[ 1.8341e-02]],\n",
      "\n",
      "         [[-2.9859e-01]],\n",
      "\n",
      "         [[ 1.1047e-02]],\n",
      "\n",
      "         [[ 4.1864e-01]],\n",
      "\n",
      "         [[ 4.4059e-01]],\n",
      "\n",
      "         [[-3.1080e-02]],\n",
      "\n",
      "         [[-3.7603e-01]],\n",
      "\n",
      "         [[-3.8320e-01]],\n",
      "\n",
      "         [[-3.9904e-17]],\n",
      "\n",
      "         [[ 3.0595e-01]],\n",
      "\n",
      "         [[-1.7269e+00]],\n",
      "\n",
      "         [[-8.3832e-02]],\n",
      "\n",
      "         [[-1.6970e-01]],\n",
      "\n",
      "         [[-6.9706e-01]],\n",
      "\n",
      "         [[-3.2347e-03]],\n",
      "\n",
      "         [[-1.3613e-02]],\n",
      "\n",
      "         [[ 4.0613e-02]],\n",
      "\n",
      "         [[ 3.2812e-01]],\n",
      "\n",
      "         [[ 1.6647e-02]],\n",
      "\n",
      "         [[-9.2776e-02]],\n",
      "\n",
      "         [[-1.7230e-01]],\n",
      "\n",
      "         [[ 8.8241e-02]],\n",
      "\n",
      "         [[-2.0986e-01]],\n",
      "\n",
      "         [[ 1.0047e-01]],\n",
      "\n",
      "         [[-5.7438e-17]],\n",
      "\n",
      "         [[-1.0933e-01]],\n",
      "\n",
      "         [[ 3.4535e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1189e-01]],\n",
      "\n",
      "         [[-1.8654e-01]],\n",
      "\n",
      "         [[-1.3033e-01]],\n",
      "\n",
      "         [[ 1.3786e-01]],\n",
      "\n",
      "         [[-8.8092e-02]],\n",
      "\n",
      "         [[-2.1625e-02]],\n",
      "\n",
      "         [[ 7.0936e-01]],\n",
      "\n",
      "         [[-1.3341e-02]],\n",
      "\n",
      "         [[-3.6951e-01]],\n",
      "\n",
      "         [[-7.9334e-01]],\n",
      "\n",
      "         [[ 6.1708e-02]],\n",
      "\n",
      "         [[ 4.4145e-01]],\n",
      "\n",
      "         [[-2.9724e-01]],\n",
      "\n",
      "         [[-5.8409e-19]],\n",
      "\n",
      "         [[-3.8139e-01]],\n",
      "\n",
      "         [[-1.0753e+00]],\n",
      "\n",
      "         [[ 6.0398e-02]],\n",
      "\n",
      "         [[ 2.6933e-01]],\n",
      "\n",
      "         [[ 1.1121e+00]],\n",
      "\n",
      "         [[-1.1882e-01]],\n",
      "\n",
      "         [[ 6.2004e-02]],\n",
      "\n",
      "         [[ 2.3762e-01]],\n",
      "\n",
      "         [[-1.5444e-01]],\n",
      "\n",
      "         [[-1.5153e-01]],\n",
      "\n",
      "         [[ 1.2307e-01]],\n",
      "\n",
      "         [[ 2.9357e-01]],\n",
      "\n",
      "         [[-1.2696e-01]],\n",
      "\n",
      "         [[ 2.2966e-01]],\n",
      "\n",
      "         [[-1.5268e-01]],\n",
      "\n",
      "         [[ 7.4061e-17]],\n",
      "\n",
      "         [[ 2.8052e-01]],\n",
      "\n",
      "         [[-2.5656e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5018e-02]],\n",
      "\n",
      "         [[ 1.3305e-02]],\n",
      "\n",
      "         [[ 3.9483e-01]],\n",
      "\n",
      "         [[ 3.5803e-01]],\n",
      "\n",
      "         [[ 3.0358e-02]],\n",
      "\n",
      "         [[-4.1929e-03]],\n",
      "\n",
      "         [[ 2.1909e-01]],\n",
      "\n",
      "         [[ 2.5503e-01]],\n",
      "\n",
      "         [[ 2.6888e-01]],\n",
      "\n",
      "         [[ 1.9605e-02]],\n",
      "\n",
      "         [[-3.9387e-02]],\n",
      "\n",
      "         [[-1.0709e-01]],\n",
      "\n",
      "         [[ 8.9207e-02]],\n",
      "\n",
      "         [[ 6.4679e-18]],\n",
      "\n",
      "         [[ 5.2283e-02]],\n",
      "\n",
      "         [[-1.9052e-02]],\n",
      "\n",
      "         [[-2.1635e-01]],\n",
      "\n",
      "         [[ 2.8509e-02]],\n",
      "\n",
      "         [[ 3.2104e-01]],\n",
      "\n",
      "         [[ 1.0168e+00]],\n",
      "\n",
      "         [[-3.5677e-01]],\n",
      "\n",
      "         [[ 1.8780e-02]],\n",
      "\n",
      "         [[-2.2160e-01]],\n",
      "\n",
      "         [[ 2.7486e-02]],\n",
      "\n",
      "         [[ 4.7647e-01]],\n",
      "\n",
      "         [[-5.0608e-02]],\n",
      "\n",
      "         [[ 2.5407e-02]],\n",
      "\n",
      "         [[-1.0171e-01]],\n",
      "\n",
      "         [[ 4.6801e-01]],\n",
      "\n",
      "         [[ 3.0209e-17]],\n",
      "\n",
      "         [[ 4.2267e-01]],\n",
      "\n",
      "         [[-9.4780e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0858e-03]],\n",
      "\n",
      "         [[-9.8850e-02]],\n",
      "\n",
      "         [[-8.7649e-01]],\n",
      "\n",
      "         [[ 2.0273e-01]],\n",
      "\n",
      "         [[-2.2941e-01]],\n",
      "\n",
      "         [[-1.4109e-02]],\n",
      "\n",
      "         [[ 1.8655e-01]],\n",
      "\n",
      "         [[-3.8349e-02]],\n",
      "\n",
      "         [[-3.6785e-02]],\n",
      "\n",
      "         [[-8.6221e-02]],\n",
      "\n",
      "         [[ 4.6289e-03]],\n",
      "\n",
      "         [[ 8.3266e-02]],\n",
      "\n",
      "         [[-3.2838e-02]],\n",
      "\n",
      "         [[-8.4601e-18]],\n",
      "\n",
      "         [[ 5.8801e-03]],\n",
      "\n",
      "         [[ 1.3072e-02]],\n",
      "\n",
      "         [[ 5.3346e-02]],\n",
      "\n",
      "         [[-1.8764e+00]],\n",
      "\n",
      "         [[-2.6884e-01]],\n",
      "\n",
      "         [[-1.2687e-01]],\n",
      "\n",
      "         [[ 7.1032e-03]],\n",
      "\n",
      "         [[ 1.7468e-02]],\n",
      "\n",
      "         [[-3.0496e-01]],\n",
      "\n",
      "         [[-2.8971e-03]],\n",
      "\n",
      "         [[ 3.7691e-01]],\n",
      "\n",
      "         [[-6.7386e-02]],\n",
      "\n",
      "         [[ 9.1708e-01]],\n",
      "\n",
      "         [[-1.0908e-02]],\n",
      "\n",
      "         [[ 9.5139e-01]],\n",
      "\n",
      "         [[-3.9619e-18]],\n",
      "\n",
      "         [[-6.9154e-02]],\n",
      "\n",
      "         [[ 3.3605e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3196e-02]],\n",
      "\n",
      "         [[-3.7312e-01]],\n",
      "\n",
      "         [[-3.6590e-01]],\n",
      "\n",
      "         [[ 6.2443e-02]],\n",
      "\n",
      "         [[ 1.1217e-01]],\n",
      "\n",
      "         [[-1.2633e-01]],\n",
      "\n",
      "         [[-7.8161e-02]],\n",
      "\n",
      "         [[ 2.9398e-01]],\n",
      "\n",
      "         [[ 2.2428e-01]],\n",
      "\n",
      "         [[ 4.6255e-02]],\n",
      "\n",
      "         [[ 1.8306e-01]],\n",
      "\n",
      "         [[-1.4801e-01]],\n",
      "\n",
      "         [[-5.4511e-02]],\n",
      "\n",
      "         [[-1.4938e-17]],\n",
      "\n",
      "         [[-2.7659e-01]],\n",
      "\n",
      "         [[-9.8176e-03]],\n",
      "\n",
      "         [[ 2.1005e-01]],\n",
      "\n",
      "         [[-1.4999e-01]],\n",
      "\n",
      "         [[ 1.7637e-01]],\n",
      "\n",
      "         [[ 1.2063e-01]],\n",
      "\n",
      "         [[-2.8176e-01]],\n",
      "\n",
      "         [[ 3.3598e-02]],\n",
      "\n",
      "         [[-1.1797e+00]],\n",
      "\n",
      "         [[-6.9036e-02]],\n",
      "\n",
      "         [[-8.4316e-01]],\n",
      "\n",
      "         [[-9.5390e-02]],\n",
      "\n",
      "         [[-5.1716e-02]],\n",
      "\n",
      "         [[-1.5118e-01]],\n",
      "\n",
      "         [[-5.9474e-01]],\n",
      "\n",
      "         [[ 1.7235e-17]],\n",
      "\n",
      "         [[-1.8186e-01]],\n",
      "\n",
      "         [[ 1.6760e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.0694e-02]],\n",
      "\n",
      "         [[ 4.3372e-01]],\n",
      "\n",
      "         [[-1.9337e-01]],\n",
      "\n",
      "         [[ 9.1684e-02]],\n",
      "\n",
      "         [[-8.3747e-02]],\n",
      "\n",
      "         [[ 2.2812e-02]],\n",
      "\n",
      "         [[ 4.9351e-01]],\n",
      "\n",
      "         [[ 1.6442e-01]],\n",
      "\n",
      "         [[-2.2929e-01]],\n",
      "\n",
      "         [[-5.7119e-01]],\n",
      "\n",
      "         [[-1.8205e-02]],\n",
      "\n",
      "         [[-2.3519e-01]],\n",
      "\n",
      "         [[-3.0015e-02]],\n",
      "\n",
      "         [[-3.6250e-17]],\n",
      "\n",
      "         [[ 3.4081e-01]],\n",
      "\n",
      "         [[ 1.1191e-01]],\n",
      "\n",
      "         [[-7.7989e-02]],\n",
      "\n",
      "         [[ 3.6005e-01]],\n",
      "\n",
      "         [[-1.6853e+00]],\n",
      "\n",
      "         [[ 1.5310e-01]],\n",
      "\n",
      "         [[-1.3770e-01]],\n",
      "\n",
      "         [[-6.3572e-01]],\n",
      "\n",
      "         [[ 1.4641e-01]],\n",
      "\n",
      "         [[ 5.5886e-01]],\n",
      "\n",
      "         [[ 2.7746e-01]],\n",
      "\n",
      "         [[ 1.7502e-01]],\n",
      "\n",
      "         [[-2.3129e-01]],\n",
      "\n",
      "         [[-2.9239e-01]],\n",
      "\n",
      "         [[-2.4926e-01]],\n",
      "\n",
      "         [[-1.2226e-16]],\n",
      "\n",
      "         [[-2.9055e-01]],\n",
      "\n",
      "         [[ 3.6800e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0023e-02]],\n",
      "\n",
      "         [[ 8.3805e-02]],\n",
      "\n",
      "         [[-8.9322e-02]],\n",
      "\n",
      "         [[-1.1030e+00]],\n",
      "\n",
      "         [[-8.6432e-02]],\n",
      "\n",
      "         [[ 1.2373e-01]],\n",
      "\n",
      "         [[ 3.6443e-02]],\n",
      "\n",
      "         [[ 3.8042e-01]],\n",
      "\n",
      "         [[-1.0206e-02]],\n",
      "\n",
      "         [[-3.3718e-02]],\n",
      "\n",
      "         [[ 5.0136e-01]],\n",
      "\n",
      "         [[-1.4288e-02]],\n",
      "\n",
      "         [[ 1.8909e-02]],\n",
      "\n",
      "         [[-2.0096e-17]],\n",
      "\n",
      "         [[ 7.0578e-02]],\n",
      "\n",
      "         [[ 3.3702e-02]],\n",
      "\n",
      "         [[ 2.4623e-01]],\n",
      "\n",
      "         [[ 4.1874e-02]],\n",
      "\n",
      "         [[ 1.1963e-01]],\n",
      "\n",
      "         [[ 7.5208e-01]],\n",
      "\n",
      "         [[ 2.6306e-01]],\n",
      "\n",
      "         [[-1.4355e-02]],\n",
      "\n",
      "         [[ 1.1260e-01]],\n",
      "\n",
      "         [[ 1.3964e-03]],\n",
      "\n",
      "         [[ 3.9340e-01]],\n",
      "\n",
      "         [[-2.9790e-02]],\n",
      "\n",
      "         [[ 7.9440e-01]],\n",
      "\n",
      "         [[-1.0249e-02]],\n",
      "\n",
      "         [[ 9.6252e-02]],\n",
      "\n",
      "         [[ 5.7733e-17]],\n",
      "\n",
      "         [[-2.1212e-02]],\n",
      "\n",
      "         [[-1.4167e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5379e-02]],\n",
      "\n",
      "         [[-1.4224e-02]],\n",
      "\n",
      "         [[ 3.1387e-01]],\n",
      "\n",
      "         [[-7.5811e-02]],\n",
      "\n",
      "         [[ 1.4114e-01]],\n",
      "\n",
      "         [[-8.5587e-03]],\n",
      "\n",
      "         [[ 1.7943e-01]],\n",
      "\n",
      "         [[ 4.3236e-02]],\n",
      "\n",
      "         [[-3.1615e-01]],\n",
      "\n",
      "         [[ 3.3590e-01]],\n",
      "\n",
      "         [[ 3.5677e-02]],\n",
      "\n",
      "         [[-1.8669e-01]],\n",
      "\n",
      "         [[ 2.1232e-02]],\n",
      "\n",
      "         [[ 5.8804e-17]],\n",
      "\n",
      "         [[-2.2436e-02]],\n",
      "\n",
      "         [[ 2.0076e-02]],\n",
      "\n",
      "         [[ 4.7261e-02]],\n",
      "\n",
      "         [[-2.9307e-01]],\n",
      "\n",
      "         [[-1.5571e-03]],\n",
      "\n",
      "         [[-2.5982e-02]],\n",
      "\n",
      "         [[-4.0571e-02]],\n",
      "\n",
      "         [[-3.0982e-02]],\n",
      "\n",
      "         [[-3.9017e-02]],\n",
      "\n",
      "         [[ 3.7642e-02]],\n",
      "\n",
      "         [[-2.5220e-01]],\n",
      "\n",
      "         [[ 2.1428e+00]],\n",
      "\n",
      "         [[ 1.1642e-01]],\n",
      "\n",
      "         [[-4.8645e-02]],\n",
      "\n",
      "         [[ 2.1545e-01]],\n",
      "\n",
      "         [[-2.8057e-17]],\n",
      "\n",
      "         [[-5.7676e-03]],\n",
      "\n",
      "         [[ 3.8386e-03]]]], device='cuda:0')\n",
      "Shape: torch.Size([16, 32, 1, 1])\n",
      "\n",
      "Layer: features.1.conv.1.param_quantizers.weight.min\n",
      "Weights: -2.1596877574920654\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.1.param_quantizers.weight.max\n",
      "Weights: 2.142815113067627\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.2.weight\n",
      "Weights: tensor([6.3647, 6.5710, 3.3553, 6.5215, 4.8815, 7.7959, 3.8385, 6.8555, 4.1766,\n",
      "        4.6549, 6.4026, 7.8247, 5.0895, 4.5356, 6.4430, 5.1102],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([16])\n",
      "\n",
      "Layer: features.1.conv.2.bias\n",
      "Weights: tensor([ 1.7123e-05, -2.7751e-05, -1.3899e-05, -1.0712e-05,  1.9244e-06,\n",
      "        -1.9829e-06, -1.2686e-05,  2.0950e-05,  4.7521e-06,  1.0942e-05,\n",
      "         1.2953e-05,  2.1889e-05, -1.9752e-05, -2.4471e-05,  1.4171e-06,\n",
      "         1.6800e-05], device='cuda:0')\n",
      "Shape: torch.Size([16])\n",
      "\n",
      "Layer: features.1.conv.2.output_quantizers.0.min\n",
      "Weights: -76.35702514648438\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.1.conv.2.output_quantizers.0.max\n",
      "Weights: 57.12407302856445\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.3426]],\n",
      "\n",
      "         [[-0.4564]],\n",
      "\n",
      "         [[-0.1110]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1685]],\n",
      "\n",
      "         [[-0.0453]],\n",
      "\n",
      "         [[ 0.0107]]],\n",
      "\n",
      "\n",
      "        [[[-0.0322]],\n",
      "\n",
      "         [[ 0.0079]],\n",
      "\n",
      "         [[ 0.6602]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3885]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         [[-0.0264]]],\n",
      "\n",
      "\n",
      "        [[[-0.0468]],\n",
      "\n",
      "         [[-0.0381]],\n",
      "\n",
      "         [[-0.1007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0481]],\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[ 0.1891]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0196]],\n",
      "\n",
      "         [[-0.0908]],\n",
      "\n",
      "         [[-0.0733]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4355]],\n",
      "\n",
      "         [[ 0.0169]],\n",
      "\n",
      "         [[-0.0293]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9530]],\n",
      "\n",
      "         [[-0.3483]],\n",
      "\n",
      "         [[ 0.0339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0953]],\n",
      "\n",
      "         [[-0.2472]],\n",
      "\n",
      "         [[ 0.1898]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0288]],\n",
      "\n",
      "         [[ 0.0049]],\n",
      "\n",
      "         [[ 0.7995]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4346]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[ 0.0118]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 16, 1, 1])\n",
      "\n",
      "Layer: features.2.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -1.517624855041504\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 1.5057684183120728\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.0.1.weight\n",
      "Weights: tensor([ 1.7247,  4.1887,  0.7494,  0.6663,  9.9635,  2.5291,  9.0602,  1.3370,\n",
      "         0.7550,  1.1049,  0.4882,  1.1830,  3.7646,  0.8134,  1.0003,  0.5323,\n",
      "         1.0350,  0.4374,  2.1823,  2.0356,  0.4916,  0.9686,  5.5052,  1.2162,\n",
      "         1.4870,  0.7033,  0.8449,  1.7252,  0.8037,  2.5920,  1.1668,  1.8728,\n",
      "         1.3435,  2.2484,  1.0678,  1.2182,  0.9369,  2.8466,  1.1962,  4.3305,\n",
      "         0.7859,  0.7134,  0.7853,  0.3656,  2.0253,  0.5066,  0.6290,  0.9783,\n",
      "         0.5842,  1.1166,  2.0352,  5.5462,  1.0852,  0.8550,  5.2345,  1.1235,\n",
      "         0.4552,  0.9469,  1.0367,  3.2726,  2.1687,  1.3887,  4.8131,  1.7548,\n",
      "         2.0701,  1.3905,  0.6339,  1.0525,  1.2559,  1.1783,  1.3257,  1.6706,\n",
      "         1.6592,  0.6895,  5.7948,  3.8543,  1.6495,  1.1311,  4.1170,  1.7610,\n",
      "         2.3540, 15.2547,  1.3815,  1.6941,  4.2721,  0.9249,  1.9517,  1.3350,\n",
      "         2.6972,  1.6992,  1.0109,  1.6386,  0.5449,  3.4082,  1.9390,  7.7758],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.0.1.bias\n",
      "Weights: tensor([ 2.6648,  1.0656,  0.5563,  2.2933,  2.5505, -0.2472,  2.3496, -0.0417,\n",
      "         0.9718,  2.9218,  5.9433,  2.2507,  2.8073,  0.2451, -0.0202,  2.2519,\n",
      "        -0.0470,  2.7474, -0.0414,  0.0610,  2.5959,  1.2214,  0.7869,  0.7366,\n",
      "         1.1480,  2.8393,  0.5980,  2.8556,  1.9898,  1.2269, -0.0754,  0.0632,\n",
      "         0.3786, -0.0381,  3.4157,  2.3872,  2.8776,  2.4608, -0.0638,  2.6482,\n",
      "         0.9673,  0.2847,  1.6630,  3.5481,  0.0507,  2.1501,  4.0111,  1.3801,\n",
      "         2.2180,  2.7637, -0.1436,  0.0754,  2.9416,  3.4455,  2.5550,  2.6879,\n",
      "         2.0186,  1.9961,  3.0597, -0.1987,  3.1346,  2.6214, -0.2483, -0.0686,\n",
      "         0.9592, -0.0347,  1.2207, -0.6273,  2.8937,  0.8233,  0.5382, -0.0295,\n",
      "         2.7192,  0.8603,  1.8965,  2.7345, -0.0776,  0.3284, -0.4123, -0.0574,\n",
      "        -0.5504,  2.9408,  3.9962,  3.4339,  4.9460,  0.9699,  0.8379, -0.0925,\n",
      "         0.1679, -0.1979, -0.8700, -0.1272,  3.2298, -0.2935, -0.0461, -0.0919],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.1.0.weight\n",
      "Weights: tensor([[[[-1.8443e-01, -2.5724e-01, -9.5347e-02],\n",
      "          [ 3.6125e-01,  5.7393e-01,  2.9340e-01],\n",
      "          [-9.7490e-02, -1.6637e-01, -1.1422e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0175e-02,  5.9562e-02,  2.5728e-02],\n",
      "          [-7.7576e-03, -1.0879e-01, -1.0682e-01],\n",
      "          [-2.3336e-01, -2.8364e-01, -1.6213e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7585e-02, -2.0966e-01, -1.5505e-02],\n",
      "          [ 6.5486e-02,  6.7997e-01,  3.9819e-01],\n",
      "          [-1.8469e-03, -2.4071e-01, -5.7320e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9437e-02, -6.2980e-02,  4.9549e-02],\n",
      "          [-1.5582e-01,  6.1941e-01, -2.9313e-01],\n",
      "          [ 1.4129e-01, -5.4622e-01,  2.7290e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6414e-01,  1.4690e-02,  1.7512e-01],\n",
      "          [-5.4443e-01, -9.5207e-03,  5.3700e-01],\n",
      "          [-1.6040e-01, -6.1250e-03,  1.4033e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5948e-01,  2.3380e-01,  1.5859e-01],\n",
      "          [ 2.1495e-01,  3.6795e-01,  2.7573e-01],\n",
      "          [ 1.0597e-01,  1.5579e-01,  1.3932e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2506e-02, -2.0453e-01, -9.4891e-02],\n",
      "          [-1.7996e-01, -3.4537e-01, -1.8327e-01],\n",
      "          [-9.6741e-02, -1.5630e-01, -9.1874e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4574e-02,  1.1895e-01,  1.9723e-01],\n",
      "          [ 7.3621e-02,  3.2703e-01,  4.2314e-01],\n",
      "          [ 4.5503e-02,  2.9531e-01,  2.8764e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9451e-02, -2.4091e-01, -1.8478e-01],\n",
      "          [-1.4970e-01, -3.5666e-01, -1.9055e-01],\n",
      "          [ 1.2075e-01,  5.2274e-01,  4.6165e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3893e-02, -1.7144e-01,  1.2910e-01],\n",
      "          [-1.4037e-01,  4.6024e-01, -3.2350e-01],\n",
      "          [ 7.2830e-02, -2.7382e-01,  2.0132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7590e-01, -2.4140e-01,  8.5013e-02],\n",
      "          [-1.9427e-01, -1.8394e-01,  5.5550e-01],\n",
      "          [-4.1399e-02,  1.7406e-01,  4.4368e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6428e-01, -3.7046e-01, -2.8189e-01],\n",
      "          [-2.8182e-02,  1.2357e-01,  1.5820e-01],\n",
      "          [ 1.9776e-01,  3.5490e-01,  2.4783e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7906e-01, -3.6492e-01, -2.3282e-01],\n",
      "          [-1.1521e-02, -7.2736e-03,  2.5643e-02],\n",
      "          [ 1.4471e-01,  4.3509e-01,  2.4617e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2307e-01,  1.5311e-02, -1.5318e-01],\n",
      "          [ 2.3981e-01,  1.1212e-01, -3.6555e-01],\n",
      "          [ 1.3363e-01,  1.1364e-01, -2.1147e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4066e-02,  1.4693e-01,  2.8537e-01],\n",
      "          [ 2.4858e-02,  3.6846e-01,  5.8395e-01],\n",
      "          [ 2.3824e-02,  2.5721e-01,  4.1281e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4990e-01,  4.9075e-01, -3.2664e-01],\n",
      "          [ 1.1522e-01, -2.5519e-01,  1.6880e-01],\n",
      "          [ 3.9638e-02, -2.6960e-01,  1.6144e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5091e-01, -3.6035e-01, -2.5460e-01],\n",
      "          [-2.3755e-01, -5.2636e-01, -4.0691e-01],\n",
      "          [-1.3892e-01, -2.1655e-01, -1.5979e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8980e-02, -9.1439e-02,  3.6661e-02],\n",
      "          [ 3.5798e-01, -6.2869e-01,  2.4738e-01],\n",
      "          [ 3.1356e-01, -4.9230e-01,  1.5849e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4897e-03,  2.2524e-01,  2.2280e-01],\n",
      "          [ 1.0227e-01,  3.7792e-01,  5.3631e-01],\n",
      "          [ 5.6323e-02,  2.5256e-01,  3.9371e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0970e-01,  1.0900e-01, -9.1141e-02],\n",
      "          [ 4.1786e-01,  2.6050e-01, -1.8480e-01],\n",
      "          [ 2.3796e-01,  2.3407e-01, -3.2036e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5411e-02, -3.3268e-01,  3.0939e-01],\n",
      "          [-8.4398e-02,  5.4583e-01, -5.0386e-01],\n",
      "          [ 4.9191e-02, -2.2330e-01,  1.9041e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8185e-01,  3.5363e-01,  2.2586e-01],\n",
      "          [-1.6487e-01, -3.6737e-01, -2.1013e-01],\n",
      "          [-2.5498e-02,  5.2223e-02, -2.2639e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.6521e-02, -1.5010e-01, -6.6369e-02],\n",
      "          [-2.3178e-01, -3.8416e-01, -1.4150e-01],\n",
      "          [-1.9551e-01, -2.9067e-01, -1.2052e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1718e-01, -1.3063e-01,  2.3976e-01],\n",
      "          [-1.7568e-01, -2.8733e-01,  4.5672e-01],\n",
      "          [-1.4254e-01, -1.5174e-01,  3.1421e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.8979e-02, -2.0796e-01, -2.8846e-01],\n",
      "          [ 2.4488e-04,  1.1016e-01,  9.9218e-02],\n",
      "          [-1.6072e-01,  4.6569e-01,  6.7172e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.6879e-02, -2.1220e-01, -9.5952e-02],\n",
      "          [-3.0997e-01, -4.3179e-01, -2.5946e-01],\n",
      "          [-2.1414e-01, -3.2550e-01, -1.9410e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2413e-01, -4.3817e-01, -2.2438e-01],\n",
      "          [-2.3347e-01,  2.3859e-01,  3.8458e-01],\n",
      "          [ 1.3699e-01,  3.5230e-01,  3.9368e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4866e-01,  2.8679e-03,  1.1821e-01],\n",
      "          [ 3.8855e-01, -2.9074e-02, -4.4824e-01],\n",
      "          [-2.7080e-01, -6.5110e-02,  2.7280e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0171e-01,  1.9035e-01, -2.8021e-01],\n",
      "          [ 8.2809e-02,  2.4612e-01, -5.2528e-01],\n",
      "          [ 7.3050e-02,  1.0156e-01, -3.0767e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0402e-01, -7.6626e-02, -3.1821e-02],\n",
      "          [-4.5154e-01, -2.8018e-01, -7.3102e-02],\n",
      "          [-2.0360e-01, -1.5420e-01, -7.6864e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9043e-02,  1.5258e-01,  2.2451e-01],\n",
      "          [ 3.9971e-02,  4.1465e-01,  4.9260e-01],\n",
      "          [ 2.9923e-02,  3.1183e-01,  3.7471e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1794e-02,  1.7795e-01,  6.0928e-02],\n",
      "          [-7.3710e-02,  3.1512e-01,  1.6593e-01],\n",
      "          [ 2.0093e-02,  2.3833e-01,  1.6535e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9611e-01, -1.2899e-01, -5.0494e-02],\n",
      "          [ 4.1330e-01, -1.9627e-01, -6.3805e-02],\n",
      "          [ 1.9833e-01, -2.3857e-02, -1.2965e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4327e-01, -2.7494e-01, -1.9668e-01],\n",
      "          [-3.2851e-01, -4.9188e-01, -3.6122e-01],\n",
      "          [-1.9934e-01, -3.7935e-01, -2.7371e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2211e-01, -3.6623e-01, -3.8703e-02],\n",
      "          [ 3.2832e-01, -6.2017e-01, -7.5133e-02],\n",
      "          [ 6.5813e-02, -2.5518e-01, -9.6677e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3187e-01,  1.9641e-01,  3.2848e-02],\n",
      "          [-3.9901e-01,  3.2890e-01,  9.6587e-02],\n",
      "          [-2.5677e-01,  2.1237e-01,  8.8836e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4130e-02, -2.7551e-01,  2.3959e-01],\n",
      "          [-1.9265e-01,  6.5930e-01, -4.6679e-01],\n",
      "          [ 1.2896e-01, -3.1693e-01,  1.6895e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4746e-01, -2.0045e-02, -2.1396e-01],\n",
      "          [ 5.6203e-01, -1.8745e-03, -5.2021e-01],\n",
      "          [ 2.0336e-01,  2.9689e-02, -1.5971e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5913e-01,  3.3721e-01,  2.6574e-01],\n",
      "          [ 1.9313e-01,  3.8682e-01,  2.6792e-01],\n",
      "          [ 4.7948e-02,  1.3460e-01,  9.8264e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3219e-02, -1.5708e-01, -1.5641e-01],\n",
      "          [-1.0087e-01, -3.9932e-01, -3.3464e-01],\n",
      "          [-8.1203e-02, -2.6770e-01, -2.6005e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1664e-02, -7.3078e-02, -2.9284e-01],\n",
      "          [ 9.1677e-02,  6.7136e-01,  3.7172e-01],\n",
      "          [-3.0643e-01, -3.9730e-01, -1.0753e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.8954e-02, -3.8683e-01, -3.8410e-01],\n",
      "          [ 6.0673e-02,  1.2305e-01,  3.3184e-02],\n",
      "          [-1.1377e-01,  5.6073e-01,  5.9268e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1135e-02,  2.4692e-01, -1.6056e-01],\n",
      "          [-1.3565e-01,  4.6063e-01, -3.3516e-01],\n",
      "          [-8.4310e-02,  2.8162e-01, -1.9822e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5530e-02,  1.7582e-01,  3.7282e-01],\n",
      "          [ 2.2387e-02,  3.0925e-01,  5.7316e-01],\n",
      "          [ 2.2001e-02,  1.9365e-01,  3.6587e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0883e-02,  1.9780e-01,  9.3333e-02],\n",
      "          [ 1.3971e-01,  3.4927e-01,  1.7715e-01],\n",
      "          [ 1.2430e-01,  2.7050e-01,  1.5053e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1140e-02, -1.5921e-01,  6.9742e-02],\n",
      "          [-3.6314e-01,  7.2204e-01, -3.1501e-01],\n",
      "          [ 2.8319e-01, -5.2464e-01,  2.5993e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8798e-01,  3.6908e-01,  2.3360e-01],\n",
      "          [ 2.4415e-01,  4.1559e-01,  2.5626e-01],\n",
      "          [ 9.4011e-02,  1.4295e-01,  5.9721e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5635e-02,  1.5367e-01,  8.7368e-02],\n",
      "          [ 1.5757e-01,  3.0185e-01,  2.9770e-01],\n",
      "          [ 8.5064e-02,  1.8149e-01,  1.3317e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.8343e-02,  2.7537e-01, -1.6641e-01],\n",
      "          [ 2.6203e-01, -7.0834e-01,  3.4951e-01],\n",
      "          [-1.6341e-01,  4.0708e-01, -1.9319e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4568e-01, -3.6181e-01,  2.1956e-01],\n",
      "          [ 6.7455e-02, -1.2125e-01,  7.1369e-02],\n",
      "          [-2.4259e-01,  5.8700e-01, -2.3630e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5154e-01,  3.0262e-01,  2.3808e-01],\n",
      "          [ 2.9219e-01,  5.4087e-01,  4.1261e-01],\n",
      "          [ 2.0751e-01,  3.6232e-01,  2.3781e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6657e-02, -1.0654e-01, -8.3082e-02],\n",
      "          [-1.0866e-01, -3.5695e-01, -3.2384e-01],\n",
      "          [-7.3726e-02, -1.8221e-01, -1.5163e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6671e-01,  8.1198e-02, -2.4854e-01],\n",
      "          [-3.1769e-01, -3.1412e-01,  6.4342e-01],\n",
      "          [ 1.2531e-01,  1.7823e-01, -3.0401e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3431e-01, -1.3946e-02,  3.4058e-02],\n",
      "          [ 9.0866e-02, -4.3755e-01, -4.6675e-01],\n",
      "          [-5.2202e-02, -4.7553e-01, -5.6220e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8006e-01, -5.5236e-02, -2.6660e-01],\n",
      "          [ 4.6333e-01, -2.4823e-02, -5.0352e-01],\n",
      "          [ 2.4865e-01,  2.7517e-03, -2.4666e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3319e-01,  3.9027e-01, -4.7003e-02],\n",
      "          [ 4.7870e-01, -5.2083e-01,  2.2427e-02],\n",
      "          [-1.2419e-01,  8.3537e-02,  2.3675e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6094e-01, -1.2775e-01,  2.7526e-01],\n",
      "          [ 1.8510e-01, -2.5262e-01, -5.0334e-01],\n",
      "          [-1.8796e-02,  3.7895e-01,  1.9610e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5662e-01,  2.0165e-01,  1.1456e-01],\n",
      "          [ 2.3454e-02,  8.2308e-02,  2.1143e-01],\n",
      "          [-1.4463e-01, -4.9376e-01, -4.5556e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.7893e-02,  2.9219e-01, -1.8730e-01],\n",
      "          [-7.0436e-02,  5.3544e-01, -2.7460e-01],\n",
      "          [-1.9700e-02,  3.1822e-01, -1.8396e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7074e-02, -1.1443e-01, -5.0513e-02],\n",
      "          [-2.4905e-01, -1.8732e-01, -9.1637e-02],\n",
      "          [-1.4723e-01, -1.9738e-01, -8.8182e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0958e-02,  5.8653e-02,  1.1984e-03],\n",
      "          [-8.6233e-02, -2.9119e-01, -2.2656e-01],\n",
      "          [-1.5162e-01, -3.3271e-01, -2.0242e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2814e-02, -6.9034e-02,  6.3164e-02],\n",
      "          [ 2.3146e-01,  6.8355e-01,  2.4584e-01],\n",
      "          [-7.0936e-02, -2.2718e-01, -2.5433e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7065e-02, -1.7017e-01, -1.3632e-01],\n",
      "          [-2.0581e-01, -4.8141e-01, -3.1561e-01],\n",
      "          [-1.2754e-01, -3.1105e-01, -2.2552e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6258e-01, -3.1452e-01, -2.4419e-01],\n",
      "          [-3.0385e-01, -5.4714e-01, -4.0412e-01],\n",
      "          [-2.0453e-01, -3.6282e-01, -2.4638e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3764e-01,  2.0585e-01,  1.7119e-01],\n",
      "          [-1.2142e-01, -7.9279e-02, -2.3861e-02],\n",
      "          [-1.7875e-01, -4.2164e-01, -3.2082e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0492e-02,  6.4712e-02, -2.0738e-02],\n",
      "          [ 3.3405e-01,  2.7804e-01, -1.9910e-01],\n",
      "          [ 1.8382e-01,  1.7538e-01, -2.3810e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8395e-01, -1.8051e-01, -1.9933e-02],\n",
      "          [-5.6086e-03,  3.8411e-01, -3.1618e-01],\n",
      "          [-1.4583e-01, -1.8083e-01,  3.8836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0771e-02,  2.2745e-01,  1.7642e-01],\n",
      "          [ 1.7451e-01,  4.6989e-01,  3.7945e-01],\n",
      "          [ 5.3422e-02,  1.7825e-01,  1.4390e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7659e-01,  4.6864e-01,  3.4525e-01],\n",
      "          [-9.1141e-02, -3.6178e-01, -3.1909e-01],\n",
      "          [-8.4650e-02, -8.4309e-02,  3.7520e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8457e-02,  1.4598e-01,  6.6904e-02],\n",
      "          [ 2.1123e-01,  3.9055e-01,  2.1135e-01],\n",
      "          [ 1.4287e-01,  2.2613e-01,  1.0797e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0479e-01,  9.7311e-02,  6.9448e-02],\n",
      "          [ 1.8973e-01,  2.5572e-01,  1.5598e-01],\n",
      "          [-1.8651e-01, -3.2158e-01, -1.8028e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9815e-02,  1.3926e-01, -9.6380e-03],\n",
      "          [ 4.1061e-02,  5.1406e-01, -1.1698e-01],\n",
      "          [ 1.0136e-01,  4.4064e-01,  5.5079e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2075e-02,  1.8388e-02,  4.5014e-02],\n",
      "          [-7.6733e-02, -2.8535e-01, -2.3702e-01],\n",
      "          [ 1.9185e-01,  5.0103e-01,  3.8408e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.3650e-02, -1.4294e-01, -1.3348e-01],\n",
      "          [-1.5555e-01, -3.9698e-01, -2.1404e-01],\n",
      "          [ 1.1655e-01,  3.8528e-01,  2.9314e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.8761e-02, -2.0506e-01, -1.0923e-01],\n",
      "          [-1.4768e-01, -3.7901e-01, -2.6238e-01],\n",
      "          [-4.3386e-02, -1.5421e-01, -1.3970e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8622e-01, -4.0944e-02, -2.5092e-01],\n",
      "          [ 4.4363e-01, -1.5038e-03, -4.3708e-01],\n",
      "          [ 2.1610e-01,  3.3031e-02, -1.9869e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3699e-01,  2.0247e-01,  1.9052e-01],\n",
      "          [ 2.4433e-01,  4.1936e-01,  3.8402e-01],\n",
      "          [ 1.4706e-01,  2.5063e-01,  1.8556e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1367e-01, -2.4623e-01, -4.1036e-01],\n",
      "          [-1.1153e-02,  1.8389e-01,  1.9350e-01],\n",
      "          [-1.9793e-01,  4.0965e-01,  6.7757e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2130e-02, -1.2980e-01, -1.1265e-01],\n",
      "          [-1.4634e-01, -2.0862e-01, -1.8155e-01],\n",
      "          [-7.9812e-02, -1.5335e-01, -1.2400e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7400e-01,  3.0228e-01,  1.7959e-01],\n",
      "          [ 2.9627e-01,  5.4663e-01,  4.0688e-01],\n",
      "          [ 1.8987e-01,  3.6853e-01,  3.0609e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1047e-02,  1.5038e-01,  1.2249e-01],\n",
      "          [ 1.3915e-01,  3.8367e-01,  3.0674e-01],\n",
      "          [ 1.2462e-01,  2.8242e-01,  1.9540e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.1602e-02, -2.1966e-01, -9.5104e-02],\n",
      "          [-1.0835e-01, -4.1997e-01, -2.0734e-01],\n",
      "          [-6.3506e-02, -2.4519e-01, -1.1520e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9197e-02, -1.9223e-02,  9.2073e-03],\n",
      "          [-1.5492e-01,  5.5895e-02,  1.0389e-01],\n",
      "          [-1.1167e-02, -3.8805e-01, -4.8559e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2209e-02, -2.6266e-01, -2.2131e-01],\n",
      "          [-1.5540e-01, -2.4963e-01, -1.9201e-01],\n",
      "          [ 1.5796e-01,  5.7585e-01,  4.3814e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5278e-02,  1.9793e-01,  1.9949e-01],\n",
      "          [-1.9170e-03, -4.5099e-04, -1.1482e-01],\n",
      "          [-2.6390e-02, -3.1286e-01, -4.6755e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5433e-02,  9.6400e-02, -4.4782e-02],\n",
      "          [-2.8308e-01,  4.7741e-01, -1.9588e-01],\n",
      "          [-1.9488e-01,  1.6312e-01, -3.9993e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5921e-02, -1.2828e-01,  1.4585e-01],\n",
      "          [-1.4339e-01, -2.5685e-01,  4.1156e-01],\n",
      "          [-1.2018e-01, -1.7831e-01,  2.8822e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7742e-02, -1.8929e-01, -1.0727e-01],\n",
      "          [-1.8547e-01, -4.6418e-01, -3.4301e-01],\n",
      "          [-1.2256e-01, -3.4591e-01, -2.6809e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4570e-01, -1.7422e-01, -2.0412e-01],\n",
      "          [-4.7459e-02,  1.7810e-01,  1.5609e-01],\n",
      "          [-1.8567e-02,  3.6146e-01,  4.7401e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9862e-02,  2.7317e-01,  1.4058e-01],\n",
      "          [ 1.6430e-01,  5.3506e-01,  2.4512e-01],\n",
      "          [ 8.6946e-02,  3.4831e-01,  1.5966e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.8603e-02,  1.5227e-01,  1.2644e-01],\n",
      "          [ 1.8811e-01,  3.6936e-01,  2.5579e-01],\n",
      "          [ 8.7888e-02,  1.9393e-01,  1.1616e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7390e-01,  3.1331e-01,  2.1142e-01],\n",
      "          [ 2.8858e-01,  5.4540e-01,  3.9854e-01],\n",
      "          [ 1.7707e-01,  3.4809e-01,  2.8804e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9319e-01,  2.7881e-01,  9.5896e-02],\n",
      "          [ 3.7916e-01,  4.9554e-01,  1.6486e-01],\n",
      "          [ 2.3662e-01,  3.1106e-01,  1.0653e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.8036e-02, -1.4082e-01, -5.8639e-02],\n",
      "          [-2.5474e-01, -2.4524e-01, -1.4744e-01],\n",
      "          [-1.5995e-01, -1.5864e-01, -8.7619e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6946e-01,  3.0224e-01,  2.3848e-01],\n",
      "          [ 2.8642e-01,  5.4142e-01,  3.9161e-01],\n",
      "          [ 2.0536e-01,  3.6715e-01,  2.4917e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6545e-02,  7.6723e-02,  9.8602e-02],\n",
      "          [-6.5597e-02,  8.8207e-03, -3.6653e-02],\n",
      "          [-1.7955e-01, -2.6694e-01, -3.1255e-01]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 1, 3, 3])\n",
      "\n",
      "Layer: features.2.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.7277262806892395\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.7220408916473389\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.1.1.weight\n",
      "Weights: tensor([1.3826, 0.4465, 1.0057, 1.1802, 0.8556, 0.8711, 0.6861, 0.8786, 0.9178,\n",
      "        1.2051, 0.7146, 1.0985, 1.1563, 0.4949, 0.7424, 1.0774, 0.7993, 1.3455,\n",
      "        0.9056, 0.8236, 1.1919, 1.0849, 1.6064, 0.9530, 0.7053, 1.2147, 0.7584,\n",
      "        1.1402, 1.3563, 1.7262, 0.7506, 0.5948, 0.8841, 1.0125, 1.4416, 1.8425,\n",
      "        1.0929, 0.8497, 0.6907, 0.7241, 0.9112, 0.5655, 1.2805, 1.6659, 0.7497,\n",
      "        1.1215, 2.4085, 0.9152, 1.2689, 1.1327, 0.9139, 1.7826, 1.1984, 0.9393,\n",
      "        0.8438, 1.1397, 1.1630, 1.3912, 1.2265, 1.4921, 1.2953, 1.5999, 0.9642,\n",
      "        0.9935, 0.5862, 0.6060, 0.9339, 0.6797, 1.4553, 0.8006, 1.0123, 0.8413,\n",
      "        1.3069, 1.3651, 0.7587, 0.7095, 0.9532, 0.6985, 1.1660, 0.9955, 0.7094,\n",
      "        0.7646, 0.7931, 0.9855, 0.5435, 0.7759, 1.0488, 0.7934, 0.5261, 0.9567,\n",
      "        0.6295, 0.9668, 1.6556, 0.6938, 0.9707, 0.4797], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.1.1.bias\n",
      "Weights: tensor([ 7.5620e-03,  7.4247e-01, -7.8194e-02,  2.6745e-04,  1.7465e+00,\n",
      "         8.8393e-01,  7.3902e-01,  8.1962e-01,  1.8966e-03, -6.3273e-03,\n",
      "         1.8983e+00,  2.1015e-01,  5.8337e-01,  1.2677e+00,  7.7360e-01,\n",
      "        -3.2448e-03,  5.1843e+00, -7.3580e-02,  1.6421e+00,  9.1868e-01,\n",
      "        -5.2219e-03, -2.1875e-02,  9.3169e-02,  2.5153e-02,  6.0127e-01,\n",
      "         1.9374e-01,  5.5692e-02, -7.3861e-03, -2.0706e-02, -2.8862e-02,\n",
      "         8.1430e-01,  1.3865e+00,  1.0753e-01,  3.4712e+00, -1.1026e-01,\n",
      "         1.3338e-01, -1.2485e-03,  3.0101e+00,  6.1986e-01,  1.9540e+00,\n",
      "        -7.2392e-03,  2.2067e-01,  2.0340e-02, -3.0140e-01,  2.5100e+00,\n",
      "         1.7716e-03, -7.9313e-01,  5.5139e-02, -5.0518e-03, -1.3580e-02,\n",
      "         1.4445e+00, -2.7540e-01, -9.7532e-04,  2.6185e+00,  2.1548e+00,\n",
      "        -1.3273e-03,  2.7660e-03, -5.9199e-02, -2.9659e-02,  3.2645e-01,\n",
      "        -3.3436e-01, -9.5921e-02,  4.1960e+00,  4.2505e+00,  9.3749e-01,\n",
      "         1.8490e+00,  3.0445e-04,  4.5149e-01, -4.6984e-02,  1.7726e-01,\n",
      "         1.1132e-02,  5.9014e-01, -1.4441e-02, -5.0097e-01,  7.8250e-01,\n",
      "         2.6715e+00,  9.5167e-01,  2.7783e-01,  5.7987e-02,  1.9873e+00,\n",
      "         1.1893e+00,  8.8009e-01,  1.9211e-01,  6.9451e-02,  2.8057e-01,\n",
      "         2.3206e-02,  1.0861e-02,  4.9461e+00,  2.4318e-01,  1.2453e+00,\n",
      "         3.3583e-01,  1.7951e+00, -2.3536e-01,  2.5779e+00,  2.2427e+00,\n",
      "         4.7208e-01], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.2.weight\n",
      "Weights: tensor([[[[-0.1680]],\n",
      "\n",
      "         [[ 0.0610]],\n",
      "\n",
      "         [[ 0.1652]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0985]],\n",
      "\n",
      "         [[ 0.1989]],\n",
      "\n",
      "         [[-0.0177]]],\n",
      "\n",
      "\n",
      "        [[[-0.3762]],\n",
      "\n",
      "         [[ 0.0889]],\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0473]],\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         [[-0.0124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0762]],\n",
      "\n",
      "         [[-0.5220]],\n",
      "\n",
      "         [[ 0.4601]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3724]],\n",
      "\n",
      "         [[-0.2044]],\n",
      "\n",
      "         [[-0.3410]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7030]],\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[-0.1395]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0261]],\n",
      "\n",
      "         [[ 0.0780]],\n",
      "\n",
      "         [[-0.0275]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0539]],\n",
      "\n",
      "         [[-0.0503]],\n",
      "\n",
      "         [[ 0.1892]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1650]],\n",
      "\n",
      "         [[ 1.0237]],\n",
      "\n",
      "         [[-0.0188]]],\n",
      "\n",
      "\n",
      "        [[[-0.1638]],\n",
      "\n",
      "         [[-0.2871]],\n",
      "\n",
      "         [[ 0.0037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0950]],\n",
      "\n",
      "         [[ 0.1159]],\n",
      "\n",
      "         [[-0.1064]]]], device='cuda:0')\n",
      "Shape: torch.Size([24, 96, 1, 1])\n",
      "\n",
      "Layer: features.2.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.8741174936294556\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.8594759702682495\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.3.weight\n",
      "Weights: tensor([5.2228, 5.2894, 5.4275, 3.9051, 3.2605, 5.6396, 6.7108, 7.2005, 6.5244,\n",
      "        5.9433, 7.1542, 6.2734, 5.2621, 5.5405, 5.0873, 6.6448, 3.3335, 5.3758,\n",
      "        4.6607, 5.6264, 4.3071, 7.7067, 6.9634, 5.4482], device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.2.conv.3.bias\n",
      "Weights: tensor([ 1.0881e-06,  3.0214e-06,  4.3825e-06,  1.5142e-06,  2.4640e-06,\n",
      "        -6.3383e-08,  5.0872e-06,  6.8371e-06,  2.7354e-06,  1.0333e-06,\n",
      "         1.7848e-07, -6.2331e-06,  3.8128e-07, -8.5036e-07,  6.6239e-06,\n",
      "        -1.0822e-06, -2.1203e-06,  1.5032e-06,  4.5900e-06,  1.1467e-05,\n",
      "         3.6715e-06,  1.4438e-05,  3.8392e-06, -2.5940e-06], device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.2.conv.3.output_quantizers.0.min\n",
      "Weights: -41.19752502441406\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.2.conv.3.output_quantizers.0.max\n",
      "Weights: 56.380615234375\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.1575]],\n",
      "\n",
      "         [[ 0.0842]],\n",
      "\n",
      "         [[-0.1252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1475]],\n",
      "\n",
      "         [[-0.0208]],\n",
      "\n",
      "         [[ 0.1073]]],\n",
      "\n",
      "\n",
      "        [[[-0.0812]],\n",
      "\n",
      "         [[ 0.3641]],\n",
      "\n",
      "         [[-0.0048]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3482]],\n",
      "\n",
      "         [[-0.2009]],\n",
      "\n",
      "         [[ 0.0918]]],\n",
      "\n",
      "\n",
      "        [[[-0.0345]],\n",
      "\n",
      "         [[-0.1274]],\n",
      "\n",
      "         [[ 0.0390]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3065]],\n",
      "\n",
      "         [[ 0.0241]],\n",
      "\n",
      "         [[-0.0779]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0490]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[ 0.0162]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4867]],\n",
      "\n",
      "         [[-0.2367]],\n",
      "\n",
      "         [[-0.0338]]],\n",
      "\n",
      "\n",
      "        [[[-0.2036]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.0829]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1718]],\n",
      "\n",
      "         [[-0.1291]],\n",
      "\n",
      "         [[ 0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.0956]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1969]],\n",
      "\n",
      "         [[ 0.2275]],\n",
      "\n",
      "         [[ 0.0758]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 24, 1, 1])\n",
      "\n",
      "Layer: features.3.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -1.1380555629730225\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 1.129164457321167\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.0.1.weight\n",
      "Weights: tensor([ 1.4705,  3.9500,  1.4371,  2.9074,  0.5869,  1.8881,  1.1719,  1.5630,\n",
      "         1.0753,  1.1106,  0.8656,  1.6424,  0.5247,  2.8106,  0.7844,  1.8731,\n",
      "         1.3254,  1.2403,  3.3885,  1.4286,  1.3130,  2.0703,  0.4931,  2.1968,\n",
      "         1.2217,  1.2172,  2.1691,  1.0059,  0.4284,  1.8862,  1.0327,  1.1014,\n",
      "         1.8866,  1.1264,  2.1209,  0.8309,  1.9617,  0.8717,  1.8313,  1.9960,\n",
      "         1.6821,  2.8242,  1.2718,  0.9867,  2.7427,  1.5671,  2.5326,  1.7861,\n",
      "         1.1244,  0.8854,  1.9865,  0.7512,  0.6260,  1.4307,  0.8909,  1.5297,\n",
      "         1.6954,  0.8946,  2.0853,  0.6280,  0.9074,  1.7771,  0.6599,  1.9918,\n",
      "         3.6987,  1.3391,  1.0758,  0.8746,  0.7409,  1.5825,  1.1363,  1.3878,\n",
      "         1.6332,  0.8567,  1.4563,  2.0853,  0.9557,  3.1424,  1.3901,  0.8912,\n",
      "         1.9686,  2.0343, -0.1904,  1.0059,  1.1780,  1.9324,  0.7931,  0.8474,\n",
      "         2.1453,  2.0205,  0.9631,  1.3360,  0.9160,  1.1844,  1.4485,  0.8336,\n",
      "         1.7230,  3.1257,  1.0907,  1.6966,  1.2159,  0.3927,  0.4711,  0.9441,\n",
      "         0.9869,  2.4748,  0.3877,  0.8638,  1.1051,  0.8813,  2.0619,  0.7175,\n",
      "         0.7268,  1.1465,  0.6309,  1.7022,  0.8760,  2.5244,  1.3976,  1.4171,\n",
      "         0.8820,  1.0383,  1.9960,  1.7679,  1.5610,  0.7921,  1.0721,  2.4079,\n",
      "         1.9697,  1.7457,  1.0617,  2.6330,  2.1217,  0.6383,  0.4111,  2.2287,\n",
      "         1.0802,  1.0018,  0.7214,  3.8245,  1.6819,  0.8121,  1.0306,  1.5368],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.0.1.bias\n",
      "Weights: tensor([-0.5232, -3.1802,  1.5296, -1.2349,  1.8479, -0.9926,  1.8178,  1.6625,\n",
      "         0.8027,  1.4830,  2.4380, -1.1387,  1.7272,  1.6183,  1.5773, -0.9225,\n",
      "         0.5680,  1.4517, -3.3136, -0.3723,  1.0956, -0.0978,  2.1974, -1.2445,\n",
      "        -1.1887,  1.2709, -0.4919,  0.8362,  1.4255, -0.3078,  1.9176,  1.6258,\n",
      "        -0.8781,  1.2311, -1.0883,  1.1537, -0.2803,  1.6166, -0.2742, -0.5851,\n",
      "        -1.4594, -2.0855, -0.3799,  1.1365, -2.8877, -1.4197, -2.9356, -0.2443,\n",
      "         1.3150,  1.3154,  0.7153,  0.5749,  2.1254,  1.4043,  2.6706,  1.0689,\n",
      "        -0.4070,  1.0811, -0.9382,  2.1009,  1.5768, -0.3971,  2.4209, -0.4000,\n",
      "        -2.7176,  1.0587,  1.0363,  1.3204,  0.9793,  0.5368,  2.0689, -1.6877,\n",
      "         0.0446,  1.4897, -0.0239, -0.2206,  1.5489, -1.9373,  0.4771,  2.9947,\n",
      "        -0.5353, -0.0832, -1.8680,  1.0696,  1.5789,  1.8354,  0.2771,  2.4789,\n",
      "        -0.1117,  0.1722,  0.8008,  0.9835,  2.0963,  3.1257,  0.7726,  1.2979,\n",
      "        -0.7372,  3.0755,  1.1197, -0.7724,  2.3576,  3.3552,  5.5105,  1.5695,\n",
      "         2.8269,  3.6163,  3.6288,  1.8301,  1.8532,  1.2849, -0.2604,  2.5892,\n",
      "         1.7444,  0.3364,  1.9969,  1.5724,  1.2440,  1.4637,  0.4011,  1.2331,\n",
      "         1.4448,  0.1138, -0.6111,  0.1576, -0.4200,  1.2432,  2.7150,  2.7100,\n",
      "         0.4211, -0.4594,  0.5366,  1.0729,  1.6563,  1.2238,  2.0673, -2.0134,\n",
      "         1.4736,  0.2564,  1.3629,  4.9738,  1.3160,  1.4545,  1.3644, -0.3849],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0044, -0.1482, -0.0025],\n",
      "          [ 0.0576,  0.1330,  0.0086],\n",
      "          [ 0.1016,  0.2966,  0.0783]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0917,  0.1543,  0.1421],\n",
      "          [-0.0501, -0.7903, -0.1335],\n",
      "          [ 0.0780,  0.0840,  0.1025]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1437, -0.4141,  0.1264],\n",
      "          [ 0.0858, -0.2970,  0.1174],\n",
      "          [ 0.1316, -0.5710,  0.1309]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0784,  0.1673, -0.1362],\n",
      "          [ 0.3877,  0.1857, -0.4764],\n",
      "          [ 0.1749, -0.1880, -0.2622]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0067,  0.1376, -0.0119],\n",
      "          [-0.3247,  0.6082, -0.1075],\n",
      "          [-0.0718,  0.1341, -0.1093]]],\n",
      "\n",
      "\n",
      "        [[[-0.1851, -0.2015,  0.6039],\n",
      "          [-0.1613, -0.0538, -0.0851],\n",
      "          [ 0.5323, -0.0086, -0.3313]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 1, 3, 3])\n",
      "\n",
      "Layer: features.3.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -1.39398193359375\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 1.3830914497375488\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.1.1.weight\n",
      "Weights: tensor([1.0484, 0.5453, 1.7957, 0.8726, 3.1691, 0.8834, 0.9053, 1.1800, 1.4355,\n",
      "        1.2199, 1.3819, 0.5177, 1.3578, 0.8317, 1.0966, 0.5962, 0.5823, 1.0062,\n",
      "        0.4840, 0.5120, 0.9160, 1.2373, 1.8740, 0.5472, 0.3596, 1.5106, 0.7291,\n",
      "        0.9804, 2.5180, 0.6472, 0.9336, 0.8728, 0.8871, 1.5701, 0.7105, 1.3158,\n",
      "        1.0303, 1.2513, 0.7031, 0.9187, 0.5797, 0.9106, 0.6124, 1.0269, 0.6915,\n",
      "        0.5485, 1.1414, 0.7799, 0.9681, 0.9744, 1.1301, 1.1109, 1.1294, 1.7731,\n",
      "        1.3318, 1.1713, 0.7863, 1.0319, 0.5835, 1.2527, 1.2582, 0.9243, 0.8246,\n",
      "        0.9665, 0.6110, 0.9205, 1.2405, 1.2000, 1.4102, 0.8589, 0.8317, 0.3950,\n",
      "        1.0655, 1.1464, 0.5862, 1.1509, 1.2173, 0.8281, 1.1580, 4.3548, 0.9781,\n",
      "        1.1158, 0.5397, 1.3602, 1.3729, 0.7663, 1.8210, 1.4286, 1.1494, 0.7470,\n",
      "        1.3593, 0.7299, 1.1442, 0.8895, 0.6520, 1.3868, 0.6388, 1.0983, 1.0498,\n",
      "        0.7341, 1.4697, 2.1416, 1.2755, 1.1909, 0.7445, 1.5495, 4.8102, 1.2479,\n",
      "        0.9831, 1.0044, 0.8886, 1.4183, 1.0457, 1.2022, 1.3125, 1.2659, 1.2307,\n",
      "        1.2132, 0.9878, 0.7791, 1.1402, 1.1023, 0.8364, 0.7902, 0.8022, 1.2410,\n",
      "        1.2686, 1.2770, 1.0265, 0.7513, 1.1410, 1.1307, 1.1551, 1.0097, 2.3919,\n",
      "        0.8638, 0.8451, 0.9614, 1.1221, 1.5679, 1.2282, 1.1022, 1.3413, 0.6503],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.1.1.bias\n",
      "Weights: tensor([-1.3360e+00,  3.1414e+00, -1.0548e+00,  2.1674e-01, -3.1877e+00,\n",
      "         9.4011e-02,  2.6164e-03,  2.7771e-01, -5.2949e-01, -1.7107e-01,\n",
      "        -2.8380e-01,  2.5221e+00, -1.1125e-01,  7.4532e-01,  3.1851e-02,\n",
      "         2.3968e+00,  1.8716e+00, -5.8063e-02,  1.1389e+00,  2.3893e+00,\n",
      "         3.9203e-01,  2.5424e-02, -1.6268e+00,  1.8135e+00,  2.6642e+00,\n",
      "        -1.2059e+00,  2.8084e+00, -6.8557e-02, -6.3216e-01,  1.4009e+00,\n",
      "         2.1943e+00,  5.5944e-01,  7.2002e-03, -6.7995e-01,  6.2051e-01,\n",
      "        -5.1100e-03,  5.4799e-03, -5.1318e-01,  3.3272e+00,  5.9600e-02,\n",
      "         1.0165e+00,  3.8100e-01,  2.9263e+00, -1.0969e-01, -2.4174e-01,\n",
      "         3.8776e+00, -3.5973e+00,  4.7224e+00,  7.9077e-01,  5.4057e-02,\n",
      "         2.1317e-02, -2.3211e-01,  6.0020e-01,  6.8948e+00, -1.0372e-01,\n",
      "         7.2680e-03,  5.8811e-01,  1.1594e-02,  3.7885e+00, -1.5496e-02,\n",
      "         3.7930e-03, -1.8444e-01,  2.3845e+00, -2.9691e-02,  1.8386e+00,\n",
      "         7.5800e-01, -7.2158e-01, -1.3044e-02, -2.4782e-01,  3.5527e+00,\n",
      "         3.0909e+00,  3.5342e+00,  5.8332e-02, -2.7726e-01,  3.6157e+00,\n",
      "        -4.5028e-02, -4.3413e-01, -1.1491e-01,  1.7729e+00, -3.7289e-01,\n",
      "         7.5847e-03,  4.4589e-02, -6.3821e-01, -9.7726e-01, -2.6957e-01,\n",
      "         3.4671e-01, -1.1596e+00, -9.5065e-01, -6.5904e-03,  1.9222e+00,\n",
      "        -1.0770e-01,  2.3386e-01, -2.0107e-01,  1.1042e+00,  9.0699e-01,\n",
      "        -2.7845e-01,  2.6434e+00,  2.4803e-01, -3.3316e-01, -9.2999e-01,\n",
      "        -1.9949e-01,  4.8973e-01, -2.5600e-01,  3.3059e-02,  3.3313e+00,\n",
      "        -7.3918e-01, -2.5631e+00, -8.9273e-03,  1.5617e+00, -8.3449e-02,\n",
      "         1.8885e-01, -1.0513e+00, -4.5201e-02, -2.2191e-01, -4.7450e-02,\n",
      "        -3.9315e-01, -1.1857e-01, -5.3980e-02,  5.6569e-01, -2.3768e-02,\n",
      "        -1.1561e-01, -2.2656e-01, -7.1466e-02,  3.0843e-01,  2.7804e+00,\n",
      "        -1.4833e-01, -2.0032e-01, -9.8723e-02, -1.9379e-02,  7.1101e-01,\n",
      "        -1.5793e-01, -5.2176e-04, -3.7700e-01,  6.5474e-01, -2.9873e+00,\n",
      "        -8.3942e-01,  3.2947e+00,  5.9254e-01, -2.7000e-01, -1.2329e+00,\n",
      "        -2.5178e-02, -1.1659e-01, -1.4326e-01,  3.8965e+00], device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.2.weight\n",
      "Weights: tensor([[[[ 0.1717]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[-0.0907]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1531]],\n",
      "\n",
      "         [[-0.1316]],\n",
      "\n",
      "         [[ 0.0274]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0616]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.1291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1601]],\n",
      "\n",
      "         [[ 0.0864]],\n",
      "\n",
      "         [[-0.0418]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0569]],\n",
      "\n",
      "         [[-0.1338]],\n",
      "\n",
      "         [[-0.0136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0808]],\n",
      "\n",
      "         [[-0.0587]],\n",
      "\n",
      "         [[-0.0410]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1046]],\n",
      "\n",
      "         [[-0.3163]],\n",
      "\n",
      "         [[-0.1079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0920]],\n",
      "\n",
      "         [[ 0.0929]],\n",
      "\n",
      "         [[-0.0221]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0259]],\n",
      "\n",
      "         [[ 0.3398]],\n",
      "\n",
      "         [[-0.0430]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0793]],\n",
      "\n",
      "         [[-0.3462]],\n",
      "\n",
      "         [[-0.1475]]],\n",
      "\n",
      "\n",
      "        [[[-0.0062]],\n",
      "\n",
      "         [[ 0.0785]],\n",
      "\n",
      "         [[-0.0539]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0616]],\n",
      "\n",
      "         [[-0.0482]],\n",
      "\n",
      "         [[ 0.0340]]]], device='cuda:0')\n",
      "Shape: torch.Size([24, 144, 1, 1])\n",
      "\n",
      "Layer: features.3.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.0848462581634521\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.0763709545135498\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.3.weight\n",
      "Weights: tensor([ 5.1378,  4.7547,  2.2893,  6.0456, 10.0808,  5.4543,  3.4893,  4.6860,\n",
      "         2.0659,  6.4861,  4.4153,  4.6330,  2.4860,  3.1361,  7.1040,  2.9484,\n",
      "        10.2731,  4.7423,  4.0836,  6.4447,  6.0243,  2.7786,  5.7020,  2.1510],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.3.conv.3.bias\n",
      "Weights: tensor([ 6.3783e-07,  1.0743e-06,  1.3509e-06,  5.6569e-07,  2.5455e-06,\n",
      "        -1.2566e-06,  3.8278e-06,  3.7090e-06,  4.7356e-07,  2.6085e-06,\n",
      "        -8.7942e-06, -3.9438e-06, -9.0818e-07, -7.1828e-07, -1.3535e-08,\n",
      "        -3.9213e-06,  1.9390e-06,  4.8957e-06,  6.2979e-07,  3.7465e-06,\n",
      "         4.7056e-06,  1.0944e-05,  2.3808e-06, -4.6929e-06], device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.3.conv.3.output_quantizers.0.min\n",
      "Weights: -72.18489837646484\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.3.conv.3.output_quantizers.0.max\n",
      "Weights: 72.17890930175781\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.2264]],\n",
      "\n",
      "         [[ 0.1353]],\n",
      "\n",
      "         [[ 0.0187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3013]],\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         [[-0.0167]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1615]],\n",
      "\n",
      "         [[ 0.0351]],\n",
      "\n",
      "         [[-0.0508]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1164]],\n",
      "\n",
      "         [[-0.0584]],\n",
      "\n",
      "         [[ 0.3263]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0732]],\n",
      "\n",
      "         [[ 0.0015]],\n",
      "\n",
      "         [[ 0.1558]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2342]],\n",
      "\n",
      "         [[ 0.0659]],\n",
      "\n",
      "         [[-0.1773]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0804]],\n",
      "\n",
      "         [[-0.0498]],\n",
      "\n",
      "         [[ 0.0212]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2225]],\n",
      "\n",
      "         [[-0.8159]],\n",
      "\n",
      "         [[-0.0336]]],\n",
      "\n",
      "\n",
      "        [[[-0.2520]],\n",
      "\n",
      "         [[ 0.1753]],\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4517]],\n",
      "\n",
      "         [[-0.0596]],\n",
      "\n",
      "         [[-0.0750]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0122]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[-0.6465]],\n",
      "\n",
      "         [[ 0.0507]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 24, 1, 1])\n",
      "\n",
      "Layer: features.4.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -1.5615171194076538\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 1.549317717552185\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.0.0.input_quantizers.0.min\n",
      "Weights: -73.5665512084961\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.0.0.input_quantizers.0.max\n",
      "Weights: 75.62728118896484\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.0.1.weight\n",
      "Weights: tensor([2.2369, 1.4738, 3.6327, 1.4013, 1.3992, 1.2629, 1.4573, 4.0059, 2.0175,\n",
      "        2.8470, 2.1820, 1.8551, 2.6802, 1.6920, 1.0090, 2.4253, 1.5307, 1.6719,\n",
      "        0.9758, 2.2957, 2.3644, 0.9213, 1.2862, 1.2355, 1.2170, 2.1270, 0.9452,\n",
      "        2.5388, 1.7158, 2.5274, 2.6421, 0.8484, 1.7902, 2.1487, 2.5015, 0.7637,\n",
      "        0.4686, 2.2535, 1.6168, 2.1135, 0.8464, 0.9237, 1.6183, 3.2904, 1.4617,\n",
      "        1.3740, 1.3918, 1.4688, 1.5761, 1.2394, 0.9115, 0.7763, 1.2161, 1.2297,\n",
      "        1.1300, 1.7883, 2.2473, 4.1798, 2.7102, 3.8978, 2.0793, 1.9123, 1.1888,\n",
      "        0.6734, 1.2773, 1.0395, 0.7821, 3.1244, 1.4891, 0.4185, 3.6612, 2.0465,\n",
      "        1.5604, 3.1105, 1.1223, 1.2049, 2.3392, 1.2523, 1.9331, 0.5851, 1.1710,\n",
      "        1.7746, 1.3706, 1.6128, 1.1468, 1.3938, 1.0986, 1.6300, 2.0689, 2.2090,\n",
      "        4.3002, 1.0057, 1.0135, 1.5171, 1.7037, 0.7852, 2.4912, 2.2777, 0.9821,\n",
      "        1.3826, 2.3538, 2.3194, 2.0294, 3.0632, 3.0419, 1.1543, 1.8169, 3.0965,\n",
      "        2.2415, 3.3154, 3.3182, 1.5402, 2.6372, 2.0929, 3.2703, 1.2346, 1.6202,\n",
      "        1.0144, 2.1630, 0.9933, 0.4861, 0.5109, 2.0687, 1.6936, 2.5403, 1.3318,\n",
      "        1.0740, 1.0930, 2.3555, 1.1639, 2.3474, 2.7985, 1.3384, 1.8416, 2.4805,\n",
      "        1.9009, 2.0629, 3.0202, 4.0851, 3.0758, 2.3877, 2.4670, 3.6558, 1.7344],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.0.1.bias\n",
      "Weights: tensor([-1.0041, -2.2723,  0.1727,  0.5893,  0.8099, -0.0219, -0.3419,  1.6427,\n",
      "        -1.0926,  4.6672, -1.8937,  0.0323, -1.2680, -0.5612,  0.6553, -0.8568,\n",
      "        -0.4177, -0.5648,  1.8210, -0.4014, -1.0975,  0.1124, -1.2683,  0.0799,\n",
      "        -0.8365, -0.3541,  0.7097, -2.0862,  0.2308,  0.0260, -1.7066, -0.2801,\n",
      "        -0.9940, -0.4207,  0.5891,  0.5104,  1.7426, -0.3184, -0.3920,  2.7225,\n",
      "         0.9297,  0.2083, -0.5575, -0.4435, -0.9565,  0.3844, -0.7018,  0.1271,\n",
      "        -1.2774, -0.2287,  0.8559,  0.3299,  0.4216,  0.7357,  0.3025,  0.5548,\n",
      "        -0.1615,  0.6427,  0.9184, -0.8191, -0.7536,  2.3566, -0.1294,  1.3628,\n",
      "        -0.0297,  0.6189,  1.3305, -0.9879, -0.1336,  1.1663,  0.2930, -1.0249,\n",
      "        -1.2917,  0.9303,  0.0100,  0.3111,  5.5986, -1.6798, -0.8039,  1.4727,\n",
      "        -0.3513, -0.1628, -0.3404,  2.2219,  1.2453,  0.4051,  0.1982, -1.3802,\n",
      "         0.0320,  2.7404, -1.1067,  0.9235, -0.1420, -1.3834,  0.1664,  1.2832,\n",
      "        -0.4833,  1.1943,  0.9504, -1.8088, -0.7069,  0.7565,  5.3276, -0.4533,\n",
      "         0.2845, -0.7368, -0.2467, -1.1306, -2.0307, -2.6805, -0.2317, -2.7627,\n",
      "         2.2826, -0.2068, -3.6284,  1.7060,  3.1853,  1.7100, -0.5282, -1.2024,\n",
      "         1.7985,  2.0764, -0.4361, -0.4741,  0.5294, -0.9663,  1.8879,  0.0312,\n",
      "        -2.0869, -0.0642,  1.5564, -1.8572, -0.4360, -0.0155,  2.5979,  3.3513,\n",
      "        -2.0807, -4.2992,  0.9501, -0.7168,  1.1991,  1.4821,  2.0369, -1.4841],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0369, -0.1349, -0.0946],\n",
      "          [-0.1142, -0.2704, -0.1790],\n",
      "          [-0.0886, -0.1903, -0.1447]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1032,  0.1668,  0.1483],\n",
      "          [ 0.1662,  0.2045,  0.1770],\n",
      "          [ 0.1166,  0.1614,  0.1396]]],\n",
      "\n",
      "\n",
      "        [[[-0.0880, -0.1551, -0.1004],\n",
      "          [-0.1473, -0.2526, -0.1715],\n",
      "          [-0.0945, -0.1826, -0.1204]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0682, -0.1680, -0.1729],\n",
      "          [-0.1674, -0.2851, -0.2150],\n",
      "          [-0.1574, -0.2182, -0.1240]]],\n",
      "\n",
      "\n",
      "        [[[-0.0432, -0.1345, -0.0944],\n",
      "          [-0.1176, -0.2445, -0.2021],\n",
      "          [-0.0596, -0.1680, -0.1236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1152,  0.1799,  0.0623],\n",
      "          [ 0.1592,  0.3269,  0.2542],\n",
      "          [ 0.0308,  0.2138,  0.2069]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 1, 3, 3])\n",
      "\n",
      "Layer: features.4.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.4925461411476135\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.4886981248855591\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.1.1.weight\n",
      "Weights: tensor([0.7261, 0.3465, 2.5337, 0.8213, 0.9702, 0.9505, 0.9197, 2.2751, 0.8717,\n",
      "        0.8335, 0.8297, 1.1587, 0.8061, 0.8651, 0.8729, 0.8481, 0.8413, 0.8552,\n",
      "        1.1066, 1.7382, 0.9099, 0.8687, 0.6885, 1.1281, 0.7856, 1.0491, 1.0757,\n",
      "        0.6695, 0.9269, 1.4746, 0.7835, 0.7310, 0.9648, 1.7556, 2.3967, 1.0735,\n",
      "        0.9006, 1.5241, 0.7658, 2.3220, 0.9926, 1.2957, 0.8557, 1.0462, 0.7438,\n",
      "        0.7836, 0.9545, 0.8915, 0.6668, 0.9748, 0.9929, 1.0063, 0.9102, 1.4203,\n",
      "        0.8937, 1.1869, 1.6314, 1.9627, 1.7616, 1.9999, 0.9106, 1.0332, 0.9049,\n",
      "        1.2957, 0.7470, 0.8401, 1.6645, 2.0251, 0.9237, 1.9586, 3.6156, 0.8826,\n",
      "        0.6460, 2.3717, 0.8831, 1.1359, 0.9812, 0.7636, 1.0006, 1.7259, 0.7762,\n",
      "        0.8487, 0.7184, 1.2705, 1.1751, 0.9654, 0.8600, 0.5355, 1.4665, 1.9383,\n",
      "        1.7031, 1.0787, 1.0987, 0.7832, 0.8984, 0.8285, 1.2391, 1.3090, 1.2199,\n",
      "        0.5316, 1.9012, 1.8150, 1.0321, 1.3140, 1.8869, 0.6805, 0.9396, 1.3266,\n",
      "        0.7261, 0.8493, 1.6665, 0.4452, 2.4666, 1.1827, 0.5519, 1.2743, 1.4426,\n",
      "        1.0256, 1.7497, 0.8090, 1.4783, 1.8026, 1.1696, 0.9103, 1.1204, 0.7137,\n",
      "        1.1238, 0.8461, 0.6183, 0.8246, 1.8448, 0.8402, 1.0072, 0.9631, 1.0890,\n",
      "        1.3488, 0.7219, 1.0054, 2.6044, 1.5106, 1.6173, 2.8169, 2.8924, 0.8173],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.1.1.bias\n",
      "Weights: tensor([ 5.2370,  0.1270, -1.3967,  1.5023,  1.7834,  1.0116,  1.1932, -0.6150,\n",
      "         0.9475,  1.4066,  0.3781,  0.2520,  0.5593,  2.5467,  1.7511,  0.3656,\n",
      "         1.0340,  0.9629,  2.3361,  0.6535,  0.6885,  1.0785,  0.4266,  1.2879,\n",
      "         1.0967,  1.6065,  1.5466,  0.4464,  3.5142, -0.1750,  0.6386,  0.7801,\n",
      "         1.4182,  0.8451, -1.3534, -0.3171,  3.2001,  0.2491,  1.3243, -2.4091,\n",
      "        -0.1302, -0.4909,  0.8836,  1.5284,  0.8005,  1.3958,  0.6821,  4.5130,\n",
      "         0.2742,  1.3969, -0.2023, -0.2390,  0.8965, -0.4294,  1.4053,  1.4944,\n",
      "        -0.0201, -0.7961, -0.2522, -1.1536,  0.8202,  2.6362,  0.6780, -0.2099,\n",
      "         2.6013,  1.3559, -0.5828, -0.7797,  1.2649, -0.5460, -3.0757,  2.1770,\n",
      "         0.4486, -0.8580,  1.1001,  1.2822,  1.3086,  2.3402,  0.8884, -0.4220,\n",
      "         1.0344,  1.0497,  0.7848, -0.3230, -0.1687,  2.4975,  1.0518,  0.3715,\n",
      "         0.5728, -2.0167, -0.1627, -0.2605,  1.4521,  1.9300,  1.4268,  0.3423,\n",
      "         1.2723,  0.2245, -0.3154,  0.8325,  0.6607, -0.3248,  1.0065,  1.2415,\n",
      "        -0.3753,  0.6976,  1.5444,  1.0625,  0.4370,  1.4925,  0.3264,  0.1511,\n",
      "        -0.4226,  1.3229,  0.1938, -0.2064, -0.3165,  1.4591, -0.0300,  1.8116,\n",
      "        -0.4072, -0.7881,  0.5462,  1.5608,  0.3831,  0.5804,  2.1728,  0.8799,\n",
      "         0.2989,  0.6063,  0.0638,  0.6306,  1.9533,  1.2390,  0.5278,  0.1031,\n",
      "         3.3595, -0.1674, -1.1965,  1.2332,  0.0595, -0.8469, -1.7791,  1.1729],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.2.weight\n",
      "Weights: tensor([[[[ 0.1212]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[-0.2634]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0487]],\n",
      "\n",
      "         [[ 0.1192]],\n",
      "\n",
      "         [[ 0.1421]]],\n",
      "\n",
      "\n",
      "        [[[-0.0111]],\n",
      "\n",
      "         [[ 0.0802]],\n",
      "\n",
      "         [[-0.0359]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3386]],\n",
      "\n",
      "         [[-0.0748]],\n",
      "\n",
      "         [[-0.1906]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0735]],\n",
      "\n",
      "         [[ 0.3767]],\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3106]],\n",
      "\n",
      "         [[ 0.2452]],\n",
      "\n",
      "         [[-0.2738]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0141]],\n",
      "\n",
      "         [[-0.0820]],\n",
      "\n",
      "         [[ 0.5217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0065]],\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         [[-0.0428]]],\n",
      "\n",
      "\n",
      "        [[[-0.3648]],\n",
      "\n",
      "         [[-0.1968]],\n",
      "\n",
      "         [[ 0.0329]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2351]],\n",
      "\n",
      "         [[ 0.0217]],\n",
      "\n",
      "         [[-0.3777]]],\n",
      "\n",
      "\n",
      "        [[[-0.1456]],\n",
      "\n",
      "         [[ 0.1378]],\n",
      "\n",
      "         [[-0.1040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0130]],\n",
      "\n",
      "         [[ 0.1997]],\n",
      "\n",
      "         [[ 0.1276]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 144, 1, 1])\n",
      "\n",
      "Layer: features.4.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.3723613023757935\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.3616397380828857\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.3.weight\n",
      "Weights: tensor([4.9028, 6.2684, 4.9340, 6.2001, 4.3269, 5.8029, 5.0184, 4.4519, 5.9551,\n",
      "        6.0546, 5.6649, 4.5998, 6.5915, 3.2259, 5.5010, 6.6378, 4.3936, 4.7463,\n",
      "        3.4861, 5.3670, 6.8166, 3.7912, 5.0145, 5.6286, 5.6646, 5.8290, 5.6283,\n",
      "        5.7119, 4.2634, 5.6147, 5.4345, 7.4288], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.4.conv.3.bias\n",
      "Weights: tensor([-4.3353e-07,  1.7914e-06,  2.5913e-06,  2.6290e-06, -1.8708e-06,\n",
      "        -1.4881e-07, -3.3277e-07,  1.2786e-06, -2.1400e-06,  6.3715e-07,\n",
      "         1.6981e-07, -1.0889e-06, -8.8385e-07, -7.4630e-07,  2.8402e-07,\n",
      "         1.2994e-06, -1.3340e-06, -6.6812e-07, -1.0725e-06,  1.1744e-06,\n",
      "        -1.0800e-06,  2.4396e-06, -1.2818e-06,  2.9553e-06,  1.5508e-06,\n",
      "         4.9451e-07, -1.7859e-06, -2.2576e-06,  1.8819e-06,  7.1620e-08,\n",
      "         1.3129e-07,  1.2972e-06], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.4.conv.3.output_quantizers.0.min\n",
      "Weights: -31.84093475341797\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.4.conv.3.output_quantizers.0.max\n",
      "Weights: 34.5457878112793\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.1083]],\n",
      "\n",
      "         [[-0.1098]],\n",
      "\n",
      "         [[ 0.1325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1126]],\n",
      "\n",
      "         [[-0.0357]],\n",
      "\n",
      "         [[ 0.0544]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0870]],\n",
      "\n",
      "         [[-0.0438]],\n",
      "\n",
      "         [[-0.0459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0192]],\n",
      "\n",
      "         [[ 0.0544]],\n",
      "\n",
      "         [[ 0.2662]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1540]],\n",
      "\n",
      "         [[-0.1716]],\n",
      "\n",
      "         [[ 0.1190]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         [[-0.0770]],\n",
      "\n",
      "         [[-0.1777]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1003]],\n",
      "\n",
      "         [[ 0.1773]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0036]],\n",
      "\n",
      "         [[ 0.0084]],\n",
      "\n",
      "         [[-0.1530]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0401]],\n",
      "\n",
      "         [[ 0.0782]],\n",
      "\n",
      "         [[-0.0162]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[ 0.1727]],\n",
      "\n",
      "         [[ 0.2245]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0179]],\n",
      "\n",
      "         [[ 0.0639]],\n",
      "\n",
      "         [[-0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[ 0.0789]],\n",
      "\n",
      "         [[ 0.0984]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 32, 1, 1])\n",
      "\n",
      "Layer: features.5.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.702543318271637\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.6970546841621399\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.0.1.weight\n",
      "Weights: tensor([1.1080, 0.8199, 0.7798, 1.0138, 1.9251, 1.8279, 1.0542, 1.1945, 1.4307,\n",
      "        1.2311, 0.9359, 1.8228, 1.0253, 0.8480, 0.9317, 1.3302, 0.8085, 0.7431,\n",
      "        1.1524, 1.1843, 0.7515, 0.9013, 1.3220, 1.4406, 1.0030, 0.8915, 0.9438,\n",
      "        1.5107, 0.9146, 1.2934, 0.9666, 1.1265, 1.7415, 1.1471, 1.0861, 1.1046,\n",
      "        0.7756, 0.7765, 1.2916, 1.3263, 0.8056, 0.7406, 0.7331, 1.4359, 1.1534,\n",
      "        1.3664, 0.9369, 1.2411, 1.0602, 0.9496, 0.9233, 0.9996, 0.8872, 1.2786,\n",
      "        0.7198, 1.2096, 0.1720, 1.3983, 0.9113, 0.8634, 0.8133, 0.9947, 1.0365,\n",
      "        1.0349, 1.1003, 0.9561, 1.0338, 0.8518, 1.5006, 1.2092, 0.8852, 2.6781,\n",
      "        1.0947, 0.6527, 0.7703, 1.0564, 1.2133, 0.4999, 0.6207, 1.0265, 0.8756,\n",
      "        1.4968, 1.3028, 1.0696, 0.4973, 1.5661, 1.2293, 1.5227, 1.4677, 0.8851,\n",
      "        1.2656, 1.3382, 1.5687, 1.6905, 1.7996, 1.5857, 1.4342, 0.9115, 0.7465,\n",
      "        3.0256, 0.8414, 0.7096, 0.2533, 1.0365, 1.3154, 0.8064, 0.9716, 1.6955,\n",
      "        0.5585, 0.9089, 0.8014, 1.0437, 1.6837, 1.2087, 1.6723, 1.8250, 0.7967,\n",
      "        0.9474, 1.1700, 1.6067, 1.2041, 0.7718, 0.8579, 1.6724, 0.8662, 0.9816,\n",
      "        0.8369, 1.1159, 0.4524, 1.0016, 1.0178, 1.3851, 1.1137, 1.5984, 0.3596,\n",
      "        1.7484, 0.8290, 1.3969, 0.7956, 1.0636, 1.0604, 1.0861, 1.2685, 0.5797,\n",
      "        1.9814, 1.8503, 1.6001, 2.3665, 1.0080, 0.5198, 0.8858, 0.7869, 1.1424,\n",
      "        0.9184, 1.3033, 1.6423, 0.6892, 1.1091, 1.5440, 0.7942, 0.5346, 1.4680,\n",
      "        1.4861, 1.3289, 1.0240, 0.9188, 1.2690, 1.5794, 1.4328, 1.0004, 1.5113,\n",
      "        1.6207, 0.9171, 1.2657, 1.2052, 1.5501, 1.4821, 1.5640, 1.6189, 0.9061,\n",
      "        0.7574, 1.1972, 0.8526, 0.4889, 0.9939, 0.4885, 1.6071, 1.4995, 1.7677,\n",
      "        1.0520, 0.9439, 1.5952], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.0.1.bias\n",
      "Weights: tensor([-0.6321,  1.7301,  1.4955,  1.4657,  0.3186,  3.0372,  1.0514,  1.8080,\n",
      "         1.4596, -0.4394,  0.7613,  0.3089,  1.3106,  1.6003,  1.2276, -2.3040,\n",
      "         1.3358,  0.6621,  1.4977,  1.4328,  1.6855,  1.0089,  1.4696, -0.3902,\n",
      "         0.9553,  1.1692,  0.9312, -1.0802,  1.2085, -0.1462,  1.3503,  1.6300,\n",
      "        -1.2448,  1.4456,  2.0456,  2.2065,  1.2983,  1.4920, -1.5475, -0.4649,\n",
      "         1.6717,  1.5919,  1.2341,  0.8986,  0.2032, -0.5742,  1.5787,  1.4476,\n",
      "         0.9369,  1.0493,  1.6649,  1.3093,  1.4274,  1.4131,  1.4943, -1.8162,\n",
      "         3.5096,  1.1399,  1.4570,  2.2535,  3.0559,  1.4272,  1.3734,  1.7661,\n",
      "         3.3985,  1.4291,  2.0007,  1.6367, -0.6913,  0.7240,  1.5041,  2.8269,\n",
      "         1.5225,  1.6379,  0.7181,  1.7530,  1.3687,  2.1632,  2.0032,  1.5286,\n",
      "         1.1041, -0.9721,  0.0351,  2.2508,  2.0746, -0.7570, -0.1140, -1.8896,\n",
      "        -2.1774,  1.3546,  1.3085,  0.5257, -0.5924, -0.1340,  1.1243,  2.2176,\n",
      "         0.5400,  1.3139,  1.2544, -0.1220,  1.6864,  1.9011,  2.4554,  1.2370,\n",
      "        -0.5433,  0.8329,  1.9715,  0.5506,  2.4027,  1.5688,  1.5753,  1.3758,\n",
      "         0.1310, -0.1230,  0.3610, -0.7091,  0.7256,  2.6412,  1.1538, -1.3965,\n",
      "        -0.5833,  1.6821,  1.2527, -0.4237,  1.5691,  1.0308,  1.2852,  0.5719,\n",
      "         2.0166,  0.9368,  2.2125,  1.5620,  0.9070, -0.8415,  1.7637, -0.5970,\n",
      "         1.1645, -0.3983,  1.0789,  0.7530,  2.9759,  1.7000,  1.3792,  1.8193,\n",
      "         2.6336,  1.0009,  0.6380,  0.5727,  0.8914,  1.6514,  1.3985,  1.3996,\n",
      "         1.5399,  2.2648, -0.7523,  0.0628,  1.4306,  1.5470, -2.1429,  1.6102,\n",
      "         1.4361,  1.9000, -0.3307,  1.4363,  1.4541,  2.1810, -2.2566, -2.6672,\n",
      "        -1.8935,  0.5000, -0.2117,  0.6438,  3.4583, -0.3894,  1.0468, -0.4223,\n",
      "        -0.6591,  0.3914,  0.2017,  1.3934,  3.2001,  1.9090,  0.7471,  1.7090,\n",
      "         0.8918,  1.7600,  0.0865, -0.0602,  0.4964,  1.2025,  1.2939,  0.1246],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0027, -0.2112, -0.0109],\n",
      "          [-0.2004,  0.0576, -0.2278],\n",
      "          [-0.0028, -0.1982, -0.0051]]],\n",
      "\n",
      "\n",
      "        [[[-0.0782, -0.0171,  0.0842],\n",
      "          [-0.4048, -0.0473,  0.4577],\n",
      "          [-0.1088, -0.0307,  0.1269]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721,  0.3964,  0.1021],\n",
      "          [-0.0110,  0.0090, -0.0435],\n",
      "          [-0.0770, -0.3844, -0.1098]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0701, -0.1196,  0.0399],\n",
      "          [-0.2441, -0.2079,  0.4240],\n",
      "          [-0.0545,  0.1230,  0.0602]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1009,  0.4717,  0.1150],\n",
      "          [ 0.0067, -0.0996,  0.0165],\n",
      "          [-0.1136, -0.3870, -0.1250]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0134, -0.1110,  0.0043],\n",
      "          [-0.0956, -0.1530, -0.1686],\n",
      "          [-0.0155, -0.1258, -0.0125]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 1, 3, 3])\n",
      "\n",
      "Layer: features.5.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -1.1449635028839111\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 1.1360185146331787\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.1.1.weight\n",
      "Weights: tensor([3.6588, 0.9327, 0.8331, 0.8979, 0.8972, 0.9275, 1.3142, 0.8784, 0.9916,\n",
      "        0.4690, 0.8371, 0.5801, 0.8921, 0.9310, 1.1299, 3.1569, 0.7838, 1.3640,\n",
      "        0.6354, 2.0154, 0.9925, 0.8892, 2.4617, 0.5991, 0.8516, 1.0558, 1.5816,\n",
      "        0.5124, 0.7473, 0.5010, 0.9259, 0.9353, 0.8907, 0.5452, 0.9162, 1.0461,\n",
      "        0.8045, 0.9200, 0.4433, 0.5015, 1.0689, 0.8900, 0.8183, 2.2863, 0.7318,\n",
      "        0.8993, 0.9627, 1.2408, 1.1460, 1.0870, 1.0347, 1.6060, 0.8904, 0.9617,\n",
      "        0.7988, 0.5081, 1.0798, 1.7039, 1.0260, 0.7695, 0.8499, 0.8307, 1.5548,\n",
      "        0.9754, 5.6211, 0.9040, 0.9989, 0.8936, 0.5654, 0.6828, 1.0595, 0.8928,\n",
      "        0.9609, 1.1159, 1.5107, 1.0150, 3.0899, 1.6330, 1.9912, 0.9165, 0.9727,\n",
      "        0.6329, 1.1206, 1.1460, 1.5398, 1.0385, 0.4930, 2.2946, 0.5158, 1.4169,\n",
      "        1.2513, 1.4488, 0.4444, 0.4668, 2.8671, 1.2401, 2.0311, 0.9856, 2.0045,\n",
      "        1.8666, 2.0446, 1.1865, 1.1086, 0.7469, 0.4918, 1.8173, 1.7957, 1.1046,\n",
      "        2.0615, 1.0666, 1.2060, 0.8698, 0.6256, 0.5136, 0.9158, 0.3479, 1.6742,\n",
      "        1.0274, 0.9154, 0.5980, 0.7085, 1.1286, 0.7941, 0.6011, 0.8180, 0.9140,\n",
      "        1.0256, 1.4059, 1.3392, 1.5929, 1.0596, 0.9917, 0.6106, 0.5792, 1.7699,\n",
      "        0.3643, 0.8857, 0.4291, 0.9576, 1.0330, 0.9058, 1.5630, 1.1657, 2.3188,\n",
      "        1.4182, 2.7563, 2.6372, 2.2193, 1.3698, 1.0926, 0.9056, 1.2264, 0.7171,\n",
      "        1.1786, 0.6381, 0.8371, 1.4561, 0.9270, 0.6213, 0.9834, 0.9065, 2.3070,\n",
      "        0.5981, 1.3284, 0.9271, 1.1762, 0.5817, 0.7917, 0.6666, 1.0051, 0.7083,\n",
      "        0.5665, 0.7244, 0.4299, 0.8390, 1.3262, 0.5673, 0.9828, 0.6382, 0.8874,\n",
      "        2.6305, 0.9537, 1.4207, 1.4360, 1.1148, 1.6594, 0.5995, 0.8516, 0.5381,\n",
      "        0.8843, 0.8579, 1.4098], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.1.1.bias\n",
      "Weights: tensor([-1.3198e+00, -6.7988e-02, -9.4947e-02, -6.1492e-02, -1.4465e-02,\n",
      "         2.1085e-02, -8.0046e-01, -7.1468e-02, -5.4054e-02,  3.1265e+00,\n",
      "        -1.0668e-01,  2.0972e+00, -1.9811e-01, -6.5346e-02, -1.6393e-01,\n",
      "        -3.4134e+00,  8.4012e-02, -1.2860e+00,  2.4388e-01, -1.7810e+00,\n",
      "        -9.5745e-02, -1.0249e-01, -2.6471e+00,  8.2793e-02, -9.9117e-02,\n",
      "        -3.7137e-01, -1.3414e+00,  2.1890e+00, -4.7516e-02,  2.1221e+00,\n",
      "        -9.2361e-02, -5.7570e-02, -1.6861e+00,  2.7471e+00, -4.8315e-02,\n",
      "        -9.7194e-02, -5.8725e-02, -8.0010e-02,  3.6001e+00,  3.0061e+00,\n",
      "        -2.3374e-01, -6.9083e-02, -1.9120e-01, -1.5239e+00, -3.9726e-01,\n",
      "        -1.9561e+00,  1.1958e-03, -6.3034e-01, -3.0003e-01, -3.9785e-01,\n",
      "        -2.8566e-02, -1.3711e+00,  1.1149e-03, -1.3885e-01,  1.4926e+00,\n",
      "         4.2849e+00,  3.3116e-01, -1.3239e+00, -1.2592e-01,  2.9500e+00,\n",
      "         3.4330e-01, -7.3270e-02, -1.1489e+00, -5.5692e-02, -1.1893e+01,\n",
      "        -1.5726e-01, -6.9493e-02, -2.2731e-01,  2.0232e-01,  2.4773e+00,\n",
      "        -4.7782e-02, -2.5324e-01,  1.4262e-02, -1.7850e-01, -1.2664e+00,\n",
      "        -3.3157e-02, -2.7901e+00, -7.3685e-02, -1.6905e+00, -7.6723e-02,\n",
      "        -4.1989e-02, -7.7617e-02, -1.5365e+00, -1.6751e-01, -1.7647e+00,\n",
      "        -1.3244e+00,  2.4611e+00, -5.0226e-01,  5.3356e-01, -1.3031e+00,\n",
      "        -6.2405e-01, -1.9640e+00,  2.1309e+00,  2.4186e+00, -2.7187e+00,\n",
      "        -4.4776e-01, -4.2508e+00, -3.5425e-01, -2.3552e+00, -9.5259e-01,\n",
      "        -1.9200e+00, -2.8149e-01,  2.3627e+00, -1.2309e-01,  2.5919e+00,\n",
      "        -4.9296e+00, -1.3600e+00, -2.7057e-01, -3.4806e+00, -2.7429e-01,\n",
      "        -3.8040e-01, -2.0586e-01,  1.6229e-01,  3.5688e+00, -2.7773e-01,\n",
      "         1.4331e+00, -4.6078e+00, -2.1764e-01, -4.4950e-01,  4.1372e-01,\n",
      "        -8.8355e-01, -3.1431e-01, -1.0492e-01,  2.7134e+00, -1.1884e-02,\n",
      "        -4.3980e-02, -2.8911e-01, -2.4548e+00, -1.0777e+00, -1.1327e+00,\n",
      "         1.9487e-02, -2.2267e-02, -6.0721e-02,  4.0448e+00, -2.2496e+00,\n",
      "         1.2683e+00, -1.4564e-01,  2.2652e+00, -7.6952e-03, -1.7834e-01,\n",
      "         2.0252e+00, -1.1836e+00, -6.0749e-01, -2.7153e+00, -7.7461e-01,\n",
      "        -2.2756e+00, -1.9855e+00, -7.2187e-01, -1.0059e+00, -4.0434e-01,\n",
      "        -1.5177e-01, -4.5178e-01,  2.6970e+00, -8.0103e-02, -4.3912e-01,\n",
      "        -1.0765e+00, -8.0281e-01, -4.9205e-02,  3.4417e+00, -1.9168e-01,\n",
      "        -3.0450e-01, -2.8600e+00,  1.1666e+00, -7.3492e-01, -1.4572e-01,\n",
      "        -4.2563e-02, -2.0833e+00,  6.3244e-01, -1.8994e+00, -8.5769e-01,\n",
      "        -4.4696e-02,  1.7825e-01,  5.4371e-01,  2.2791e+00, -2.0680e-01,\n",
      "        -3.4206e-01,  4.4814e+00, -7.9222e-01,  2.5951e+00, -3.2195e-02,\n",
      "        -3.6064e+00, -8.3044e-02, -2.1782e+00, -1.2028e+00, -6.2642e-01,\n",
      "        -1.4455e+00,  2.5186e+00, -1.3062e-01,  3.0082e+00, -1.3192e-01,\n",
      "        -5.1006e-02, -2.6194e-01], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0171]],\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[-0.0515]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0997]],\n",
      "\n",
      "         [[-0.0883]],\n",
      "\n",
      "         [[-0.0484]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0021]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[ 0.0519]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[-0.0089]]],\n",
      "\n",
      "\n",
      "        [[[-0.0867]],\n",
      "\n",
      "         [[-0.0571]],\n",
      "\n",
      "         [[ 0.1442]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         [[ 0.0855]],\n",
      "\n",
      "         [[ 0.2315]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0042]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[-0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0399]],\n",
      "\n",
      "         [[ 0.1018]],\n",
      "\n",
      "         [[-0.0390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0728]],\n",
      "\n",
      "         [[ 0.0577]],\n",
      "\n",
      "         [[ 0.0753]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0629]],\n",
      "\n",
      "         [[ 0.0764]],\n",
      "\n",
      "         [[ 0.0045]]],\n",
      "\n",
      "\n",
      "        [[[-0.0891]],\n",
      "\n",
      "         [[ 0.0402]],\n",
      "\n",
      "         [[ 0.0603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0598]],\n",
      "\n",
      "         [[-0.0031]],\n",
      "\n",
      "         [[ 0.0934]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 192, 1, 1])\n",
      "\n",
      "Layer: features.5.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.1435623168945312\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.1346282958984375\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.3.weight\n",
      "Weights: tensor([1.8504, 2.4106, 3.1048, 2.2347, 3.5254, 1.5071, 1.9146, 2.3095, 2.2912,\n",
      "        3.1115, 2.3757, 1.7182, 1.6727, 5.5134, 1.5428, 1.5395, 2.9440, 2.5768,\n",
      "        7.8259, 2.3754, 1.9300, 5.9415, 3.1814, 1.6341, 6.0258, 2.4171, 2.1446,\n",
      "        1.7618, 5.1358, 1.6920, 2.0558, 2.6001], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.5.conv.3.bias\n",
      "Weights: tensor([-1.3089e-07,  2.1377e-06,  2.2826e-06,  3.1088e-06, -4.8461e-07,\n",
      "        -1.2732e-06, -1.6444e-07,  7.6097e-08, -2.8071e-07, -1.1957e-07,\n",
      "        -9.9765e-07, -1.1833e-06,  5.2089e-07, -1.8745e-07,  1.5195e-06,\n",
      "         1.3220e-06, -7.1936e-07, -1.4845e-06, -1.1570e-06,  1.8697e-06,\n",
      "        -3.9736e-07,  9.1128e-07, -7.6910e-07, -4.5134e-07,  1.5619e-06,\n",
      "         1.0951e-07,  6.3376e-07, -1.4328e-06,  2.0770e-06, -1.1447e-06,\n",
      "         1.8749e-06,  1.7566e-06], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.5.conv.3.output_quantizers.0.min\n",
      "Weights: -39.2614631652832\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.5.conv.3.output_quantizers.0.max\n",
      "Weights: 29.52932357788086\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.1142]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2228]],\n",
      "\n",
      "         [[ 0.0761]],\n",
      "\n",
      "         [[-0.1166]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0545]],\n",
      "\n",
      "         [[-0.2082]],\n",
      "\n",
      "         [[ 0.0745]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0222]],\n",
      "\n",
      "         [[ 0.1749]],\n",
      "\n",
      "         [[-0.0736]]],\n",
      "\n",
      "\n",
      "        [[[-0.0086]],\n",
      "\n",
      "         [[ 0.0211]],\n",
      "\n",
      "         [[-0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0956]],\n",
      "\n",
      "         [[-0.0344]],\n",
      "\n",
      "         [[ 0.0832]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0888]],\n",
      "\n",
      "         [[-0.0618]],\n",
      "\n",
      "         [[ 0.0445]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[-0.0838]],\n",
      "\n",
      "         [[-0.0377]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0841]],\n",
      "\n",
      "         [[-0.1064]],\n",
      "\n",
      "         [[ 0.1025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0126]],\n",
      "\n",
      "         [[ 0.1327]],\n",
      "\n",
      "         [[-0.2382]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1094]],\n",
      "\n",
      "         [[ 0.1500]],\n",
      "\n",
      "         [[-0.0114]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.2036]],\n",
      "\n",
      "         [[ 0.1267]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 32, 1, 1])\n",
      "\n",
      "Layer: features.6.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.7740095257759094\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.7679625749588013\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.0.0.input_quantizers.0.min\n",
      "Weights: -41.94163513183594\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.0.0.input_quantizers.0.max\n",
      "Weights: 47.82924270629883\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.0.1.weight\n",
      "Weights: tensor([1.2764, 1.6089, 0.6316, 1.2476, 0.9759, 0.8111, 1.5027, 1.1746, 1.3136,\n",
      "        1.3437, 1.0125, 1.4031, 0.9400, 1.6430, 0.6995, 1.7408, 0.7815, 1.0188,\n",
      "        1.4212, 1.2009, 1.3564, 1.8750, 0.2940, 2.2067, 0.8606, 1.9364, 1.1680,\n",
      "        0.6797, 1.3273, 1.3835, 2.2106, 1.9314, 0.8408, 1.8470, 1.2532, 0.7963,\n",
      "        0.5576, 1.4990, 1.3067, 2.0888, 1.3872, 1.1313, 1.3588, 1.5783, 1.6698,\n",
      "        0.7696, 0.8864, 0.8730, 1.1621, 0.7516, 0.8691, 1.4087, 1.2809, 2.1468,\n",
      "        1.5282, 1.0197, 1.4433, 2.1798, 1.2121, 1.4007, 1.2368, 1.4114, 1.5409,\n",
      "        1.4833, 0.9242, 1.3162, 1.6041, 2.0921, 0.8727, 0.9365, 1.2996, 2.6119,\n",
      "        2.0940, 1.0963, 1.7719, 1.6227, 1.2455, 0.8172, 1.6465, 1.4215, 1.2626,\n",
      "        0.8321, 1.6243, 1.5956, 0.6840, 1.4437, 0.7285, 1.7361, 1.4481, 1.8235,\n",
      "        0.8982, 1.3630, 0.6345, 0.8176, 0.9484, 0.5312, 1.3064, 0.5752, 0.9805,\n",
      "        1.2156, 1.4071, 0.6511, 1.4165, 0.9006, 1.0456, 0.7815, 1.0052, 0.8296,\n",
      "        1.4775, 0.9258, 1.4882, 1.4678, 1.9727, 0.6195, 1.0275, 0.7554, 2.0670,\n",
      "        0.6583, 1.2901, 1.4866, 0.8705, 2.3609, 0.9680, 0.8056, 0.7456, 1.4466,\n",
      "        1.8345, 1.3172, 1.0919, 1.5468, 1.1092, 1.1712, 0.8060, 0.7276, 1.0607,\n",
      "        1.0122, 0.6815, 1.3763, 1.0798, 0.7935, 1.3988, 2.1456, 0.9885, 1.3291,\n",
      "        1.7109, 0.8712, 1.1464, 1.5853, 1.2481, 1.6456, 0.9897, 1.4344, 0.6364,\n",
      "        0.8178, 1.0320, 0.9112, 1.2751, 0.5683, 0.7323, 1.4230, 0.9454, 1.2244,\n",
      "        1.2431, 0.8678, 1.2122, 1.3930, 1.9234, 0.5264, 1.5444, 1.6733, 1.2477,\n",
      "        1.3893, 1.2661, 1.4375, 0.5970, 1.3762, 0.8627, 0.7606, 1.1691, 1.5878,\n",
      "        1.8852, 1.2184, 0.9412, 0.8030, 1.3245, 1.3297, 1.3349, 1.3720, 1.3066,\n",
      "        1.5379, 1.2482, 0.5730], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.0.1.bias\n",
      "Weights: tensor([-1.0138, -0.2723,  1.5498,  1.1579,  1.8743, -0.5113, -0.3506,  1.6892,\n",
      "        -1.4452,  0.3010,  1.3006,  0.9635,  0.7547, -0.1281,  1.6000,  1.1199,\n",
      "         1.3270,  2.4239,  0.3288,  1.5117,  0.7132,  0.7507,  1.3733, -0.0445,\n",
      "         1.1348, -1.0610, -1.0289,  1.5714,  2.0002, -0.9603,  0.8445,  0.4076,\n",
      "         1.1261,  1.1766, -2.0157,  2.3385,  1.8849, -0.5780, -1.5987, -0.9709,\n",
      "        -1.3022,  1.2693, -0.5773, -0.9236,  0.7682,  1.4904,  1.6947,  2.2865,\n",
      "         0.6189,  1.3664,  2.0191, -0.6180,  0.8177, -1.2570, -1.4049,  0.8356,\n",
      "         0.6979,  0.0220, -0.4635,  0.1308,  0.4107, -0.9143, -0.0188, -1.5075,\n",
      "         1.0602,  0.1543, -1.1070, -1.5640,  1.3826,  1.1943,  1.5190, -1.2060,\n",
      "         2.0078,  2.2724, -0.7797,  0.0187,  1.6176,  1.2249,  1.2318, -1.0938,\n",
      "        -0.7763,  1.4549,  0.7480,  0.8782,  2.5354, -0.1219,  1.3539, -0.6149,\n",
      "        -0.1361, -0.9645,  1.4306, -0.1660,  1.3469,  1.2204,  1.3595,  1.8874,\n",
      "        -1.2280,  1.7156,  0.2510,  1.2557, -0.1181,  2.9917, -0.8341,  0.7431,\n",
      "         0.8263,  1.6481,  1.3891,  2.4107, -0.8533,  1.1455, -0.4185, -1.7651,\n",
      "        -0.1739,  1.2729,  1.9984,  1.4260, -0.2278,  3.3311,  0.2405, -0.2497,\n",
      "         1.0270,  0.2022,  1.7721,  1.4807,  1.4902,  0.5633, -0.5503,  0.8975,\n",
      "        -0.7029, -1.1576,  1.4341,  0.5620,  0.6353,  0.7546,  1.1692,  1.9971,\n",
      "         1.2476, -1.1519,  0.8654, -0.5412, -0.3377, -0.8481,  0.4749,  1.0399,\n",
      "         0.0869, -0.2530, -0.1837,  0.6106, -0.6184, -0.1149,  0.6630,  0.6969,\n",
      "         1.3424,  0.7441,  1.6705,  1.1518,  1.7462,  1.4103,  0.7381, -0.2206,\n",
      "        -0.0262, -0.2388,  0.8487,  1.5627,  1.0761, -0.7400, -0.8659,  1.4100,\n",
      "         1.9330,  1.6464,  1.2561,  0.7622,  0.2830, -0.9568,  1.9578,  0.0905,\n",
      "         1.3952,  1.0841,  0.1497,  0.3120, -3.2301, -1.4217,  1.3634,  1.2069,\n",
      "        -0.1666, -0.5466,  0.8250,  0.5436,  1.0045,  0.4103, -0.9055,  1.2999],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0394,  0.1204,  0.0495],\n",
      "          [ 0.1054, -0.6780,  0.1046],\n",
      "          [ 0.0418,  0.1541,  0.0485]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0125,  0.2270,  0.0834],\n",
      "          [-0.0803, -0.4119, -0.0882],\n",
      "          [ 0.0599,  0.1398,  0.0267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0528, -0.1878,  0.0182],\n",
      "          [-0.1372, -0.4605,  0.2606],\n",
      "          [-0.0087,  0.2387,  0.2316]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0069, -0.0749,  0.0026],\n",
      "          [-0.1533, -0.0672, -0.1787],\n",
      "          [-0.0052, -0.0869, -0.0436]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0355,  0.1140,  0.0022],\n",
      "          [ 0.1349,  0.2346,  0.1782],\n",
      "          [ 0.0282,  0.1429,  0.0240]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1446,  0.3484,  0.1485],\n",
      "          [-0.0286, -0.1860, -0.0765],\n",
      "          [-0.0966, -0.1330, -0.0813]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 1, 3, 3])\n",
      "\n",
      "Layer: features.6.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.9115997552871704\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.9044778943061829\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.1.1.weight\n",
      "Weights: tensor([0.8958, 0.8874, 1.2139, 1.4007, 1.1834, 2.0182, 0.9398, 1.3544, 0.7719,\n",
      "        1.4759, 1.1618, 1.2117, 1.4552, 0.6127, 1.4564, 2.6535, 1.7178, 1.6046,\n",
      "        0.6995, 1.4002, 1.4253, 1.2219, 1.5637, 0.7370, 1.5033, 2.6674, 0.4675,\n",
      "        1.3963, 1.9720, 0.5678, 7.7972, 1.6829, 1.2428, 2.5061, 0.3087, 2.4386,\n",
      "        1.1180, 0.5371, 0.2684, 1.0820, 0.6703, 2.3756, 0.7062, 1.0450, 2.4568,\n",
      "        1.0398, 0.9238, 1.5477, 1.1128, 1.2210, 0.9662, 0.8026, 0.6451, 7.4910,\n",
      "        0.3754, 1.5166, 1.6056, 0.7591, 1.0937, 0.7379, 1.4918, 0.9568, 1.3466,\n",
      "        0.3224, 1.1089, 1.0238, 0.6446, 8.7082, 1.0090, 0.9822, 3.3796, 1.2280,\n",
      "        2.4050, 1.1087, 1.1812, 0.6378, 1.5660, 1.7830, 2.0451, 0.6081, 0.5629,\n",
      "        1.1021, 2.0740, 0.5007, 0.7945, 1.2292, 1.1781, 1.0388, 0.6794, 1.1644,\n",
      "        1.2512, 0.6704, 0.8376, 1.6420, 1.5035, 1.1505, 0.4735, 1.0544, 1.2431,\n",
      "        1.1627, 0.7018, 1.3859, 0.8161, 0.9679, 0.9621, 1.1200, 0.8865, 1.7234,\n",
      "        1.2816, 1.0031, 0.8641, 0.4601, 2.1031, 1.1510, 1.5187, 1.0698, 4.2675,\n",
      "        3.5604, 0.8706, 1.3248, 0.8520, 2.0677, 0.9238, 1.0854, 0.9926, 0.4421,\n",
      "        0.4275, 0.9499, 0.9522, 1.4538, 0.8891, 1.1433, 1.0831, 0.9948, 0.9767,\n",
      "        1.5672, 0.9242, 0.3931, 0.9104, 1.6800, 1.2669, 1.2142, 1.1423, 0.8245,\n",
      "        0.9434, 2.4734, 1.3324, 1.0003, 1.8407, 0.6076, 1.9629, 1.9318, 0.8668,\n",
      "        1.0683, 2.3358, 1.2820, 2.9992, 1.1858, 1.0598, 0.6463, 1.6061, 0.6398,\n",
      "        1.6224, 1.3305, 1.1134, 1.2005, 1.0901, 1.2109, 2.2858, 2.1058, 1.2556,\n",
      "        1.5337, 1.5854, 0.6289, 1.0036, 1.0070, 1.1552, 1.2608, 0.5971, 1.2611,\n",
      "        1.3429, 0.9213, 1.1492, 1.0174, 0.7385, 1.7840, 0.9985, 1.3268, 1.0055,\n",
      "        1.8652, 1.0765, 1.2448], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.1.1.bias\n",
      "Weights: tensor([ 9.1343e-01, -7.5100e-02, -3.3606e-01, -7.8758e-01, -2.4197e-01,\n",
      "        -8.4443e-01, -7.5334e-01, -5.2277e-01, -3.1062e-03, -1.9916e+00,\n",
      "        -5.1679e-01, -1.7483e-01, -3.3072e+00,  2.0667e+00, -9.8595e-01,\n",
      "        -1.7365e+00, -2.9286e+00, -1.9570e+00,  2.0596e+00, -7.3158e-01,\n",
      "        -9.5676e-01, -3.9886e-01, -1.4231e+00,  3.0134e+00, -2.3952e+00,\n",
      "        -7.1580e+00, -2.5996e-02, -6.1191e-01, -2.2296e+00,  5.7431e-02,\n",
      "        -9.3650e+00, -7.8725e-01, -5.3861e-01, -1.5990e+00, -1.3228e-01,\n",
      "        -2.0393e+00, -4.4720e-01,  2.4389e+00,  2.2363e+00, -2.4743e-01,\n",
      "        -8.4914e-01, -2.3480e+00,  3.7385e-01, -3.1203e-01, -2.1504e+00,\n",
      "        -1.1582e-01,  2.6827e+00, -2.0522e+00, -4.7457e-01, -3.0105e-01,\n",
      "        -3.4454e-01, -1.1167e+00,  1.3349e+00, -6.2084e+00,  2.2624e+00,\n",
      "        -1.6713e+00, -1.2054e+00,  3.1458e+00, -1.8087e+00, -2.0947e-01,\n",
      "        -1.0035e+00, -1.6318e+00, -1.5265e+00,  7.9093e-01, -4.7939e-01,\n",
      "        -1.3615e+00,  1.6098e+00, -2.5502e+00, -3.3980e-01, -2.3600e-01,\n",
      "        -4.4359e+00, -3.8477e-01, -2.9576e+00, -3.2164e-01, -3.1942e-01,\n",
      "         2.9302e+00, -1.1233e+00, -3.0634e+00, -1.2873e+00,  3.3724e-01,\n",
      "         5.5638e-02, -3.1193e-01, -1.9069e+00,  1.4170e+00,  4.2119e-01,\n",
      "        -1.6041e+00, -3.2731e-01, -1.5676e+00,  2.3422e+00, -3.0526e-01,\n",
      "        -7.7621e-01,  3.2553e-01, -2.1459e-01, -2.7066e+00, -8.0422e-01,\n",
      "        -3.0993e-01, -2.8130e-02, -3.5278e-01, -2.9817e-01, -5.8043e-01,\n",
      "         1.3690e+00, -7.2632e-01, -7.8579e-01, -2.0418e-01, -5.4568e-02,\n",
      "        -4.9564e-01, -5.5753e-02, -7.6332e-01, -3.3999e-01, -3.4093e-01,\n",
      "        -6.6696e-01,  1.0974e-01, -1.6268e+00, -4.2143e-01, -9.3238e-01,\n",
      "        -1.6298e-01, -3.4838e+00, -4.8640e+00, -8.4231e-02, -1.5776e+00,\n",
      "        -1.5521e-02, -8.1711e-01, -3.4647e-01, -1.7954e-01, -1.1594e-01,\n",
      "         8.4441e-01,  2.3986e+00, -4.4166e-02, -1.7043e+00, -4.9945e+00,\n",
      "         1.6213e-02, -1.1082e+00, -2.1669e-01, -2.1185e-01, -3.1798e-01,\n",
      "        -1.5685e+00, -1.9480e-01,  2.1013e+00, -1.4240e-01,  4.0164e+00,\n",
      "        -1.0985e+00, -3.6301e-01, -3.5348e-01, -3.1727e-01, -4.0984e-01,\n",
      "        -2.6479e+00, -2.8448e+00, -3.8255e-01, -5.0275e+00,  3.1011e+00,\n",
      "        -4.6029e+00, -1.0923e+00, -1.6496e-01, -2.4081e-01, -2.8228e+00,\n",
      "        -1.6596e+00, -3.8198e+00, -2.5719e-01, -1.5458e-01,  2.1840e+00,\n",
      "        -6.4481e-01,  2.8528e-02, -1.5083e+00, -3.3184e-01, -2.8100e-01,\n",
      "        -2.1431e+00, -1.7658e-01, -3.3467e-01, -2.6022e+00, -1.3198e+00,\n",
      "        -6.6175e-01, -1.1021e+00, -2.2268e+00,  2.3786e-01, -1.6133e-01,\n",
      "        -1.5209e-01, -4.2308e-01, -9.7563e-01, -1.0561e-01, -3.2366e-01,\n",
      "        -3.5449e+00,  4.0140e+00, -3.5861e-01, -2.6811e-01, -2.6390e-01,\n",
      "        -3.1834e+00, -2.1754e-01, -7.7023e-01, -4.9779e-01, -1.0004e+00,\n",
      "        -8.7814e-01, -6.3863e-01], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.2.weight\n",
      "Weights: tensor([[[[-0.1693]],\n",
      "\n",
      "         [[-0.0757]],\n",
      "\n",
      "         [[-0.1058]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0714]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[-0.1297]]],\n",
      "\n",
      "\n",
      "        [[[-0.0016]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[-0.0300]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0011]],\n",
      "\n",
      "         [[-0.0194]],\n",
      "\n",
      "         [[-0.0576]]],\n",
      "\n",
      "\n",
      "        [[[-0.0292]],\n",
      "\n",
      "         [[-0.0771]],\n",
      "\n",
      "         [[-0.1455]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1384]],\n",
      "\n",
      "         [[ 0.0203]],\n",
      "\n",
      "         [[ 0.0357]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0874]],\n",
      "\n",
      "         [[-0.0296]],\n",
      "\n",
      "         [[ 0.0129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0046]],\n",
      "\n",
      "         [[-0.1060]],\n",
      "\n",
      "         [[-0.0245]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0310]],\n",
      "\n",
      "         [[-0.0337]],\n",
      "\n",
      "         [[ 0.0818]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0906]],\n",
      "\n",
      "         [[ 0.1218]],\n",
      "\n",
      "         [[-0.1784]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0817]],\n",
      "\n",
      "         [[ 0.0213]],\n",
      "\n",
      "         [[-0.0050]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0561]],\n",
      "\n",
      "         [[-0.0162]],\n",
      "\n",
      "         [[-0.1362]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 192, 1, 1])\n",
      "\n",
      "Layer: features.6.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.877480149269104\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.870624840259552\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.3.weight\n",
      "Weights: tensor([ 1.3031,  1.6153,  3.6860,  1.8646,  4.2714,  1.1679,  1.1188,  1.9756,\n",
      "         1.3828,  2.0659,  2.1791,  1.0369,  1.7859, 12.3622,  1.4574,  1.3365,\n",
      "         2.9994,  3.8325,  6.1924,  2.1878,  2.1189,  3.9293,  2.8397,  1.3792,\n",
      "         7.7294,  2.2338,  2.2770,  1.5190,  4.5124,  1.0372,  1.8825,  1.8724],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.6.conv.3.bias\n",
      "Weights: tensor([ 1.9880e-08,  9.6169e-07,  1.1876e-06,  2.2520e-06, -9.4791e-07,\n",
      "         1.0793e-06, -1.1531e-07, -7.7937e-07, -1.0639e-06, -9.4290e-08,\n",
      "        -3.1666e-07, -1.4618e-06, -1.0784e-06,  1.5291e-06,  7.5439e-07,\n",
      "         3.5494e-07,  8.3515e-07, -8.5871e-07, -1.1881e-06,  1.1209e-06,\n",
      "        -1.0833e-06,  1.1094e-06, -7.1011e-07, -2.0106e-06,  1.0150e-07,\n",
      "        -1.2871e-06, -1.0712e-06, -1.2361e-06,  6.2901e-07, -1.9035e-06,\n",
      "        -4.9620e-07,  1.0358e-06], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.6.conv.3.output_quantizers.0.min\n",
      "Weights: -43.2132453918457\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.6.conv.3.output_quantizers.0.max\n",
      "Weights: 50.986473083496094\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0837]],\n",
      "\n",
      "         [[-0.0673]],\n",
      "\n",
      "         [[-0.3664]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0243]],\n",
      "\n",
      "         [[-0.1280]],\n",
      "\n",
      "         [[ 0.1523]]],\n",
      "\n",
      "\n",
      "        [[[-0.0465]],\n",
      "\n",
      "         [[ 0.0630]],\n",
      "\n",
      "         [[ 0.0754]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2346]],\n",
      "\n",
      "         [[-0.0108]],\n",
      "\n",
      "         [[ 0.0623]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.6404]],\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0235]],\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[ 0.4107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0200]],\n",
      "\n",
      "         [[ 0.0671]],\n",
      "\n",
      "         [[ 0.3451]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         [[ 0.1897]],\n",
      "\n",
      "         [[-0.0291]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2250]],\n",
      "\n",
      "         [[-0.5676]],\n",
      "\n",
      "         [[-0.0434]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0284]],\n",
      "\n",
      "         [[-0.0896]],\n",
      "\n",
      "         [[ 0.6948]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3341]],\n",
      "\n",
      "         [[ 0.3176]],\n",
      "\n",
      "         [[ 0.1479]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0842]],\n",
      "\n",
      "         [[-0.1933]],\n",
      "\n",
      "         [[-0.2003]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 32, 1, 1])\n",
      "\n",
      "Layer: features.7.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -1.2047405242919922\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 1.1953284740447998\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.0.0.input_quantizers.0.min\n",
      "Weights: -53.637229919433594\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.0.0.input_quantizers.0.max\n",
      "Weights: 65.70173645019531\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.0.1.weight\n",
      "Weights: tensor([1.4475, 0.7053, 1.2833, 1.2769, 1.2610, 0.9718, 1.9706, 1.4851, 0.7424,\n",
      "        2.1487, 1.7827, 0.9752, 2.1316, 1.2237, 0.9248, 1.3937, 1.7525, 1.9055,\n",
      "        1.1787, 1.4476, 2.3869, 1.8935, 1.1646, 0.7818, 1.5184, 2.8785, 2.4223,\n",
      "        1.4519, 2.6137, 1.5061, 1.4898, 1.6938, 1.3915, 1.5767, 2.7065, 0.6752,\n",
      "        1.5031, 2.1060, 1.4614, 0.6792, 1.4254, 1.8735, 1.3151, 1.9691, 1.4984,\n",
      "        1.7060, 1.3657, 1.3047, 1.1543, 1.0512, 1.4901, 0.7932, 1.5603, 1.2785,\n",
      "        1.4116, 1.7910, 1.6635, 1.2031, 1.1287, 1.4329, 1.8765, 2.0297, 0.9419,\n",
      "        1.4580, 1.8558, 1.3981, 1.6554, 0.5583, 2.1085, 0.9910, 1.4555, 1.2155,\n",
      "        1.9243, 1.9665, 1.4248, 1.1543, 1.1075, 1.1448, 1.6946, 1.7284, 1.5196,\n",
      "        0.8480, 1.2595, 1.9297, 1.5609, 0.9716, 1.0502, 1.0315, 0.9782, 2.1666,\n",
      "        1.9025, 1.7670, 1.2052, 1.9299, 1.5723, 0.5870, 2.1790, 1.2268, 1.7597,\n",
      "        1.3814, 2.6201, 1.0102, 1.2964, 1.6394, 1.5469, 1.6861, 1.3844, 1.3282,\n",
      "        1.5295, 1.3901, 1.0933, 0.7767, 1.5828, 1.2544, 1.7683, 1.3332, 1.6344,\n",
      "        1.4324, 1.7472, 1.4741, 1.2081, 1.7713, 1.4790, 1.2631, 1.5529, 1.3749,\n",
      "        1.1886, 1.5782, 1.4398, 1.7304, 1.2306, 2.2526, 1.0114, 1.8456, 1.0004,\n",
      "        2.2090, 1.8044, 1.2463, 1.4128, 1.3906, 1.4538, 1.1795, 0.5657, 1.6245,\n",
      "        1.0721, 1.3556, 1.5177, 1.2204, 1.7447, 1.4815, 1.6514, 1.1066, 1.2771,\n",
      "        1.1032, 1.2682, 1.3931, 1.9798, 1.1453, 1.1041, 1.7539, 1.2274, 1.2033,\n",
      "        1.4184, 1.5484, 1.3023, 2.0150, 0.9180, 1.4313, 1.6607, 2.3907, 0.6106,\n",
      "        2.0719, 1.1288, 1.1903, 1.4954, 1.4150, 1.5462, 1.8253, 0.8033, 1.5109,\n",
      "        1.1588, 1.2568, 1.3880, 1.2549, 1.3589, 1.2952, 2.0122, 1.2842, 1.0836,\n",
      "        1.2361, 1.2513, 1.2227], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.0.1.bias\n",
      "Weights: tensor([ 8.0111e-01,  3.0361e-01,  1.4105e-01, -1.2132e+00, -7.5173e-02,\n",
      "         2.3419e+00,  2.1147e-01, -1.5065e+00,  1.5972e-01,  1.0114e+00,\n",
      "        -3.1587e-01,  1.7879e+00,  4.3799e-01, -1.8763e+00, -5.8389e-01,\n",
      "        -7.5751e-02,  1.0926e+00, -7.8798e-01,  4.1252e-01, -4.3961e-01,\n",
      "         8.9231e-01, -1.8799e+00,  3.0205e-01,  6.9119e-01,  4.6871e-01,\n",
      "         1.1085e+00,  2.0741e-01, -6.5506e-01, -7.9232e-01,  1.9575e-01,\n",
      "        -1.7984e+00, -7.0940e-02, -4.9481e-01, -9.0466e-01,  1.1777e+00,\n",
      "         1.2433e-01,  9.8375e-01, -1.2868e+00, -1.6631e-01,  2.0235e+00,\n",
      "        -6.4421e-01,  1.7650e-01, -9.7631e-01,  5.3333e-01, -1.2582e+00,\n",
      "        -1.9675e+00, -1.6913e-01, -1.4387e+00, -3.9907e-02, -6.7926e-01,\n",
      "        -7.5377e-01,  5.1385e-01, -1.0166e+00, -7.2470e-01, -7.1369e-01,\n",
      "        -2.2953e+00, -2.0373e+00, -5.4904e-01,  1.9548e-01, -9.8337e-01,\n",
      "         1.7157e-01, -1.6871e-01,  1.9705e-01,  1.7849e-03, -1.6642e+00,\n",
      "        -2.2781e-01, -8.5328e-02,  1.3907e+00,  1.3069e+00, -7.5624e-02,\n",
      "        -1.2585e+00, -3.8903e-01, -1.2368e+00, -1.1226e+00, -2.7059e-01,\n",
      "        -3.2184e-01, -2.9145e-01,  1.0267e-01,  6.1851e-01, -3.5564e-01,\n",
      "         1.4928e+00,  8.9047e-01,  1.1415e-01,  1.9925e-01,  3.2021e-01,\n",
      "         1.8355e+00,  1.2115e-01,  8.5182e-01,  1.3610e+00, -8.6966e-02,\n",
      "         9.6677e-01, -1.2843e+00, -6.7260e-01, -5.7960e-01,  1.0412e+00,\n",
      "         3.9570e-01,  5.9277e-01, -5.1432e-01, -2.9324e-03, -1.1414e+00,\n",
      "         4.7527e-01,  6.9123e-01, -2.6116e-02,  1.6276e+00, -3.1591e-01,\n",
      "        -1.4855e+00, -1.2713e+00,  4.8559e-01, -8.6697e-01, -2.6159e-01,\n",
      "         8.6428e-01,  1.8266e+00, -1.2675e+00,  3.6323e-01, -7.4445e-01,\n",
      "        -7.9946e-01, -1.2892e+00,  8.5094e-02, -1.0354e+00, -1.7283e+00,\n",
      "        -2.5682e+00, -4.2259e+00, -1.8656e+00, -1.2296e+00, -3.9067e-01,\n",
      "        -1.4867e+00, -8.0471e-01, -1.3286e+00, -1.3721e+00, -1.5070e+00,\n",
      "         3.0556e-01,  1.9858e-01, -7.0610e-02, -1.4206e+00, -1.5420e+00,\n",
      "        -1.3234e+00, -1.1438e+00,  7.9510e-01, -4.3455e-01, -8.9592e-01,\n",
      "        -7.1319e-01,  9.2059e-01,  3.3891e-01, -1.1412e+00,  6.4110e-01,\n",
      "         6.5814e-01,  5.2832e-01, -8.4056e-01, -8.6229e-01, -3.0611e-01,\n",
      "         5.8471e-01,  1.2924e-01,  2.0356e-01,  6.5843e-01, -1.9903e-01,\n",
      "        -1.0718e+00, -2.2806e+00, -3.6958e-01, -1.2210e-02, -1.6844e+00,\n",
      "        -6.2470e-01, -3.4114e-01, -8.0347e-01, -2.7153e+00, -5.3505e-01,\n",
      "        -2.6030e-01,  3.1264e-01, -8.8703e-02,  6.9225e-01,  8.9789e-01,\n",
      "         2.3728e-01, -1.6002e-01,  1.0537e-01, -1.3314e-01, -8.7320e-01,\n",
      "         5.3498e-01,  4.1497e-01,  1.6912e+00,  3.8446e-01, -7.1414e-01,\n",
      "        -2.3859e-01,  2.2595e-01, -1.9683e+00, -1.6616e-01, -1.8015e+00,\n",
      "        -3.0713e-01, -1.1204e+00,  5.8478e-01,  6.2189e-01, -3.8468e-01,\n",
      "        -2.6405e-01, -1.2117e+00], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0338, -0.0552, -0.0523],\n",
      "          [-0.1635, -0.3457, -0.2524],\n",
      "          [-0.1376, -0.2814, -0.2011]]],\n",
      "\n",
      "\n",
      "        [[[-0.0609, -0.1427, -0.1051],\n",
      "          [-0.0614, -0.1519, -0.1516],\n",
      "          [ 0.0976,  0.2657,  0.1850]]],\n",
      "\n",
      "\n",
      "        [[[-0.1057, -0.1830, -0.1228],\n",
      "          [-0.1706, -0.3587, -0.2427],\n",
      "          [-0.1167, -0.2310, -0.1604]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0486,  0.0925,  0.0669],\n",
      "          [ 0.1124,  0.2293,  0.1758],\n",
      "          [ 0.0721,  0.1716,  0.1341]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0307,  0.1269,  0.0999],\n",
      "          [ 0.1285,  0.4070,  0.3225],\n",
      "          [ 0.0905,  0.2852,  0.2349]]],\n",
      "\n",
      "\n",
      "        [[[-0.0544, -0.1203, -0.0938],\n",
      "          [-0.1144, -0.2201, -0.1834],\n",
      "          [-0.0866, -0.1772, -0.1320]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 1, 3, 3])\n",
      "\n",
      "Layer: features.7.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.4763753414154053\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.47265365719795227\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.1.1.weight\n",
      "Weights: tensor([0.9948, 0.8585, 0.8769, 0.5647, 0.7958, 1.1984, 1.1168, 0.8039, 0.9363,\n",
      "        2.0749, 0.8343, 1.3263, 1.3119, 0.4866, 1.9176, 0.9108, 1.6624, 0.8331,\n",
      "        0.9826, 0.8091, 1.2873, 0.6844, 0.8569, 1.0736, 0.9161, 1.2236, 1.1061,\n",
      "        0.8425, 1.1015, 0.7894, 0.7545, 0.8492, 0.8087, 0.6974, 1.3740, 0.9868,\n",
      "        1.1035, 0.8783, 0.9250, 0.9638, 1.2711, 1.2234, 0.6574, 1.1724, 0.6528,\n",
      "        0.6992, 0.8424, 1.3203, 0.9352, 0.7049, 0.7876, 0.7462, 0.7691, 0.8331,\n",
      "        0.7319, 0.6624, 0.7027, 0.8050, 0.8429, 0.6615, 1.3248, 1.7202, 1.0117,\n",
      "        0.8813, 0.6248, 0.7959, 1.0029, 0.7908, 1.7528, 0.9652, 0.6302, 0.7626,\n",
      "        0.8073, 0.7599, 0.7784, 0.6869, 0.8718, 0.9391, 1.1764, 0.9581, 2.2524,\n",
      "        0.7716, 0.9620, 2.1410, 0.9837, 0.9743, 0.9396, 1.1253, 0.9049, 1.5117,\n",
      "        2.4770, 0.7964, 0.8829, 1.3801, 1.3758, 0.9294, 1.2250, 0.7612, 0.9037,\n",
      "        0.7564, 0.9080, 1.3064, 1.0086, 2.2132, 0.8186, 0.6403, 0.6843, 0.9349,\n",
      "        0.6607, 0.7404, 0.7806, 1.1330, 0.5965, 0.8364, 0.7820, 0.6662, 0.6599,\n",
      "        1.4800, 0.8013, 0.5987, 0.3722, 1.7486, 0.5556, 0.6276, 1.2338, 0.7140,\n",
      "        0.8614, 0.7278, 0.5524, 0.7862, 0.9253, 1.5307, 0.8634, 0.7100, 0.5622,\n",
      "        0.8738, 0.8006, 1.1315, 0.7833, 0.7474, 0.7514, 1.0314, 0.9281, 0.7717,\n",
      "        1.0704, 0.9982, 1.1702, 0.9374, 0.7134, 0.8672, 0.9207, 0.9899, 0.9260,\n",
      "        0.8334, 0.7665, 0.7509, 0.7510, 0.8265, 0.9013, 0.6744, 0.9487, 0.7812,\n",
      "        0.7263, 0.7390, 0.6846, 1.3638, 0.9258, 0.8397, 1.1948, 1.2978, 0.9253,\n",
      "        1.5623, 0.8349, 0.8038, 0.7226, 0.8648, 1.0852, 1.2092, 1.0651, 0.6697,\n",
      "        0.7317, 0.8314, 0.5907, 0.7993, 0.5398, 0.7829, 0.8058, 1.0239, 0.8502,\n",
      "        0.7211, 1.0515, 0.5923], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.1.1.bias\n",
      "Weights: tensor([ 4.1648, -0.1677,  3.6543,  0.5011,  0.5249,  2.9729,  1.1251,  0.4414,\n",
      "        -0.3485, -0.3876,  1.1080,  0.0146,  0.7800,  0.1937,  2.6402,  3.8656,\n",
      "        -0.3601,  1.0537,  3.9126,  0.7867,  1.0059,  0.3995,  3.3653, -0.5866,\n",
      "         3.3281,  0.0971,  0.8238,  5.2025,  0.4825,  3.8238,  1.7012,  2.9460,\n",
      "         0.8865,  0.6567, -0.1055, -0.2141,  0.9663, -0.0430,  1.3874,  2.8610,\n",
      "         1.4608,  0.2599,  5.0922,  1.0286,  0.4462,  0.3608,  5.1173,  0.7632,\n",
      "         0.9693,  0.6353,  0.9756,  0.2216,  0.6392,  2.0888,  1.4641,  1.8997,\n",
      "         0.3632,  1.1398,  3.7406,  0.7412,  0.5415,  0.1610,  1.0230,  1.2398,\n",
      "         0.6083,  0.8803,  1.1712,  0.8442, -0.5795,  0.9204,  0.4791,  2.8089,\n",
      "         0.3560,  5.3275,  4.9954,  0.5994,  2.3430,  4.7305,  0.6548,  0.5985,\n",
      "        -0.1074,  2.9094,  0.0245, -0.7090,  0.4342,  3.0736,  0.9586, -0.1582,\n",
      "         2.9498,  0.1442, -1.0848,  0.6531,  4.8700,  0.4323,  0.0798, -0.1644,\n",
      "         0.4223,  0.6839,  1.9791,  0.3666,  1.5669,  4.1732,  1.3243, -0.0931,\n",
      "         4.4862,  0.6875,  0.4432,  3.7057,  0.4926,  1.8602,  2.5578,  0.0313,\n",
      "         0.8661,  2.9627,  2.6793,  5.1765,  0.4049,  0.8774,  0.8500,  0.3713,\n",
      "         0.0827,  0.3710,  0.7086,  0.3721,  1.1178,  0.3269,  0.4685,  4.5774,\n",
      "         0.2818,  1.9588,  0.6310,  0.5611,  0.8173,  1.1823,  0.1759, -0.0909,\n",
      "         1.2916,  0.3535,  5.1910,  0.6026,  0.7259,  3.3524,  0.9955,  0.4978,\n",
      "         4.3324,  4.0413,  0.6696,  0.4714,  0.8439,  1.8340,  1.2896,  0.9401,\n",
      "         3.5714,  3.0298,  0.9461,  0.4518,  0.4094,  0.6219,  3.2914,  0.3965,\n",
      "         0.6349,  4.9253,  1.4254, -0.0167,  0.6852,  0.2714,  1.2512,  0.9223,\n",
      "         0.1240,  1.0234, -0.3625,  0.2868,  2.4609,  3.7127,  0.8551,  1.3398,\n",
      "         4.5068,  0.2285, -0.2920,  0.7450,  1.6389,  2.0957,  0.4726,  4.5406,\n",
      "         0.1956,  4.9449,  0.6690,  0.2735,  3.1163,  0.6732,  0.8308,  5.3966],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.2.weight\n",
      "Weights: tensor([[[[-0.0950]],\n",
      "\n",
      "         [[-0.0125]],\n",
      "\n",
      "         [[ 0.0167]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         [[ 0.0303]],\n",
      "\n",
      "         [[-0.0685]]],\n",
      "\n",
      "\n",
      "        [[[-0.2837]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         [[-0.3037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0257]],\n",
      "\n",
      "         [[ 0.3578]],\n",
      "\n",
      "         [[-0.1221]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0783]],\n",
      "\n",
      "         [[ 0.0079]],\n",
      "\n",
      "         [[ 0.0564]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1061]],\n",
      "\n",
      "         [[ 0.2310]],\n",
      "\n",
      "         [[ 0.0674]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1834]],\n",
      "\n",
      "         [[-0.1250]],\n",
      "\n",
      "         [[ 0.1619]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2192]],\n",
      "\n",
      "         [[ 0.0911]],\n",
      "\n",
      "         [[-0.1507]]],\n",
      "\n",
      "\n",
      "        [[[-0.0120]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[-0.1125]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1478]],\n",
      "\n",
      "         [[-0.3139]],\n",
      "\n",
      "         [[-0.2116]]],\n",
      "\n",
      "\n",
      "        [[[-0.0606]],\n",
      "\n",
      "         [[ 0.0617]],\n",
      "\n",
      "         [[-0.4877]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1798]],\n",
      "\n",
      "         [[-0.1686]],\n",
      "\n",
      "         [[-0.0026]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 192, 1, 1])\n",
      "\n",
      "Layer: features.7.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.2707322835922241\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.2608046531677246\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.3.weight\n",
      "Weights: tensor([3.4909, 5.0772, 3.4203, 4.9683, 2.5276, 4.0449, 5.0557, 5.4148, 3.1032,\n",
      "        3.5418, 4.2296, 3.8709, 5.4469, 3.8369, 3.1175, 3.5389, 2.6501, 5.6267,\n",
      "        3.8622, 4.0628, 4.9248, 2.7033, 6.4886, 4.1041, 4.7610, 3.1811, 3.7074,\n",
      "        4.1247, 5.5939, 5.7338, 3.9746, 4.0841, 5.5424, 3.1707, 5.2315, 4.1086,\n",
      "        4.0435, 4.3210, 2.2280, 5.1654, 4.6756, 4.8783, 5.9836, 5.5982, 2.8929,\n",
      "        3.0458, 4.9810, 2.6632, 6.0324, 4.2237, 3.7914, 5.6260, 5.2592, 5.0913,\n",
      "        4.3263, 4.2697, 4.3860, 2.6081, 5.6625, 3.5980, 5.1861, 4.9160, 3.9668,\n",
      "        6.1849], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.7.conv.3.bias\n",
      "Weights: tensor([ 7.0355e-07, -9.4960e-07,  8.0578e-07, -2.5877e-07,  1.6052e-06,\n",
      "         2.9280e-07,  2.2018e-06, -1.7202e-06, -4.2902e-07, -5.6242e-07,\n",
      "        -2.4155e-07,  1.5350e-06, -9.0778e-07,  1.4574e-06, -1.7577e-06,\n",
      "        -8.0902e-07,  4.8703e-08,  1.1551e-06, -4.6082e-07, -1.7447e-06,\n",
      "         1.5194e-06, -9.7728e-07, -1.5073e-06,  7.8497e-09, -1.0841e-06,\n",
      "        -3.8008e-07, -7.1193e-07,  2.5575e-06,  1.7590e-06,  2.6706e-06,\n",
      "         9.1619e-09,  1.5506e-06,  3.7418e-07, -6.4105e-07, -1.9798e-06,\n",
      "        -2.0963e-08,  6.4487e-07,  5.5833e-07,  4.1162e-08, -5.8162e-07,\n",
      "         2.3458e-06, -1.5582e-06, -9.5809e-07,  5.4557e-07, -2.3324e-06,\n",
      "        -7.6304e-07, -1.1273e-06, -6.7281e-07,  1.0622e-06, -2.1107e-06,\n",
      "        -6.8348e-07,  1.9201e-07,  5.9632e-07, -9.3814e-07, -1.5318e-07,\n",
      "         5.9577e-07, -2.6176e-07, -1.0978e-06, -1.4485e-06, -8.2112e-08,\n",
      "         8.5230e-07, -1.6214e-06,  4.2095e-07, -3.9995e-07], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.7.conv.3.output_quantizers.0.min\n",
      "Weights: -30.382665634155273\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.7.conv.3.output_quantizers.0.max\n",
      "Weights: 32.43199157714844\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0346]],\n",
      "\n",
      "         [[-0.0285]],\n",
      "\n",
      "         [[ 0.0848]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0257]],\n",
      "\n",
      "         [[ 0.0247]],\n",
      "\n",
      "         [[ 0.1087]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0617]],\n",
      "\n",
      "         [[-0.0513]],\n",
      "\n",
      "         [[ 0.1027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1441]],\n",
      "\n",
      "         [[ 0.0108]],\n",
      "\n",
      "         [[ 0.0508]]],\n",
      "\n",
      "\n",
      "        [[[-0.0580]],\n",
      "\n",
      "         [[-0.0125]],\n",
      "\n",
      "         [[ 0.0055]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0286]],\n",
      "\n",
      "         [[ 0.0700]],\n",
      "\n",
      "         [[ 0.0076]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2637]],\n",
      "\n",
      "         [[ 0.0237]],\n",
      "\n",
      "         [[ 0.0532]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0462]],\n",
      "\n",
      "         [[-0.0344]],\n",
      "\n",
      "         [[-0.0079]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0080]],\n",
      "\n",
      "         [[ 0.0107]],\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1256]],\n",
      "\n",
      "         [[ 0.0966]],\n",
      "\n",
      "         [[-0.0268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0488]],\n",
      "\n",
      "         [[ 0.1133]],\n",
      "\n",
      "         [[ 0.0109]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0752]],\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[-0.0607]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.8.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.47648584842681885\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.4727632999420166\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.0.1.weight\n",
      "Weights: tensor([0.8284, 1.1204, 0.9475, 1.1092, 1.1616, 1.4802, 0.9515, 0.8518, 1.4569,\n",
      "        1.2612, 1.0200, 1.3870, 1.0982, 1.0198, 0.8574, 0.7480, 0.8058, 2.0396,\n",
      "        1.3823, 0.8071, 0.7984, 1.7803, 1.3590, 1.1740, 1.4933, 0.9050, 1.0073,\n",
      "        1.7909, 1.0633, 1.1453, 1.1761, 0.7099, 1.1754, 0.7333, 0.6466, 0.5983,\n",
      "        0.8571, 1.4184, 1.3680, 1.5683, 1.1689, 1.2855, 1.2191, 0.8485, 0.8217,\n",
      "        0.7986, 2.4725, 1.1756, 1.2914, 0.8845, 0.9082, 1.6219, 0.7320, 1.2502,\n",
      "        1.3607, 1.0703, 1.2898, 0.7701, 1.1508, 0.9456, 1.2169, 0.8393, 1.7461,\n",
      "        0.9180, 0.9539, 1.1281, 0.8869, 1.1577, 0.9772, 0.5352, 0.6976, 1.3741,\n",
      "        1.0615, 1.1860, 0.4224, 0.6838, 1.2411, 1.3892, 0.9654, 1.2261, 0.7977,\n",
      "        0.9899, 1.2436, 1.1046, 1.2748, 1.1457, 1.0218, 1.3260, 1.0252, 0.8335,\n",
      "        0.7278, 1.0090, 1.2660, 0.5976, 0.7512, 0.8421, 1.1791, 0.4380, 1.1117,\n",
      "        0.6834, 0.9450, 0.8456, 0.9176, 1.6302, 1.2563, 0.9362, 0.9731, 0.9592,\n",
      "        1.1805, 0.6416, 1.0945, 0.9530, 0.9581, 1.0323, 1.5806, 0.7471, 1.2551,\n",
      "        0.7777, 0.6557, 1.2490, 1.0327, 0.9110, 1.0589, 1.1899, 1.0831, 0.6448,\n",
      "        0.9927, 1.4514, 1.0162, 0.9467, 1.3576, 0.7772, 1.1184, 1.4386, 1.3598,\n",
      "        1.1429, 1.5112, 0.8473, 1.4451, 0.7149, 1.1017, 0.4332, 1.5427, 0.9329,\n",
      "        0.8928, 0.7807, 1.5208, 1.5840, 0.5344, 1.2297, 0.8382, 1.0852, 0.8047,\n",
      "        0.7813, 0.5127, 1.2792, 1.4979, 0.4432, 1.0757, 0.9777, 0.9333, 0.9596,\n",
      "        0.8273, 1.5701, 1.0238, 1.3675, 0.8766, 1.1342, 1.1984, 0.6647, 1.5695,\n",
      "        0.6859, 1.1082, 1.0083, 1.1101, 0.3919, 0.9456, 1.0219, 1.0028, 1.0637,\n",
      "        1.5030, 0.7903, 0.8494, 0.8871, 0.7925, 1.1354, 1.2838, 1.5585, 1.7610,\n",
      "        0.9039, 0.4815, 1.2488, 1.5563, 1.1780, 0.6409, 0.6666, 0.7282, 0.8197,\n",
      "        1.0832, 1.6211, 1.3366, 0.7779, 1.2918, 0.6430, 1.1329, 1.1239, 0.3816,\n",
      "        0.9506, 0.5007, 0.8700, 1.1732, 0.5860, 1.4405, 0.9604, 0.8865, 0.8333,\n",
      "        0.5645, 1.2111, 1.4191, 1.2265, 0.6468, 1.2580, 1.0604, 1.3966, 1.2944,\n",
      "        1.2095, 0.5962, 1.0575, 0.9384, 1.0353, 1.4902, 1.4330, 0.8097, 1.3723,\n",
      "        1.2101, 0.8387, 0.7621, 0.7528, 1.4239, 1.0120, 0.8598, 1.0055, 1.0721,\n",
      "        0.6402, 1.1105, 0.6751, 0.5352, 1.4766, 0.7936, 1.1736, 0.7923, 1.4277,\n",
      "        1.4406, 0.8198, 0.3704, 1.1576, 1.0302, 0.8499, 0.8596, 0.3358, 0.7827,\n",
      "        0.8056, 1.3512, 1.2342, 1.0618, 0.7730, 1.1888, 0.9532, 0.5952, 0.9462,\n",
      "        0.8761, 0.6574, 1.3030, 1.4818, 1.2338, 0.9907, 0.9350, 0.8367, 1.2840,\n",
      "        1.0310, 1.1483, 1.1006, 1.4312, 1.4883, 0.9556, 1.4052, 1.0226, 0.8139,\n",
      "        1.1075, 1.3623, 1.4351, 0.8628, 1.0371, 0.8568, 1.0349, 1.1157, 1.5574,\n",
      "        1.0136, 1.6235, 0.6489, 1.0558, 1.1865, 1.0181, 1.7590, 0.8035, 1.2843,\n",
      "        1.6887, 0.6964, 0.7736, 0.8231, 0.7292, 0.9584, 1.2590, 1.2665, 1.1206,\n",
      "        0.7950, 0.6815, 1.0586, 1.4787, 1.4134, 0.9430, 0.8500, 0.8348, 1.2532,\n",
      "        0.7398, 0.8055, 0.9681, 0.9184, 0.8713, 0.8152, 1.3714, 0.8441, 1.4310,\n",
      "        0.6104, 0.8090, 1.0887, 1.0186, 1.1828, 1.2849, 0.9849, 0.7614, 0.8050,\n",
      "        0.7324, 0.8292, 1.3121, 0.9376, 0.7941, 1.4366, 1.2445, 0.6326, 0.8972,\n",
      "        0.6945, 1.0635, 1.1059, 1.2511, 0.8916, 1.0204, 0.7389, 0.9079, 0.2858,\n",
      "        1.2982, 0.6289, 0.8780, 0.9911, 0.9252, 0.7219, 0.9194, 0.9517, 0.6093,\n",
      "        1.5321, 0.8655, 0.6389, 0.5657, 1.4675, 1.9323, 1.0231, 0.3759, 1.5259,\n",
      "        0.8208, 0.8775, 1.5185, 0.8946, 0.4485, 0.8958], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.0.1.bias\n",
      "Weights: tensor([ 1.1080e+00,  5.0562e-01,  1.0183e+00,  1.4906e+00,  1.1653e+00,\n",
      "        -4.4482e-01,  1.2343e+00,  1.1669e+00,  2.0300e-01,  1.0827e+00,\n",
      "         9.6976e-01, -1.1398e+00,  1.3755e-01,  1.2921e+00,  1.2268e+00,\n",
      "         1.1074e+00,  1.1944e+00, -3.4355e+00,  4.2203e-01,  9.8519e-01,\n",
      "         1.3263e+00, -7.6559e-01, -3.3385e-01, -4.5704e-01, -1.0657e+00,\n",
      "         9.9664e-01,  1.0283e+00,  1.0203e+00, -1.6502e+00, -8.7633e-01,\n",
      "         7.9810e-01,  1.3196e+00, -2.9677e-01,  1.3487e+00,  2.6285e+00,\n",
      "         1.8504e+00,  1.3218e+00, -1.1370e+00, -7.4434e-01,  2.7937e-02,\n",
      "         3.5456e-01, -2.1654e-01, -2.5624e-01,  9.6426e-01,  1.0186e+00,\n",
      "         1.4466e+00,  1.6163e+00,  1.0301e+00, -1.2582e+00,  1.3435e+00,\n",
      "         1.2950e+00, -1.2106e+00,  1.5334e+00, -9.7030e-01, -3.6214e-01,\n",
      "         1.1444e+00, -1.2012e+00,  1.0362e+00,  4.0590e-01,  1.2516e+00,\n",
      "        -7.7962e-01,  1.2714e+00, -7.5580e-02,  1.2809e+00,  1.3888e+00,\n",
      "         7.1695e-01,  1.3051e+00, -1.3105e+00,  9.2374e-01,  1.2624e+00,\n",
      "         1.2294e+00,  1.8591e+00,  1.2963e+00,  2.1821e-01,  2.7794e+00,\n",
      "         9.1757e-01,  8.0828e-01, -5.9700e-01,  1.1069e+00, -2.7309e-01,\n",
      "         1.4762e+00,  6.2831e-01, -1.5206e-01, -7.3576e-01,  1.4088e+00,\n",
      "         1.3819e+00,  1.0244e+00,  1.4181e+00, -3.9286e+00,  1.4835e+00,\n",
      "         1.4562e+00,  9.4657e-01, -8.3221e-02,  1.9655e+00,  1.1507e+00,\n",
      "         1.1379e+00,  4.6532e-01, -2.4626e+00,  1.3578e+00,  1.2360e+00,\n",
      "         1.6467e+00,  1.0516e+00,  1.2932e+00, -1.5040e-01, -8.2870e-01,\n",
      "         1.0495e+00, -1.3663e+00,  1.3687e+00, -9.2209e-01,  1.8452e+00,\n",
      "         8.0645e-01,  9.3561e-01, -8.7899e-01,  1.1996e+00, -2.6015e+00,\n",
      "         1.4684e+00,  1.6750e+00,  1.1137e+00,  2.0312e+00, -1.1742e+00,\n",
      "         1.2688e+00,  1.3324e+00, -1.5944e-01,  1.5873e+00,  1.6796e+00,\n",
      "         1.1694e+00,  1.0895e+00,  3.1536e-02, -2.5737e-03,  1.3041e+00,\n",
      "         1.9014e-01,  1.4119e+00,  1.3713e+00,  1.4026e-01,  3.6310e-02,\n",
      "        -6.5684e-01,  6.8303e-01,  9.6861e-01, -4.7678e-02,  1.3454e+00,\n",
      "        -9.2591e-01,  1.6636e+00,  2.0623e-02,  8.5316e-01,  9.6819e-01,\n",
      "         1.1853e+00, -2.7520e+00, -2.3305e-03,  1.7146e+00, -3.1654e-01,\n",
      "         1.2491e+00, -7.7049e-01,  1.2586e+00,  1.1153e+00,  1.6932e+00,\n",
      "         4.6474e-01, -7.8455e-01,  2.4370e+00,  1.2054e+00,  8.9117e-01,\n",
      "         9.5678e-01,  1.1546e+00,  1.5096e+00,  1.8448e+00,  1.2954e+00,\n",
      "        -4.2678e-01, -1.3636e+00,  4.8038e-01,  6.9695e-01,  1.2360e+00,\n",
      "         1.3973e-01,  1.5028e+00, -1.5365e+00, -5.3808e-01,  4.5377e-01,\n",
      "         1.4934e+00,  1.0644e+00,  1.0409e+00,  9.5230e-01, -9.3394e-01,\n",
      "         1.3379e+00,  1.0816e+00,  1.1710e+00,  1.6282e+00,  1.1453e+00,\n",
      "         1.1464e+00, -5.1774e-01,  3.4406e-01, -8.5693e-01,  1.2420e+00,\n",
      "         1.1879e+00, -3.6180e-01, -9.4694e-01, -8.1218e-01,  1.3685e+00,\n",
      "         1.5185e+00,  2.8449e+00,  1.5240e+00,  1.3958e+00, -8.7492e-01,\n",
      "        -1.3478e+00,  1.1101e+00,  2.4428e+00,  1.2718e+00,  1.0506e+00,\n",
      "        -7.0619e-02,  3.0173e+00,  1.4499e+00,  1.4692e+00,  1.3329e+00,\n",
      "         4.7165e-01,  3.4379e+00, -1.9067e+00,  8.5566e-01,  1.2185e+00,\n",
      "         1.4656e+00,  1.4998e+00, -1.4734e+00,  4.2771e-01,  1.1819e+00,\n",
      "         1.2401e+00,  4.5974e-01, -8.9125e-01, -1.5907e+00,  1.4822e-01,\n",
      "         6.9739e-01,  1.1184e+00,  1.1884e+00,  1.1403e+00,  1.3088e-01,\n",
      "        -8.1635e-01, -3.0778e-01,  8.6722e-01,  5.4695e-01,  6.8414e-01,\n",
      "         1.5621e+00,  1.6749e+00,  1.5232e+00, -5.0810e-01,  1.4368e+00,\n",
      "         1.2813e+00,  1.2203e+00,  6.7916e-01,  1.0375e+00,  1.2828e+00,\n",
      "         1.5895e+00,  1.5852e+00,  5.8038e-01,  1.0083e+00, -8.2948e-01,\n",
      "         1.1652e+00,  1.6023e+00,  7.4950e-01,  1.0436e+00,  1.6583e+00,\n",
      "         1.0942e+00,  1.5901e+00,  1.0655e+00,  1.6368e+00,  1.2619e+00,\n",
      "         1.2817e+00,  1.7335e+00, -7.3325e-02,  3.1109e-01,  5.8219e-01,\n",
      "         2.4599e+00,  4.2329e-01,  1.0522e+00,  1.0710e+00,  1.6198e+00,\n",
      "         1.2235e+00,  9.0721e-01,  5.9254e-02, -7.5689e-01, -9.0611e-01,\n",
      "         1.7575e+00,  1.4247e+00,  1.3443e+00,  9.4425e-01,  4.9349e-01,\n",
      "         6.1611e-01, -7.4518e-01, -6.1105e-01, -1.5826e-01,  1.1952e+00,\n",
      "        -9.9673e-01,  1.2867e+00,  1.2254e+00,  3.3601e-02, -4.6906e-01,\n",
      "        -1.7318e+00,  8.7018e-01,  1.0890e+00,  1.1819e+00,  1.0342e+00,\n",
      "        -3.5816e-01, -8.3410e-01,  8.1382e-01,  6.6531e-01,  1.5319e+00,\n",
      "        -9.2415e-01,  1.6495e+00,  1.2403e+00, -8.0503e-01,  7.8153e-01,\n",
      "        -3.0415e-01,  1.6089e+00,  1.3075e+00,  1.0594e+00,  1.4029e+00,\n",
      "         1.3443e+00,  1.1273e+00, -1.0265e+00,  2.4229e-01, -5.6223e-01,\n",
      "         1.6125e+00,  1.1479e+00,  1.1338e+00, -2.6935e-01,  7.7036e-01,\n",
      "         1.1932e+00,  1.0723e+00,  1.3945e+00, -3.8067e-01,  1.2487e+00,\n",
      "         1.3421e+00,  1.1702e+00,  1.5083e+00,  8.2712e-01,  1.2670e+00,\n",
      "        -2.1505e-01,  1.0874e+00, -6.0648e-01,  2.0291e+00,  1.2374e+00,\n",
      "         1.5560e+00,  8.4237e-01, -1.2254e-01, -4.4108e-01,  1.2449e+00,\n",
      "         1.2757e+00,  1.1005e+00,  1.5063e+00,  9.5069e-01, -3.2607e-01,\n",
      "         1.2332e+00,  1.4244e+00,  1.3049e-01,  3.9028e-01,  1.6806e+00,\n",
      "         8.2451e-01,  1.7497e+00,  1.2481e+00,  1.3697e+00, -9.2058e-02,\n",
      "         1.1929e+00,  4.9009e-01,  1.6120e+00,  1.2492e+00,  2.9322e+00,\n",
      "        -4.7594e-02,  1.7051e+00,  1.0426e+00, -1.1951e+00,  6.1147e-01,\n",
      "         1.5296e+00,  9.7097e-01,  7.4113e-01,  1.3715e+00,  1.6972e-01,\n",
      "         7.7703e-01,  1.1677e+00,  1.6069e+00,  1.7604e+00, -6.5044e-01,\n",
      "         9.4531e-01,  2.7876e+00, -1.4466e+00,  1.3482e+00,  9.8740e-01,\n",
      "        -8.6544e-01,  1.0822e+00,  1.7059e+00,  1.2179e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0114,  0.0153, -0.0350],\n",
      "          [ 0.2751, -0.2081, -0.1776],\n",
      "          [ 0.0358,  0.0149, -0.0543]]],\n",
      "\n",
      "\n",
      "        [[[-0.0878, -0.1321, -0.1117],\n",
      "          [-0.1370,  0.3901, -0.1423],\n",
      "          [-0.0522, -0.1384, -0.0691]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0748,  0.3992,  0.0834],\n",
      "          [-0.0008, -0.1331,  0.0140],\n",
      "          [-0.0565, -0.3057, -0.0629]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0537, -0.0571, -0.0310],\n",
      "          [ 0.3341, -0.3015, -0.0377],\n",
      "          [ 0.0594, -0.0597, -0.0306]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174, -0.0831,  0.0290],\n",
      "          [-0.0836, -0.2823, -0.0803],\n",
      "          [ 0.0316, -0.0671,  0.0330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0490, -0.0813, -0.0361],\n",
      "          [-0.0680,  0.3082, -0.0133],\n",
      "          [-0.0527, -0.0271, -0.0696]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.8.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.7435277700424194\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.737718939781189\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.1.1.weight\n",
      "Weights: tensor([2.2056, 0.5348, 1.0448, 1.0461, 1.3236, 0.8818, 0.9702, 0.9639, 2.5181,\n",
      "        0.6802, 1.7958, 0.4458, 1.3204, 1.1280, 0.9913, 0.9994, 0.9210, 1.0034,\n",
      "        1.3272, 1.1273, 1.0678, 8.1944, 0.9502, 0.9111, 0.5075, 1.7521, 1.0799,\n",
      "        2.9968, 2.6702, 0.4609, 0.8589, 1.3415, 1.4582, 1.1861, 0.9654, 1.4726,\n",
      "        1.0283, 0.4420, 1.3046, 1.2491, 0.9834, 0.4354, 0.5898, 1.2345, 0.8672,\n",
      "        1.0886, 1.7560, 1.9951, 0.3984, 0.9603, 1.0780, 0.9656, 1.7989, 0.4050,\n",
      "        1.6103, 1.2088, 1.0949, 1.0111, 1.3924, 0.9701, 0.5817, 0.8560, 1.5565,\n",
      "        1.1173, 1.0013, 1.2465, 1.0924, 0.3230, 1.6207, 0.8210, 1.3923, 2.9803,\n",
      "        1.0532, 1.2067, 3.2694, 1.4073, 1.6223, 0.9725, 1.0388, 0.5011, 1.0723,\n",
      "        0.7993, 0.8055, 0.7658, 0.9822, 2.0198, 1.3053, 0.9120, 2.0328, 1.1219,\n",
      "        1.1166, 0.9330, 1.2456, 2.4578, 1.9136, 0.8659, 0.5197, 4.3416, 1.1744,\n",
      "        1.0547, 1.0186, 0.9506, 1.0659, 1.1395, 0.6680, 1.1936, 0.9082, 1.0010,\n",
      "        0.7964, 1.3160, 0.9172, 0.8756, 0.5787, 1.0597, 1.1162, 1.2815, 1.1519,\n",
      "        1.4730, 2.7108, 0.7557, 0.9938, 1.6249, 0.8043, 1.1466, 1.1877, 1.3009,\n",
      "        1.1977, 0.8690, 0.9024, 1.0731, 0.9449, 1.3167, 1.1092, 1.1883, 2.1687,\n",
      "        0.6003, 1.1818, 0.9749, 2.0615, 1.1139, 0.6226, 1.3787, 2.0828, 1.1354,\n",
      "        1.0363, 0.9214, 1.8205, 0.5272, 1.2786, 1.0126, 1.0057, 0.6876, 1.0908,\n",
      "        1.0381, 1.7412, 0.9365, 0.7021, 1.5340, 2.6393, 1.4852, 0.9214, 1.0045,\n",
      "        1.4832, 1.3174, 1.0387, 1.0681, 0.8090, 1.3103, 1.5254, 1.6061, 2.2567,\n",
      "        1.7024, 0.4378, 0.8105, 1.0396, 2.0641, 0.8919, 2.1444, 2.1790, 0.7846,\n",
      "        0.8767, 0.9506, 1.5672, 1.2481, 2.2654, 0.9097, 0.5492, 0.5759, 7.1716,\n",
      "        1.0709, 0.6702, 0.8305, 1.6848, 0.7773, 1.9153, 1.1567, 3.1382, 1.1598,\n",
      "        1.1031, 1.6002, 0.4192, 1.0507, 5.5110, 1.3161, 0.7905, 0.5657, 1.8134,\n",
      "        1.2044, 1.1940, 1.1129, 0.6201, 2.5777, 0.4047, 0.9654, 1.2328, 2.5275,\n",
      "        1.7188, 0.7167, 1.0440, 1.3632, 1.2220, 1.1120, 0.8448, 0.5351, 1.2521,\n",
      "        2.0321, 0.9657, 0.8605, 0.9406, 0.8333, 1.6608, 0.6330, 1.1966, 1.2487,\n",
      "        1.3240, 1.0026, 1.2792, 2.1557, 1.5535, 1.1390, 0.8896, 1.0585, 1.6802,\n",
      "        0.4738, 1.1811, 1.4117, 1.8129, 1.4291, 1.2739, 0.6342, 0.8765, 1.0701,\n",
      "        2.7961, 1.1032, 1.3169, 0.9552, 1.1157, 0.9682, 1.1478, 1.9132, 1.0196,\n",
      "        1.1418, 0.8309, 0.5541, 4.6048, 0.9446, 0.8023, 1.0916, 1.2646, 1.1118,\n",
      "        0.9599, 0.8714, 0.6944, 0.4782, 0.5619, 1.9174, 1.8018, 0.8714, 1.8047,\n",
      "        0.9798, 0.6048, 0.4999, 0.7641, 0.7122, 2.8098, 0.5741, 0.9961, 1.3045,\n",
      "        1.0290, 1.2705, 0.6602, 1.0380, 0.9660, 1.2145, 0.9610, 0.7637, 1.6382,\n",
      "        0.7855, 2.7030, 1.7156, 0.7232, 2.6970, 1.0432, 2.0588, 1.0347, 1.1773,\n",
      "        0.6750, 1.5590, 1.4403, 1.0526, 1.3752, 1.0473, 0.5793, 0.6361, 0.8748,\n",
      "        1.5924, 1.2096, 0.9493, 1.8145, 1.0386, 1.9946, 0.9617, 1.3005, 1.1581,\n",
      "        1.0206, 0.9206, 0.9388, 1.1464, 1.2204, 0.9464, 1.8168, 1.3643, 1.1772,\n",
      "        2.5307, 1.1163, 1.1957, 1.6632, 0.6051, 0.6378, 0.9920, 1.6187, 1.7163,\n",
      "        1.3907, 1.3645, 0.4756, 1.0143, 1.0437, 1.4477, 0.8146, 2.4328, 0.9719,\n",
      "        2.6244, 0.9618, 1.0988, 0.7343, 0.9977, 0.7777, 2.2296, 1.3463, 3.1860,\n",
      "        1.0105, 0.9760, 0.8999, 0.2862, 1.0686, 2.2185, 1.5826, 0.9887, 1.3527,\n",
      "        1.3569, 1.1242, 1.0464, 1.5298, 0.9699, 2.4838, 1.1136, 1.7729, 0.8392,\n",
      "        1.0505, 1.2000, 1.6058, 1.2118, 1.6971, 1.4762], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.1.1.bias\n",
      "Weights: tensor([-2.2880e+00,  1.1662e+00, -1.8449e-01, -1.5887e-01, -1.5456e+00,\n",
      "         1.5474e-01, -1.3016e-01, -2.0207e-01, -1.5889e+00,  2.5408e+00,\n",
      "        -2.1592e+00,  2.6129e+00, -2.0648e+00, -1.1270e-01, -1.8089e-01,\n",
      "        -2.3930e-01, -1.0245e-01, -2.7740e+00, -5.7584e-01, -2.7595e-01,\n",
      "        -1.9493e-01, -5.6517e+00, -6.9978e-01, -6.5886e-01,  1.0392e+00,\n",
      "        -1.0611e+00, -1.2996e-02, -1.8956e+00, -5.4760e-01,  2.3935e+00,\n",
      "        -1.3456e-01, -1.9535e-01, -1.6882e+00, -2.1413e-01,  6.5721e-01,\n",
      "        -1.4263e+00, -1.3546e-01,  3.0586e+00,  1.1739e-01, -4.3801e-01,\n",
      "        -8.5371e-01,  1.8159e+00, -2.5354e-01, -9.3614e-01,  2.8002e-01,\n",
      "        -1.6873e-01, -1.1246e+00, -1.6429e+00,  1.0317e-01, -1.4303e-01,\n",
      "        -1.4691e-01,  5.0491e-01, -7.9472e-01,  1.0118e+00, -3.3278e-01,\n",
      "        -3.4448e-01, -2.8202e+00, -1.3103e-01, -1.5915e+00, -5.3766e-02,\n",
      "         2.1535e-01,  2.5898e-01, -3.3072e+00, -2.8096e-01, -1.4154e-02,\n",
      "        -8.7402e-01, -7.9811e-02,  1.7786e+00, -1.1642e+00, -1.5078e-01,\n",
      "        -4.4531e-01, -3.3804e+00, -1.6540e-01, -1.2375e+00, -2.1894e+00,\n",
      "        -9.4609e-01, -6.7523e-01, -1.8606e+00, -2.4980e-01,  1.3277e+00,\n",
      "        -1.5061e-01,  5.0641e-01, -2.0220e-01, -8.2776e-01, -1.1232e-01,\n",
      "        -1.9844e+00, -7.8735e-01, -1.9660e-01, -7.0284e-01, -4.1420e-02,\n",
      "        -1.8974e-01, -2.7378e-01, -1.3226e+00, -3.3656e+00, -2.5139e+00,\n",
      "        -1.1407e-01,  2.5735e+00, -8.9287e-01, -1.9160e-01, -1.5853e-01,\n",
      "        -1.0590e-01, -1.4623e-01, -2.3391e-01, -2.3157e-01, -5.9041e-02,\n",
      "        -5.3487e-01, -3.8668e-01, -1.9367e-01, -1.5986e+00,  2.8254e-01,\n",
      "        -1.7459e-02,  2.9249e-01, -7.9914e-02, -1.2027e-01,  1.8672e+00,\n",
      "        -5.0854e-01, -3.6931e-01, -6.1376e-01, -3.7012e+00, -9.2239e-01,\n",
      "        -1.2255e-01, -1.5379e+00, -8.3593e-01, -5.6772e-02, -1.1562e-01,\n",
      "        -7.4481e-01, -4.4826e-01,  1.2312e-01,  2.5009e+00, -8.1079e-02,\n",
      "         1.1156e-01, -1.2632e-01, -7.7714e-02, -3.5745e-02, -1.2258e+00,\n",
      "        -5.2018e-01, -2.5546e-01,  2.4113e-01, -1.1178e+00,  1.9980e-02,\n",
      "        -6.6314e-01,  1.5619e-01, -1.0516e+00, -3.3419e-01, -3.2856e-01,\n",
      "        -1.6314e-01, -2.4973e+00,  2.4497e+00,  3.6238e-01, -2.2081e+00,\n",
      "        -1.4156e-01, -3.6120e-01, -1.8063e-01, -7.7170e-02, -1.4898e+00,\n",
      "         2.1298e-02, -7.4237e-01,  4.9642e-02, -2.5020e+00, -1.0401e+00,\n",
      "        -1.2313e-01, -1.6171e-01, -7.5706e-01, -9.6268e-01, -6.5296e-02,\n",
      "        -1.3818e+00, -3.3109e+00, -5.2676e-01, -8.4386e-01, -1.5238e+00,\n",
      "        -1.1653e+00, -6.2380e-01,  2.2994e+00, -1.2417e+00, -3.4926e-01,\n",
      "        -1.8247e+00, -1.6187e-01, -1.3900e+00, -1.4349e+00, -1.2270e+00,\n",
      "         3.1454e-01, -2.1081e-01, -6.7784e-01,  1.6767e-02, -3.0886e+00,\n",
      "        -1.8952e-01,  2.6897e+00,  1.5748e+00, -4.2525e+00, -1.0194e-01,\n",
      "         1.8971e+00, -5.1647e-01, -5.2635e-01, -3.9951e-01, -2.5932e+00,\n",
      "        -7.1740e-02, -4.9863e+00, -8.3583e-02, -2.0192e-01, -8.8036e-02,\n",
      "         1.2658e+00, -2.4254e-01, -8.4222e+00, -5.4129e-01,  3.5836e-01,\n",
      "         1.7701e-01, -5.1058e-01, -2.7325e-01,  1.8076e-01, -2.1652e-01,\n",
      "         2.0516e+00, -5.1125e-01,  9.1529e-02, -3.0498e-01, -4.1111e-01,\n",
      "        -2.0800e+00, -1.4302e+00, -1.4638e+00, -6.0455e-01, -6.0855e-01,\n",
      "        -2.9916e-01, -8.3353e-01, -1.2250e+00,  1.9912e+00, -1.6663e+00,\n",
      "        -1.2360e+00, -3.7833e-02, -6.5865e-02, -1.6246e-01, -1.9448e-01,\n",
      "        -5.0714e-01,  2.6733e+00, -5.8749e-01, -4.9030e-01, -1.1274e+00,\n",
      "        -9.8689e-02,  7.3401e-01, -1.7703e+00, -2.3017e-01, -1.2463e-01,\n",
      "        -1.3837e-01, -1.1648e-01, -1.0305e+00,  1.0885e+00, -2.9856e-01,\n",
      "         4.1140e-01, -2.7728e+00, -1.0470e-01, -2.7720e-01,  2.3048e+00,\n",
      "        -1.2202e-01, -2.7429e-01, -1.8144e+00, -2.7435e-01, -1.0694e+00,\n",
      "        -2.3683e-01, -9.0983e-02, -1.5407e-01, -5.7553e-02, -1.1508e+00,\n",
      "        -2.3061e-01,  6.1433e-02,  1.3914e-01,  1.8034e+00, -4.8391e+00,\n",
      "         3.5702e-01,  3.9118e-01, -1.5145e-01, -3.8461e-01, -1.0340e-01,\n",
      "        -1.7378e-01, -2.8085e-01,  2.7413e+00,  6.8859e-01,  4.6162e-01,\n",
      "        -1.9619e+00, -1.5784e+00,  6.6865e-01, -1.0793e+00,  2.3698e-03,\n",
      "         2.0845e+00,  7.7262e-01,  3.7148e-01,  3.8132e-01, -2.8006e+00,\n",
      "         1.6508e-01, -1.3651e-01, -5.4360e-01, -1.0459e+00, -1.0474e-01,\n",
      "         9.2405e-01, -7.8172e-01, -1.3193e-01, -3.5455e-01, -1.6735e-01,\n",
      "        -8.2591e-01, -5.2584e-01,  4.1587e-01, -1.7864e+00, -1.5373e+00,\n",
      "        -1.4316e+00, -2.8390e+00, -1.8756e-01, -5.0244e-01, -6.2711e-01,\n",
      "        -5.0864e-01,  1.3805e+00, -6.7854e-01, -1.2733e+00, -1.5499e-01,\n",
      "        -4.9401e-01, -1.6704e-01,  5.5896e-01,  2.2323e+00, -8.9735e-01,\n",
      "        -9.8596e-01, -4.6223e-01, -2.1796e-01, -5.7308e-01, -2.5387e-01,\n",
      "        -1.1511e+00, -2.1810e-01, -2.8645e-02, -2.9318e-01, -1.0809e-01,\n",
      "         2.3630e-01, -1.7926e-01, -1.5979e-01, -8.3438e-01, -1.5599e-01,\n",
      "        -1.7885e-01, -7.9877e-01,  9.1309e-02, -4.5110e+00, -2.6579e-01,\n",
      "        -1.0908e-01, -9.8625e-01,  8.8400e-01,  6.6456e-01, -2.9203e-01,\n",
      "        -1.7430e+00, -1.1392e+00, -8.9908e-01, -8.4892e-01,  1.3939e+00,\n",
      "        -2.5099e-01, -6.0728e-03,  3.3052e-02,  1.6374e-01, -3.2597e+00,\n",
      "        -1.1394e-01, -2.8892e+00, -1.7021e-01,  7.4032e-02,  7.7582e-01,\n",
      "        -2.3341e-01, -3.3132e-02, -1.9573e+00, -6.3186e-01, -4.7945e+00,\n",
      "        -4.3385e-01, -7.2496e-02, -1.6405e-01,  2.7470e+00, -7.8944e-01,\n",
      "        -2.0351e+00, -1.4804e+00, -3.7836e-01, -2.9204e-01, -1.9908e+00,\n",
      "        -3.4169e-01, -2.5531e-01, -4.7015e-01, -1.8226e-01, -8.0380e+00,\n",
      "        -3.1750e-01, -5.0041e-01, -2.8405e-01, -2.1286e-01, -9.4528e-01,\n",
      "        -5.0160e-01, -4.5813e-01, -1.7940e+00, -2.2183e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0391]],\n",
      "\n",
      "         [[ 0.1005]],\n",
      "\n",
      "         [[-0.3028]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0325]],\n",
      "\n",
      "         [[-0.0300]],\n",
      "\n",
      "         [[ 0.0328]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0082]],\n",
      "\n",
      "         [[ 0.0277]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         [[ 0.0687]],\n",
      "\n",
      "         [[ 0.1747]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0557]],\n",
      "\n",
      "         [[-0.2247]],\n",
      "\n",
      "         [[-0.0555]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1919]],\n",
      "\n",
      "         [[ 0.0095]],\n",
      "\n",
      "         [[-0.0044]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0416]],\n",
      "\n",
      "         [[ 0.1816]],\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0651]],\n",
      "\n",
      "         [[-0.0065]],\n",
      "\n",
      "         [[-0.0220]]],\n",
      "\n",
      "\n",
      "        [[[-0.0669]],\n",
      "\n",
      "         [[ 0.0156]],\n",
      "\n",
      "         [[-0.0310]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[ 0.1093]],\n",
      "\n",
      "         [[ 0.0129]]],\n",
      "\n",
      "\n",
      "        [[[-0.0259]],\n",
      "\n",
      "         [[ 0.0074]],\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1508]],\n",
      "\n",
      "         [[ 0.1671]],\n",
      "\n",
      "         [[-0.0322]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 384, 1, 1])\n",
      "\n",
      "Layer: features.8.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.0926624536514282\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.0841259956359863\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.3.weight\n",
      "Weights: tensor([7.8360, 1.0584, 3.5380, 1.3484, 3.8707, 2.0086, 1.1544, 1.2525, 3.5590,\n",
      "        2.9910, 2.1427, 2.9652, 1.6902, 2.1715, 5.0603, 3.3359, 4.4349, 1.0763,\n",
      "        2.4037, 2.0562, 1.9034, 3.3303, 0.7753, 2.5673, 1.5712, 3.4064, 2.7877,\n",
      "        4.6141, 1.4077, 0.7443, 2.6933, 1.6813, 1.3904, 3.0798, 2.1638, 1.7055,\n",
      "        1.5508, 1.5130, 8.2281, 1.1929, 1.5605, 1.3594, 0.8352, 1.2160, 4.2037,\n",
      "        2.9349, 1.0145, 3.0941, 1.1828, 1.5339, 2.1415, 1.1163, 0.9817, 1.4607,\n",
      "        1.9959, 2.3850, 1.9434, 4.9441, 1.5986, 3.3613, 1.4026, 1.4228, 1.7048,\n",
      "        0.7788], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.8.conv.3.bias\n",
      "Weights: tensor([ 9.5386e-07, -2.1270e-06,  3.1705e-07, -1.2848e-06,  1.6270e-06,\n",
      "         1.1604e-06,  1.4727e-06, -1.7946e-06, -7.6655e-07,  5.6483e-07,\n",
      "         6.4463e-07,  9.4201e-07, -9.1535e-07,  1.0354e-06, -1.9462e-06,\n",
      "        -1.0773e-06, -1.9959e-07,  8.5836e-07,  3.6076e-07, -1.5350e-06,\n",
      "         2.4976e-06, -8.4938e-07, -6.9491e-07, -1.9235e-07, -3.9416e-07,\n",
      "        -7.0716e-07, -3.2572e-07,  2.0955e-06,  2.7134e-06,  1.3194e-06,\n",
      "         1.2889e-08,  9.0924e-07,  5.3636e-07, -1.6711e-08, -8.9832e-07,\n",
      "        -6.7974e-07,  1.0358e-06,  8.8916e-08,  5.0032e-07, -4.1835e-07,\n",
      "         1.7055e-06, -1.2290e-06, -2.4564e-06,  4.0875e-07, -1.3184e-06,\n",
      "        -4.9341e-07, -1.1799e-06, -6.8926e-07,  9.4612e-07, -2.7302e-06,\n",
      "        -9.3285e-07, -3.3220e-07,  3.7139e-07, -1.5727e-06, -9.6127e-07,\n",
      "         1.2016e-07, -1.6230e-07, -9.1434e-07, -3.0399e-07,  5.2820e-07,\n",
      "         8.2581e-07, -8.0286e-07,  9.3195e-07,  7.8068e-07], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.8.conv.3.output_quantizers.0.min\n",
      "Weights: -27.17969512939453\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.8.conv.3.output_quantizers.0.max\n",
      "Weights: 30.52593231201172\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.1028]],\n",
      "\n",
      "         [[ 0.1069]],\n",
      "\n",
      "         [[ 0.0267]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         [[ 0.2539]]],\n",
      "\n",
      "\n",
      "        [[[-0.1232]],\n",
      "\n",
      "         [[ 0.0303]],\n",
      "\n",
      "         [[-0.1224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0274]],\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[ 0.0862]]],\n",
      "\n",
      "\n",
      "        [[[-0.0809]],\n",
      "\n",
      "         [[-0.0221]],\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0646]],\n",
      "\n",
      "         [[ 0.0508]],\n",
      "\n",
      "         [[-0.0372]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0393]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0762]],\n",
      "\n",
      "         [[-0.1868]],\n",
      "\n",
      "         [[ 0.0809]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0132]],\n",
      "\n",
      "         [[-0.0494]],\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0094]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         [[-0.0616]]],\n",
      "\n",
      "\n",
      "        [[[-0.0570]],\n",
      "\n",
      "         [[ 0.1543]],\n",
      "\n",
      "         [[ 0.1038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         [[ 0.0676]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.9.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -1.160643219947815\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 1.1515756845474243\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.0.0.input_quantizers.0.min\n",
      "Weights: -29.63642120361328\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.0.0.input_quantizers.0.max\n",
      "Weights: 32.289146423339844\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.0.1.weight\n",
      "Weights: tensor([1.2247, 1.1375, 1.5587, 1.2605, 1.7905, 1.3319, 0.9271, 0.7306, 1.1570,\n",
      "        1.1270, 1.2706, 0.9174, 1.2075, 0.9994, 1.1334, 1.2735, 1.2341, 1.1240,\n",
      "        0.6217, 1.0682, 1.3678, 0.9267, 0.7160, 1.3272, 0.5850, 1.0568, 1.1308,\n",
      "        1.1699, 1.1467, 1.1139, 1.1899, 0.9553, 1.4446, 0.9257, 1.1200, 1.1544,\n",
      "        1.2099, 1.3622, 1.0605, 1.2864, 1.4646, 1.2600, 1.0775, 1.3196, 1.0544,\n",
      "        1.4159, 1.0296, 1.7860, 0.8223, 0.8773, 1.1370, 1.3795, 1.0294, 0.9859,\n",
      "        0.6218, 1.4418, 1.1956, 1.3195, 0.7942, 1.2628, 0.8311, 0.5926, 1.3720,\n",
      "        1.3514, 1.2451, 1.2751, 0.5950, 0.9713, 0.5686, 0.9298, 0.6719, 1.4048,\n",
      "        1.3249, 0.9544, 1.1625, 1.3505, 1.1257, 1.2884, 0.3721, 0.6023, 1.2198,\n",
      "        0.7009, 0.6254, 0.6601, 1.2044, 1.1272, 0.4512, 1.1454, 1.2123, 1.2149,\n",
      "        1.6064, 1.3374, 0.5999, 0.6180, 1.1897, 0.7004, 1.1596, 1.0527, 0.7141,\n",
      "        0.6673, 1.3365, 0.5321, 1.2933, 1.4120, 1.1460, 0.6605, 1.0941, 1.5137,\n",
      "        1.0643, 1.0473, 1.2784, 0.9210, 0.5798, 1.0701, 0.5918, 1.2109, 1.1027,\n",
      "        0.9317, 1.1368, 0.9343, 1.3213, 0.9702, 0.5929, 1.4052, 1.1654, 0.6157,\n",
      "        1.4288, 0.6099, 1.1879, 1.3866, 1.1631, 1.2171, 1.3828, 0.9685, 1.0189,\n",
      "        0.7135, 1.2614, 0.9958, 0.5219, 0.8380, 1.0442, 1.4127, 0.7038, 0.5785,\n",
      "        1.1623, 0.8370, 1.0238, 1.3738, 1.4752, 0.7426, 1.4060, 1.1875, 0.9354,\n",
      "        1.0247, 1.5004, 1.2205, 0.9207, 1.1096, 1.2854, 1.2910, 1.0682, 0.6870,\n",
      "        0.4800, 1.0331, 0.7883, 1.0602, 0.5652, 1.3000, 1.3198, 0.6695, 0.6855,\n",
      "        1.1397, 0.4620, 1.1411, 1.0324, 1.1645, 1.2394, 0.7520, 1.3329, 1.3988,\n",
      "        1.2085, 1.0467, 0.9672, 0.8114, 1.1462, 1.2935, 0.9463, 1.2793, 0.9609,\n",
      "        1.2150, 1.2541, 1.0114, 1.1022, 0.9757, 1.1047, 1.0835, 0.4400, 1.1525,\n",
      "        1.3645, 1.2801, 0.9070, 1.2803, 1.0506, 1.0975, 0.6680, 1.2554, 1.0576,\n",
      "        1.0020, 0.5412, 1.6024, 1.2508, 1.3417, 0.5715, 0.7739, 1.2930, 1.0637,\n",
      "        1.2778, 0.5556, 1.6170, 1.1505, 1.2391, 1.5787, 0.7590, 0.6874, 0.4593,\n",
      "        1.4690, 1.0302, 0.9585, 0.6635, 1.3803, 1.4930, 1.0763, 0.6895, 1.6858,\n",
      "        0.7701, 1.3450, 0.8564, 1.3328, 0.9498, 0.8946, 1.2266, 1.6966, 1.2953,\n",
      "        1.1048, 1.2038, 0.8577, 1.1502, 1.2335, 1.0836, 0.5851, 0.9193, 1.7771,\n",
      "        1.1180, 0.3746, 1.1419, 0.8631, 0.5371, 0.5888, 0.4927, 0.9812, 0.7242,\n",
      "        1.0284, 1.0119, 1.2319, 1.5432, 1.3668, 1.1239, 1.3172, 1.5897, 0.4537,\n",
      "        1.0931, 0.5889, 0.6831, 0.6870, 1.4803, 0.8453, 0.9494, 1.2484, 0.5748,\n",
      "        1.3145, 1.2412, 1.1966, 0.5682, 1.1510, 1.2905, 1.5041, 1.3102, 0.6730,\n",
      "        1.1696, 0.5652, 1.2835, 1.1091, 0.9145, 1.2322, 1.1157, 1.3320, 1.3608,\n",
      "        1.0650, 1.0816, 1.2727, 0.8668, 0.4862, 1.0629, 1.0235, 0.6801, 1.1817,\n",
      "        1.0384, 1.1515, 0.8617, 1.2278, 0.6188, 1.2520, 0.9429, 1.5417, 1.5592,\n",
      "        0.8589, 1.1344, 0.6190, 1.1346, 1.1565, 1.0179, 1.0926, 0.6457, 0.9641,\n",
      "        0.6314, 1.3112, 1.2587, 1.2944, 0.3347, 1.2255, 1.4568, 1.3431, 0.8822,\n",
      "        1.2660, 1.3949, 1.2419, 1.2546, 1.7418, 0.9883, 0.5059, 1.1343, 1.0440,\n",
      "        0.7269, 1.2580, 1.2497, 0.8218, 1.4405, 0.5258, 1.0814, 1.4908, 1.3569,\n",
      "        0.6677, 0.7482, 1.1102, 1.4171, 1.3310, 0.9778, 0.7552, 1.1442, 1.3026,\n",
      "        0.6240, 1.2633, 0.6307, 0.6129, 1.3931, 1.2825, 1.5428, 1.6562, 1.2040,\n",
      "        1.1929, 1.3232, 1.6134, 1.3370, 1.0972, 1.5372, 1.1384, 1.4837, 1.0083,\n",
      "        1.1821, 1.1027, 1.0670, 1.2188, 2.8051, 1.2074], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.0.1.bias\n",
      "Weights: tensor([-3.2372e-01, -1.8765e+00,  1.4882e+00, -3.0089e-01,  1.1437e+00,\n",
      "        -1.1333e+00,  8.1730e-01,  1.0791e+00,  3.9402e-02, -6.4035e-01,\n",
      "         1.7595e+00,  7.3942e-01,  7.1933e-01,  1.1604e+00, -6.6969e-01,\n",
      "        -9.4501e-01,  2.9424e-01, -9.0298e-02,  1.0008e+00, -9.0757e-02,\n",
      "         4.8240e-01, -1.2557e+00,  1.2607e+00, -3.6026e-01,  1.3371e+00,\n",
      "         7.0015e-01,  5.5856e-01, -1.1235e+00, -5.6212e-01,  4.9198e-01,\n",
      "        -6.0216e-01,  9.8026e-01, -8.5122e-01,  1.0291e+00,  8.3081e-01,\n",
      "         7.3905e-01,  5.9484e-01,  4.3449e-02,  6.0487e-01, -2.0276e-01,\n",
      "        -8.9012e-01,  2.0483e-01, -1.1112e+00, -1.1006e-01, -7.2662e-01,\n",
      "        -5.7325e-01,  9.8976e-01, -1.4405e+00,  1.2537e+00, -1.0667e+00,\n",
      "        -1.0065e-01, -9.0243e-01,  9.3452e-01, -1.0358e+00,  1.2787e+00,\n",
      "         1.8021e+00,  3.0598e-01,  9.7220e-02,  9.1296e-01,  7.5202e-01,\n",
      "         9.3218e-01,  1.0692e+00, -4.8578e-01, -2.1600e-01, -6.3231e-02,\n",
      "         1.0696e-01,  1.3584e+00, -1.4057e+00,  1.1853e+00,  1.5787e+00,\n",
      "         1.2912e+00, -8.2016e-01,  1.5396e-01, -9.8854e-01,  4.2354e-01,\n",
      "        -5.3753e-01, -8.2151e-01, -7.9073e-01,  1.3882e+00,  1.1481e+00,\n",
      "         1.3999e-01,  1.2147e+00,  1.7614e+00,  9.4833e-01, -3.4347e-01,\n",
      "        -6.6727e-01,  1.2369e+00,  9.8356e-01,  1.4226e-01,  1.2118e+00,\n",
      "        -9.9549e-01,  1.7688e-01,  1.9047e+00,  1.1853e+00,  7.2337e-01,\n",
      "         1.1084e+00, -1.3660e-01,  3.8580e-01,  1.3991e+00,  1.0050e+00,\n",
      "         2.1241e-01,  1.2422e+00, -7.3368e-01, -1.1834e-01, -1.1421e+00,\n",
      "         1.1962e+00,  7.8071e-01, -9.8592e-01,  4.1459e-01,  7.2877e-01,\n",
      "        -9.8509e-01,  7.9047e-01,  1.8030e+00,  5.8128e-01,  1.3498e+00,\n",
      "        -3.5446e-01,  1.0782e-01,  6.8958e-01,  3.7628e-01, -9.9576e-01,\n",
      "         8.0870e-01,  8.9852e-01,  1.3857e+00, -4.3562e-01,  1.2856e+00,\n",
      "         1.1700e+00, -1.1244e+00,  1.1997e+00, -4.5031e-01, -3.3478e-01,\n",
      "        -9.1685e-01, -1.2817e-01,  9.0440e-02, -1.8404e+00, -8.3392e-01,\n",
      "         9.7533e-01, -1.9185e-01,  3.7612e-01,  1.4056e+00,  1.2719e+00,\n",
      "         5.9657e-01, -1.8727e-01,  1.0884e+00,  1.2094e+00,  6.3172e-01,\n",
      "         2.0508e+00,  6.8588e-01,  3.1477e-01,  7.7176e-01,  1.3779e+00,\n",
      "        -1.6982e-01, -7.3240e-01,  8.3516e-01,  1.1421e+00,  1.8792e-01,\n",
      "        -1.1964e-01,  1.0223e+00,  1.6759e-03, -5.2079e-01,  1.8675e-01,\n",
      "         1.2255e+00,  1.5084e+00,  2.1510e+00, -1.3598e+00,  1.0145e+00,\n",
      "        -5.0576e-01,  1.1472e+00, -1.3530e+00,  1.0190e-01,  1.5358e+00,\n",
      "         1.3085e+00,  5.4804e-01,  1.4734e+00,  9.2088e-01, -9.8157e-01,\n",
      "         1.1946e-02,  8.4432e-01,  1.0628e+00, -1.6476e-02, -3.2200e-01,\n",
      "         1.5064e-03, -3.5100e-01, -1.0025e+00,  4.8554e-01,  2.0533e+00,\n",
      "        -3.0114e-02,  7.1926e-01, -7.7459e-01,  7.2858e-01, -1.1830e+00,\n",
      "        -2.9894e-01, -8.0097e-01,  3.2070e-01,  9.9228e-01,  5.4093e-01,\n",
      "        -7.4802e-01,  1.3746e+00, -5.8820e-01, -2.9297e-01, -5.0861e-01,\n",
      "         7.3956e-01, -8.6296e-01,  8.6694e-01,  3.9240e-01,  1.2625e+00,\n",
      "         1.3972e-01,  7.5223e-01, -8.0534e-01,  1.3934e+00, -2.8851e-01,\n",
      "        -8.0099e-01, -5.0818e-02,  1.2869e+00,  1.1616e+00,  6.6944e-01,\n",
      "        -4.1568e-01, -2.2770e-01,  1.2645e+00, -1.2789e+00,  2.0523e-01,\n",
      "         1.5668e-01, -3.5524e-01,  1.8497e+00,  9.3451e-01,  1.2829e+00,\n",
      "         9.8627e-01, -9.4876e-01,  7.5155e-01,  1.2395e+00,  1.5923e-02,\n",
      "        -1.7489e-01, -5.3632e-01,  8.6865e-01, -8.0808e-01,  8.4111e-01,\n",
      "        -2.4051e-02,  8.7339e-01, -5.7973e-01,  5.8347e-01,  1.2832e+00,\n",
      "        -7.7010e-01, -9.3090e-01, -2.6166e-01, -8.0142e-01, -1.7003e-01,\n",
      "         1.0464e+00, -8.3371e-01,  5.3250e-02,  7.1268e-01,  1.1815e+00,\n",
      "         1.0128e+00, -2.2324e-01, -6.4767e-01,  1.4832e+00,  4.6491e-01,\n",
      "         9.6979e-01,  1.4739e+00,  1.4113e+00,  1.2262e+00,  9.9623e-01,\n",
      "         1.4615e+00,  5.4483e-01, -4.0937e-01, -4.3403e-01,  1.8275e+00,\n",
      "        -3.1348e-01,  5.4469e-01, -2.5643e-01, -1.6659e+00,  1.7619e+00,\n",
      "         1.0875e+00,  1.2256e+00,  1.3126e+00,  9.4571e-01, -4.0425e-01,\n",
      "         9.7487e-01,  5.2372e-01, -2.4667e-01,  1.4636e+00,  1.9808e-01,\n",
      "         3.6560e-01, -1.2618e-01,  1.2091e+00,  1.6888e-01, -3.3194e-01,\n",
      "        -3.1604e-01, -8.8200e-01,  1.4826e+00, -9.7396e-01,  1.4890e+00,\n",
      "         1.6974e+00, -8.1492e-01,  9.3601e-01, -1.4010e+00,  5.5445e-01,\n",
      "        -8.7787e-01, -3.9964e-01,  3.2829e-01,  6.5151e-01, -2.4316e-01,\n",
      "         9.6468e-01,  1.1005e+00, -4.5817e-01,  7.3000e-01,  1.2843e+00,\n",
      "         9.9958e-02,  1.0509e+00,  2.7769e-01,  1.2468e+00, -8.4509e-02,\n",
      "         1.1832e+00,  3.9825e-02, -6.2028e-01, -1.1149e+00,  1.0095e+00,\n",
      "         1.2789e+00,  7.1910e-01,  1.2329e+00, -5.4907e-01, -9.2781e-01,\n",
      "         7.0935e-01, -7.9145e-01,  1.2964e+00,  1.1865e+00,  1.7870e+00,\n",
      "        -4.4338e-01,  5.7930e-01,  1.8001e-01, -1.4640e+00,  4.0916e-01,\n",
      "        -9.8748e-01, -8.6795e-02,  1.5707e+00, -3.1613e-01, -3.6647e-01,\n",
      "         1.1661e+00,  2.6075e-01,  1.5539e+00, -9.8121e-01,  1.4665e+00,\n",
      "        -2.1876e-01,  8.1020e-01,  1.8546e+00, -1.4988e-01,  1.1734e-01,\n",
      "         9.2945e-01,  2.9455e-01,  1.0983e+00, -7.5200e-01, -8.2301e-01,\n",
      "         6.9018e-01, -1.1504e+00,  1.1765e+00, -9.6073e-01, -1.2053e+00,\n",
      "        -8.8442e-01, -5.6788e-01,  1.1335e+00, -3.2093e-01, -7.1361e-01,\n",
      "         1.1220e+00, -4.2796e-01,  1.6160e+00,  1.4159e+00,  3.2731e-01,\n",
      "         9.9334e-02,  7.4840e-01, -4.3162e-01, -5.9208e-01, -4.8068e-01,\n",
      "        -1.1396e-01, -3.0549e-01, -9.0022e-01,  3.7152e-01, -3.1887e-01,\n",
      "        -1.2246e+00, -7.6393e-01,  4.7923e-01, -9.1393e-01, -6.7876e-01,\n",
      "        -5.7567e-01, -1.2653e+00,  5.3300e-01, -8.7161e-02], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0228, -0.0108,  0.0094],\n",
      "          [ 0.0190,  0.1936,  0.0175],\n",
      "          [ 0.0886,  0.1106,  0.0539]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0280,  0.0889, -0.0113],\n",
      "          [ 0.0748,  0.3087,  0.0727],\n",
      "          [-0.0015,  0.0464,  0.0678]]],\n",
      "\n",
      "\n",
      "        [[[-0.1253, -0.0791, -0.0947],\n",
      "          [-0.0870,  0.0066, -0.0835],\n",
      "          [-0.0961, -0.0759, -0.0604]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0391,  0.0313,  0.0313],\n",
      "          [ 0.0187,  0.3106,  0.0299],\n",
      "          [ 0.0344,  0.0398,  0.0255]]],\n",
      "\n",
      "\n",
      "        [[[-0.0829, -0.2055, -0.0470],\n",
      "          [-0.1397,  0.2251, -0.0395],\n",
      "          [-0.0540, -0.0011, -0.0072]]],\n",
      "\n",
      "\n",
      "        [[[-0.1174, -0.0458, -0.1329],\n",
      "          [-0.0478,  0.7905, -0.0814],\n",
      "          [-0.1381, -0.0553, -0.1214]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.9.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.7966748476028442\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.7904508113861084\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.1.1.weight\n",
      "Weights: tensor([0.5250, 1.7151, 3.2216, 0.5674, 4.3309, 0.5055, 1.8063, 1.0272, 1.0621,\n",
      "        0.6975, 2.7806, 0.7727, 0.9472, 0.6514, 0.5760, 1.1489, 0.5135, 0.8056,\n",
      "        0.9966, 1.1238, 1.2854, 0.3494, 2.4143, 0.9230, 1.3578, 1.0195, 0.6271,\n",
      "        0.4953, 0.8441, 0.5718, 0.8020, 1.0234, 1.4853, 1.8625, 1.0375, 0.5596,\n",
      "        1.9328, 0.6923, 1.1891, 0.6960, 1.5010, 1.6797, 0.3971, 0.6800, 0.6809,\n",
      "        1.2867, 0.9515, 8.4395, 1.7885, 0.3232, 0.7655, 0.5712, 1.0026, 0.5237,\n",
      "        0.8089, 3.0344, 0.7394, 0.6424, 0.6825, 0.8533, 0.8906, 1.7530, 1.1866,\n",
      "        0.5582, 1.2391, 0.6638, 1.4737, 0.3957, 1.2195, 1.7494, 1.0701, 1.4387,\n",
      "        0.5325, 0.9158, 1.1889, 0.7995, 0.8170, 0.7805, 2.0655, 1.4929, 1.5388,\n",
      "        1.2552, 2.1766, 1.2576, 0.9573, 0.8131, 1.0943, 0.9496, 0.7426, 2.0734,\n",
      "        0.6910, 1.2389, 1.5607, 1.2827, 1.7584, 1.3459, 0.7398, 0.9569, 1.6798,\n",
      "        1.1476, 0.8811, 1.2608, 1.0766, 0.9917, 4.0969, 1.1590, 0.8488, 0.6353,\n",
      "        1.4974, 1.2611, 0.4454, 1.4890, 1.7309, 0.9885, 1.2747, 0.9531, 0.7768,\n",
      "        1.0172, 0.6285, 0.4626, 1.0363, 0.9837, 1.2626, 1.1193, 1.8655, 1.7304,\n",
      "        1.0056, 1.3073, 0.4204, 0.4604, 0.4863, 0.4441, 2.1229, 0.4076, 0.4887,\n",
      "        1.4396, 0.4762, 1.6909, 1.5860, 1.5380, 0.4820, 1.0675, 1.2138, 1.0445,\n",
      "        1.0641, 3.0025, 0.5554, 0.5240, 1.0550, 1.5556, 0.5586, 0.5777, 1.3192,\n",
      "        1.4976, 0.9033, 1.2041, 1.4747, 0.7504, 0.5227, 0.5389, 1.3042, 2.2231,\n",
      "        2.1372, 0.5230, 1.4147, 0.9392, 1.7440, 0.4671, 1.8456, 1.8573, 1.3550,\n",
      "        1.4423, 1.6955, 1.1662, 0.6212, 0.7896, 1.3490, 1.5940, 0.6285, 0.6281,\n",
      "        1.0369, 0.9740, 0.7555, 1.1835, 2.6697, 0.7729, 0.8725, 0.4744, 1.4037,\n",
      "        1.0649, 0.6038, 0.6316, 0.9634, 1.6472, 0.5770, 0.4242, 1.3836, 0.7175,\n",
      "        0.8767, 0.8166, 1.6490, 1.2102, 1.6702, 1.0320, 1.6088, 0.5287, 0.9783,\n",
      "        0.5096, 1.7424, 0.8664, 1.1594, 0.5787, 1.3340, 1.0098, 0.9782, 1.0640,\n",
      "        0.5847, 1.2206, 0.6660, 0.7545, 1.0870, 1.7881, 1.1706, 0.5670, 1.1876,\n",
      "        3.0093, 0.6785, 2.1137, 1.6654, 0.6100, 0.5079, 0.3850, 2.0281, 1.6395,\n",
      "        1.2067, 1.1961, 1.2009, 0.9631, 1.0606, 1.8718, 0.5062, 0.6887, 0.5091,\n",
      "        0.4049, 0.6541, 1.5026, 0.4508, 0.7197, 1.1099, 1.1601, 1.0472, 2.1934,\n",
      "        0.5028, 1.1402, 1.1743, 1.1967, 1.0975, 1.2024, 2.4396, 0.7191, 1.0968,\n",
      "        1.2785, 0.7483, 0.5162, 2.6821, 0.9195, 1.0889, 1.3723, 1.4052, 1.6314,\n",
      "        1.3695, 2.0667, 1.5056, 1.2573, 0.9509, 0.9825, 0.6892, 0.6290, 0.8388,\n",
      "        0.5815, 0.9973, 0.9889, 1.5381, 0.6784, 0.4449, 1.0903, 1.0661, 1.2361,\n",
      "        0.4753, 1.8047, 2.6610, 1.1997, 1.3166, 0.5583, 0.6332, 1.9280, 0.7534,\n",
      "        1.0215, 1.3988, 0.6149, 1.5088, 1.4614, 1.0157, 1.4578, 1.5047, 0.5565,\n",
      "        1.0940, 0.8774, 1.8352, 0.5443, 2.3571, 0.4837, 1.0862, 0.6299, 2.2598,\n",
      "        1.0042, 0.6761, 1.4077, 0.7926, 0.5275, 0.7669, 0.5049, 1.6025, 1.8200,\n",
      "        2.3097, 0.9298, 1.1379, 0.5101, 0.6460, 0.9042, 0.5731, 1.5992, 1.6405,\n",
      "        0.6240, 0.9097, 2.3338, 0.5235, 2.9395, 0.4093, 1.4009, 0.5956, 0.7553,\n",
      "        1.0905, 0.5095, 1.2821, 1.3804, 1.0181, 0.8931, 0.4012, 1.5412, 1.1034,\n",
      "        2.3177, 1.5337, 0.4228, 0.5548, 0.5022, 0.5225, 1.6676, 0.5847, 1.0184,\n",
      "        1.4110, 0.9656, 1.9720, 1.0745, 0.8857, 0.7918, 3.6490, 0.8842, 0.4553,\n",
      "        0.6473, 1.1950, 1.9238, 0.3574, 0.6459, 0.5209, 0.3875, 0.6921, 1.2324,\n",
      "        1.1098, 0.4079, 0.7759, 1.2701, 1.2571, 0.5313], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.1.1.bias\n",
      "Weights: tensor([-1.8232e-01, -3.5230e+00, -3.4527e+00,  1.3376e+00, -4.9679e+00,\n",
      "         1.8277e+00, -2.7361e+00, -1.7246e-01, -1.4002e+00, -8.5535e-01,\n",
      "        -3.1674e+00, -1.9495e-01, -1.4121e-01,  1.7991e+00,  1.2190e+00,\n",
      "        -1.1625e+00,  1.6339e+00, -4.5809e-01, -1.7331e-01, -1.3993e+00,\n",
      "        -5.5476e-01,  4.0669e+00, -2.2389e+00, -1.3050e+00,  3.1525e-01,\n",
      "        -3.1410e-01,  3.7858e-01,  5.0899e-02, -1.5023e+00,  6.1377e-01,\n",
      "        -1.4918e+00, -4.3500e-01, -4.7019e-01, -2.3914e+00, -2.6103e-01,\n",
      "         1.6652e+00, -1.1773e+00,  3.6893e-01, -5.5615e-01,  1.5619e-01,\n",
      "        -4.8105e-01, -3.2978e+00,  7.3339e-02,  1.3489e-01, -1.5201e-01,\n",
      "        -3.1965e+00, -2.0774e-01, -4.0275e+00, -1.8106e+00,  7.1763e-01,\n",
      "        -1.4286e-01,  3.7352e-01, -7.2528e-02, -2.9680e-01,  3.1689e-01,\n",
      "        -3.5497e+00,  5.6167e-03,  5.2743e-02,  2.6852e+00,  1.1892e-02,\n",
      "        -8.6113e-02, -1.4669e+00, -2.3282e+00,  1.7919e+00, -2.1374e+00,\n",
      "         9.9770e-02, -2.1418e+00,  2.4123e-01, -5.8749e-01, -1.9647e+00,\n",
      "        -3.9463e-01, -4.5058e-01,  1.7948e+00, -9.7429e-01, -6.5483e-01,\n",
      "         1.7837e-01, -6.9834e-01, -1.2827e+00, -2.3446e+00, -1.3156e+00,\n",
      "        -2.4653e+00, -1.1085e+00, -2.8875e+00, -1.4639e+00, -1.5902e+00,\n",
      "         1.0764e+00, -1.9262e-01, -1.7722e-01,  1.5278e-01, -1.9297e+00,\n",
      "        -1.4211e-01, -2.4701e+00, -1.4170e+00, -1.7266e-01, -1.0425e+00,\n",
      "        -7.9772e-01, -3.3385e-01, -8.4322e-01, -7.3235e-01, -4.8604e-01,\n",
      "         3.4075e-02, -6.9328e-01, -9.6762e-01, -2.9107e-01, -1.6932e+00,\n",
      "        -4.1696e-01,  3.2968e-01, -4.5411e-01, -2.6586e+00, -9.8221e-01,\n",
      "         1.1800e-01, -1.5409e+00, -1.8840e+00, -3.0280e-01,  3.8522e-02,\n",
      "        -1.0117e+00, -4.2868e-01, -5.9629e-01,  4.0847e-01,  4.3905e-01,\n",
      "        -1.3268e-01, -3.7926e-01,  3.4895e-01, -1.3188e+00, -1.9316e+00,\n",
      "        -1.5840e+00, -4.4183e-01, -2.6085e-01,  2.0353e+00,  2.2017e+00,\n",
      "         1.3488e-01,  3.8959e-01, -1.1856e+00,  4.0021e-01,  1.6693e+00,\n",
      "        -1.1693e+00,  2.5059e+00, -3.9257e+00, -1.2287e+00, -1.2377e+00,\n",
      "         1.0965e+00, -1.0254e+00, -7.6103e-01, -3.1492e-02, -4.2883e-01,\n",
      "        -4.0493e+00,  1.5768e+00,  2.5867e+00, -2.8798e-01, -5.0214e-01,\n",
      "         5.4002e-01,  6.7227e-01, -9.7163e-01, -8.3220e-01, -5.8125e-01,\n",
      "        -2.6138e+00, -8.4142e-01, -3.5902e-01,  8.1660e-01,  1.1970e+00,\n",
      "        -4.9647e-01, -2.6900e+00, -3.4175e+00,  1.1478e+00, -9.3168e-01,\n",
      "        -2.4779e+00, -1.1218e+00,  2.2233e-01, -3.6104e+00, -1.8560e+00,\n",
      "        -1.1155e+00, -1.3427e+00, -1.2132e+00, -5.0707e-01, -2.6819e-01,\n",
      "        -7.1653e-01, -3.5859e-01, -1.5966e+00,  2.8434e-01,  2.7399e-01,\n",
      "        -1.0379e+00, -4.2322e-01, -4.0357e-01, -9.3672e-01, -3.7877e+00,\n",
      "        -3.0166e-01, -8.3538e-02,  2.9280e-01, -9.6712e-01, -3.1921e+00,\n",
      "         1.5991e+00, -1.6884e-01,  3.3759e-01, -1.0033e+00,  3.8241e-01,\n",
      "         2.7753e+00, -5.0461e-01, -3.4836e-01, -1.2009e-01, -9.3318e-01,\n",
      "        -2.8873e+00, -1.6793e+00, -1.2261e+00, -4.8646e-01, -1.9311e+00,\n",
      "         5.6711e-01, -2.8732e-01,  2.2662e+00, -1.3902e+00,  7.4449e-01,\n",
      "        -1.2861e+00,  1.6783e+00, -4.0211e-01, -2.5468e-01, -2.8798e-01,\n",
      "        -1.5633e+00,  1.5310e+00, -4.8541e-01,  3.4600e-01,  1.1429e-01,\n",
      "        -1.2303e+00, -4.5774e+00,  4.4684e-01,  4.4062e-01, -2.3319e-01,\n",
      "        -3.1478e+00, -1.1458e+00, -4.0469e+00, -1.2259e+00,  8.6267e-01,\n",
      "         6.5120e-01,  1.4736e+00, -4.2855e+00, -4.8857e+00, -9.3563e-01,\n",
      "        -1.5110e+00, -7.6495e-01, -1.4133e+00, -1.0504e+00, -1.7936e+00,\n",
      "         2.0565e+00, -3.4389e-01,  2.1341e+00,  2.0642e+00,  3.5084e-01,\n",
      "        -9.6963e-01,  7.1680e-01, -5.5866e-01, -6.2489e-01,  3.0970e-01,\n",
      "        -2.8006e-01, -5.8275e+00,  2.5934e+00,  1.3509e-01, -1.0744e+00,\n",
      "        -4.2471e-01, -2.5211e-01,  3.7750e-01, -2.6480e+00,  1.2402e+00,\n",
      "         1.5800e-01, -1.4470e+00, -4.7699e-01,  1.7420e+00, -2.4828e+00,\n",
      "         1.3865e-01, -3.2556e-01, -2.5367e+00, -1.0890e+00, -1.7630e+00,\n",
      "        -6.3041e-01, -1.6931e+00, -1.1403e+00, -7.4301e-01, -9.0488e-01,\n",
      "        -1.9815e-01, -1.3956e-01,  6.0863e-01,  2.3374e-01,  2.0154e+00,\n",
      "        -1.6331e-02, -1.1832e+00, -1.3919e+00, -5.3566e-02,  6.1461e-01,\n",
      "        -1.1214e+00, -2.5208e+00,  2.5998e-01,  2.3767e+00, -1.3270e+00,\n",
      "        -2.8912e+00, -1.4201e+00, -6.9705e-01,  1.3652e+00,  1.6491e+00,\n",
      "        -4.7187e-01,  3.9201e-01, -1.0859e+00, -8.0448e-01,  4.5124e-01,\n",
      "        -8.9680e-01, -7.2596e-01, -7.5460e-01, -1.4828e+00, -8.5318e-01,\n",
      "         1.3679e+00, -2.9146e-01, -3.9049e-01, -1.4426e+00,  2.5848e-01,\n",
      "        -4.8758e+00,  1.8169e+00, -1.1325e+00,  3.4561e-01, -1.7861e+00,\n",
      "        -3.8364e-01,  1.6693e+00, -6.0267e-01, -8.7105e-01,  2.5471e-01,\n",
      "         1.3181e-02,  4.1059e-01, -2.1264e+00, -1.9110e+00, -2.9541e+00,\n",
      "        -1.1355e+00, -4.1122e-01,  1.8335e+00, -1.5078e+00, -2.0221e-01,\n",
      "         1.9257e+00, -3.7638e+00, -1.0537e+00,  2.3011e-01,  2.1461e-02,\n",
      "        -2.0711e+00,  1.1290e+00, -2.0932e+00,  2.8662e-01, -4.8219e-01,\n",
      "         1.3440e+00,  1.9015e+00,  6.2811e-01,  2.5538e+00, -5.8639e-01,\n",
      "        -1.2281e+00, -1.1724e+00,  4.4286e-01,  3.5739e-01, -5.2951e-01,\n",
      "        -6.1469e-01, -1.7704e+00, -8.9433e-01,  1.7648e-01,  2.8165e-01,\n",
      "         2.7764e+00,  1.4646e-01, -1.2034e+00, -4.7363e-01, -8.9330e-01,\n",
      "        -1.3469e+00, -1.4399e+00, -1.7488e+00, -1.9003e-01,  2.8347e-01,\n",
      "        -2.6900e-01, -3.5838e+00,  6.8681e-01,  2.3002e-01,  2.6737e-02,\n",
      "        -4.1083e-01, -4.5345e+00,  1.4432e+00,  3.2285e-02,  5.8610e-01,\n",
      "         1.0390e+00, -5.4471e-01, -2.1708e+00, -8.1303e-01,  2.7784e+00,\n",
      "        -1.0696e+00, -2.7113e+00, -7.2411e-01,  1.5415e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.2.weight\n",
      "Weights: tensor([[[[-0.0983]],\n",
      "\n",
      "         [[ 0.1338]],\n",
      "\n",
      "         [[ 0.0957]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         [[ 0.0304]],\n",
      "\n",
      "         [[ 0.0458]]],\n",
      "\n",
      "\n",
      "        [[[-0.1257]],\n",
      "\n",
      "         [[-0.0734]],\n",
      "\n",
      "         [[ 0.0144]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0697]],\n",
      "\n",
      "         [[ 0.0113]],\n",
      "\n",
      "         [[ 0.0631]]],\n",
      "\n",
      "\n",
      "        [[[-0.0872]],\n",
      "\n",
      "         [[-0.0151]],\n",
      "\n",
      "         [[ 0.0985]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0075]],\n",
      "\n",
      "         [[ 0.0266]],\n",
      "\n",
      "         [[ 0.0409]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0464]],\n",
      "\n",
      "         [[-0.0671]],\n",
      "\n",
      "         [[-0.0978]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0663]],\n",
      "\n",
      "         [[-0.0609]],\n",
      "\n",
      "         [[ 0.0414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1015]],\n",
      "\n",
      "         [[ 0.0631]],\n",
      "\n",
      "         [[ 0.0344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1766]],\n",
      "\n",
      "         [[ 0.0023]],\n",
      "\n",
      "         [[-0.0054]]],\n",
      "\n",
      "\n",
      "        [[[-0.0338]],\n",
      "\n",
      "         [[ 0.2749]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1361]],\n",
      "\n",
      "         [[-0.0468]],\n",
      "\n",
      "         [[ 0.0297]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 384, 1, 1])\n",
      "\n",
      "Layer: features.9.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.0252841711044312\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.0172741413116455\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.3.weight\n",
      "Weights: tensor([4.0139, 1.0381, 4.9999, 1.5891, 5.1128, 1.8994, 1.6986, 1.5771, 4.7695,\n",
      "        2.9778, 2.6517, 3.1057, 1.3664, 3.1281, 3.5239, 3.9334, 4.1106, 2.2833,\n",
      "        3.6815, 1.7932, 1.6130, 4.5159, 1.2931, 3.0917, 1.9548, 4.0787, 3.0074,\n",
      "        4.0454, 1.2622, 1.3055, 3.3019, 1.2488, 1.6542, 3.7581, 1.0676, 2.9645,\n",
      "        2.0916, 1.7270, 4.1136, 1.4224, 1.9086, 1.3162, 1.2018, 1.1067, 3.1520,\n",
      "        5.1115, 1.7988, 3.9100, 1.5210, 1.8581, 2.7534, 1.2647, 1.1804, 1.1914,\n",
      "        1.9094, 2.6008, 2.0109, 3.4761, 1.4089, 4.6844, 2.0796, 1.5178, 2.1971,\n",
      "        1.4005], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.9.conv.3.bias\n",
      "Weights: tensor([-8.4964e-07, -2.2777e-06,  3.0347e-07, -1.2773e-06,  6.7043e-07,\n",
      "         7.8253e-08,  1.1301e-06, -2.2724e-06,  1.5217e-07,  2.7333e-07,\n",
      "         4.4017e-08, -8.5987e-08, -2.9115e-07,  1.6596e-06, -5.8144e-07,\n",
      "        -7.3607e-07,  3.2431e-07,  1.2212e-06, -2.1649e-07, -5.2412e-07,\n",
      "         1.3040e-06, -3.8831e-07, -1.3338e-06,  4.6735e-08, -4.5250e-07,\n",
      "        -4.4467e-07, -4.5450e-07,  1.4347e-06,  1.4358e-06,  1.6739e-06,\n",
      "        -3.2338e-07,  1.6206e-06,  5.3682e-07,  5.4699e-07, -1.3205e-06,\n",
      "        -3.5321e-07,  6.7596e-07,  5.4651e-08,  1.0551e-06, -3.8971e-07,\n",
      "         7.2752e-07, -1.5838e-06, -1.6754e-06,  4.6236e-07, -1.0805e-06,\n",
      "        -6.5832e-07,  2.0918e-07,  8.0463e-08, -4.4652e-08, -1.9199e-06,\n",
      "        -3.8964e-07, -1.9357e-07, -4.9755e-07, -1.5784e-06,  3.1265e-07,\n",
      "         7.1842e-07, -1.0249e-06, -4.8917e-07, -3.6831e-07,  6.5335e-07,\n",
      "         6.6431e-07, -1.1618e-06,  6.8385e-07, -1.7435e-08], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.9.conv.3.output_quantizers.0.min\n",
      "Weights: -24.813220977783203\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.9.conv.3.output_quantizers.0.max\n",
      "Weights: 31.06067657470703\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0062]],\n",
      "\n",
      "         [[ 0.0600]],\n",
      "\n",
      "         [[-0.0239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1140]],\n",
      "\n",
      "         [[-0.1440]],\n",
      "\n",
      "         [[ 0.0252]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2051]],\n",
      "\n",
      "         [[ 0.0558]],\n",
      "\n",
      "         [[ 0.2291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0085]],\n",
      "\n",
      "         [[-0.0322]],\n",
      "\n",
      "         [[ 0.0350]]],\n",
      "\n",
      "\n",
      "        [[[-0.0122]],\n",
      "\n",
      "         [[-0.0990]],\n",
      "\n",
      "         [[ 0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1174]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         [[ 0.0183]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0288]],\n",
      "\n",
      "         [[-0.0034]],\n",
      "\n",
      "         [[-0.1387]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0013]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         [[ 0.0273]]],\n",
      "\n",
      "\n",
      "        [[[-0.0841]],\n",
      "\n",
      "         [[-0.1137]],\n",
      "\n",
      "         [[-0.1486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[ 0.0771]],\n",
      "\n",
      "         [[ 0.0347]]],\n",
      "\n",
      "\n",
      "        [[[-0.0393]],\n",
      "\n",
      "         [[-0.1354]],\n",
      "\n",
      "         [[-0.0777]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[-0.0206]],\n",
      "\n",
      "         [[ 0.0124]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.10.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.7217694520950317\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.7161306142807007\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.0.0.input_quantizers.0.min\n",
      "Weights: -30.183277130126953\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.0.0.input_quantizers.0.max\n",
      "Weights: 31.246427536010742\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.0.1.weight\n",
      "Weights: tensor([0.8384, 0.9399, 0.5547, 1.1175, 1.3795, 1.5326, 0.9934, 0.9072, 0.9317,\n",
      "        1.0473, 0.9409, 1.0078, 0.6418, 0.8856, 1.1907, 1.1189, 1.0533, 1.5419,\n",
      "        1.1749, 0.9897, 1.5076, 1.3177, 0.4890, 1.1002, 1.1330, 0.9449, 1.2394,\n",
      "        0.4413, 0.3597, 1.2642, 1.0619, 1.1887, 1.0832, 0.6682, 0.7698, 1.4585,\n",
      "        0.7542, 1.1843, 0.9538, 1.2725, 1.3898, 1.2297, 1.1023, 1.1041, 0.7631,\n",
      "        0.7608, 1.3335, 1.3548, 1.2222, 1.2096, 1.0968, 1.1671, 1.1259, 1.3498,\n",
      "        0.8837, 1.2118, 1.1696, 0.7441, 0.9355, 0.9170, 1.5154, 1.6156, 1.0900,\n",
      "        1.2188, 0.6000, 1.0866, 1.1620, 1.5096, 1.3313, 0.6033, 1.2619, 1.2819,\n",
      "        1.3805, 0.7039, 0.5105, 1.2047, 1.1455, 1.8528, 0.6513, 1.1302, 0.7940,\n",
      "        1.0581, 0.5113, 1.3989, 1.0269, 0.7269, 1.1020, 1.4804, 0.6600, 1.2555,\n",
      "        1.7417, 1.0856, 0.9829, 0.9811, 1.1449, 1.1379, 1.0570, 1.0783, 1.2326,\n",
      "        1.2378, 1.2558, 0.8216, 1.1531, 0.9549, 1.2290, 1.1715, 1.0043, 1.2913,\n",
      "        1.4780, 0.7191, 1.0960, 1.1234, 1.0809, 1.4230, 1.2894, 0.4606, 1.1341,\n",
      "        1.4085, 1.0552, 1.1025, 1.3915, 1.4144, 1.0604, 0.8302, 0.8846, 1.1015,\n",
      "        1.5155, 0.8433, 1.0699, 1.1959, 1.0386, 1.0981, 1.1764, 0.5950, 1.3334,\n",
      "        0.5970, 1.1373, 0.8371, 1.1744, 1.2204, 1.0524, 1.2177, 1.2127, 1.2188,\n",
      "        1.3542, 0.4120, 1.2541, 1.1766, 1.1333, 0.7530, 1.0914, 1.1368, 1.0235,\n",
      "        1.1399, 1.1696, 1.0876, 1.1291, 0.4810, 1.0469, 0.6525, 0.6734, 1.1238,\n",
      "        1.1117, 1.1517, 0.5864, 1.1348, 1.2990, 0.8471, 0.6965, 1.1984, 1.3771,\n",
      "        0.8853, 1.2780, 1.0487, 1.2856, 1.3035, 0.9933, 0.7980, 1.3828, 0.9243,\n",
      "        1.2252, 1.1731, 0.8978, 1.1817, 1.2306, 1.2852, 1.0191, 1.0565, 1.1033,\n",
      "        1.0912, 0.6048, 1.1122, 1.0465, 1.0660, 1.0823, 0.9592, 1.1019, 1.2957,\n",
      "        1.5923, 1.2002, 1.5722, 1.1155, 0.6631, 0.6337, 0.4827, 1.1310, 0.6711,\n",
      "        1.1487, 0.4797, 0.4482, 0.9806, 1.1786, 0.7987, 1.3117, 1.0882, 1.0680,\n",
      "        1.0968, 0.6804, 0.9365, 0.8631, 0.7153, 1.0675, 0.6184, 1.0284, 0.9462,\n",
      "        1.2846, 0.9748, 0.9797, 1.1769, 1.0453, 0.9985, 1.7365, 1.2432, 1.3276,\n",
      "        1.1839, 0.6818, 1.2092, 1.2642, 1.3371, 1.2011, 1.6665, 0.9690, 1.1857,\n",
      "        1.1576, 1.2386, 0.6297, 0.8453, 0.6006, 0.9092, 0.8416, 0.9960, 1.2798,\n",
      "        1.0550, 1.2346, 0.6056, 1.2746, 1.2245, 1.3714, 0.5629, 1.1983, 0.9385,\n",
      "        1.5302, 1.0740, 0.7351, 1.1718, 1.1694, 1.1967, 1.0154, 0.9992, 1.0614,\n",
      "        1.2135, 1.2285, 0.5267, 1.1548, 0.5553, 1.1178, 1.3473, 1.1415, 0.8713,\n",
      "        0.7438, 1.2333, 0.8234, 1.5388, 1.0992, 1.2565, 1.0869, 1.2526, 0.7076,\n",
      "        0.8800, 0.8345, 1.4145, 1.1505, 1.2325, 1.3512, 1.1314, 1.3317, 1.2423,\n",
      "        1.0524, 0.9157, 1.1870, 0.4813, 0.9691, 1.1488, 1.2995, 1.6443, 1.1962,\n",
      "        1.0267, 0.9792, 1.0511, 0.9022, 1.1920, 1.0522, 1.3035, 0.8738, 1.0344,\n",
      "        1.0051, 0.8244, 1.0912, 1.0923, 1.0979, 0.9333, 0.8380, 1.1813, 1.0978,\n",
      "        0.7890, 0.4129, 1.1087, 0.9218, 0.9741, 0.8633, 1.0583, 0.7335, 1.1026,\n",
      "        1.0656, 0.9542, 1.0512, 1.1115, 0.4301, 1.1184, 0.4976, 1.0783, 1.1294,\n",
      "        1.1074, 0.9617, 1.0073, 1.4481, 1.0598, 1.0917, 1.1016, 0.9082, 0.9092,\n",
      "        0.5274, 0.3821, 1.2110, 1.2183, 1.0480, 1.0611, 1.1408, 1.1081, 0.5238,\n",
      "        1.6584, 1.1637, 1.2739, 1.1152, 1.1818, 0.7285, 1.1121, 0.8760, 1.0032,\n",
      "        0.9138, 1.1871, 1.2944, 1.1747, 1.7334, 1.1465, 1.3166, 0.6650, 0.4866,\n",
      "        1.0419, 0.8960, 1.1853, 0.9377, 1.1187, 0.7011], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.0.1.bias\n",
      "Weights: tensor([ 1.0480e+00,  9.1100e-01,  1.0231e+00, -4.3094e-01, -3.1793e-01,\n",
      "        -2.4482e-01, -6.3643e-01,  7.1579e-01,  7.5852e-01, -1.1583e+00,\n",
      "        -1.0918e+00, -1.0775e+00,  1.1366e+00, -1.5093e+00, -4.3303e-01,\n",
      "         4.7133e-01, -5.4242e-01, -5.1453e-01, -7.5186e-01, -9.5022e-01,\n",
      "        -1.2393e+00, -4.9089e-01,  1.8141e+00, -4.1869e-01, -5.0568e-01,\n",
      "        -8.1444e-01, -4.0511e-01,  1.2887e+00,  1.6205e+00, -2.4891e-01,\n",
      "        -7.5603e-01,  1.8523e-01, -1.6006e-01,  9.7984e-01,  9.9763e-01,\n",
      "        -5.7607e-01,  8.7795e-01, -5.8504e-01,  5.7509e-01, -2.9419e-01,\n",
      "        -1.6286e-01, -1.2389e+00, -3.6012e-01,  2.6708e-01,  9.0266e-01,\n",
      "         1.3664e+00, -9.7553e-01, -4.3327e-01, -4.6591e-01, -2.1081e-01,\n",
      "        -2.3300e-01,  6.9378e-01, -9.5021e-01, -3.6284e-01,  8.3826e-01,\n",
      "         5.7266e-02, -4.9500e-01,  1.6921e+00, -6.6958e-01,  1.0112e+00,\n",
      "        -1.0758e+00, -1.3546e+00, -6.3787e-01,  7.9305e-01,  1.3816e+00,\n",
      "        -6.4807e-01, -1.6884e-02, -7.7820e-01, -1.1608e-01,  1.2878e+00,\n",
      "        -6.6105e-01, -7.0807e-01, -2.2295e+00,  1.3137e+00,  1.5561e+00,\n",
      "         6.1171e-02, -4.9403e-01,  1.4905e+00,  1.5379e+00, -6.3293e-01,\n",
      "         1.2202e+00, -6.3352e-01,  1.1790e+00, -4.2638e-01,  1.1065e+00,\n",
      "         1.0695e+00, -2.7709e-01,  1.9769e-02,  9.2078e-01, -1.2144e+00,\n",
      "        -3.3144e+00, -1.6426e+00, -6.6347e-01, -9.8945e-01,  6.1236e-01,\n",
      "         1.0577e-01,  3.0318e-01, -8.9757e-01,  1.2113e-01,  2.1264e-01,\n",
      "         1.3534e-01,  9.1065e-01, -5.0761e-01,  1.3526e+00, -4.6380e-01,\n",
      "        -8.9371e-01, -1.3725e+00, -7.6697e-02, -3.1684e-01,  8.1234e-01,\n",
      "         3.0665e-01, -6.7090e-01,  3.0784e-02, -6.3646e-01,  3.0907e-01,\n",
      "         1.3234e+00,  1.3436e-01, -4.0942e-01,  2.7782e-01, -3.9590e-01,\n",
      "        -8.2225e-01, -1.8897e+00,  1.3781e+00,  1.8407e+00, -1.2201e-01,\n",
      "         3.0068e-01, -5.7808e-01,  1.4141e+00, -4.4749e-01, -4.5097e-01,\n",
      "         6.7319e-01,  7.1802e-01, -3.5413e-01,  1.4386e+00, -3.5395e-03,\n",
      "         2.0827e+00, -3.1263e-01,  1.3675e+00,  4.2472e-01,  3.3647e-01,\n",
      "         4.5722e-01, -1.1283e+00, -6.5970e-01, -6.8614e-01, -3.3853e-01,\n",
      "         1.1448e+00, -1.0623e+00, -2.4222e-01, -7.0199e-01,  1.3730e+00,\n",
      "        -2.3285e-02, -8.0778e-01,  5.0944e-01,  9.3612e-02, -2.6624e-01,\n",
      "        -2.5299e-01, -2.6870e-01,  1.5364e+00, -1.2573e-01,  1.1872e+00,\n",
      "         1.2733e+00,  4.2364e-01,  3.6562e-01, -4.2439e-01,  1.7830e+00,\n",
      "         1.0978e+00,  4.0575e-05,  1.1003e+00,  1.1190e+00,  4.9664e-01,\n",
      "        -1.1227e+00,  8.1517e-01,  4.5914e-01,  8.5543e-01, -4.3175e-01,\n",
      "        -5.6873e-01,  1.1051e+00,  7.9963e-01, -4.3868e-02, -9.0335e-01,\n",
      "        -6.4453e-01, -1.4727e-01, -1.2596e+00, -3.3933e-02,  3.7932e-01,\n",
      "        -1.0317e+00, -9.4346e-01, -5.0353e-01,  2.2811e-01, -1.6485e-01,\n",
      "         1.4105e+00,  6.5726e-01, -5.8306e-01,  3.9866e-01, -9.2203e-01,\n",
      "         8.6619e-01, -4.2111e-01,  1.0400e-01, -1.3025e+00, -2.6060e-01,\n",
      "        -9.0598e-01,  5.2402e-01,  9.6730e-01,  1.3415e+00,  1.8230e+00,\n",
      "         1.7132e-01,  1.1101e+00,  2.3795e-01,  1.6230e+00,  1.7251e+00,\n",
      "         5.0618e-01,  1.3632e-01,  9.3957e-01, -9.5370e-01, -5.0050e-01,\n",
      "         3.4146e-01, -4.5077e-01,  1.1261e+00, -7.6565e-01,  9.5185e-01,\n",
      "         9.5123e-01, -4.5007e-01,  1.0905e+00, -7.3592e-01,  1.8993e+00,\n",
      "        -4.4336e-01,  1.0768e+00, -6.0922e-01,  2.7937e-01,  8.6479e-01,\n",
      "        -1.0926e+00, -6.6051e-02, -7.3178e-01,  4.1825e-01, -1.2517e+00,\n",
      "         1.5891e+00, -5.4501e-01, -6.1561e-01, -7.3093e-01,  3.7760e-02,\n",
      "        -7.0638e-01,  1.5996e+00, -6.7713e-02, -8.0189e-01, -9.7556e-01,\n",
      "         1.1268e+00,  1.0635e+00,  1.3705e+00, -7.4154e-01,  1.0914e+00,\n",
      "         5.5618e-01,  1.1354e+00, -7.1124e-01, -4.5994e-01,  1.0999e+00,\n",
      "        -8.4040e-01,  8.8211e-01, -9.3559e-02,  1.3953e+00,  1.0457e-01,\n",
      "         8.0885e-01,  1.6294e+00, -2.6126e-01,  1.2471e+00, -8.3744e-01,\n",
      "        -2.2050e-01, -9.2337e-01, -9.0380e-01,  7.0204e-01, -6.6978e-01,\n",
      "        -5.5532e-01, -1.0569e+00,  1.4049e+00, -6.3144e-01,  1.1088e+00,\n",
      "        -2.8760e-02, -5.4089e-01, -8.7708e-01,  6.7200e-01,  1.2201e+00,\n",
      "         5.7736e-01, -4.7172e-01, -2.7782e-01, -2.6789e-01,  2.1465e-01,\n",
      "        -5.1630e-01,  1.1133e-01,  1.1517e+00,  8.5605e-01,  1.2005e+00,\n",
      "         1.1810e-01, -2.7912e-01, -4.3232e-01, -4.4129e-01, -5.8305e-01,\n",
      "        -6.1311e-01, -3.7357e-01,  3.3112e-01, -7.0520e-01, -7.8810e-01,\n",
      "         1.4800e+00, -6.3095e-01,  1.1133e-01, -3.1126e-01, -1.3207e+00,\n",
      "        -1.1588e-02,  4.3230e-01,  6.7008e-01, -1.3277e-01,  1.9187e+00,\n",
      "        -1.4521e-01,  7.1978e-01, -8.8925e-01,  1.1790e+00, -8.2598e-01,\n",
      "        -2.2596e+00,  5.1619e-01, -1.1306e+00, -8.5202e-02,  4.3400e-01,\n",
      "         1.3742e+00,  8.6796e-01,  6.9598e-02, -3.1875e-01,  1.1972e+00,\n",
      "         1.2787e+00, -2.0617e-01, -6.7190e-01, -1.0664e+00,  9.1266e-01,\n",
      "        -4.0725e-01,  9.0178e-01, -2.5362e-01, -1.0544e+00,  8.9853e-01,\n",
      "        -7.1402e-01,  6.9600e-02,  1.4364e+00, -1.5772e-01,  1.2248e+00,\n",
      "        -7.2673e-01, -1.1300e+00, -1.4456e+00, -5.9768e-01, -8.6821e-01,\n",
      "        -1.3768e+00,  1.1972e+00,  3.5325e-01,  7.1293e-02, -7.0335e-01,\n",
      "         9.6290e-01,  9.5984e-01,  1.3268e+00, -2.7872e-01,  1.4399e-01,\n",
      "         8.6268e-02, -4.1552e-01,  8.2340e-02,  3.7282e-01,  1.6087e+00,\n",
      "        -1.1896e+00,  3.0887e-03, -3.9219e-01,  9.6691e-01,  5.3129e-02,\n",
      "         8.7245e-01, -1.2251e+00, -8.0874e-01, -7.8129e-01,  7.3335e-01,\n",
      "        -6.8510e-01, -5.0933e-01,  5.2032e-02, -1.4730e+00,  7.0952e-01,\n",
      "         2.0388e-01,  8.9897e-01,  1.4309e+00,  5.1228e-01,  7.6007e-01,\n",
      "        -3.9373e-01, -1.2797e+00, -7.2417e-01,  1.0586e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.1.0.weight\n",
      "Weights: tensor([[[[-5.0462e-02, -8.0521e-02, -4.4498e-02],\n",
      "          [-7.8831e-02, -1.0647e-01, -9.5035e-02],\n",
      "          [-2.3903e-02, -1.1521e-01, -2.8724e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3492e-01,  9.2133e-02,  1.3120e-01],\n",
      "          [ 1.2560e-01, -3.2119e-01,  1.0872e-01],\n",
      "          [ 9.1903e-02,  5.9489e-02,  8.6197e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3387e-02,  1.0068e-02, -8.0975e-02],\n",
      "          [-1.8131e-01, -1.0268e-02,  2.4308e-01],\n",
      "          [ 8.4934e-02,  3.9660e-02, -1.1195e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.7331e-02, -6.3483e-02,  4.3272e-02],\n",
      "          [-2.8044e-01, -1.4931e-01,  1.7585e-01],\n",
      "          [-5.8480e-03,  8.0385e-02,  2.4625e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5204e-02, -1.6924e-01, -2.0029e-01],\n",
      "          [ 2.3787e-04,  7.2921e-03, -3.2232e-02],\n",
      "          [ 2.1134e-01,  1.8388e-01,  3.6585e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5433e-02, -3.3323e-02,  6.6884e-02],\n",
      "          [ 2.4483e-02, -2.1936e-01,  2.8432e-01],\n",
      "          [-2.7703e-02, -3.3312e-02,  8.4945e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.10.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.6296762228012085\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.6247568726539612\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.1.1.weight\n",
      "Weights: tensor([1.7614, 1.6871, 1.1576, 0.4178, 0.3668, 0.6751, 0.5607, 0.8781, 0.5108,\n",
      "        0.5102, 0.4349, 0.3057, 1.2037, 0.7762, 0.8918, 1.5237, 0.3631, 1.4866,\n",
      "        0.5743, 0.4291, 0.4249, 0.4924, 2.3656, 0.8607, 0.7765, 0.3943, 0.4464,\n",
      "        1.2093, 1.8385, 0.6160, 0.3606, 1.1642, 0.5425, 0.8887, 2.1860, 1.3354,\n",
      "        0.6677, 0.8909, 0.8414, 0.7061, 0.5730, 0.5126, 0.7654, 1.2494, 1.5467,\n",
      "        2.2573, 0.3069, 1.3278, 0.9817, 0.6854, 0.9751, 2.5580, 0.8472, 0.5439,\n",
      "        0.9930, 0.5059, 1.1905, 1.8208, 0.5213, 1.3834, 0.4591, 0.3631, 0.9015,\n",
      "        1.8618, 0.9453, 0.6491, 0.5251, 0.5246, 0.4967, 1.0607, 0.6128, 0.5595,\n",
      "        0.4276, 1.3858, 1.9333, 1.2296, 0.4177, 3.5417, 2.2067, 0.5838, 1.3065,\n",
      "        0.7236, 0.8670, 0.7349, 1.4403, 1.2818, 0.6165, 0.5712, 1.0169, 0.5080,\n",
      "        1.6019, 0.3966, 0.5661, 0.4357, 1.7129, 0.6774, 1.0401, 0.5489, 0.8569,\n",
      "        0.6075, 1.0026, 2.3664, 0.4662, 1.2174, 0.4573, 0.9819, 0.2240, 1.7046,\n",
      "        0.5624, 1.0747, 0.8531, 0.7428, 0.7443, 0.3447, 1.6445, 1.8935, 0.4500,\n",
      "        0.4442, 0.6693, 0.7167, 0.3469, 0.3812, 1.3417, 0.6511, 1.0356, 1.4150,\n",
      "        0.6482, 2.4499, 0.4540, 0.4395, 0.9187, 2.2150, 1.0337, 1.4784, 1.7377,\n",
      "        3.2860, 4.0820, 2.0404, 1.0147, 1.5940, 0.9528, 0.8673, 0.6145, 0.4177,\n",
      "        0.6106, 0.9277, 0.7096, 0.6651, 0.4406, 1.3287, 0.8397, 0.5755, 0.7921,\n",
      "        0.5817, 0.8323, 0.4578, 0.8028, 2.2233, 1.4028, 0.4592, 1.2169, 1.1915,\n",
      "        0.7067, 0.6845, 2.5505, 2.3601, 1.2598, 2.7937, 0.8400, 0.5815, 0.8559,\n",
      "        2.2343, 1.4837, 1.4562, 0.9501, 0.5136, 1.6370, 1.0740, 0.6846, 0.3389,\n",
      "        0.5704, 0.9707, 0.8493, 0.4765, 0.5150, 0.2990, 0.4007, 0.4331, 0.9604,\n",
      "        0.4945, 1.4331, 0.9433, 0.5505, 0.8302, 0.4058, 1.1412, 0.5068, 0.5946,\n",
      "        0.4317, 0.5418, 1.4065, 1.0523, 1.3346, 1.2406, 2.4884, 0.7088, 0.7158,\n",
      "        0.5470, 1.4518, 2.3038, 0.9102, 1.2784, 1.0223, 0.9356, 0.8287, 0.9568,\n",
      "        0.4726, 1.2251, 0.3936, 1.5607, 1.2539, 0.5232, 1.2281, 1.4891, 1.8972,\n",
      "        0.6147, 1.4989, 0.6862, 0.5139, 1.5037, 0.5017, 1.1765, 0.4935, 1.6346,\n",
      "        1.8916, 2.0998, 0.5462, 0.5679, 0.8774, 0.9058, 5.8928, 2.2332, 1.3655,\n",
      "        0.4084, 0.3697, 0.8527, 0.8767, 0.7666, 0.4644, 1.4847, 0.8334, 1.5123,\n",
      "        0.6198, 0.7915, 1.1592, 0.8427, 1.0924, 1.6457, 1.1716, 1.1529, 1.3337,\n",
      "        1.7588, 0.4166, 0.8679, 0.7547, 0.5159, 0.4478, 0.3791, 1.0316, 0.3782,\n",
      "        0.7044, 0.4730, 1.0922, 0.6267, 0.7726, 0.8741, 0.4771, 0.3772, 0.9587,\n",
      "        1.6150, 0.4477, 1.3165, 0.6400, 0.6630, 1.2495, 0.4525, 1.5891, 0.7609,\n",
      "        1.6170, 1.2426, 1.0182, 0.7587, 0.5192, 0.8857, 0.7185, 0.4775, 1.1074,\n",
      "        0.7799, 1.0701, 0.4471, 1.4327, 0.3702, 1.3999, 1.1818, 0.3679, 0.7785,\n",
      "        0.7361, 1.4514, 0.8860, 0.7037, 1.1287, 1.6277, 0.4362, 1.1576, 0.7804,\n",
      "        1.1923, 0.9519, 0.4216, 1.5048, 0.5090, 1.2164, 1.4044, 0.5780, 0.5660,\n",
      "        1.3160, 1.5327, 0.6888, 0.7063, 0.4934, 0.9712, 1.1012, 1.1052, 0.5099,\n",
      "        0.3681, 1.1572, 1.4916, 0.8299, 1.7649, 0.5282, 1.5708, 0.5164, 0.4149,\n",
      "        1.2241, 0.3932, 0.3951, 1.1179, 1.7539, 0.4608, 0.7356, 0.4380, 0.8522,\n",
      "        1.7900, 1.5523, 0.5549, 1.8362, 0.9211, 0.7782, 0.6179, 1.2762, 0.7728,\n",
      "        0.4722, 0.8785, 0.9086, 0.5489, 0.3975, 1.2287, 0.2735, 0.3865, 0.5136,\n",
      "        1.5447, 0.4289, 0.7720, 0.5232, 0.4507, 0.6515, 1.9110, 1.4198, 1.3732,\n",
      "        0.8834, 1.2761, 0.7271, 0.9455, 0.4022, 1.0764], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.1.1.bias\n",
      "Weights: tensor([-1.6860e+00, -1.9292e+00, -1.0530e+00,  2.1579e+00,  1.4332e+00,\n",
      "         8.8952e-02, -2.9376e-01, -6.7400e-01,  2.6178e-01,  2.2084e+00,\n",
      "         1.2912e+00,  1.5315e-01, -7.1289e-01, -5.4374e-01, -1.1077e+00,\n",
      "        -2.7512e+00,  3.5208e-01, -2.8462e+00, -5.1227e-01, -5.6360e-02,\n",
      "         1.8069e-01,  1.7270e-01, -7.2766e+00, -5.5100e-01, -9.9924e-01,\n",
      "         3.2930e-01,  1.9525e+00, -1.4202e+00, -3.2279e+00, -5.2274e-01,\n",
      "         1.8478e+00, -1.4266e+00, -1.1236e-01, -2.9600e-01, -2.3237e+00,\n",
      "        -3.7263e+00, -7.4676e-02, -6.7619e-01, -3.9197e-01, -2.1707e-01,\n",
      "         3.2730e+00, -1.7002e-01, -7.1433e-01, -1.6306e+00, -2.5696e+00,\n",
      "        -2.6193e+00,  8.7605e-01, -2.7480e+00, -1.8760e+00, -6.7134e-01,\n",
      "        -2.7471e+00, -5.4059e+00, -1.1645e+00,  1.3393e-02, -4.8009e-01,\n",
      "         2.8741e-01, -3.1684e+00, -2.3256e+00, -3.4360e-01, -1.2753e+00,\n",
      "         1.7439e-01,  5.0337e-01, -2.3370e+00, -1.6023e+00,  3.9177e-01,\n",
      "        -5.1098e-01,  1.7367e-01, -1.0810e-02,  9.6965e-01, -2.6689e-01,\n",
      "        -3.8232e-01,  2.2772e+00,  2.9117e+00, -1.2467e+00, -1.7391e+00,\n",
      "        -2.0135e+00,  1.1108e+00, -4.9742e+00, -1.9800e+00,  7.9088e-01,\n",
      "        -7.0062e-01, -3.8670e-01,  3.4695e-01, -3.5263e-01, -3.7685e-01,\n",
      "        -1.2722e+00, -1.6680e-03,  2.9553e-01, -3.7260e-01,  6.9386e-01,\n",
      "         2.7590e+00,  2.3266e+00, -3.4060e-01,  1.2175e-01, -3.1099e+00,\n",
      "        -2.1094e-01, -1.8176e+00, -8.7392e-01,  1.1185e-02,  3.0278e-02,\n",
      "        -2.0797e-01, -4.7940e+00,  2.0609e+00, -1.1177e+00,  9.0728e-01,\n",
      "        -9.3532e-01,  1.7453e+00, -3.5532e+00,  2.1270e+00, -8.1266e-01,\n",
      "        -4.1798e-01, -8.6945e-01, -6.8777e-01,  1.9473e+00, -1.1103e+00,\n",
      "        -1.5715e+00,  1.4915e+00,  1.2196e+00, -4.8230e-01, -9.1285e-01,\n",
      "         2.0954e-01,  1.9008e+00, -9.7766e-01,  1.4780e+00, -2.9057e+00,\n",
      "        -2.5121e+00, -3.9597e-01, -2.9617e+00,  1.5809e+00,  1.7344e+00,\n",
      "        -1.7792e-01, -5.2561e+00, -1.2538e+00, -1.6112e+00, -8.4341e-01,\n",
      "        -6.2242e+00, -1.7343e+00, -2.0180e+00, -2.4363e-01, -9.5824e-01,\n",
      "        -1.1717e+00, -6.4918e-02,  4.2947e-01,  2.4513e+00, -7.5598e-02,\n",
      "        -3.5480e-01, -1.3951e+00, -6.3412e-01,  1.8883e+00, -5.8158e-01,\n",
      "        -4.9390e-01, -6.0666e-01, -2.6852e-01,  5.7815e-02, -1.1450e+00,\n",
      "         9.9047e-02, -9.1434e-01, -2.7120e+00, -4.7730e+00,  6.1176e-01,\n",
      "        -3.4479e-01, -3.8060e-01, -2.4672e-01, -7.2907e-01, -2.7684e+00,\n",
      "        -2.5547e+00, -2.7793e+00, -5.6594e+00, -6.7149e-02,  1.1152e-01,\n",
      "        -1.6020e+00, -4.8618e+00, -6.3957e-01, -1.1704e+00, -1.3541e+00,\n",
      "         1.3908e-01, -1.1428e+00, -6.9268e-01,  2.3471e-01,  1.6234e+00,\n",
      "        -4.9405e-01, -9.7055e-01, -1.8001e+00,  1.1149e+00,  1.7137e+00,\n",
      "         1.9021e-01, -1.1008e-01,  1.3116e+00, -1.4179e+00,  7.8332e-02,\n",
      "        -1.2675e+00, -2.2253e-01, -6.6251e-01, -3.0017e-01,  5.1885e-02,\n",
      "        -8.8720e-01, -3.0543e-01,  2.0092e-01,  1.4921e-01,  5.3450e-01,\n",
      "        -3.6300e+00, -4.6544e-01, -1.5042e+00, -6.1189e-01, -4.0025e+00,\n",
      "        -5.8980e-01, -4.3559e-02,  2.7312e-01, -1.3228e+00, -3.2918e+00,\n",
      "        -6.2026e-01, -2.7267e+00, -6.5863e-01, -2.0089e+00, -1.4555e-01,\n",
      "        -1.0292e+00, -1.6427e-02, -1.4022e+00,  2.9716e-02, -1.0968e+00,\n",
      "        -1.2026e+00, -2.4008e-01, -7.6010e-01, -4.6562e-01, -2.7589e+00,\n",
      "         1.4444e-01, -4.2325e-01, -1.0442e+00,  1.9011e+00, -1.5382e+00,\n",
      "        -2.0001e-01, -2.2186e+00,  1.1160e+00, -5.9425e-01, -1.1197e+00,\n",
      "        -2.9211e+00, -7.3471e-02, -2.4868e-01, -1.9925e+00, -6.8507e-01,\n",
      "        -2.8308e+00, -2.2321e+00, -2.7519e+00,  2.6564e+00,  2.1406e-01,\n",
      "        -2.1709e-01,  2.0272e-01,  9.6139e-01, -2.2131e-01, -1.5494e+00,\n",
      "        -2.0824e-01, -1.0663e+00,  1.3765e-02, -6.6245e-01, -9.4454e-01,\n",
      "        -2.6533e-01, -1.2016e+00, -6.5767e-01, -5.5014e-01, -2.3487e-01,\n",
      "        -9.5682e-01, -1.8761e+00,  1.2738e-01,  3.0688e-02,  4.5622e-02,\n",
      "         8.0198e-01,  1.2725e-01,  4.2344e-01, -5.8125e-01,  1.1130e+00,\n",
      "        -7.1504e-01,  4.1446e-03, -5.9068e-01, -6.2118e-01,  3.8273e-01,\n",
      "        -1.0234e+00,  2.0015e+00,  1.7736e+00, -5.6943e-01, -1.8014e+00,\n",
      "         4.5359e-01, -1.8691e-01, -3.9602e-01, -4.7924e-01, -5.1838e-01,\n",
      "         1.8732e+00, -2.5176e+00,  4.6852e-01, -3.3864e+00, -8.6585e-01,\n",
      "        -2.1781e-01, -7.5760e-01,  1.0813e-01, -1.0849e+00, -3.4090e-01,\n",
      "         1.8533e+00, -2.4369e+00, -1.4579e-01, -1.3168e+00,  2.0141e-01,\n",
      "        -2.0152e+00,  2.7416e-01, -2.7210e+00, -1.4297e-01,  6.1430e-01,\n",
      "        -1.3741e+00, -1.9152e-01, -2.0366e+00, -1.2505e+00,  9.1348e-01,\n",
      "        -1.4997e+00, -2.5609e+00,  2.2006e-01, -1.2702e+00, -1.0339e+00,\n",
      "        -3.6549e+00, -1.8179e+00,  2.0999e+00, -4.7236e+00,  2.1428e+00,\n",
      "        -1.2482e+00, -1.7201e+00, -2.0599e-01, -1.9456e-01, -6.1703e-01,\n",
      "        -3.2048e-01, -1.1398e-01, -9.5324e-01, -4.1460e-01, -5.3052e-01,\n",
      "        -2.0352e+00, -1.7795e+00, -9.2434e-02,  1.3669e-01, -7.7642e-01,\n",
      "        -3.0362e+00, -1.4375e-01, -1.8707e+00,  1.3503e-01, -1.3054e+00,\n",
      "        -2.1628e-01,  9.8951e-02, -3.0878e-01,  5.4288e-01,  3.2816e+00,\n",
      "         9.1935e-01, -1.7921e+00,  1.1480e+00, -4.7884e-01,  3.4175e-01,\n",
      "         2.2155e-01, -2.1436e+00, -1.7722e+00,  4.9098e-01, -4.7889e+00,\n",
      "        -1.3480e+00, -1.0723e+00, -8.3306e-02, -2.4353e+00,  3.5074e-02,\n",
      "         1.3334e-01, -3.8055e-01, -1.3414e+00,  4.3070e-01,  1.0843e+00,\n",
      "        -8.9623e-01,  2.2447e+00, -4.4980e-02, -3.7996e-01, -3.4153e+00,\n",
      "         1.9043e+00, -9.5483e-01,  8.3323e-01,  8.1806e-01,  2.6549e-01,\n",
      "        -4.6761e+00, -1.9026e+00, -6.5945e-01, -4.1188e-01, -1.4196e+00,\n",
      "        -4.4763e-01, -1.9713e-01,  1.6761e+00, -8.1595e-01], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0671]],\n",
      "\n",
      "         [[ 0.0348]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0687]],\n",
      "\n",
      "         [[ 0.0121]],\n",
      "\n",
      "         [[-0.0123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0075]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[-0.0464]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0032]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         [[ 0.1225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0723]],\n",
      "\n",
      "         [[ 0.1953]],\n",
      "\n",
      "         [[-0.0502]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1621]],\n",
      "\n",
      "         [[-0.0066]],\n",
      "\n",
      "         [[ 0.1163]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0191]],\n",
      "\n",
      "         [[ 0.0096]],\n",
      "\n",
      "         [[ 0.0523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0475]],\n",
      "\n",
      "         [[-0.0201]],\n",
      "\n",
      "         [[ 0.0311]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1116]],\n",
      "\n",
      "         [[ 0.0091]],\n",
      "\n",
      "         [[ 0.0529]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0231]],\n",
      "\n",
      "         [[ 0.1721]],\n",
      "\n",
      "         [[-0.0607]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0196]],\n",
      "\n",
      "         [[ 0.0374]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         [[ 0.0032]],\n",
      "\n",
      "         [[-0.0154]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 384, 1, 1])\n",
      "\n",
      "Layer: features.10.conv.2.param_quantizers.weight.min\n",
      "Weights: -1.069281816482544\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.2.param_quantizers.weight.max\n",
      "Weights: 1.0609281063079834\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.3.weight\n",
      "Weights: tensor([1.9378, 0.9872, 6.9928, 1.5813, 5.1038, 2.0274, 1.2569, 1.1775, 4.2219,\n",
      "        3.5326, 2.3307, 3.0572, 1.0382, 2.7175, 4.3027, 4.7480, 4.6148, 1.2230,\n",
      "        3.2733, 1.5476, 1.5013, 4.7089, 1.1100, 2.4626, 1.8728, 3.7182, 2.6695,\n",
      "        4.8734, 1.0934, 0.9412, 3.7655, 1.3054, 1.1903, 3.9655, 1.2690, 2.2902,\n",
      "        1.6020, 1.5254, 1.6357, 1.1028, 1.5539, 1.2705, 1.1657, 1.2440, 4.4574,\n",
      "        6.2776, 1.1568, 4.3910, 1.1096, 1.4099, 3.3740, 1.4511, 1.1916, 1.3195,\n",
      "        1.2786, 2.4235, 1.5877, 7.0662, 1.4588, 5.1415, 1.4237, 1.3148, 1.8732,\n",
      "        0.9873], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.10.conv.3.bias\n",
      "Weights: tensor([-6.4385e-07, -2.7339e-06,  8.0729e-07, -1.1939e-08,  1.1810e-06,\n",
      "        -3.2340e-09,  9.4471e-07, -7.1138e-07,  1.3689e-07, -4.7650e-08,\n",
      "         2.3305e-07,  1.6059e-07,  8.2482e-09,  8.3813e-07, -3.8147e-07,\n",
      "        -2.1289e-07,  6.6519e-07,  7.1511e-07,  7.1958e-07, -1.2390e-06,\n",
      "         1.0269e-06,  1.9098e-07, -1.0201e-06, -1.1513e-07, -8.3142e-07,\n",
      "        -3.3052e-07, -9.6507e-08,  1.4103e-06,  9.5611e-07,  1.3663e-06,\n",
      "         1.1550e-07,  1.3260e-06,  1.3175e-06,  2.1705e-07, -1.0543e-06,\n",
      "         4.5691e-07,  1.9202e-07, -1.0362e-07,  7.8162e-07, -2.4831e-07,\n",
      "         4.3724e-07, -7.5882e-07, -1.7948e-06,  3.8779e-07, -6.9935e-07,\n",
      "        -6.6828e-07,  8.8063e-07,  6.6335e-07, -1.0470e-07, -1.2610e-06,\n",
      "        -7.6499e-09, -1.4330e-07, -1.3259e-07, -1.1523e-06,  3.2641e-07,\n",
      "         1.8865e-07, -1.3416e-06, -6.0434e-07,  4.7090e-07,  4.2432e-07,\n",
      "         5.8093e-07, -1.0854e-06, -2.8033e-07,  5.9377e-07], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.10.conv.3.output_quantizers.0.min\n",
      "Weights: -36.87617874145508\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.10.conv.3.output_quantizers.0.max\n",
      "Weights: 42.573814392089844\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.0209]],\n",
      "\n",
      "         [[-0.2387]],\n",
      "\n",
      "         [[ 0.0540]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0413]],\n",
      "\n",
      "         [[-0.0739]],\n",
      "\n",
      "         [[ 0.0554]]],\n",
      "\n",
      "\n",
      "        [[[-0.0199]],\n",
      "\n",
      "         [[ 0.2173]],\n",
      "\n",
      "         [[-0.0966]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1849]],\n",
      "\n",
      "         [[-0.0354]],\n",
      "\n",
      "         [[-0.0875]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0248]],\n",
      "\n",
      "         [[-0.2514]],\n",
      "\n",
      "         [[-0.0258]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0130]],\n",
      "\n",
      "         [[-0.1779]],\n",
      "\n",
      "         [[ 0.1439]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0886]],\n",
      "\n",
      "         [[-0.0573]],\n",
      "\n",
      "         [[-0.2098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[ 0.0863]],\n",
      "\n",
      "         [[ 0.0534]]],\n",
      "\n",
      "\n",
      "        [[[-0.0657]],\n",
      "\n",
      "         [[ 0.2107]],\n",
      "\n",
      "         [[ 0.0688]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0914]],\n",
      "\n",
      "         [[-0.2014]],\n",
      "\n",
      "         [[ 0.0119]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0277]],\n",
      "\n",
      "         [[-0.1450]],\n",
      "\n",
      "         [[ 0.0520]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0390]],\n",
      "\n",
      "         [[ 0.0338]],\n",
      "\n",
      "         [[ 0.0547]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.11.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -1.0433753728866577\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 1.0352239608764648\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.0.0.input_quantizers.0.min\n",
      "Weights: -37.771759033203125\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.0.0.input_quantizers.0.max\n",
      "Weights: 42.853424072265625\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.0.1.weight\n",
      "Weights: tensor([1.0653, 1.1748, 0.6834, 1.3344, 1.2329, 1.3266, 1.3392, 1.3528, 1.5336,\n",
      "        1.4694, 1.1259, 1.5070, 1.3940, 1.1592, 1.1809, 1.2428, 1.3787, 1.0781,\n",
      "        1.0042, 0.3570, 1.3401, 0.9163, 1.4291, 1.4720, 1.3933, 1.3051, 1.8400,\n",
      "        1.3953, 1.3010, 1.1175, 0.9711, 0.7644, 1.1909, 1.5157, 1.4897, 1.7730,\n",
      "        1.3950, 1.3379, 0.5332, 0.7859, 0.4322, 1.1519, 1.0429, 1.1295, 1.2696,\n",
      "        1.4281, 1.2681, 1.2734, 1.6332, 1.4555, 1.4633, 1.0856, 1.5455, 1.1250,\n",
      "        1.3335, 1.1245, 1.2785, 1.2026, 1.3196, 1.2784, 1.6063, 1.1249, 1.4101,\n",
      "        1.5803, 0.7828, 1.4252, 1.5660, 1.1769, 0.5878, 1.5242, 1.5586, 1.2284,\n",
      "        1.2755, 1.3069, 1.3107, 0.9983, 1.2548, 1.2906, 1.3038, 1.3206, 1.2590,\n",
      "        1.3318, 1.2827, 0.9802, 1.1993, 1.5205, 1.4092, 1.1615, 1.6462, 1.2719,\n",
      "        1.3224, 1.1879, 1.1718, 1.3275, 1.1662, 1.2930, 1.0354, 1.0467, 1.3297,\n",
      "        1.5094, 0.5880, 1.2629, 0.6660, 1.6909, 1.2714, 1.2858, 1.3503, 1.2753,\n",
      "        1.2575, 1.3846, 1.6170, 1.1866, 1.1869, 1.3428, 1.3171, 0.9672, 1.3274,\n",
      "        1.5827, 1.4505, 0.6065, 1.4596, 1.5251, 1.1615, 1.3687, 1.5792, 1.5114,\n",
      "        1.4104, 1.4863, 0.5567, 1.2976, 1.1959, 0.9906, 0.9250, 1.5068, 1.1655,\n",
      "        1.4619, 1.2172, 1.4645, 1.3888, 1.2417, 1.1011, 1.2537, 1.4516, 1.1796,\n",
      "        1.3328, 1.0910, 1.2547, 1.2958, 0.8166, 1.2871, 1.5372, 1.2963, 1.2995,\n",
      "        1.3933, 1.3516, 1.0032, 1.2639, 1.4672, 1.0977, 2.3011, 1.4447, 1.6099,\n",
      "        1.2847, 0.8300, 1.3673, 1.1200, 1.1778, 1.1896, 1.4364, 1.4700, 0.8645,\n",
      "        1.0268, 1.3171, 1.2423, 1.2146, 1.3246, 1.3057, 1.4855, 0.5458, 1.0774,\n",
      "        1.5748, 1.2179, 1.0712, 1.0311, 1.2291, 1.4528, 1.1169, 1.1913, 1.4442,\n",
      "        0.7808, 1.2505, 1.2939, 1.3017, 1.2540, 1.4373, 1.0656, 1.1767, 1.3250,\n",
      "        1.1716, 0.6949, 1.4213, 1.3973, 1.8008, 1.1915, 1.4125, 0.8987, 1.0506,\n",
      "        1.2754, 1.2896, 1.2257, 1.4095, 1.0099, 1.5551, 1.0938, 1.1848, 1.1833,\n",
      "        1.4799, 1.4782, 0.8993, 1.2132, 1.5666, 0.8360, 1.2055, 1.3040, 1.3258,\n",
      "        1.5043, 1.2579, 1.1979, 1.3589, 1.2941, 1.5201, 1.1491, 1.1241, 1.4784,\n",
      "        1.6316, 1.3290, 1.3502, 1.2455, 1.5282, 1.4477, 1.0303, 0.9400, 0.9492,\n",
      "        1.0750, 1.1495, 1.3824, 2.0096, 1.2162, 1.2270, 1.2503, 1.5286, 1.3138,\n",
      "        0.4112, 1.1664, 1.2967, 1.1272, 1.0982, 1.3710, 1.1970, 1.2451, 1.1396,\n",
      "        0.6001, 1.2598, 1.9278, 1.3641, 1.3146, 1.5506, 1.6435, 1.4488, 1.2609,\n",
      "        1.3667, 0.5885, 1.5727, 1.4283, 0.8309, 1.3717, 1.2026, 1.2312, 1.3904,\n",
      "        1.2973, 1.2075, 1.3014, 0.8991, 1.1865, 1.3941, 1.3610, 1.0903, 1.4510,\n",
      "        1.5555, 0.4803, 1.4450, 1.4490, 1.2605, 1.4272, 1.2989, 1.1175, 1.5200,\n",
      "        1.4705, 1.6879, 1.1078, 1.0853, 1.3081, 1.3863, 1.4368, 1.2188, 1.3774,\n",
      "        1.1651, 1.2563, 1.3376, 1.1862, 1.1606, 1.5641, 1.2495, 1.6775, 1.0013,\n",
      "        1.3107, 1.2325, 1.4235, 1.4602, 1.7501, 1.1995, 1.0234, 1.3206, 1.3106,\n",
      "        1.2779, 1.2842, 1.3172, 1.4999, 1.5539, 1.5722, 0.9856, 1.4934, 1.2686,\n",
      "        1.4157, 1.4387, 1.1998, 1.2959, 1.2124, 1.0351, 1.4116, 1.2256, 1.3218,\n",
      "        1.3513, 1.2958, 1.2179, 1.3943, 1.5164, 1.3539, 1.3482, 1.3986, 1.2798,\n",
      "        1.1134, 0.5530, 1.5435, 1.4823, 0.5287, 1.2689, 1.2932, 1.3030, 1.1652,\n",
      "        0.8793, 1.0312, 1.3030, 1.0858, 0.9611, 1.6050, 1.2484, 1.2993, 0.6648,\n",
      "        1.0238, 1.1197, 1.2147, 1.4730, 1.5315, 0.9052, 0.5683, 1.1487, 0.9084,\n",
      "        1.3849, 1.2824, 1.2613, 1.2633, 1.0070, 0.6274], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.0.1.bias\n",
      "Weights: tensor([-0.1576,  0.7837,  1.9044, -0.7876,  0.6068, -0.4094, -0.2696,  0.0169,\n",
      "         0.2671, -0.9222,  1.6837, -0.2191, -0.3021,  0.2019,  0.0385,  0.4504,\n",
      "         0.0240,  0.3857,  0.0653,  1.6351,  0.2038,  1.4827,  0.7771, -0.4229,\n",
      "         0.0974, -0.3766, -0.1431, -0.1358, -0.7717,  0.4155,  1.5652,  1.7263,\n",
      "        -0.7153, -1.5665, -0.1382,  0.5840, -0.0218, -0.5747,  3.6936,  0.4572,\n",
      "        -0.0256, -0.0573,  0.5809,  1.0647,  1.7891,  0.4680,  0.4109, -0.7749,\n",
      "        -0.7168,  0.5410, -0.5127,  0.9732, -0.0426,  1.3883, -0.6187, -0.1847,\n",
      "         0.1976, -0.1430, -0.9572, -0.0463, -0.8450, -0.1530, -0.4282, -0.6077,\n",
      "         1.8759,  0.0115, -0.2511,  0.2060,  1.5379,  0.3458,  0.6756,  0.6087,\n",
      "        -0.9053, -0.7929,  0.1056,  0.8723,  1.0099, -0.0854, -0.1670, -0.0699,\n",
      "        -0.4687, -0.5225,  0.2523, -0.5401, -0.2328, -0.5532,  0.6112, -0.2164,\n",
      "        -0.2260,  1.0657, -0.5041, -0.1931, -0.1866, -0.7709, -0.4205,  0.7702,\n",
      "         0.9870,  0.1684, -0.0194,  0.4252,  1.4484, -0.9562,  1.6919, -0.6445,\n",
      "        -0.6649,  0.2337,  2.1018, -0.6360, -0.2496,  0.3810,  0.2271, -0.2972,\n",
      "        -0.2192, -0.2027,  0.1062,  0.9095,  1.2418, -0.1854,  0.4183,  0.3957,\n",
      "         0.1559, -0.7482,  0.7325, -0.5466,  2.2542, -0.6612, -1.0543, -0.1536,\n",
      "         1.8853, -0.3178, -0.4590,  0.5390,  1.6451, -0.0764,  0.1395,  0.0831,\n",
      "        -0.7590, -0.1262, -1.2446, -0.6383, -0.3961, -1.0283, -0.2948,  0.1845,\n",
      "         0.3687,  1.1496, -0.6338,  0.7759,  1.7510, -0.3031, -0.1241,  0.1892,\n",
      "        -0.2775, -0.4049,  0.5285, -0.4048, -0.0289, -0.8509,  0.9910,  0.3513,\n",
      "         0.5165, -0.6024, -0.4299,  1.9614,  0.5025, -0.2912,  0.4907, -0.2899,\n",
      "        -0.3464,  0.2936, -0.3204,  0.9759, -0.3318, -0.2051, -0.5438,  0.0089,\n",
      "         0.1403,  0.0565,  1.9054,  1.5053,  0.5446,  0.8330,  0.7623,  0.9168,\n",
      "         0.1791, -0.0675, -0.2818,  0.0809, -0.4231,  2.0986,  0.5917,  1.2191,\n",
      "         0.4102, -0.3079,  0.0624,  1.3518,  0.8209,  0.8241, -0.7147,  1.7941,\n",
      "         0.1053, -0.2634,  0.0978, -1.3734,  0.4173,  1.5533,  1.1427, -0.6136,\n",
      "         0.2145,  0.0289,  0.2943,  0.4769, -1.8222,  0.0227,  0.8840, -0.2986,\n",
      "         0.7518, -0.2828,  1.7271,  1.0617, -0.5995,  2.1815,  1.3297,  0.0309,\n",
      "        -0.6224, -0.2793, -1.0855,  1.5901, -0.2017, -0.5170, -0.4518,  0.8666,\n",
      "         1.2799, -0.4048,  0.5648, -0.6741, -0.1975, -0.3762,  0.2341, -0.2773,\n",
      "         0.9097, -0.2928, -0.1931,  0.7897, -0.6239,  0.1095,  0.1258, -0.7722,\n",
      "        -0.3525,  1.5550,  0.0208,  0.2256,  0.7450,  1.0465, -0.5804, -0.8582,\n",
      "        -0.3019,  1.0391,  0.1066, -0.5947,  0.0183,  1.5648, -0.5590,  0.5523,\n",
      "         0.3831,  2.1059, -0.4827, -0.6148,  0.2435, -0.6077,  1.9654,  1.5422,\n",
      "        -0.7434,  0.3624,  0.3651,  0.1939, -0.2947, -0.1325,  2.2594, -0.2039,\n",
      "        -2.1780, -0.4043,  0.4584,  0.1604, -0.1053, -0.5958, -0.1488, -0.4878,\n",
      "        -0.1155, -0.1295,  0.4589, -0.5169,  0.1595, -0.1277, -0.4722,  1.3653,\n",
      "        -0.6715,  1.6744,  0.8912,  0.0527,  1.4696,  0.2187,  0.2924,  0.8012,\n",
      "        -0.5733, -0.4287,  0.1368, -0.5821,  0.9838,  0.4676, -0.1598,  0.5534,\n",
      "         0.4470, -0.2059,  1.1840,  0.1323,  0.3970, -0.1575, -0.0933, -0.6444,\n",
      "         1.7797,  1.2909, -0.8902, -0.3012,  0.7909, -0.3415,  0.7637, -0.7677,\n",
      "         0.5083, -0.3626,  0.0924,  0.6773,  0.9406,  0.1850,  0.3540,  0.7464,\n",
      "         1.0366,  1.2839,  1.3520,  0.7960,  0.2923, -0.7434, -0.1224, -0.3727,\n",
      "        -0.6526, -0.5136, -0.1758, -0.3901, -0.2980, -0.9460, -0.8022,  1.1045,\n",
      "         1.6277, -0.5406,  0.0481, -0.3989, -0.6038, -0.4311, -0.7374, -0.3581,\n",
      "         2.1029,  1.8823, -0.2276, -0.0834,  0.3363,  0.7860, -0.1152, -0.1198,\n",
      "         1.6242,  1.0393,  0.3620, -0.2943,  0.3746,  1.1881,  0.1785,  1.5429,\n",
      "         0.0345, -0.1553, -0.5829, -0.5274,  1.2515,  1.0312,  1.8793,  1.3705],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.1.0.weight\n",
      "Weights: tensor([[[[-1.1589e-01, -6.6866e-02, -1.2909e-01],\n",
      "          [-5.1430e-02, -5.6317e-03, -4.9895e-02],\n",
      "          [-1.3824e-01, -7.3430e-02, -1.3444e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7623e-03, -4.8888e-02, -3.6841e-03],\n",
      "          [-8.3434e-02, -3.4875e-01, -9.3236e-02],\n",
      "          [-4.3724e-02, -5.9930e-02, -3.7883e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.7786e-04, -7.1330e-02,  1.7061e-03],\n",
      "          [-6.8612e-02, -3.4188e-01, -8.6674e-02],\n",
      "          [-2.4407e-02, -8.4478e-02, -1.6576e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.9653e-02,  2.0546e-01,  4.0452e-02],\n",
      "          [-9.0566e-02, -7.1098e-02, -7.7015e-02],\n",
      "          [-1.3687e-01, -3.3485e-01, -1.4459e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3074e-02,  1.7918e-01,  3.4782e-02],\n",
      "          [ 1.5058e-01, -9.1790e-01,  8.9586e-02],\n",
      "          [ 5.1830e-02,  4.7739e-02,  5.4556e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6702e-02, -2.0779e-01,  1.0262e-02],\n",
      "          [-1.3448e-01,  5.3438e-01, -1.0691e-01],\n",
      "          [ 3.6431e-02, -2.4226e-01,  1.4608e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.11.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.9178959727287292\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.910724937915802\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.1.1.weight\n",
      "Weights: tensor([0.7270, 0.7479, 1.1373, 0.5958, 0.8306, 0.6505, 0.6371, 1.2207, 0.8265,\n",
      "        0.7315, 2.0185, 0.7965, 0.7867, 1.8377, 1.1576, 0.7019, 0.6082, 0.8035,\n",
      "        1.2279, 1.9053, 0.8237, 1.0353, 1.7569, 0.7661, 1.2023, 0.6416, 0.5145,\n",
      "        0.7261, 0.8418, 0.8416, 0.9299, 1.2667, 0.6132, 0.4586, 0.8898, 2.2488,\n",
      "        0.9692, 0.5341, 3.3451, 1.0796, 1.9557, 0.6791, 0.7075, 0.9297, 1.6600,\n",
      "        0.7631, 0.7147, 0.6056, 0.4528, 0.6160, 0.4950, 0.7959, 0.5548, 0.9853,\n",
      "        0.7914, 0.6622, 0.7386, 0.7900, 0.5453, 0.8785, 0.4771, 0.8693, 0.6546,\n",
      "        0.5385, 0.9758, 0.8971, 0.9619, 0.7522, 0.7927, 1.6277, 0.8276, 0.8854,\n",
      "        0.5703, 0.5371, 1.2829, 0.8865, 0.7457, 0.7138, 0.5961, 0.6749, 0.7415,\n",
      "        0.5293, 0.6896, 0.9605, 0.9791, 0.6505, 0.8116, 0.7440, 0.7888, 1.6663,\n",
      "        0.7843, 0.8548, 0.9571, 0.4725, 0.5398, 0.7171, 0.8996, 0.8165, 0.8495,\n",
      "        0.8072, 0.8331, 0.6450, 1.0667, 0.8345, 0.7268, 0.6255, 1.0175, 0.4950,\n",
      "        0.7097, 0.8315, 0.9642, 0.6736, 0.6048, 0.8322, 0.7003, 0.8069, 1.4822,\n",
      "        0.8345, 0.7724, 0.9485, 0.7073, 0.7543, 0.7478, 0.5449, 3.4346, 0.6551,\n",
      "        1.0346, 0.8637, 1.0328, 0.7548, 0.6749, 1.1997, 1.3149, 0.6782, 0.9485,\n",
      "        1.3427, 0.5906, 0.6536, 0.6193, 0.5883, 0.6696, 0.5858, 0.6769, 1.0203,\n",
      "        0.8515, 1.2669, 0.6042, 0.6664, 0.8512, 0.5554, 0.8028, 0.7480, 0.6027,\n",
      "        0.8031, 1.1505, 0.6251, 0.7121, 1.0819, 0.8353, 0.6777, 0.8722, 0.8208,\n",
      "        0.7020, 0.9163, 1.5501, 0.5826, 0.7021, 0.6662, 0.5233, 0.9753, 1.3113,\n",
      "        0.7583, 0.6093, 0.8055, 0.8098, 0.6307, 0.8559, 0.6912, 1.2572, 1.0509,\n",
      "        1.2084, 1.5229, 0.9761, 0.8460, 0.7293, 0.7312, 0.8771, 1.2177, 0.7529,\n",
      "        1.3131, 0.6798, 2.0793, 0.8025, 0.8259, 0.7215, 0.9370, 0.7272, 0.9950,\n",
      "        0.7930, 0.9912, 0.7391, 0.6816, 0.7962, 0.5858, 1.3346, 0.8408, 0.7772,\n",
      "        0.6631, 0.8775, 0.6703, 1.4361, 0.9882, 0.7134, 0.6764, 0.8705, 0.9107,\n",
      "        1.0788, 0.6841, 0.7532, 0.8218, 0.6473, 1.4338, 0.6951, 0.6745, 0.6619,\n",
      "        0.6254, 0.7131, 0.9320, 0.6440, 0.6385, 0.6025, 1.0990, 0.7886, 0.8952,\n",
      "        0.9314, 0.5493, 0.8787, 0.6425, 0.6635, 0.7359, 0.9046, 0.6840, 0.7978,\n",
      "        0.8032, 0.5566, 0.7548, 1.0174, 0.7525, 0.7087, 1.2543, 0.7133, 0.6744,\n",
      "        1.5243, 0.9268, 0.6449, 0.5402, 0.8720, 1.7201, 1.1387, 0.6762, 0.7131,\n",
      "        0.9676, 0.6892, 0.7078, 0.6438, 1.7138, 0.8746, 0.8389, 0.7103, 0.5969,\n",
      "        1.1124, 0.9600, 0.5753, 1.0062, 1.1421, 0.8193, 0.6274, 0.8513, 1.9196,\n",
      "        0.7631, 1.3097, 0.4109, 1.3187, 0.8176, 0.5891, 0.7980, 0.7067, 0.6694,\n",
      "        0.8316, 3.4203, 0.7932, 0.6500, 0.7696, 0.5747, 0.6649, 0.8984, 0.4764,\n",
      "        1.4736, 0.7643, 0.7376, 0.9177, 0.6678, 1.0372, 1.1685, 0.7178, 0.5562,\n",
      "        0.8355, 0.6710, 1.4381, 1.3558, 0.8504, 0.8362, 1.1143, 0.5807, 0.8834,\n",
      "        0.6623, 0.9477, 0.7242, 0.8142, 0.8237, 1.0392, 0.9581, 0.6093, 0.8760,\n",
      "        0.8382, 0.8999, 1.6040, 0.5367, 0.7212, 0.7547, 1.4964, 0.8707, 0.8443,\n",
      "        0.7465, 1.6708, 1.0172, 1.3960, 0.9208, 0.8899, 1.7391, 0.8549, 0.7335,\n",
      "        0.7038, 0.6826, 0.5785, 0.7276, 0.5382, 0.5855, 0.8016, 0.7059, 0.4428,\n",
      "        0.6978, 0.9461, 0.4958, 0.7659, 1.5768, 0.8209, 0.8476, 0.7134, 0.7769,\n",
      "        2.3742, 0.9350, 0.7732, 0.7299, 1.2093, 1.4640, 0.7840, 0.6077, 0.9116,\n",
      "        0.9228, 1.2770, 0.8830, 0.8032, 0.6061, 0.6567, 1.1066, 1.0420, 0.6708,\n",
      "        0.6988, 0.7185, 0.7085, 0.7977, 0.9331, 1.0114], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.1.1.bias\n",
      "Weights: tensor([ 7.3851e-01,  7.3549e-01, -4.4571e-01,  1.5337e-02,  1.3252e+00,\n",
      "         3.1545e-01,  3.2549e-01, -1.0135e-01,  4.2000e+00,  6.7198e-01,\n",
      "        -1.3562e+00,  4.5963e-01,  5.4034e-01, -2.2089e+00, -1.6174e+00,\n",
      "         4.7691e-01,  2.2349e+00,  2.0955e-01, -7.3506e-01, -2.3936e+00,\n",
      "        -1.0213e-01,  2.6030e+00, -1.0869e+00,  8.1308e-02, -8.8340e-01,\n",
      "         3.1841e-01,  6.5252e-01,  3.8198e-01, -1.3247e+00,  1.8835e-01,\n",
      "         3.4111e+00, -1.7249e-01, -4.0365e-01,  3.2976e+00,  8.7287e-02,\n",
      "        -1.1388e+00, -4.9168e-01,  1.0686e+00, -3.3419e+00, -6.4303e-01,\n",
      "        -3.7007e-01,  3.0134e+00,  5.8837e-01,  4.3376e+00, -5.3020e-01,\n",
      "         3.7002e-01,  2.8680e+00,  3.8818e-02,  1.9981e+00,  1.8261e+00,\n",
      "         2.2149e+00,  1.8790e+00,  2.1520e+00,  3.8436e+00, -4.9147e-01,\n",
      "         2.3394e-01,  2.1055e-01, -1.2290e-01,  2.6487e-01, -1.2890e-01,\n",
      "         3.3885e-01,  7.2316e-02,  5.1825e-01,  1.6557e+00,  2.8751e+00,\n",
      "         5.6288e-01,  2.2747e-01,  4.4823e-02,  2.2619e-01, -8.4554e-01,\n",
      "         2.8067e+00,  1.1969e+00,  1.1362e+00,  2.0176e+00, -1.4145e+00,\n",
      "         2.8155e-01,  4.3017e-01,  2.7309e-01,  4.0158e+00,  4.4956e-01,\n",
      "        -3.9287e-01,  1.5840e+00,  4.1709e-01, -9.9363e-01, -9.1442e-01,\n",
      "         2.6534e+00,  1.6490e+00, -7.0156e-02,  7.1433e-02, -7.7910e-01,\n",
      "        -4.0313e-01, -7.8682e-01, -1.2442e+00,  1.5552e+00,  7.4173e-02,\n",
      "         1.1959e+00,  1.1995e-01,  8.8195e-02,  2.2225e-01,  2.2265e+00,\n",
      "         3.1682e-01, -6.4946e-01,  9.7244e-02,  3.0827e+00, -9.1679e-01,\n",
      "         3.1239e+00,  5.7486e-02,  3.0691e-01,  3.9116e-01,  1.2096e+00,\n",
      "         6.7613e-01,  2.0232e-01,  1.7679e-01,  1.9411e-02,  3.6331e+00,\n",
      "         2.8731e+00, -5.5937e-01,  6.0676e-01,  6.9554e-01,  1.6689e+00,\n",
      "         5.4996e-01, -1.0961e-01,  2.2259e+00,  3.1971e+00, -3.3467e+00,\n",
      "         5.2047e-01,  7.3346e-01,  6.2727e-01,  8.8583e-02,  3.4419e-01,\n",
      "         1.7316e-02, -5.8806e-01, -2.8673e-01,  9.7336e-01, -1.9140e-01,\n",
      "        -2.7065e-01, -1.4633e-01,  1.1563e+00, -1.7330e-01, -1.2259e-03,\n",
      "        -1.5208e-01, -2.8551e-01,  6.9069e-01, -3.0556e-01,  1.0800e+00,\n",
      "        -1.3643e-01, -1.6767e-01,  2.3058e+00,  3.9010e+00,  3.2470e+00,\n",
      "         4.7368e-01,  4.7232e-01,  3.2868e+00, -1.2775e-01, -2.8666e-01,\n",
      "        -2.3898e-01,  2.3393e-01,  3.3489e-01,  1.2214e+00,  9.3957e-01,\n",
      "         1.7790e+00,  2.6644e+00, -2.4961e-01,  4.6497e-01, -7.2387e-01,\n",
      "         2.3885e-01,  9.4110e-02, -8.0530e-02,  3.4392e+00, -3.9067e-01,\n",
      "        -7.7182e-01,  1.7792e+00,  4.2342e-01, -3.3165e-01, -1.1893e-01,\n",
      "         3.8718e+00,  4.3652e-01,  2.6460e+00, -4.7476e-01, -3.4953e-02,\n",
      "        -1.2668e-01, -8.6223e-01,  5.7717e-01,  1.1318e+00,  4.2533e-01,\n",
      "         3.8108e-01, -5.2585e-01, -1.2048e+00,  2.5537e-01, -9.1395e-02,\n",
      "         7.1151e-01, -1.3963e+00,  3.6598e-01, -5.3852e-01,  2.8181e-01,\n",
      "         1.3814e+00,  2.5139e+00,  1.2285e+00, -8.2660e-01,  2.7550e-01,\n",
      "         4.9912e-01,  2.0420e+00,  1.6861e+00,  1.6091e-01, -2.5898e-01,\n",
      "         5.4164e-01,  7.4250e-01, -3.7358e-01,  8.7416e-02,  1.2915e+00,\n",
      "        -4.9335e-01, -1.9283e-01,  1.2425e+00,  2.8761e+00,  3.9685e-01,\n",
      "        -8.1801e-01,  9.6430e-02,  5.6361e-01,  7.5770e-01,  1.6491e+00,\n",
      "         1.9638e-01, -2.5259e-01,  6.6849e-01,  4.0595e-01,  1.1426e+00,\n",
      "         5.6511e-01, -2.2427e-01,  5.0051e-01,  4.3231e-01,  2.0512e-01,\n",
      "         4.6073e-01, -3.0768e-01,  2.7112e+00, -7.9873e-02,  1.4219e+00,\n",
      "         3.1466e-01, -1.0306e-02,  6.6097e-01,  3.2097e+00,  6.6619e-01,\n",
      "         8.3433e-02,  2.4626e+00, -7.4078e-01,  1.6184e+00, -2.5986e-03,\n",
      "         1.5049e+00,  7.4849e-03, -1.6659e-01, -3.2683e-01, -3.5083e-01,\n",
      "         1.8460e+00,  4.4711e-01, -1.2574e+00,  8.7386e-01, -3.3008e-02,\n",
      "        -1.9937e-01, -4.7572e-01, -8.6988e-01, -6.5205e-01,  3.1576e-02,\n",
      "         9.8169e-01,  2.3211e-01, -5.3487e-02,  8.8117e-01,  1.4322e+00,\n",
      "        -5.3620e-01,  2.5385e-01,  2.8238e+00,  1.3947e+00,  2.3077e-01,\n",
      "         3.4623e+00,  9.4043e-01,  3.9674e+00, -4.0259e-01, -1.0833e+00,\n",
      "         5.1012e-01,  2.2164e-01,  2.3634e-01, -1.2147e+00,  2.2369e-01,\n",
      "         2.4050e+00,  3.5888e-01, -9.9776e-01,  2.3825e-01,  7.6572e-01,\n",
      "        -7.0855e-01,  4.7220e-02,  1.3056e+00,  2.8891e+00, -8.2598e-01,\n",
      "         3.5338e-01,  2.5313e+00,  5.2007e-01,  2.8876e-01,  2.3199e+00,\n",
      "         1.0083e+00,  3.3694e-01, -4.0320e-01,  1.6390e+00,  2.1507e-01,\n",
      "         1.5326e+00,  3.2514e-01, -1.6963e-01, -2.4290e-01, -1.0427e-01,\n",
      "         6.7288e-02,  3.3325e-01, -3.2756e-01, -7.7695e-01, -1.1303e+00,\n",
      "        -3.5389e-01,  3.5189e+00, -2.3770e-01,  9.1936e-01,  3.7517e+00,\n",
      "         4.6934e-01,  3.1354e-01,  3.6663e-01,  2.7689e+00,  2.8366e+00,\n",
      "         3.7699e-01,  2.1191e+00, -2.2876e-01, -8.0470e-02,  1.7080e+00,\n",
      "        -1.2786e-01, -2.9619e+00,  3.6572e-01,  1.0359e+00,  1.9434e+00,\n",
      "        -5.8175e-01,  1.5777e+00,  5.2208e-01,  1.7799e+00, -5.7440e-01,\n",
      "         1.4760e-01, -7.7315e-01,  4.7193e+00,  2.1117e+00, -7.4468e-01,\n",
      "         3.8568e-01, -4.8341e-01, -1.9333e-01,  3.1464e-01,  4.4727e-01,\n",
      "        -1.0360e-01,  6.6191e-01,  3.1211e-01,  2.8075e-02, -7.5305e-03,\n",
      "         2.7576e+00,  5.3324e-01,  4.2957e-01,  1.4722e+00,  4.0007e+00,\n",
      "         4.7229e+00, -9.4386e-01, -3.3874e-01, -7.1062e-01, -6.2849e-01,\n",
      "        -2.6164e+00,  3.8077e+00,  2.3474e-01, -1.8497e-01, -8.9474e-01,\n",
      "        -9.2402e-01,  1.2277e-01,  2.3629e-01,  3.5288e+00,  1.0353e+00,\n",
      "        -1.1109e+00, -5.4483e-01,  1.2381e+00,  5.9471e-01,  1.8784e+00,\n",
      "        -5.8136e-02, -1.0474e+00,  2.3388e-02,  7.2995e-02, -3.8702e-01,\n",
      "         1.1071e+00,  1.2868e+00,  3.6389e+00,  3.5779e-01], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.2.weight\n",
      "Weights: tensor([[[[-0.0610]],\n",
      "\n",
      "         [[-0.0040]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1468]],\n",
      "\n",
      "         [[ 0.1996]],\n",
      "\n",
      "         [[ 0.0240]]],\n",
      "\n",
      "\n",
      "        [[[-0.0143]],\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[ 0.1100]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0551]],\n",
      "\n",
      "         [[-0.1201]],\n",
      "\n",
      "         [[ 0.0318]]],\n",
      "\n",
      "\n",
      "        [[[-0.1181]],\n",
      "\n",
      "         [[ 0.0395]],\n",
      "\n",
      "         [[-0.1187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0378]],\n",
      "\n",
      "         [[ 0.0656]],\n",
      "\n",
      "         [[-0.1202]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0440]],\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0955]],\n",
      "\n",
      "         [[-0.1132]],\n",
      "\n",
      "         [[ 0.0011]]],\n",
      "\n",
      "\n",
      "        [[[-0.0852]],\n",
      "\n",
      "         [[-0.0574]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0634]],\n",
      "\n",
      "         [[-0.2565]],\n",
      "\n",
      "         [[-0.0611]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0048]],\n",
      "\n",
      "         [[-0.1114]],\n",
      "\n",
      "         [[ 0.0891]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[-0.0103]],\n",
      "\n",
      "         [[-0.0059]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 384, 1, 1])\n",
      "\n",
      "Layer: features.11.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.7274985909461975\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.7218149900436401\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.3.weight\n",
      "Weights: tensor([2.9741, 5.5332, 3.2604, 4.0375, 2.8986, 3.1309, 2.7739, 3.1628, 3.3457,\n",
      "        2.9168, 4.2698, 3.1080, 3.9861, 5.2623, 3.5785, 3.1324, 3.9318, 2.6281,\n",
      "        3.8744, 4.6508, 4.8861, 3.2463, 2.8417, 4.5962, 4.2495, 2.6260, 2.9381,\n",
      "        4.0735, 4.0897, 4.1590, 3.2609, 4.9767, 2.8378, 4.4331, 4.9978, 2.6178,\n",
      "        2.8788, 4.0455, 2.9217, 2.3867, 2.9513, 2.9133, 4.4409, 2.4029, 3.1889,\n",
      "        4.4372, 3.5394, 4.1361, 3.6185, 3.7651, 5.3719, 2.8776, 3.1763, 4.3046,\n",
      "        2.8378, 4.8691, 2.9758, 4.4852, 3.6803, 2.6420, 3.1134, 3.6995, 2.9466,\n",
      "        4.2564, 2.7176, 3.6013, 3.4084, 3.0422, 4.1733, 2.6794, 4.1583, 3.3241,\n",
      "        3.2797, 2.6427, 3.3332, 3.1261, 2.8712, 2.9212, 3.3155, 2.4594, 3.3921,\n",
      "        3.4952, 5.2719, 2.8673, 3.7296, 2.9474, 2.6561, 2.7415, 2.8212, 2.6919,\n",
      "        4.0853, 3.1541, 3.7723, 3.0184, 3.4575, 4.1154], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.11.conv.3.bias\n",
      "Weights: tensor([-2.0243e-07, -4.8820e-07, -6.9870e-08,  1.5077e-06, -9.5832e-07,\n",
      "        -2.9177e-07, -1.5487e-06,  1.7722e-07, -2.0332e-07,  1.6077e-06,\n",
      "        -1.5140e-07,  4.6030e-09, -7.2116e-07, -1.8416e-06, -4.1749e-07,\n",
      "        -6.6610e-07, -2.7996e-07, -9.5907e-07, -9.9642e-09, -1.0053e-06,\n",
      "        -8.1612e-07,  6.7731e-07,  1.0918e-07, -1.1630e-06,  1.2033e-06,\n",
      "        -7.6328e-07,  1.0589e-06, -1.2107e-06, -1.5177e-07, -2.2695e-07,\n",
      "         7.2759e-07, -4.1832e-07, -3.5047e-07, -1.1325e-07,  1.3356e-06,\n",
      "        -1.5299e-06,  4.4778e-07,  1.2048e-06, -1.2090e-06,  1.0251e-06,\n",
      "         3.1870e-07, -3.0226e-07, -5.8349e-07,  2.2791e-06, -5.4127e-07,\n",
      "         4.0925e-07,  5.3115e-07, -1.3387e-07, -1.1326e-07, -2.2188e-06,\n",
      "         1.5248e-06, -2.3296e-07,  1.4183e-06,  2.6719e-07, -4.2346e-07,\n",
      "         3.4140e-07,  7.9001e-08,  4.8099e-07, -1.0306e-06, -1.7724e-06,\n",
      "         1.4905e-07, -2.4811e-07, -1.2946e-06,  1.1764e-06, -8.5550e-07,\n",
      "         3.5046e-08, -3.0477e-07, -1.0621e-06,  1.7086e-06,  7.2543e-07,\n",
      "         1.5367e-06, -8.7346e-08, -1.6616e-06, -2.0005e-07,  4.9133e-07,\n",
      "         4.1884e-07,  7.8050e-07, -7.7125e-07,  1.8921e-07, -1.8378e-07,\n",
      "         1.8187e-07,  2.6906e-07, -6.9544e-07,  5.7481e-07, -1.5392e-07,\n",
      "         2.4390e-07, -1.1330e-06, -1.2455e-08, -1.6742e-06,  1.5721e-06,\n",
      "         1.6854e-07, -3.2157e-07,  8.3526e-07,  8.2384e-07, -3.2154e-07,\n",
      "         1.2549e-06], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.11.conv.3.output_quantizers.0.min\n",
      "Weights: -26.592435836791992\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.11.conv.3.output_quantizers.0.max\n",
      "Weights: 26.98370361328125\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0024]],\n",
      "\n",
      "         [[ 0.0629]],\n",
      "\n",
      "         [[ 0.0657]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0781]],\n",
      "\n",
      "         [[ 0.0231]],\n",
      "\n",
      "         [[-0.0295]]],\n",
      "\n",
      "\n",
      "        [[[-0.0194]],\n",
      "\n",
      "         [[ 0.0415]],\n",
      "\n",
      "         [[-0.0348]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0156]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[-0.0823]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1166]],\n",
      "\n",
      "         [[-0.0282]],\n",
      "\n",
      "         [[-0.0094]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2079]],\n",
      "\n",
      "         [[-0.1185]],\n",
      "\n",
      "         [[ 0.0392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0750]],\n",
      "\n",
      "         [[ 0.0958]],\n",
      "\n",
      "         [[-0.0510]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1194]],\n",
      "\n",
      "         [[ 0.0462]],\n",
      "\n",
      "         [[ 0.0426]]],\n",
      "\n",
      "\n",
      "        [[[-0.0072]],\n",
      "\n",
      "         [[ 0.0940]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0179]],\n",
      "\n",
      "         [[-0.0217]],\n",
      "\n",
      "         [[-0.0549]]],\n",
      "\n",
      "\n",
      "        [[[-0.0050]],\n",
      "\n",
      "         [[ 0.1478]],\n",
      "\n",
      "         [[ 0.0473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0630]],\n",
      "\n",
      "         [[-0.0064]],\n",
      "\n",
      "         [[-0.0173]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 96, 1, 1])\n",
      "\n",
      "Layer: features.12.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.5090275406837463\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.505050778388977\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.0.1.weight\n",
      "Weights: tensor([0.7594, 1.1064, 1.1134, 1.1040, 1.0824, 1.2655, 0.5072, 1.2841, 1.3580,\n",
      "        0.9926, 1.0181, 0.8181, 1.3877, 1.4232, 1.1767, 1.2266, 1.1949, 1.0320,\n",
      "        1.2356, 0.9549, 1.0766, 0.9764, 0.8662, 1.0245, 1.1646, 1.2725, 1.1435,\n",
      "        1.0536, 0.7598, 1.3088, 1.3005, 1.1798, 1.2387, 0.7272, 1.2152, 1.3525,\n",
      "        0.7503, 0.7965, 1.1013, 1.3179, 1.2801, 1.0357, 1.1546, 1.1366, 1.3002,\n",
      "        0.6004, 1.3330, 0.9353, 1.2064, 1.3403, 1.3019, 1.3529, 1.1263, 1.0709,\n",
      "        1.3626, 1.0189, 0.4106, 1.2049, 1.0061, 1.1658, 1.1716, 1.2699, 1.0206,\n",
      "        1.1483, 0.8508, 1.0712, 1.2537, 1.2533, 1.0386, 1.0715, 1.0928, 1.2500,\n",
      "        0.8601, 0.7399, 1.0890, 1.1374, 1.0216, 1.3330, 1.2934, 1.3617, 1.2659,\n",
      "        0.9717, 1.2401, 1.1664, 1.2791, 1.2996, 1.3638, 1.1917, 1.0590, 0.5950,\n",
      "        0.7919, 0.5684, 0.9987, 2.1275, 1.1426, 1.2353, 1.1251, 1.5497, 0.7368,\n",
      "        1.2045, 0.9341, 0.9501, 1.2485, 1.2099, 0.9014, 0.9312, 1.1487, 1.1847,\n",
      "        0.6648, 0.9201, 1.2186, 1.5022, 1.1115, 1.0537, 1.1492, 1.1466, 1.0609,\n",
      "        1.3012, 1.2213, 1.2418, 1.1595, 0.7429, 1.0704, 0.8080, 1.0181, 1.1132,\n",
      "        1.0508, 1.0581, 1.1127, 0.9418, 1.1973, 1.0076, 1.3314, 1.1090, 1.1521,\n",
      "        0.8179, 1.4207, 1.2080, 1.2884, 0.9751, 1.1951, 1.1980, 1.2184, 1.2027,\n",
      "        1.1604, 1.2604, 1.0840, 0.8806, 0.9959, 3.5900, 1.0088, 1.0545, 1.1393,\n",
      "        1.4067, 1.0152, 1.3979, 0.5362, 0.9811, 1.1631, 1.2612, 0.4815, 1.3638,\n",
      "        1.1203, 1.1804, 1.3027, 1.1182, 0.8836, 1.1096, 0.8778, 1.1804, 1.2946,\n",
      "        1.1795, 1.1624, 1.0817, 1.2229, 0.9853, 1.1210, 1.0527, 1.1382, 1.0302,\n",
      "        1.1663, 1.3470, 1.2351, 1.3298, 1.1916, 0.8817, 1.3211, 1.1219, 1.0470,\n",
      "        1.2064, 0.7759, 1.0010, 1.0756, 1.3333, 1.0700, 1.3184, 1.1978, 0.7726,\n",
      "        1.1102, 1.3539, 1.3467, 0.8705, 1.1323, 0.8064, 0.9680, 1.1137, 1.1817,\n",
      "        0.9932, 1.2301, 1.0522, 1.0327, 1.1880, 1.1647, 1.3468, 1.2920, 0.8675,\n",
      "        1.1650, 1.0893, 1.1524, 1.1468, 1.0817, 0.8214, 1.2529, 0.8981, 1.0887,\n",
      "        1.1049, 1.2498, 0.6590, 1.0183, 1.1166, 1.1526, 1.3800, 1.3553, 1.0348,\n",
      "        1.3621, 1.2765, 1.3541, 1.0487, 0.9527, 1.2360, 1.2018, 0.7915, 1.1238,\n",
      "        1.3006, 0.3665, 1.3565, 1.2798, 1.1887, 1.0869, 1.2386, 1.2056, 1.0624,\n",
      "        1.3634, 1.3102, 0.8440, 0.8190, 1.2233, 0.7065, 0.6642, 1.4104, 0.6924,\n",
      "        1.0342, 1.5235, 1.1452, 1.1956, 1.1999, 0.8511, 1.3930, 0.5254, 0.6328,\n",
      "        1.1367, 1.2651, 0.9815, 1.1093, 0.8287, 0.8107, 0.7770, 1.1429, 1.1958,\n",
      "        1.2634, 1.0049, 1.0931, 1.1487, 1.1811, 0.8517, 0.6480, 1.1450, 1.1402,\n",
      "        1.2028, 1.4769, 0.9994, 1.0214, 0.9869, 1.0554, 1.1372, 1.4214, 1.3911,\n",
      "        1.2301, 1.2093, 1.0439, 1.3263, 0.4175, 1.1690, 1.0576, 1.2168, 1.1388,\n",
      "        1.2452, 1.0525, 1.4911, 1.4570, 0.3893, 1.1783, 1.0511, 1.3735, 0.7776,\n",
      "        1.1013, 0.7344, 1.2958, 1.1121, 0.4722, 0.7511, 1.2411, 1.1639, 1.1671,\n",
      "        1.3035, 0.9470, 1.2139, 1.1585, 1.1924, 1.7824, 1.0011, 1.0021, 1.5084,\n",
      "        1.2822, 0.8105, 1.0653, 1.0867, 1.5717, 1.2011, 2.4077, 1.0112, 1.3135,\n",
      "        1.0240, 1.3082, 1.2119, 1.0426, 0.9859, 1.1096, 1.0509, 1.3342, 0.9093,\n",
      "        1.3384, 1.2047, 0.8537, 1.0012, 1.2759, 0.6288, 1.2908, 1.1721, 1.2363,\n",
      "        0.8440, 1.2120, 1.0431, 1.2122, 0.8342, 0.7803, 1.1043, 1.1553, 1.1310,\n",
      "        1.2127, 1.0870, 0.9738, 1.1847, 1.1181, 0.9195, 1.4009, 1.0893, 0.9074,\n",
      "        0.4990, 1.0929, 0.9645, 1.0095, 1.4290, 0.9787, 0.7954, 1.2488, 1.1382,\n",
      "        1.0756, 0.7223, 0.8321, 0.9225, 1.7372, 1.2359, 1.3951, 1.3569, 0.9617,\n",
      "        0.9043, 1.1223, 1.0691, 1.2812, 1.2498, 0.8007, 1.1504, 1.1175, 0.8172,\n",
      "        1.1084, 1.0665, 1.2629, 0.9825, 0.8650, 1.1250, 0.5073, 1.3942, 0.8534,\n",
      "        1.1759, 1.2897, 0.9592, 1.4290, 1.0974, 1.1608, 1.3180, 0.9064, 1.2914,\n",
      "        1.2028, 1.5255, 1.2608, 1.3337, 2.8321, 0.9823, 0.7875, 1.0029, 1.1246,\n",
      "        1.1279, 1.4547, 1.3344, 1.3611, 1.0541, 1.3993, 1.3057, 1.2199, 1.2780,\n",
      "        1.1590, 1.5576, 1.2044, 0.9628, 1.2474, 1.0255, 1.1953, 1.1854, 0.6371,\n",
      "        0.9924, 1.2883, 1.3162, 1.0738, 0.5925, 1.3987, 1.1331, 1.0662, 1.2911,\n",
      "        0.8244, 0.4484, 1.2890, 0.6921, 1.1634, 1.2448, 1.2487, 0.8683, 1.3288,\n",
      "        1.1543, 1.2579, 1.2266, 0.9958, 1.2095, 1.0910, 1.1160, 0.7133, 0.9379,\n",
      "        1.1857, 1.0273, 1.2023, 1.0572, 0.7486, 0.4913, 1.0360, 1.0928, 1.1841,\n",
      "        0.9025, 1.1203, 1.3334, 0.9276, 1.1947, 1.1863, 1.0256, 1.0752, 1.1428,\n",
      "        0.9104, 1.2557, 1.2460, 1.0736, 1.0096, 1.2858, 0.8826, 1.1557, 0.9107,\n",
      "        1.1561, 1.3161, 0.8715, 1.0842, 1.1062, 0.6495, 0.9292, 1.3803, 1.0906,\n",
      "        1.6002, 1.3953, 0.9303, 1.2051, 1.3240, 1.4497, 1.3563, 1.1684, 1.0023,\n",
      "        1.2438, 0.8602, 0.6066, 1.3455, 0.9111, 0.6813, 0.6507, 0.6316, 1.2209,\n",
      "        1.2586, 0.4542, 0.7673, 1.1349, 1.2082, 1.1843, 1.2011, 2.1799, 1.3677,\n",
      "        1.2789, 1.2324, 1.2958, 1.0403, 1.2362, 0.4359, 0.7223, 0.8642, 1.1085,\n",
      "        1.2551, 1.3478, 1.1803, 0.5649, 1.0757, 1.0277, 1.1622, 0.9007, 1.2547,\n",
      "        1.1263, 1.0676, 0.9878, 1.1433, 1.3520, 0.6851, 1.3245, 0.9984, 0.9998,\n",
      "        1.0053, 1.0668, 0.6820, 1.0333, 1.0217, 1.1859, 1.0046, 1.0133, 0.7727],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.0.1.bias\n",
      "Weights: tensor([-0.0203,  0.1077, -0.4481,  0.3536, -0.7823, -1.1826,  1.1160, -0.9622,\n",
      "        -0.1455, -0.5723, -1.3229,  0.1494, -0.3831,  0.5368, -0.0607,  0.2174,\n",
      "         0.3153, -0.2389, -1.7505, -1.3642,  0.3722,  0.6254, -0.8842,  1.4759,\n",
      "        -0.9487, -0.6390,  0.5313, -0.7817,  0.1341, -0.3555, -0.6292,  0.2146,\n",
      "        -1.1371,  1.2961, -1.1607, -1.1768,  0.9630,  0.9533, -0.9130, -0.5646,\n",
      "        -0.6221,  0.7541, -0.0058, -0.4986, -1.5709,  1.2741, -0.9130, -1.2433,\n",
      "        -0.3180, -1.3259, -0.4626, -1.1289,  1.7128,  0.4996,  0.2715, -0.6211,\n",
      "         1.2948, -0.6960, -1.2618, -0.2493, -0.3225, -0.2762, -0.7404, -0.8966,\n",
      "         0.8287, -0.9149, -1.1568, -0.6368,  1.8644,  0.5022, -0.5686, -0.7332,\n",
      "         0.9036,  1.1223,  0.5909, -0.5223,  0.4831, -0.6630, -0.9076, -0.6310,\n",
      "        -0.3758,  0.8322, -0.5036, -0.5983,  0.0941, -0.5983,  1.4446, -0.7842,\n",
      "         1.8090,  1.1291,  1.0660,  1.2092, -1.1585,  1.6444, -0.5230, -1.4019,\n",
      "        -0.4904, -0.5640,  1.0493, -1.1509, -1.0883, -0.9309, -0.1463, -0.5138,\n",
      "         1.0362, -0.9644,  0.6918,  0.2130,  1.0201,  0.7875, -1.1006, -1.1872,\n",
      "        -0.6590, -1.0851,  0.8419,  0.2083, -0.9872, -0.3242, -0.3951, -0.2952,\n",
      "        -1.4502,  0.9878, -1.0613,  0.9004,  0.4940, -2.0278, -0.8066, -0.5686,\n",
      "         0.4857,  0.7671,  0.1912,  0.4118, -0.6217,  1.0116, -0.5918,  0.8278,\n",
      "         0.0268, -0.4636, -0.7921,  0.6986, -0.4066, -0.3636, -2.1904, -0.4583,\n",
      "        -0.4938, -0.1352, -1.1813,  0.9209, -0.2497,  0.9673, -0.5545,  1.1211,\n",
      "         0.4321, -0.3027, -0.4893, -0.4295,  1.3061, -1.3529, -0.4158, -0.3760,\n",
      "         1.2575, -1.3498, -1.1114,  0.3520, -0.7047, -0.7068, -0.1985, -0.3442,\n",
      "         1.0806, -0.9606, -1.4305, -1.0362, -1.8104, -0.1445, -0.5125,  0.4875,\n",
      "         0.6840, -0.0372, -0.3344,  0.3660, -1.7536,  0.1931, -0.2430, -0.8781,\n",
      "        -0.3588,  1.1301, -0.3476, -1.0047,  0.6586, -0.7074,  0.9200, -1.2560,\n",
      "         0.1114,  0.0341,  0.2145,  0.0469,  0.1058,  0.8834, -0.3051, -0.4733,\n",
      "        -0.3888,  0.6855, -0.1786,  0.9710,  0.6930, -1.6657, -0.7414, -0.6999,\n",
      "         0.3444, -0.5981, -1.2141, -0.3307, -0.5679,  0.2207, -1.5616,  0.7742,\n",
      "        -0.7898, -0.2977,  0.5579, -0.4155, -0.9036,  0.8905, -0.5863,  0.8620,\n",
      "         0.1208,  0.0799,  0.2416,  1.0630, -0.5931, -0.3087, -0.8004, -0.2263,\n",
      "        -0.2625,  0.7086, -0.4142, -0.4338, -0.3942, -0.5089, -1.8433, -0.2722,\n",
      "        -1.2949,  1.5783, -0.5178, -1.1342,  1.4929, -0.2673, -0.8445, -0.4742,\n",
      "        -0.7723, -0.2038, -0.3284, -0.7931, -0.8864, -0.8143,  1.7137,  0.7791,\n",
      "        -0.9282,  0.5892,  0.9324, -0.3290,  1.0478,  0.6328, -0.8427, -0.2438,\n",
      "        -0.9944, -0.1634,  1.0415,  0.1271,  1.5426,  1.1661, -0.6123, -0.5170,\n",
      "        -1.3553, -1.2130,  0.6016,  0.8296,  1.0180, -1.5339,  0.1849, -0.7673,\n",
      "         0.7016, -0.8372,  0.2788, -0.9649,  1.0099,  1.1213, -0.7317, -0.2986,\n",
      "        -0.4299, -0.0905, -0.9613,  0.3332, -1.0449,  1.1246, -0.5923,  0.3384,\n",
      "        -0.7794,  0.1605, -0.4377, -0.9393, -0.8918,  1.2392,  0.2499, -1.0494,\n",
      "         0.9426, -1.1892, -0.1211,  0.7823, -0.8405, -0.3173,  1.6458,  0.1837,\n",
      "        -0.7861, -1.3125,  1.0233, -0.3617,  0.0294, -0.9505,  1.7220,  1.3329,\n",
      "         1.1693,  0.1442, -0.1146, -0.3431, -0.7092,  0.7841,  0.1143, -0.3184,\n",
      "        -0.8742, -0.2077, -0.5182, -0.8943, -1.4850,  0.0772,  0.9799, -1.1324,\n",
      "         0.4059, -0.6786, -0.5606, -0.3850,  0.4889, -1.2650,  0.6659, -0.9783,\n",
      "        -1.1068, -0.8386,  0.5612,  1.8278,  0.6380, -0.8829,  0.7750, -0.4572,\n",
      "         0.2229,  0.9251,  0.7157, -0.0487,  1.0651,  0.7988, -1.1671, -0.6217,\n",
      "         1.5175, -0.6479,  0.0353, -0.0257, -0.2374,  1.0639, -0.1375,  0.4640,\n",
      "        -0.8372, -0.5072,  0.9480, -1.5917, -1.0715,  0.3461, -0.9014, -0.9888,\n",
      "         0.0819,  0.7485,  1.4193,  0.4095,  0.6989,  0.8840,  0.3299, -0.9597,\n",
      "         0.9292, -1.1574, -0.3039, -1.3465,  1.1911,  0.8198,  0.9575,  0.2285,\n",
      "         0.2822, -0.6630, -1.0965, -0.8857,  0.7217, -0.9302,  0.6366,  0.2143,\n",
      "        -0.9629,  1.6650,  0.1615, -1.1545,  0.7701, -0.4936, -1.1289, -0.3316,\n",
      "        -0.6327,  0.9757, -1.3797,  0.9910, -0.9189,  0.9264, -1.0752, -0.0165,\n",
      "        -1.4630, -0.0193,  0.6926, -0.3484,  1.4911,  0.9454, -0.3153,  0.2820,\n",
      "         0.2633, -0.5402,  0.3417, -0.1181,  0.7823,  0.7177, -1.3429,  0.7656,\n",
      "        -0.4643,  0.1040, -0.3013, -1.1809, -0.7690,  0.0654, -1.1184, -0.3854,\n",
      "         0.5948, -0.4908,  1.0384, -0.8512,  0.8340,  0.0572, -0.8085, -0.5127,\n",
      "        -0.3778,  1.0267,  0.5011, -0.4411,  0.9047, -0.9646,  1.2831, -0.4127,\n",
      "         0.3210, -1.0962,  0.2295,  1.0944,  2.6226, -0.4814,  1.1250, -1.7387,\n",
      "         0.2137, -0.5122,  1.1955, -1.1227,  0.0431,  1.1662, -0.1080,  0.6472,\n",
      "        -0.7664, -0.7673,  0.9757,  0.4058, -1.3428, -0.5402,  0.7513, -0.7807,\n",
      "         0.7389, -0.0667,  0.6506, -1.3059,  0.2488, -0.8279,  0.9846,  0.4271,\n",
      "        -0.5092, -0.7782, -0.7228, -1.3777, -0.8181, -1.8669, -1.2679, -0.5725,\n",
      "        -0.1658, -0.7562,  0.9933,  0.9941, -0.2937,  1.4059, -1.4131,  0.8992,\n",
      "        -0.6052,  0.2530,  0.7580, -0.4844, -0.8323,  1.0647,  1.0082, -1.1124,\n",
      "        -0.6654,  1.9502, -1.0146, -1.1617,  0.3896, -0.1734, -0.6697, -0.3674,\n",
      "        -1.2886,  0.5226, -0.8277,  1.0143,  1.1877,  0.4029, -1.1714,  1.1450,\n",
      "         1.3128,  1.0496, -0.3495, -1.0058,  1.3469,  1.1624,  0.4734, -1.0472,\n",
      "        -0.7109, -0.8036, -1.1092, -0.4677, -0.5408, -0.1024, -0.8977, -0.7765,\n",
      "        -0.4485,  1.3851, -0.4757,  0.9442, -0.9680, -0.6108, -0.2888,  0.0328,\n",
      "         1.1300, -1.2357, -0.8466, -0.6994,  1.2976, -0.7381, -0.7913, -0.6992,\n",
      "        -0.6170, -0.6642, -0.7666,  1.3576, -0.9497,  0.8184, -1.6133, -0.6632,\n",
      "        -0.9331,  1.6116,  0.5895, -1.2166,  0.0251,  0.8025,  0.7678,  0.9914],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.2502, -0.0149,  0.0554],\n",
      "          [-0.3507,  0.1649,  0.1285],\n",
      "          [-0.2285, -0.0123,  0.0564]]],\n",
      "\n",
      "\n",
      "        [[[-0.1470, -0.2473, -0.1583],\n",
      "          [-0.0834,  0.1901, -0.0796],\n",
      "          [-0.0119,  0.0910, -0.0122]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0049, -0.0562, -0.0005],\n",
      "          [ 0.0460,  0.2950,  0.0577],\n",
      "          [ 0.0323, -0.0030,  0.0328]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0243, -0.0846, -0.0318],\n",
      "          [-0.1095, -0.0290, -0.1062],\n",
      "          [-0.0410, -0.0573, -0.0303]]],\n",
      "\n",
      "\n",
      "        [[[-0.0592,  0.0077,  0.0743],\n",
      "          [-0.1790, -0.1261,  0.3115],\n",
      "          [-0.0312, -0.0368,  0.0653]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0618,  0.0549, -0.0630],\n",
      "          [ 0.2736, -0.2357, -0.0828],\n",
      "          [ 0.0710,  0.0122, -0.0806]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 1, 3, 3])\n",
      "\n",
      "Layer: features.12.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.7387786507606506\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.7330069541931152\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.1.1.weight\n",
      "Weights: tensor([2.4282, 1.7792, 0.9545, 0.7237, 0.4956, 0.6601, 1.4097, 0.7290, 1.5516,\n",
      "        0.6433, 0.4899, 1.9683, 1.0465, 2.0732, 0.9317, 1.0753, 0.8108, 1.0408,\n",
      "        0.3029, 0.3020, 0.9358, 1.1935, 0.4798, 1.6786, 0.8206, 1.0803, 1.0839,\n",
      "        0.5407, 2.5465, 1.6927, 0.4276, 1.5744, 0.7190, 1.8281, 0.2702, 0.8418,\n",
      "        1.0459, 1.4696, 0.6636, 1.0264, 0.4562, 1.1605, 0.7001, 0.6450, 0.4866,\n",
      "        0.9881, 0.4005, 0.5278, 7.5271, 1.6746, 1.1837, 0.9033, 1.2240, 0.8668,\n",
      "        1.2476, 1.3858, 1.9979, 0.5478, 0.3100, 0.9661, 0.8033, 0.6894, 0.5171,\n",
      "        0.6359, 1.3790, 0.8069, 0.9061, 0.5301, 1.6342, 1.0581, 0.8618, 0.8894,\n",
      "        1.7244, 1.5724, 1.3776, 0.6281, 1.2243, 1.1148, 0.9390, 1.2784, 0.5945,\n",
      "        1.9044, 1.8594, 0.5541, 1.8656, 0.5042, 1.1007, 0.8104, 2.0613, 1.9487,\n",
      "        1.5225, 1.7498, 0.3431, 0.8633, 0.7034, 0.3085, 0.5810, 0.6203, 1.3033,\n",
      "        0.3151, 0.6704, 0.4847, 0.6230, 0.4874, 1.8478, 0.4280, 0.9097, 0.8560,\n",
      "        1.6406, 1.4412, 0.5498, 0.9938, 0.9620, 0.4487, 1.3928, 0.8611, 0.8861,\n",
      "        0.5855, 0.5384, 1.0326, 0.4295, 1.0708, 0.6205, 1.6281, 0.5928, 0.3322,\n",
      "        0.6798, 0.5186, 1.4557, 1.6072, 0.7009, 0.9365, 1.0126, 0.7692, 0.8327,\n",
      "        1.2755, 1.2228, 0.9752, 0.9543, 0.8477, 1.1637, 0.7316, 0.5000, 1.3177,\n",
      "        0.5585, 1.1303, 0.5879, 1.8551, 1.4565, 1.2055, 0.8417, 2.4325, 1.6096,\n",
      "        0.5631, 0.9960, 0.5949, 1.2056, 0.7598, 0.9797, 0.9061, 1.5141, 0.3620,\n",
      "        0.6733, 1.5526, 0.5402, 0.7995, 1.0534, 1.2963, 1.0212, 0.9885, 0.4081,\n",
      "        0.7082, 0.4406, 1.0698, 1.1345, 1.5832, 1.0460, 1.0396, 0.5652, 0.9170,\n",
      "        0.4225, 0.6598, 1.2473, 1.1809, 0.9978, 1.3969, 0.5749, 0.7135, 1.6792,\n",
      "        0.5514, 1.1435, 0.5067, 1.1200, 1.1333, 1.0347, 1.4585, 1.1274, 1.7757,\n",
      "        1.0351, 1.0162, 1.1708, 1.1482, 1.4847, 1.5436, 1.6094, 0.5328, 0.8140,\n",
      "        0.6854, 1.7336, 0.6948, 0.6532, 0.9570, 0.5447, 1.3354, 0.4538, 1.1129,\n",
      "        0.7849, 1.0626, 1.2522, 0.6139, 0.7744, 1.1714, 0.8191, 1.0027, 0.9042,\n",
      "        0.6994, 1.7639, 1.7226, 0.7047, 0.9111, 0.4231, 0.6671, 0.5889, 0.9673,\n",
      "        0.5877, 0.7120, 0.6730, 0.7607, 0.3774, 0.8247, 0.4231, 0.9208, 0.7302,\n",
      "        0.8481, 1.8412, 0.6144, 0.8018, 0.5506, 0.3834, 1.5172, 0.9001, 0.8764,\n",
      "        0.8549, 0.7173, 1.1625, 1.2704, 0.6502, 1.0013, 1.2931, 1.4877, 1.3594,\n",
      "        0.7463, 0.5541, 0.5378, 0.8572, 0.9438, 0.8813, 1.1251, 1.9092, 1.2250,\n",
      "        0.8782, 1.4410, 0.3309, 0.2765, 1.5123, 1.4486, 1.6100, 0.5663, 1.2009,\n",
      "        0.5181, 1.0698, 0.3973, 1.5553, 0.9966, 1.3423, 1.6820, 0.5036, 0.8306,\n",
      "        0.9670, 1.1639, 0.4025, 1.5109, 0.4377, 1.2634, 0.9471, 1.4311, 1.1933,\n",
      "        0.6294, 0.6906, 0.8194, 0.3749, 1.6931, 1.1419, 0.5539, 1.3203, 0.4005,\n",
      "        0.6440, 2.6093, 1.0933, 0.6581, 1.9210, 1.1822, 0.7502, 0.3798, 1.2758,\n",
      "        1.0324, 1.4132, 0.4606, 2.1505, 1.6695, 0.8137, 1.8482, 0.7726, 0.8756,\n",
      "        1.1325, 1.3158, 1.1004, 1.0764, 0.7385, 1.2131, 0.7776, 0.4854, 0.8295,\n",
      "        0.6620, 1.0742, 0.5973, 1.2576, 0.7367, 0.6976, 1.6050, 1.1303, 0.8329,\n",
      "        2.2187, 0.5795, 0.4293, 0.4829, 0.9357, 1.5880, 0.6528, 0.9164, 0.9548,\n",
      "        1.3613, 1.9138, 0.6641, 0.8794, 0.9962, 1.4904, 0.7050, 1.0202, 0.6555,\n",
      "        2.9536, 0.7746, 1.0508, 0.9899, 1.9621, 1.4174, 0.9231, 2.1111, 0.4008,\n",
      "        0.7586, 0.9798, 0.3967, 0.5105, 1.4165, 0.6848, 0.4340, 1.1194, 1.4320,\n",
      "        1.3109, 0.8696, 1.8418, 1.9441, 1.7986, 0.4511, 1.1697, 0.4013, 0.9422,\n",
      "        0.3168, 0.9064, 0.8928, 1.6796, 2.2639, 1.8203, 1.0864, 0.7563, 0.7701,\n",
      "        0.9609, 0.8371, 1.2652, 2.2131, 0.6831, 1.7815, 1.6986, 0.7000, 1.1821,\n",
      "        1.0649, 0.5072, 1.1072, 1.3887, 1.1888, 0.5642, 1.0549, 0.5675, 1.9479,\n",
      "        0.6194, 1.2150, 0.5298, 1.7399, 1.6386, 0.8850, 1.1135, 1.3646, 1.7816,\n",
      "        1.3823, 2.8954, 0.5073, 1.7709, 1.4656, 1.0218, 1.0435, 0.4192, 1.1486,\n",
      "        0.6225, 1.7116, 0.6083, 0.3603, 0.5394, 1.3908, 0.5414, 0.5266, 1.7806,\n",
      "        0.9830, 2.2684, 0.7403, 1.3120, 0.8443, 0.4905, 0.9295, 0.9759, 1.6651,\n",
      "        1.4429, 0.7804, 1.3081, 0.3029, 1.3485, 0.5983, 1.5297, 0.6535, 0.9130,\n",
      "        1.3221, 2.1250, 0.9917, 1.2564, 0.5834, 1.4722, 0.4681, 1.6137, 0.3534,\n",
      "        0.7826, 2.3663, 0.9900, 1.8368, 0.7923, 0.5480, 1.3865, 1.4019, 0.4751,\n",
      "        1.0142, 2.0851, 0.9391, 1.5687, 2.7335, 1.6415, 0.6970, 1.8528, 0.4689,\n",
      "        1.7362, 0.6705, 0.8370, 0.8393, 0.4461, 0.4136, 0.4806, 0.3729, 0.2611,\n",
      "        1.0660, 1.3203, 0.7912, 1.7196, 1.6106, 0.5866, 1.3910, 0.7002, 1.7569,\n",
      "        0.6894, 1.1606, 1.2004, 1.6287, 0.6509, 1.1571, 1.4449, 0.5703, 0.9335,\n",
      "        0.9646, 0.4537, 0.4907, 0.6232, 1.5001, 1.0357, 1.4053, 0.3391, 1.1164,\n",
      "        0.4976, 0.9597, 1.6667, 1.3301, 0.9194, 1.6795, 1.1876, 1.2066, 0.8515,\n",
      "        0.9895, 1.7147, 1.4887, 1.2370, 0.5663, 0.8051, 0.7490, 4.4756, 0.7742,\n",
      "        0.8968, 1.0642, 0.6190, 0.6906, 0.5314, 1.5982, 2.1105, 1.7066, 0.3101,\n",
      "        0.8730, 1.4124, 0.9954, 1.2737, 0.4275, 0.5834, 0.7479, 2.1442, 0.7786,\n",
      "        0.7148, 0.7906, 0.8145, 1.0509, 0.9281, 2.1020, 1.0963, 1.2267, 0.4821,\n",
      "        0.5009, 0.4489, 2.2948, 1.6155, 0.3683, 1.8694, 2.2825, 1.3395, 1.2933],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.1.1.bias\n",
      "Weights: tensor([-8.0932e-01, -1.1458e+00, -2.1539e+00, -3.4944e-02,  6.0243e-01,\n",
      "        -9.5184e-01, -7.9764e-01, -4.4790e-01, -6.9726e-01, -4.8719e-01,\n",
      "        -5.8514e-01, -6.5039e-01, -1.1677e+00, -1.7226e+00, -3.0042e-01,\n",
      "        -9.0455e-01,  5.6477e-02, -2.0846e+00,  1.9696e+00,  2.0774e+00,\n",
      "        -6.0894e-01, -7.7356e-01,  1.6199e+00, -1.0844e+00, -2.6562e+00,\n",
      "        -2.2114e+00, -3.0650e-01,  1.1861e-01, -1.1113e+00, -2.1015e-01,\n",
      "         1.3017e+00, -8.8813e-01, -1.6117e+00, -2.0199e+00,  1.1959e+00,\n",
      "        -1.4172e+00, -1.9256e-01, -9.8474e-01, -5.2656e-01, -1.9984e+00,\n",
      "         6.9846e-01, -1.3315e+00, -7.4338e-02, -1.2009e-01, -4.5935e-01,\n",
      "         7.0889e-01,  7.3756e-01, -2.3757e-01, -3.6741e+00, -1.5698e+00,\n",
      "        -6.3920e-01, -1.7679e+00, -1.3115e+00,  1.2234e-02, -1.1894e+00,\n",
      "        -8.5446e-01, -2.6181e+00,  1.8864e+00,  1.9623e+00, -1.2197e+00,\n",
      "        -8.0108e-01, -5.3564e-01,  1.0920e-01, -1.5352e+00, -8.6823e-01,\n",
      "        -8.0846e-01, -1.7295e+00,  2.8383e+00, -7.2257e-01, -5.0934e-01,\n",
      "        -1.4077e+00, -1.0466e-01, -2.1656e+00, -1.3624e+00, -2.1838e+00,\n",
      "        -1.7546e-01, -1.2668e+00, -2.1400e+00, -1.7061e+00, -3.5751e+00,\n",
      "         8.9188e-01, -1.5900e+00, -7.3144e-01,  1.1616e+00, -1.2185e+00,\n",
      "         1.5260e+00, -4.8037e-01, -6.7007e-01, -2.6440e+00, -1.6013e+00,\n",
      "        -1.3425e+00, -1.1741e+00,  1.9283e+00, -2.0142e-01, -6.7792e-01,\n",
      "         1.8184e+00,  2.3860e+00, -3.9743e-01, -7.2694e-01,  1.4844e+00,\n",
      "        -1.1631e+00,  1.7579e+00,  2.4693e+00,  1.0985e+00, -1.1610e+00,\n",
      "        -8.7563e-03,  2.8343e-02, -1.8461e-02, -1.2353e+00, -1.1708e+00,\n",
      "         4.8391e-01, -2.9740e+00, -1.7134e+00, -1.4473e-01, -8.7900e-01,\n",
      "        -3.1476e-01, -1.5151e+00,  1.7042e+00,  2.2119e+00, -2.0712e+00,\n",
      "         2.5272e+00, -3.4521e-01, -1.0592e+00, -1.8490e+00,  6.3638e-01,\n",
      "        -2.5325e-02, -7.0050e-01, -1.1579e-02, -1.7567e+00, -1.0711e+00,\n",
      "         6.2337e-01, -2.9964e-01, -3.3705e-02,  8.4212e-01, -1.3612e+00,\n",
      "        -6.7699e-01, -8.4403e-01, -1.4092e+00, -1.4416e+00,  8.2640e-02,\n",
      "        -2.3956e-01,  1.4113e-01, -1.0092e+00, -3.5427e-01,  1.5644e+00,\n",
      "        -1.7942e+00, -1.2709e+00, -2.3010e+00, -3.6317e+00, -6.6137e-01,\n",
      "        -8.2339e-01, -2.3166e+00, -1.0785e+00,  6.0278e-01, -1.9012e+00,\n",
      "         1.4498e+00,  2.9083e-01, -1.9238e+00, -1.6451e+00, -9.6885e-01,\n",
      "        -1.5886e+00,  1.8849e+00, -9.0964e-01, -6.6321e-01,  1.5028e+00,\n",
      "         2.1141e-01, -2.3031e+00, -1.8189e+00, -5.6305e-02, -2.5828e+00,\n",
      "         1.4718e-01, -1.6234e+00, -5.1860e-01, -4.3839e-01, -1.8736e-01,\n",
      "        -1.6116e+00, -8.4465e-01, -1.5694e+00,  3.5765e-02, -3.5417e-01,\n",
      "         6.2846e-02,  1.8221e+00, -3.4415e-01, -3.3022e+00, -1.3070e-01,\n",
      "        -8.0286e-01,  1.6555e+00, -1.2576e+00, -1.2671e+00,  1.9582e+00,\n",
      "        -3.5472e-01, -2.5413e-01, -1.7540e+00, -1.3509e-01, -4.8881e-01,\n",
      "        -3.4612e-01, -1.2411e+00, -2.6800e+00, -1.3325e+00, -1.6855e+00,\n",
      "        -7.6053e-01, -6.0988e-01, -3.2133e+00, -8.9766e-01, -7.8407e-01,\n",
      "        -2.7126e+00, -1.2474e+00, -4.8281e-01, -1.1053e+00, -7.5748e-01,\n",
      "        -1.2171e+00,  3.5231e-02,  4.1453e-01, -1.3754e+00, -3.2979e-01,\n",
      "        -1.0288e+00, -1.7185e+00, -1.8607e+00, -1.3763e+00, -3.3111e-02,\n",
      "        -1.0448e+00, -6.7579e-01, -2.5608e-01, -2.4268e-01, -5.1690e-01,\n",
      "         5.7827e-02, -1.1857e+00, -1.8234e+00, -5.1304e-01, -8.8112e-01,\n",
      "         5.8419e-01, -1.5307e-01,  1.1777e+00, -2.1331e-01,  2.2192e+00,\n",
      "         2.9095e-01,  3.4487e-01, -3.7711e-01, -8.3142e-01, -6.4945e-01,\n",
      "         4.6079e-01, -2.5142e-01, -9.9721e-01, -2.3965e+00, -2.4828e+00,\n",
      "         1.1946e+00, -1.0406e+00,  4.2025e-01,  1.9842e+00, -3.6943e-01,\n",
      "        -1.2033e+00, -1.4625e+00, -1.8663e-03, -4.9404e-01,  5.4307e-01,\n",
      "        -6.9208e-01, -1.0511e+00, -9.1252e-01, -8.8746e-01, -6.6773e-01,\n",
      "        -9.0099e-01,  8.2044e-02,  2.1735e+00,  1.2882e-01, -1.5929e+00,\n",
      "        -6.3665e-01,  1.8061e-01, -1.4088e+00, -2.8788e+00, -4.3982e-01,\n",
      "         7.1730e-02, -5.2930e-01,  1.9640e+00,  1.4204e+00, -8.8340e-01,\n",
      "        -1.0821e+00, -1.3394e+00,  2.0239e-01, -2.0605e+00,  2.4701e+00,\n",
      "        -5.6264e-01,  1.9846e-01, -7.8620e-01, -1.4892e+00, -7.3350e-01,\n",
      "        -1.2640e+00,  1.6613e+00, -7.7084e-01,  3.3435e-02, -4.3058e-01,\n",
      "         1.0310e-01, -8.9603e-01,  1.1180e+00, -1.0972e+00, -1.8616e+00,\n",
      "        -6.8486e-01, -4.0330e+00,  9.8712e-01,  1.9643e-01, -1.8555e+00,\n",
      "         2.1691e+00, -1.5229e+00, -3.1399e-01, -5.3322e-01, -1.0043e+00,\n",
      "         1.6265e-01,  3.2754e-02, -2.5389e+00, -2.2078e+00,  1.4984e+00,\n",
      "        -2.5931e+00, -1.2881e+00, -1.4852e+00,  1.7641e+00, -8.3404e-01,\n",
      "        -2.0654e+00, -9.6257e-01,  1.1866e+00, -3.3557e+00, -1.6826e+00,\n",
      "         9.0249e-01, -9.3782e-01, -1.6744e-01, -1.5061e+00, -2.4672e+00,\n",
      "        -9.4117e-01, -9.9211e-01,  6.5697e-03, -1.8668e+00, -2.5769e+00,\n",
      "        -6.8563e-01,  1.4269e+00, -1.1487e+00,  8.2680e-01, -3.7793e-01,\n",
      "        -5.1438e-02, -8.0703e-01, -2.9866e-01,  8.5095e-01, -1.2344e-01,\n",
      "        -5.6101e-01, -1.1179e+00, -2.0259e+00,  1.0193e+00,  2.4634e-01,\n",
      "         2.3468e+00, -2.4160e-01, -7.2360e-01,  1.3661e+00, -1.3824e+00,\n",
      "        -2.0245e-01, -4.7602e-01, -6.9351e-01,  2.0528e+00,  9.8393e-02,\n",
      "        -8.4243e-01, -9.5411e-01,  1.0924e+00, -6.4743e-02, -5.3829e-01,\n",
      "        -3.2556e+00, -8.4056e-01, -1.2633e+00, -1.5120e-01, -1.3198e+00,\n",
      "        -1.2598e+00, -1.2047e+00, -1.6793e+00,  1.6157e+00, -5.3402e-01,\n",
      "        -3.8228e-01, -9.3500e-01,  8.2166e-01, -9.2249e-01, -8.5994e-01,\n",
      "         7.2473e-01, -1.3332e+00, -1.1662e+00,  6.3529e-02,  9.3258e-02,\n",
      "        -1.1359e+00, -1.6749e+00, -1.1370e+00,  1.1249e+00, -5.9948e-01,\n",
      "         2.4422e+00, -1.6797e+00,  2.2411e+00,  7.6514e-01, -1.7138e-01,\n",
      "        -1.3131e+00, -1.3288e+00, -1.3166e+00, -2.5516e+00, -2.0522e+00,\n",
      "        -9.2726e-01, -4.2768e-01, -1.8044e+00, -5.7382e-01, -1.5339e+00,\n",
      "        -7.9911e-01, -1.5493e+00, -8.1879e-01, -5.8963e-01, -6.0646e-01,\n",
      "        -5.1935e-01,  1.5311e+00, -1.2098e+00,  4.4674e+00, -5.7971e-01,\n",
      "        -3.1972e-01,  1.3471e-01,  1.8633e+00, -2.0369e+00, -1.2472e+00,\n",
      "        -2.1405e+00,  1.3699e+00, -7.9686e-01, -7.6680e-01, -1.2145e+00,\n",
      "        -3.3094e-01, -5.5803e-01, -7.0034e-01, -7.0254e-01, -1.4267e+00,\n",
      "         6.0199e-01, -1.1868e+00, -8.9215e-01, -3.9965e-01, -4.0879e-01,\n",
      "         5.4792e-02, -5.0704e-01, -1.7241e-01, -7.4222e-01,  2.0295e+00,\n",
      "         1.7037e+00, -3.8423e-01, -1.9980e+00,  1.7339e+00,  1.1139e+00,\n",
      "        -1.1971e+00, -1.6718e+00, -1.7710e+00, -1.2929e+00, -6.6464e-01,\n",
      "        -1.9437e-01,  5.4585e-01, -1.1522e+00, -1.5923e+00, -1.2858e+00,\n",
      "        -1.7372e+00, -2.4557e-01, -1.5580e+00,  1.2403e+00, -5.2539e-01,\n",
      "         2.4710e+00, -2.7286e+00, -1.2378e+00, -1.0141e-01, -4.7786e-01,\n",
      "        -3.8797e+00, -1.2020e+00, -5.0355e-01, -1.0291e+00, -7.4620e-01,\n",
      "         6.8660e-01, -1.3118e+00,  1.6219e+00,  4.3774e-02, -2.4227e+00,\n",
      "        -8.3605e-01, -1.6229e+00, -1.2333e+00, -2.7576e-01, -1.0605e+00,\n",
      "        -1.6703e+00,  2.7291e-01,  1.3722e-01, -1.2323e+00, -2.2285e+00,\n",
      "        -7.7863e-01, -9.6576e-01, -1.1675e+00, -2.1090e+00, -9.9341e-01,\n",
      "         2.3987e+00, -1.2857e+00,  1.5576e+00,  3.4685e-01, -1.3108e+00,\n",
      "         9.5441e-01,  9.1367e-01, -8.9250e-02, -9.3014e-01,  1.7949e+00,\n",
      "         1.6024e+00, -2.4577e+00, -6.5314e-01, -1.5003e+00, -1.3231e+00,\n",
      "         2.3494e+00, -8.2764e-01, -1.1047e+00, -1.2504e+00, -5.3919e-01,\n",
      "        -1.0350e+00, -8.7080e-01, -2.6022e+00, -6.8815e-01, -4.4726e-01,\n",
      "        -1.0419e+00,  7.5637e-01, -9.2546e-01,  2.7675e-01,  2.7273e+00,\n",
      "        -1.3876e+00,  6.9717e-01, -6.8049e-01, -1.9647e+00, -4.0191e-01,\n",
      "         1.5084e+00, -6.6711e-01,  2.0306e+00, -7.1832e-02, -1.1747e+00,\n",
      "        -6.7612e-01,  1.2594e+00, -9.4040e-01, -7.5183e-01, -1.1178e+00,\n",
      "        -8.0807e-01, -1.6969e+00, -1.3043e+00, -9.3966e-01, -3.7421e-01,\n",
      "         1.0133e+00, -1.1398e+00, -6.4484e-01, -2.5970e+00,  2.3351e-01,\n",
      "        -4.6400e-01, -1.3271e+00,  3.8755e-01, -1.2803e+00,  2.3033e+00,\n",
      "        -1.4908e+00,  1.8435e+00, -1.3741e+00,  1.0245e+00, -1.3083e+00,\n",
      "        -5.2057e-01, -1.2770e+00, -1.2733e-01,  3.3303e-02, -5.5523e-02,\n",
      "        -1.3380e+00, -2.3420e+00, -1.3307e+00, -8.5217e-01, -1.1927e+00,\n",
      "        -8.5589e-01, -2.3694e+00, -1.1539e+00, -2.0729e+00,  4.0806e-01,\n",
      "        -1.2590e+00, -1.2139e+00,  4.3243e-01,  2.3257e+00, -2.1106e+00,\n",
      "        -1.0345e+00,  2.5232e+00, -1.2316e+00, -1.7285e+00, -8.1632e-01,\n",
      "        -8.2319e-01], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.2.weight\n",
      "Weights: tensor([[[[-0.0192]],\n",
      "\n",
      "         [[ 0.0299]],\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[-0.0027]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0433]],\n",
      "\n",
      "         [[-0.0250]],\n",
      "\n",
      "         [[-0.0830]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1334]],\n",
      "\n",
      "         [[ 0.0183]],\n",
      "\n",
      "         [[-0.1385]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0186]],\n",
      "\n",
      "         [[ 0.0570]],\n",
      "\n",
      "         [[ 0.0142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[-0.0046]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0250]],\n",
      "\n",
      "         [[-0.0187]],\n",
      "\n",
      "         [[ 0.1177]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0618]],\n",
      "\n",
      "         [[ 0.1063]],\n",
      "\n",
      "         [[-0.0730]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0555]],\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.0612]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.0019]],\n",
      "\n",
      "         [[ 0.0068]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0401]],\n",
      "\n",
      "         [[-0.0652]],\n",
      "\n",
      "         [[ 0.0639]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1122]],\n",
      "\n",
      "         [[ 0.0915]],\n",
      "\n",
      "         [[-0.0669]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 576, 1, 1])\n",
      "\n",
      "Layer: features.12.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.3922070860862732\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.3891429603099823\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.3.weight\n",
      "Weights: tensor([2.5566, 0.8799, 2.5256, 1.0240, 2.3386, 2.8116, 3.5005, 2.4960, 2.2585,\n",
      "        2.4022, 1.0821, 2.1034, 1.1050, 0.9187, 1.4641, 1.8530, 1.6998, 2.8533,\n",
      "        1.1295, 0.8574, 3.2371, 1.6772, 2.0554, 0.9517, 1.6768, 2.7320, 3.2117,\n",
      "        1.3508, 1.5073, 2.5650, 2.2337, 0.6147, 3.0230, 0.8017, 0.8199, 2.5508,\n",
      "        2.6607, 1.1814, 2.6815, 2.8206, 2.3871, 2.3340, 1.0578, 3.1964, 2.0758,\n",
      "        1.2527, 1.7326, 1.3768, 1.2452, 1.1427, 0.9360, 2.8195, 2.7087, 0.9215,\n",
      "        3.1640, 0.9920, 2.2958, 0.9024, 2.6961, 3.7496, 1.8943, 1.4735, 3.4808,\n",
      "        0.9716, 2.2611, 1.6436, 2.2246, 2.2479, 1.3220, 2.8476, 1.0036, 2.6411,\n",
      "        2.0302, 2.9014, 2.2884, 2.0796, 2.5196, 2.4327, 1.6998, 2.7087, 1.8828,\n",
      "        2.7406, 0.8264, 2.2532, 2.5534, 2.0674, 2.6120, 2.5335, 2.4617, 2.4381,\n",
      "        1.3527, 3.0385, 1.4872, 2.7635, 2.2262, 1.4745], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.12.conv.3.bias\n",
      "Weights: tensor([ 6.0900e-08, -1.7132e-07, -4.4346e-07,  1.5697e-06,  5.6462e-07,\n",
      "        -5.9357e-07, -1.3538e-06,  1.4029e-07, -4.2060e-07,  2.5664e-06,\n",
      "        -8.9918e-07, -7.0696e-07, -4.4270e-07, -7.3537e-07, -8.0812e-07,\n",
      "        -1.1608e-06, -3.1466e-07, -9.2736e-07,  1.2319e-06, -9.7317e-07,\n",
      "        -2.9163e-07,  6.8122e-07,  1.9007e-07, -9.5589e-07,  1.1879e-06,\n",
      "         3.3525e-08,  5.9936e-07, -4.4263e-07, -9.2492e-08,  4.0659e-07,\n",
      "         6.2321e-07,  1.2343e-06, -1.6967e-07, -8.6141e-08,  1.0967e-06,\n",
      "        -1.2139e-06, -2.4498e-08,  2.5625e-07, -1.3401e-06, -1.3326e-07,\n",
      "         7.5974e-08,  3.0751e-07,  2.3745e-07,  2.7966e-06,  1.1673e-07,\n",
      "        -3.7220e-07,  1.7071e-07,  7.2120e-07, -1.8418e-07, -1.2193e-06,\n",
      "         1.3361e-06,  2.3924e-07,  2.1791e-06,  1.7179e-07,  1.9085e-07,\n",
      "         8.6696e-07,  5.0692e-07,  1.5688e-06, -2.5235e-07, -6.9693e-07,\n",
      "         3.9662e-07, -6.2366e-07, -1.2281e-06,  6.6132e-07, -6.8678e-07,\n",
      "         5.5917e-09, -7.0969e-07, -9.2249e-07,  1.3493e-06,  4.5264e-07,\n",
      "         1.1563e-06,  7.7708e-08, -1.3121e-06,  1.1066e-07, -2.1409e-07,\n",
      "         2.9934e-07,  1.9704e-07, -2.8354e-07, -4.0097e-07, -6.5712e-09,\n",
      "         8.4551e-07, -1.9412e-07,  1.1275e-06,  2.4918e-07, -2.0902e-07,\n",
      "         1.1418e-06, -5.6945e-07, -4.1021e-07, -1.3950e-06,  8.4881e-07,\n",
      "        -2.4792e-07, -2.3087e-07,  9.8330e-07,  1.1036e-06, -3.8849e-07,\n",
      "         1.2057e-07], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.12.conv.3.output_quantizers.0.min\n",
      "Weights: -17.582969665527344\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.12.conv.3.output_quantizers.0.max\n",
      "Weights: 21.011611938476562\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.0.0.weight\n",
      "Weights: tensor([[[[ 6.9506e-02]],\n",
      "\n",
      "         [[-3.0436e-01]],\n",
      "\n",
      "         [[-1.8298e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3036e-02]],\n",
      "\n",
      "         [[-5.8360e-02]],\n",
      "\n",
      "         [[ 1.7919e-05]]],\n",
      "\n",
      "\n",
      "        [[[-7.1825e-02]],\n",
      "\n",
      "         [[ 7.4089e-02]],\n",
      "\n",
      "         [[-9.2468e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7030e-02]],\n",
      "\n",
      "         [[-6.3917e-02]],\n",
      "\n",
      "         [[ 1.0711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3651e-02]],\n",
      "\n",
      "         [[ 6.6046e-02]],\n",
      "\n",
      "         [[-7.9683e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5008e-02]],\n",
      "\n",
      "         [[-4.0352e-02]],\n",
      "\n",
      "         [[ 1.4514e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0869e-01]],\n",
      "\n",
      "         [[ 5.4524e-02]],\n",
      "\n",
      "         [[-1.2877e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2411e-02]],\n",
      "\n",
      "         [[ 2.8880e-02]],\n",
      "\n",
      "         [[-1.1429e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3083e-01]],\n",
      "\n",
      "         [[ 8.4584e-02]],\n",
      "\n",
      "         [[ 1.0164e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3755e-02]],\n",
      "\n",
      "         [[ 2.8529e-02]],\n",
      "\n",
      "         [[-1.4559e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0942e-01]],\n",
      "\n",
      "         [[ 2.4684e-02]],\n",
      "\n",
      "         [[-1.3093e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1508e-02]],\n",
      "\n",
      "         [[-7.3107e-03]],\n",
      "\n",
      "         [[-4.8259e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 96, 1, 1])\n",
      "\n",
      "Layer: features.13.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.4864993393421173\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.48269855976104736\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.0.0.input_quantizers.0.min\n",
      "Weights: -27.28678321838379\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.0.0.input_quantizers.0.max\n",
      "Weights: 30.23141860961914\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.0.1.weight\n",
      "Weights: tensor([1.3129, 1.0618, 0.7200, 1.2027, 1.2718, 1.0866, 1.0842, 0.9471, 1.1074,\n",
      "        0.9508, 1.4767, 1.0490, 1.0604, 0.9947, 1.2521, 0.9903, 1.0383, 1.2287,\n",
      "        1.3168, 1.1587, 1.1425, 1.0854, 1.3487, 1.3563, 1.0245, 1.0061, 1.2161,\n",
      "        1.2119, 0.7751, 0.9133, 1.1162, 1.1046, 0.8038, 1.1261, 1.3268, 1.1021,\n",
      "        1.0180, 1.2447, 0.7256, 0.8709, 0.4411, 1.5799, 1.0443, 1.2683, 0.7446,\n",
      "        1.2719, 1.1950, 1.5865, 1.0757, 0.7835, 1.2679, 1.1946, 1.0675, 1.2318,\n",
      "        0.6320, 1.0234, 1.0827, 1.1088, 1.4074, 1.3521, 0.8974, 1.0228, 0.8644,\n",
      "        0.9510, 0.8855, 1.0914, 1.0687, 1.1979, 0.7114, 1.1609, 1.3959, 0.9946,\n",
      "        1.1130, 0.9168, 1.3126, 1.2539, 1.1357, 1.4045, 1.5096, 1.0838, 1.1538,\n",
      "        0.6779, 1.1156, 1.1276, 1.1828, 0.9958, 1.2208, 1.1785, 1.2781, 1.2800,\n",
      "        0.4491, 1.2448, 1.0671, 1.3866, 1.1853, 1.1681, 1.2599, 1.0552, 0.9769,\n",
      "        1.1391, 0.9111, 1.1001, 0.8669, 1.0563, 0.9955, 1.1489, 0.9614, 0.9816,\n",
      "        0.9896, 1.1416, 1.1443, 1.3810, 1.2908, 0.4846, 1.1871, 0.4989, 1.4014,\n",
      "        1.0956, 1.0591, 0.8586, 1.0703, 1.0453, 0.9787, 0.9072, 1.1783, 0.4811,\n",
      "        1.3998, 1.1922, 1.3140, 1.2020, 0.9656, 1.0911, 0.6768, 0.9981, 1.1826,\n",
      "        1.1181, 1.2746, 1.0999, 1.1846, 0.6863, 0.8138, 1.4665, 0.9795, 0.4337,\n",
      "        1.1977, 0.6705, 1.1631, 1.2865, 0.8715, 1.1423, 1.1292, 0.5405, 1.1027,\n",
      "        1.0993, 1.1784, 1.0654, 1.1474, 1.2254, 1.1429, 1.1735, 1.0598, 1.0654,\n",
      "        1.0796, 1.2650, 1.1115, 1.2671, 1.1915, 1.0346, 0.9940, 1.2043, 0.8977,\n",
      "        1.0947, 0.7239, 1.4571, 1.0712, 1.2287, 1.1926, 1.0028, 0.9783, 1.2926,\n",
      "        0.9655, 1.1899, 1.1259, 0.8602, 1.1860, 0.7926, 1.1168, 2.5590, 1.0953,\n",
      "        1.2097, 0.7910, 1.3285, 1.0092, 1.1975, 1.1952, 0.9178, 0.7386, 1.0510,\n",
      "        0.7376, 1.1714, 1.0528, 1.1573, 1.3372, 1.1365, 1.3110, 1.2517, 1.1887,\n",
      "        1.0085, 0.9935, 0.9156, 1.1824, 0.9357, 1.2701, 1.0550, 1.1813, 1.4455,\n",
      "        1.1943, 0.9530, 0.6520, 1.5878, 0.9144, 1.0554, 1.3685, 0.9797, 1.0870,\n",
      "        0.6975, 1.0098, 1.2240, 1.0463, 1.1554, 1.0632, 1.0978, 1.3450, 1.2912,\n",
      "        1.0816, 0.9215, 1.6081, 0.4660, 1.1378, 1.6015, 0.8906, 1.0390, 0.9744,\n",
      "        0.8568, 1.1076, 0.6379, 1.1993, 1.3284, 1.3123, 1.0091, 1.3354, 1.1221,\n",
      "        1.1206, 0.6315, 0.9109, 1.1393, 1.1778, 1.5572, 1.5241, 0.9288, 1.1048,\n",
      "        0.9926, 1.0524, 0.3631, 1.3050, 0.8990, 0.4773, 1.0395, 1.0278, 1.1300,\n",
      "        1.3414, 1.2611, 1.1289, 1.3272, 0.4039, 0.8373, 1.2432, 1.2143, 1.0308,\n",
      "        1.2759, 1.2228, 1.1821, 1.0093, 1.3454, 0.8026, 0.5041, 1.4054, 1.1766,\n",
      "        0.8456, 0.9704, 0.6301, 1.2475, 1.1624, 0.4767, 1.2807, 1.4405, 0.8213,\n",
      "        0.6578, 1.1539, 1.0873, 0.8319, 1.1546, 0.8593, 1.1199, 1.2137, 0.9010,\n",
      "        0.7823, 1.3559, 0.7087, 1.1617, 1.0567, 1.1287, 0.7434, 1.0020, 1.1926,\n",
      "        0.6755, 1.1587, 1.0516, 1.1138, 1.1823, 0.7727, 1.1625, 0.9154, 1.1492,\n",
      "        1.2106, 1.1802, 1.2727, 1.3185, 1.1623, 1.0592, 1.1130, 1.4003, 1.2998,\n",
      "        1.2054, 1.1044, 1.0144, 1.1061, 1.2095, 0.5116, 0.8698, 1.1739, 0.7052,\n",
      "        1.0875, 1.5356, 1.3684, 0.7980, 1.0604, 0.9175, 1.3008, 1.0075, 1.2371,\n",
      "        1.2768, 1.3003, 0.8126, 1.0749, 1.1761, 1.2453, 0.7871, 1.2353, 0.9494,\n",
      "        0.9589, 1.1302, 0.3915, 1.0358, 1.1361, 1.1976, 1.2470, 1.0555, 0.8121,\n",
      "        1.0846, 1.1591, 1.2149, 0.9765, 1.2567, 1.1599, 1.2371, 1.1225, 1.1103,\n",
      "        1.0066, 0.3822, 1.2120, 1.3083, 1.3634, 1.1283, 0.7825, 1.2514, 1.1331,\n",
      "        1.4325, 1.1645, 1.0921, 1.2001, 1.1854, 1.2786, 0.4991, 0.1092, 1.2047,\n",
      "        1.1430, 0.8163, 1.2333, 1.1564, 1.1607, 1.4303, 1.1883, 1.2928, 1.1048,\n",
      "        1.3014, 0.6405, 1.0837, 1.1507, 1.1334, 1.3134, 1.1526, 1.0000, 1.1264,\n",
      "        1.1192, 0.7816, 1.0529, 1.1445, 1.1844, 1.2384, 0.9860, 1.0113, 1.1329,\n",
      "        1.0594, 1.0936, 1.2185, 1.3098, 1.1937, 1.1694, 0.9203, 1.0866, 1.0402,\n",
      "        1.5230, 1.3623, 1.2044, 1.1555, 1.1827, 1.2313, 1.3152, 1.1065, 1.2472,\n",
      "        1.0599, 1.0144, 1.2290, 1.2482, 0.9341, 1.1471, 1.1330, 1.2763, 1.1171,\n",
      "        1.2160, 1.0820, 1.2000, 1.2348, 1.2416, 1.2248, 1.1638, 1.1699, 1.3080,\n",
      "        0.9134, 1.3910, 0.5787, 1.0071, 1.1055, 1.0031, 0.4281, 1.0586, 0.9351,\n",
      "        1.2837, 0.8398, 1.4458, 0.7638, 1.1583, 1.3845, 0.7143, 1.0907, 1.1861,\n",
      "        1.0604, 0.7736, 1.0600, 0.5647, 1.3120, 0.8468, 1.2982, 1.1004, 0.4552,\n",
      "        0.3966, 1.1247, 1.3536, 1.0594, 1.2834, 0.8949, 1.1303, 1.3833, 1.2030,\n",
      "        1.1001, 1.1248, 0.7706, 1.3213, 1.3188, 1.2185, 1.0171, 1.1595, 0.8498,\n",
      "        0.8135, 1.0636, 1.2781, 1.0573, 1.2851, 1.0572, 0.8405, 1.0464, 1.1964,\n",
      "        1.1595, 1.1180, 0.3153, 1.2285, 1.1744, 1.2124, 0.4499, 1.0722, 1.0078,\n",
      "        0.7574, 1.2718, 0.7463, 1.0804, 1.2841, 1.3574, 1.2397, 1.2981, 1.0001,\n",
      "        1.0549, 1.2852, 1.1400, 1.2315, 0.9560, 1.3933, 1.3862, 1.2243, 1.1172,\n",
      "        0.8518, 1.6866, 1.0177, 1.4783, 1.2111, 1.0782, 1.0844, 0.7494, 1.4446,\n",
      "        0.9478, 0.9406, 0.9123, 0.9244, 1.0944, 1.3772, 1.3219, 0.9654, 1.1807,\n",
      "        1.1376, 1.0847, 0.6479, 1.0004, 0.9220, 1.1314, 1.1506, 1.2477, 1.1392,\n",
      "        1.3576, 1.2479, 1.2160, 1.2844, 1.1520, 1.2053, 1.1021, 1.0072, 1.2178],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.0.1.bias\n",
      "Weights: tensor([-6.8811e-01,  4.7913e-01,  1.1079e+00, -1.5386e+00, -3.3712e-01,\n",
      "        -3.3432e-01,  1.1198e-01, -9.6005e-01, -1.2178e-01, -3.3857e-01,\n",
      "        -9.6505e-01,  2.0917e-02, -1.2905e+00,  9.8114e-01, -3.7444e-01,\n",
      "         1.0458e+00, -8.3714e-01,  1.7721e-01, -3.7903e-01, -9.6778e-01,\n",
      "         3.6742e-01, -1.2915e+00, -8.6810e-01, -6.7122e-01,  1.1709e-01,\n",
      "        -1.5585e+00, -2.3666e-01, -3.3470e-02, -5.0240e-01,  9.7308e-01,\n",
      "        -1.1258e+00,  2.9846e-01,  8.0102e-01,  4.3190e-01, -3.7795e-01,\n",
      "         1.3957e-01,  7.0685e-01,  8.6988e-02,  9.9130e-01,  1.1391e+00,\n",
      "         1.3015e+00, -2.3592e-01, -1.2630e+00, -3.8053e-01, -2.0794e-01,\n",
      "        -1.2066e+00, -3.7021e-01, -2.6874e-01, -1.4786e+00,  1.2954e+00,\n",
      "        -7.3766e-01, -1.1347e+00, -1.0459e+00, -1.0765e+00,  4.1002e-01,\n",
      "        -4.7630e-01, -1.1437e+00, -1.0135e+00, -3.3105e-01, -1.3008e-01,\n",
      "         1.0321e+00,  6.0022e-01,  7.1423e-01,  1.3245e+00,  8.8041e-01,\n",
      "         3.9893e-03, -1.1800e+00, -9.4973e-01,  9.8083e-01, -1.2763e+00,\n",
      "        -2.8505e-01, -1.2129e+00, -1.0078e+00, -1.3064e+00, -9.2836e-01,\n",
      "         1.0634e-01, -3.3524e-01, -7.1373e-01, -6.1145e-01, -2.1395e+00,\n",
      "        -5.8007e-01,  1.0424e+00, -1.0915e+00, -1.4955e+00,  8.1055e-02,\n",
      "        -5.4649e-01, -4.4101e-01, -1.1548e+00, -1.0447e+00, -5.7247e-01,\n",
      "         1.4646e+00, -1.0000e+00, -5.2786e-01,  1.2312e-01, -2.3551e-01,\n",
      "        -3.7765e-01, -9.5845e-01, -5.5925e-01, -2.2674e-01, -6.4493e-01,\n",
      "         2.2089e-01, -2.0381e-01,  1.9824e-01,  1.6436e-01,  4.1245e-01,\n",
      "         3.6336e-01, -9.2542e-01, -1.4808e+00, -1.0004e+00, -7.2124e-01,\n",
      "        -5.2629e-01, -5.9631e-01, -6.0975e-01,  1.6713e+00, -1.4983e+00,\n",
      "         1.2359e+00, -1.1848e-01, -4.1374e-01,  5.8443e-01,  9.2996e-01,\n",
      "        -1.9587e+00, -7.2126e-01,  3.2906e-01,  7.7608e-01, -1.2488e+00,\n",
      "         1.3893e+00, -7.1596e-01,  1.7292e-01, -4.8440e-01, -7.7319e-01,\n",
      "         6.5261e-01,  3.3377e-01,  5.0164e-01, -1.3081e+00, -1.1951e+00,\n",
      "        -1.1866e+00, -1.3635e+00, -4.6994e-01, -1.9838e-01,  1.0253e+00,\n",
      "         3.0006e-01, -3.9146e-01,  7.5420e-01,  1.1961e+00, -4.0022e-01,\n",
      "         9.5723e-01, -3.4582e-02, -1.4123e+00, -9.4611e-01, -2.8092e-01,\n",
      "        -8.9272e-01,  1.5090e+00, -9.2382e-01, -5.8281e-01, -9.4727e-01,\n",
      "        -9.0169e-01, -6.2933e-01, -1.9065e-02, -1.3587e+00, -1.2531e+00,\n",
      "         5.8388e-01, -8.9698e-01, -1.1871e+00, -8.1592e-01, -6.1953e-02,\n",
      "        -6.0799e-01, -5.9092e-01,  2.6572e-01,  9.3998e-01, -1.2063e+00,\n",
      "         9.2446e-01, -5.6148e-01,  1.1168e+00, -1.6046e+00, -7.5882e-01,\n",
      "         2.8871e-01, -3.8043e-01, -6.3221e-01, -6.2630e-01, -1.1393e+00,\n",
      "         7.3519e-01, -5.7907e-05,  1.3907e-01,  9.2260e-01, -4.3175e-01,\n",
      "         8.2566e-01, -8.1725e-01,  4.3053e-01, -3.5781e-01, -4.9579e-01,\n",
      "         9.1872e-01, -7.6001e-01, -1.4079e+00, -7.4629e-01, -1.4359e+00,\n",
      "        -6.4128e-01,  1.0760e+00,  4.1309e-02,  8.8303e-01, -1.0802e+00,\n",
      "        -8.2488e-01, -2.9546e-01, -1.3557e+00,  3.5004e-01, -3.4917e-01,\n",
      "        -4.0860e-01, -8.6188e-01,  1.5499e-01, -8.5266e-01, -5.2598e-01,\n",
      "         2.9822e-01,  8.8359e-01, -6.2227e-01, -2.8850e-01, -1.3739e+00,\n",
      "        -7.1734e-01,  2.9727e-01, -8.8323e-01,  1.1017e+00, -8.7006e-01,\n",
      "         8.2990e-01,  5.4909e-01, -1.2312e+00,  9.6382e-01, -4.1626e-01,\n",
      "         1.0832e+00, -1.7312e-01, -4.4168e-01, -1.0571e+00, -1.2408e+00,\n",
      "        -5.7665e-01, -7.2343e-01, -4.6456e-01,  1.8070e-01, -1.8594e+00,\n",
      "         9.3349e-01, -9.7387e-01,  1.3690e+00, -6.6027e-01, -1.1095e+00,\n",
      "        -1.0843e+00, -1.6173e+00, -7.7452e-01, -1.1391e+00, -1.1436e+00,\n",
      "         9.5985e-01,  1.7104e-01, -6.6921e-01, -8.2506e-01, -1.5003e-01,\n",
      "        -4.3306e-01, -3.2797e-01, -1.2281e+00,  1.1674e+00,  3.3813e-02,\n",
      "         2.2117e-01, -1.5616e-01, -8.6755e-01, -4.8643e-01,  5.6468e-01,\n",
      "        -1.5575e+00, -9.4775e-01, -2.4991e-01,  1.2922e+00, -5.1031e-01,\n",
      "        -4.5778e-02,  1.2165e+00,  5.6155e-01, -1.3149e+00, -8.8139e-02,\n",
      "        -1.2262e+00, -1.8139e-01, -1.2673e-01,  1.3819e-01,  1.3010e+00,\n",
      "         7.7496e-01,  1.5929e-01, -2.4601e+00, -5.9181e-02, -1.3599e+00,\n",
      "        -4.8886e-01, -2.5196e-01, -3.2622e-01, -7.4337e-01, -9.7540e-01,\n",
      "         1.6310e+00, -7.9353e-01, -1.1043e+00,  1.0994e+00, -9.7217e-01,\n",
      "         1.2527e+00, -1.7357e-01, -9.2336e-01,  1.4350e+00, -5.0141e-01,\n",
      "        -8.5410e-01,  1.1727e+00,  2.2073e-03, -7.1508e-01, -1.1510e+00,\n",
      "         6.1895e-01, -5.3328e-01, -1.0294e+00, -1.3023e-01, -1.3099e+00,\n",
      "        -1.2879e+00,  7.3467e-01, -5.0037e-01,  1.1563e+00, -6.3177e-01,\n",
      "        -1.1921e+00, -8.8047e-01,  9.0663e-01, -1.0688e+00, -7.0480e-01,\n",
      "         5.3734e-01, -6.1768e-01, -9.4505e-01, -1.0317e+00, -7.4995e-01,\n",
      "         1.0996e+00, -9.3386e-01, -1.4508e+00, -2.5155e-01, -1.1361e+00,\n",
      "        -1.5010e+00, -8.8903e-01, -8.0993e-01, -2.6516e-01, -8.1616e-01,\n",
      "        -1.0803e+00, -7.1512e-01, -2.2552e-01, -1.0081e+00, -5.4820e-02,\n",
      "         8.1218e-01, -1.1384e+00, -1.4414e+00,  1.4408e+00,  1.3913e+00,\n",
      "        -1.3690e+00,  6.2588e-01, -1.4573e+00, -1.0478e-02, -8.0563e-01,\n",
      "         1.5226e+00, -6.4413e-02,  5.3563e-01, -2.4780e-01, -1.8554e+00,\n",
      "        -5.6485e-01, -7.3927e-01, -1.2035e+00, -1.9004e+00, -6.3124e-01,\n",
      "         3.5529e-02, -6.4947e-01,  9.0935e-01, -3.6786e-01, -1.1038e+00,\n",
      "         3.0476e-01, -7.1104e-01,  1.2762e+00, -1.1388e+00,  8.3226e-01,\n",
      "        -1.1475e+00, -2.7829e-01, -9.9342e-02,  8.6783e-01, -1.1633e+00,\n",
      "        -3.5360e-01, -5.2435e-01, -5.3720e-01, -4.4764e-01, -8.3198e-01,\n",
      "        -6.6338e-01, -2.7613e-01,  3.9978e-02, -8.1012e-01,  1.4866e+00,\n",
      "        -1.0298e+00, -1.0614e-01, -7.5412e-01,  1.7650e-01,  2.8941e-01,\n",
      "        -7.4246e-01,  2.8279e-01, -3.5246e-01, -7.2937e-01, -3.6815e-01,\n",
      "        -5.7382e-01, -3.3350e-01, -1.1494e+00,  1.4667e+00, -1.0169e+00,\n",
      "         2.3352e-03, -1.0213e+00,  1.0004e+00, -9.1362e-02, -7.8765e-04,\n",
      "         6.7218e-01, -1.0454e+00, -1.2284e+00, -1.1417e+00, -1.7623e-01,\n",
      "        -8.6464e-01,  9.6737e-01,  1.0748e+00, -1.4189e+00, -5.9515e-01,\n",
      "        -9.6750e-01,  2.0307e-01, -1.4076e+00, -1.8204e-01, -7.8783e-01,\n",
      "        -5.5158e-01, -1.7000e+00, -4.9384e-01,  1.0658e-01, -4.9747e-01,\n",
      "        -1.1124e+00,  4.3037e-01, -1.3490e+00, -5.3769e-02,  7.3888e-01,\n",
      "        -7.5527e-01, -7.4699e-01,  1.6683e-01, -1.0143e+00,  8.5848e-01,\n",
      "        -6.9204e-01, -1.1693e+00, -5.1996e-01, -4.5217e-01, -3.3391e-01,\n",
      "        -2.3448e+00,  2.3619e-01, -6.8091e-01, -5.2703e-01,  2.5172e-01,\n",
      "         1.2546e-02, -8.8666e-01, -2.8037e-01, -8.3549e-01, -2.6185e-01,\n",
      "         8.6467e-01, -9.1154e-01, -1.0279e+00, -1.4084e+00, -6.2560e-01,\n",
      "        -7.4796e-02, -1.2225e+00, -1.0556e+00, -7.0154e-01, -1.0965e+00,\n",
      "        -5.3120e-02, -4.5576e-01, -1.1689e-01,  3.5786e-02,  8.4795e-01,\n",
      "        -5.4869e-01,  1.2234e+00,  7.6836e-01, -9.5040e-01,  1.5080e+00,\n",
      "         1.3493e+00,  4.1541e-01, -2.0930e+00, -1.4377e+00,  7.7598e-01,\n",
      "        -5.0522e-01,  1.6559e+00, -6.4284e-01, -1.0723e+00,  9.9723e-01,\n",
      "        -1.5704e-01, -1.6182e+00, -1.3123e+00, -1.3101e+00,  4.6346e-01,\n",
      "         1.0637e+00, -1.0700e+00,  8.5977e-01, -1.5115e-01, -7.1168e-01,\n",
      "         1.4870e+00,  1.3400e+00, -1.0443e+00, -1.0916e+00, -1.4113e+00,\n",
      "        -1.2940e-01,  1.3535e+00, -4.0737e-01, -2.0135e+00,  1.2143e-03,\n",
      "        -9.0605e-01, -4.2568e-01,  7.9707e-01, -7.9771e-01, -9.4280e-01,\n",
      "        -6.6161e-01, -1.0112e+00, -1.0027e+00, -9.6510e-01, -4.8189e-01,\n",
      "        -5.5534e-01, -4.7186e-01, -1.2540e+00, -1.4519e-01,  6.6955e-01,\n",
      "        -1.2048e+00, -4.3794e-01, -7.7246e-01, -9.2391e-01, -1.6297e-01,\n",
      "         1.3282e+00, -1.2578e+00, -6.4316e-01, -3.5181e-01,  2.3430e+00,\n",
      "        -1.1837e-01, -6.4861e-01,  8.0102e-01, -3.9638e-01,  8.8515e-01,\n",
      "        -3.0303e-01, -4.3899e-01, -7.6576e-01, -1.2331e-01, -1.4134e+00,\n",
      "         1.5847e+00, -5.6081e-01,  5.5368e-02, -9.8267e-01, -1.7459e+00,\n",
      "         7.2791e-01, -4.7001e-02, -1.1403e+00, -4.2678e-01,  6.5281e-01,\n",
      "        -8.1074e-01, -6.2384e-01, -9.0407e-01, -5.5762e-01, -6.6652e-01,\n",
      "        -1.0603e+00, -1.4441e+00, -1.1099e+00, -4.1918e-01, -6.3135e-01,\n",
      "         1.0103e+00, -6.5763e-01, -4.2753e-01, -8.3710e-01, -1.3244e-01,\n",
      "        -8.5653e-01, -7.8823e-01, -3.6590e-01, -8.9155e-01,  1.1571e+00,\n",
      "        -3.9095e-01, -1.3377e-01,  1.2301e+00, -9.5366e-01, -1.0548e-02,\n",
      "        -1.7546e-01, -9.3848e-01, -4.7648e-02, -2.0849e+00, -1.2997e+00,\n",
      "        -5.8113e-01,  2.4847e-01, -9.2764e-01,  4.5360e-01,  7.2318e-01,\n",
      "         2.7406e-01], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0169,  0.0376,  0.0119],\n",
      "          [ 0.0538,  0.3031,  0.0482],\n",
      "          [ 0.0159,  0.0492,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0405,  0.0552,  0.0358],\n",
      "          [ 0.0473,  0.3744,  0.0368],\n",
      "          [ 0.0427,  0.0413,  0.0399]]],\n",
      "\n",
      "\n",
      "        [[[-0.0100, -0.1215,  0.1981],\n",
      "          [-0.1155,  0.0303,  0.2032],\n",
      "          [ 0.0209,  0.0310, -0.1001]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0500, -0.0695, -0.0643],\n",
      "          [-0.0550, -0.0147, -0.0546],\n",
      "          [-0.0719, -0.0649, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[-0.0476, -0.0802, -0.0451],\n",
      "          [-0.0914, -0.0432, -0.0800],\n",
      "          [-0.0552, -0.0922, -0.0671]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0402,  0.0270,  0.0447],\n",
      "          [ 0.0286,  0.3983,  0.0303],\n",
      "          [ 0.0283,  0.0225,  0.0242]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 1, 3, 3])\n",
      "\n",
      "Layer: features.13.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.7241083979606628\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.7184513211250305\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.1.1.weight\n",
      "Weights: tensor([0.8197, 1.1350, 1.2490, 0.3336, 0.8391, 0.6771, 0.7417, 0.5780, 1.2267,\n",
      "        0.8866, 0.4761, 1.0175, 0.2600, 0.7095, 0.8188, 0.6553, 0.3894, 1.2913,\n",
      "        0.8359, 0.3799, 1.3840, 0.4259, 0.8764, 0.4539, 1.1850, 0.2973, 0.9425,\n",
      "        1.0412, 0.9344, 1.1527, 0.4970, 1.0488, 2.0357, 1.4550, 0.8071, 0.7514,\n",
      "        1.0405, 1.5629, 1.2118, 1.8157, 1.0384, 6.1510, 0.2719, 0.9146, 1.2670,\n",
      "        0.6601, 0.8698, 0.6331, 0.3212, 1.5318, 0.4678, 0.2725, 0.5139, 0.3896,\n",
      "        1.3475, 0.7024, 0.5132, 0.2788, 1.0743, 1.3945, 1.3692, 1.4564, 0.5129,\n",
      "        2.0098, 1.0741, 0.6468, 0.2611, 0.3851, 1.7982, 0.7113, 0.7107, 0.4949,\n",
      "        0.5736, 0.4674, 0.7469, 1.4850, 1.1471, 1.3546, 0.4912, 0.2971, 0.6554,\n",
      "        1.1456, 0.6343, 0.2769, 1.3898, 0.7645, 1.2735, 0.4332, 0.8307, 0.3873,\n",
      "        1.2922, 0.3100, 0.7449, 0.5798, 0.4520, 0.5499, 0.6584, 0.7137, 0.6571,\n",
      "        0.4959, 0.9824, 0.6167, 0.9701, 0.9784, 0.8749, 0.9773, 0.7728, 0.2743,\n",
      "        0.6751, 0.4312, 0.6628, 0.4398, 1.1899, 1.5685, 0.5049, 1.4961, 0.5267,\n",
      "        0.7121, 1.4904, 0.8937, 0.3380, 0.4779, 1.2350, 1.3473, 0.6581, 1.7795,\n",
      "        1.3347, 0.4870, 0.5308, 0.6798, 0.7455, 0.8670, 0.8149, 0.2352, 0.3889,\n",
      "        0.2747, 0.5982, 1.0033, 0.7103, 1.1714, 6.5431, 2.2172, 1.6803, 1.2661,\n",
      "        0.7196, 0.8730, 0.4228, 0.5346, 0.4789, 0.4935, 0.3922, 1.6830, 0.2700,\n",
      "        0.5591, 0.8403, 0.5951, 0.4402, 0.6302, 0.6434, 0.2470, 1.7537, 0.3652,\n",
      "        0.2528, 0.8519, 0.6461, 0.6051, 1.0873, 1.2696, 1.5064, 0.2802, 1.2265,\n",
      "        0.4693, 1.1953, 0.7200, 0.4290, 1.1472, 1.0251, 0.3808, 0.4610, 0.8683,\n",
      "        1.1734, 0.4841, 0.6633, 1.2792, 0.4507, 1.1266, 0.7215, 2.5914, 0.7257,\n",
      "        0.8392, 1.0832, 0.4277, 0.2519, 0.8509, 0.2920, 0.4552, 1.3485, 0.9599,\n",
      "        1.0913, 0.8559, 0.5563, 0.3614, 0.2897, 1.4371, 1.0257, 0.4700, 0.2495,\n",
      "        1.0314, 0.5130, 0.6894, 0.9086, 1.2851, 1.2522, 0.8364, 0.4705, 1.2447,\n",
      "        1.2158, 0.4386, 1.3586, 1.5628, 0.8240, 1.8103, 1.1469, 0.9862, 0.8179,\n",
      "        1.4937, 1.5843, 0.7255, 0.3010, 0.3903, 0.8143, 0.5099, 1.2299, 0.4728,\n",
      "        0.3265, 1.0185, 0.7472, 1.5836, 0.7451, 0.4804, 0.4683, 0.3197, 0.4478,\n",
      "        0.6888, 0.5502, 1.4275, 0.5076, 0.8857, 0.5542, 0.9734, 0.7011, 0.9452,\n",
      "        0.2600, 1.7120, 0.8720, 0.5039, 1.0143, 0.4927, 0.4431, 1.1080, 0.6294,\n",
      "        0.4985, 1.1953, 1.0966, 0.8073, 0.7386, 1.4792, 1.6128, 0.6020, 0.3343,\n",
      "        0.7443, 1.1555, 1.0404, 0.9049, 1.3085, 1.0542, 1.8962, 0.3605, 1.2025,\n",
      "        0.4950, 0.3856, 1.2546, 0.7724, 0.3167, 0.4548, 2.2421, 1.0216, 0.4123,\n",
      "        1.1912, 0.4975, 1.6594, 0.7530, 0.4141, 1.4811, 0.4584, 0.4643, 1.3237,\n",
      "        1.8780, 0.6532, 0.8338, 1.0323, 0.9170, 0.5071, 0.6964, 0.5087, 0.3836,\n",
      "        1.0217, 1.5524, 1.4304, 1.1062, 0.3851, 0.3273, 1.2435, 0.3105, 0.9905,\n",
      "        1.1862, 0.8549, 0.3177, 0.8539, 0.9527, 1.4536, 0.8503, 0.4091, 0.8122,\n",
      "        0.8330, 0.7510, 0.8779, 0.9459, 0.6614, 0.4986, 0.6076, 0.8850, 1.1895,\n",
      "        0.7202, 1.0709, 0.6897, 0.3592, 0.2659, 1.2212, 1.7146, 0.5418, 1.8539,\n",
      "        0.4881, 1.1948, 1.4012, 1.6258, 1.2099, 0.9575, 0.8734, 0.3229, 0.8336,\n",
      "        0.6418, 0.2898, 0.3373, 0.9593, 0.5624, 0.5109, 0.9003, 1.5971, 0.7640,\n",
      "        0.8881, 0.8720, 1.3220, 0.5331, 1.8486, 0.6084, 1.0022, 0.8709, 1.6427,\n",
      "        0.2672, 0.6366, 0.7681, 0.3884, 1.1501, 0.6261, 0.6547, 0.9429, 0.7420,\n",
      "        0.6868, 1.7373, 0.7749, 1.4907, 0.8288, 0.8307, 1.6512, 1.0157, 0.5183,\n",
      "        0.4867, 0.2933, 0.6406, 0.5572, 0.5765, 0.7095, 1.2603, 0.5021, 0.8183,\n",
      "        0.4000, 1.3237, 1.1516, 1.3211, 0.5829, 1.0148, 0.3162, 0.9439, 0.4904,\n",
      "        0.6242, 1.5037, 0.7650, 0.7689, 0.8051, 0.6595, 1.3425, 0.2696, 0.6443,\n",
      "        0.6250, 3.5614, 0.3216, 0.7091, 0.4666, 1.2757, 0.3572, 1.9015, 0.6103,\n",
      "        0.7664, 1.0103, 0.2944, 0.7685, 0.7022, 0.5464, 0.8472, 0.5333, 0.2534,\n",
      "        0.4712, 0.5650, 0.7558, 0.2771, 0.9492, 0.4936, 0.4409, 0.9550, 1.6230,\n",
      "        0.4000, 0.5534, 0.8079, 1.1597, 0.9556, 0.2703, 0.2825, 0.5042, 0.5169,\n",
      "        1.2320, 0.7678, 0.6362, 0.7191, 0.9013, 1.0006, 0.6817, 1.4233, 1.1194,\n",
      "        1.2294, 1.0668, 1.6979, 0.6928, 0.5611, 2.0683, 1.3422, 1.1350, 0.2258,\n",
      "        0.5670, 0.8304, 0.5185, 2.2265, 0.4404, 0.9535, 1.2813, 0.6538, 0.3248,\n",
      "        0.4491, 0.4716, 0.7848, 1.4129, 0.3042, 1.1320, 0.9305, 0.4290, 1.0839,\n",
      "        0.9387, 0.5509, 0.8728, 0.5486, 0.7599, 1.7322, 0.5838, 0.5698, 0.4886,\n",
      "        0.3923, 0.9116, 1.1425, 0.8699, 1.0134, 0.9477, 0.4397, 0.6098, 0.4094,\n",
      "        0.9481, 0.7325, 1.3822, 0.3533, 0.7966, 1.7197, 0.4987, 0.4861, 0.4436,\n",
      "        0.3967, 1.0345, 1.3649, 0.5676, 1.0324, 0.6533, 1.7330, 0.9446, 0.6043,\n",
      "        0.9193, 0.4853, 1.3805, 0.7453, 1.1119, 0.2996, 0.6176, 0.4964, 1.5898,\n",
      "        0.6931, 0.5046, 0.4553, 0.5708, 0.9148, 1.2428, 0.2642, 1.4667, 1.0731,\n",
      "        0.7070, 0.5556, 0.5954, 0.7210, 0.9235, 0.2529, 0.4587, 0.4477, 0.7193,\n",
      "        0.8399, 1.0771, 0.5788, 1.0854, 0.8920, 1.2259, 0.4472, 0.3885, 0.4331,\n",
      "        0.5909, 0.8513, 0.7101, 0.9177, 1.4364, 0.5957, 0.6729, 0.5562, 0.6483,\n",
      "        1.0610, 0.3633, 0.5853, 0.7657, 1.0523, 0.9870, 1.6699, 1.6477, 1.0297],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.1.1.bias\n",
      "Weights: tensor([-1.8662e+00, -5.0893e-01, -1.2291e+00,  1.3708e-01, -1.1880e+00,\n",
      "        -8.4866e-01, -4.9873e-01, -1.3334e+00, -1.7012e+00, -1.5864e+00,\n",
      "         3.1676e+00, -2.0877e+00,  2.5298e+00,  3.1197e-01, -7.3821e-01,\n",
      "         1.1342e-01, -1.2678e-01, -6.5159e-01,  5.2607e-02,  2.4018e+00,\n",
      "        -8.9787e-01, -6.5955e-01, -1.6292e+00,  1.1768e+00, -2.1735e+00,\n",
      "         2.7300e-01, -1.1102e+00, -3.8603e-01,  2.9605e+00, -8.1187e-01,\n",
      "        -5.7333e-01, -9.5638e-01, -2.7051e+00, -8.8464e-01, -9.1615e-01,\n",
      "        -4.3798e-01, -5.4449e-01, -1.0839e+00, -9.4657e-01, -1.4845e+00,\n",
      "        -7.0570e-01, -3.5828e+00,  2.5886e+00, -8.0324e-01,  9.2598e-01,\n",
      "        -2.2462e+00, -9.7747e-01,  1.3990e+00,  2.6427e+00, -1.8537e+00,\n",
      "         1.4562e+00,  1.3942e+00, -5.2146e-01,  2.0811e+00, -1.0063e+00,\n",
      "        -1.1949e+00, -1.0470e+00,  1.5662e+00, -2.2311e+00, -1.6141e+00,\n",
      "        -1.0933e+00, -1.0787e+00,  4.5392e-01, -1.9909e+00, -8.0261e-01,\n",
      "        -3.8507e-01,  2.0772e+00,  2.1546e+00, -2.5386e+00, -1.7881e+00,\n",
      "        -7.0121e-01, -6.3063e-01, -1.7895e+00, -7.9999e-01, -2.4755e+00,\n",
      "        -1.5531e+00, -2.5320e+00, -3.5359e+00,  1.9559e+00,  3.5688e+00,\n",
      "        -9.1577e-01, -1.0543e+00, -2.0618e+00,  1.7791e-01, -7.5585e-01,\n",
      "        -1.3222e+00, -2.3612e+00, -7.3523e-02,  4.8713e+00,  1.8111e+00,\n",
      "        -9.3094e-01,  2.5833e+00, -2.0141e+00,  2.3060e+00,  1.6297e+00,\n",
      "         1.1720e-01, -1.1747e+00, -1.0932e+00, -6.9838e-01, -4.2694e-01,\n",
      "        -1.5297e+00, -2.1055e-01, -1.9285e+00, -1.0200e+00, -5.1811e-01,\n",
      "        -4.9671e-01, -2.1412e+00,  2.6941e+00, -1.8558e+00, -6.1947e-02,\n",
      "        -9.3897e-01,  1.8478e+00, -2.4368e+00, -1.7043e+00, -2.2085e+00,\n",
      "        -1.4581e+00,  2.2500e+00, -6.8781e-01, -9.7333e-01, -2.1753e-02,\n",
      "        -3.7182e-01, -1.4650e-01, -2.6040e+00, -1.1321e+00, -4.6405e-01,\n",
      "        -2.0326e+00, -3.3468e+00,  1.0456e+00, -3.8891e-01, -1.4686e+00,\n",
      "        -4.1191e-01, -9.7934e-01, -5.1943e-01,  2.2175e+00,  2.5798e+00,\n",
      "         2.0299e+00, -1.4257e+00, -2.0314e+00, -8.3694e-02, -1.1718e+00,\n",
      "        -4.6317e+00, -1.2364e+00, -1.5828e+00, -8.0719e-01,  1.6564e-01,\n",
      "        -1.6733e-01,  1.0737e+00, -8.3422e-01, -7.5275e-01,  1.0645e+00,\n",
      "         1.5095e+00, -1.9354e+00,  1.9545e+00, -5.5444e-01, -2.0242e+00,\n",
      "        -5.9676e-01,  2.1772e+00, -5.6454e-01, -2.3799e+00,  2.0820e+00,\n",
      "        -1.9133e+00, -2.3716e-02,  1.4451e+00, -1.7836e+00, -9.0882e-02,\n",
      "        -5.6233e-01, -2.9056e+00, -2.1647e+00, -1.0677e+00,  2.0973e+00,\n",
      "        -7.0668e-01,  3.4939e-01, -8.5120e-01, -2.5434e+00, -3.9889e-02,\n",
      "        -3.7732e-01, -2.2744e+00,  4.3743e-01, -7.6406e-02, -3.4921e+00,\n",
      "        -7.6683e-01,  1.8361e+00, -7.8444e-02, -1.3302e+00,  3.4612e-01,\n",
      "        -7.5527e-01, -1.3268e+00, -1.3353e+00, -9.0547e-01, -1.4222e+00,\n",
      "        -6.6171e-01,  2.2746e+00,  2.5421e+00, -1.9096e+00,  3.0510e+00,\n",
      "        -2.7824e-01, -1.3571e+00, -1.5308e+00, -8.2528e-01, -2.2501e+00,\n",
      "        -4.2292e-01,  4.0419e-01,  2.4761e+00, -8.4979e-01, -1.1310e+00,\n",
      "         7.1650e-03,  1.5749e+00, -1.5334e+00, -4.8752e-01, -8.0462e-01,\n",
      "        -7.8947e-01, -1.0317e+00, -3.0489e+00, -7.2215e-01, -9.0800e-01,\n",
      "        -3.9628e+00, -7.3156e-01, -2.6577e-01, -1.0332e+00, -4.0011e+00,\n",
      "        -3.4986e-01, -1.4726e+00, -2.6091e+00, -6.6158e-01, -6.0923e-01,\n",
      "        -1.3892e+00, -7.8451e-01, -8.7641e-01,  1.9069e+00,  1.1709e+00,\n",
      "        -9.5295e-01, -3.0938e-01, -3.8393e+00,  1.8703e+00,  2.7964e-01,\n",
      "        -5.0640e-01, -9.5450e-01, -1.8422e+00, -1.2902e+00,  9.6745e-01,\n",
      "        -8.8984e-01,  6.5605e-01, -2.6739e-01, -1.9192e+00, -8.9494e-01,\n",
      "        -9.9580e-01,  1.9947e+00, -1.6094e+00,  1.5229e+00, -1.7291e+00,\n",
      "        -4.1894e-01, -2.4523e+00,  2.1694e+00, -1.7991e+00, -1.2669e+00,\n",
      "         9.4039e-01, -2.6676e-01,  2.6294e+00,  2.2125e+00, -1.2649e+00,\n",
      "        -1.7924e+00, -1.6550e-01, -2.6384e+00, -8.4774e-01, -1.3442e+00,\n",
      "        -4.4932e-01, -1.3912e+00, -2.9637e+00, -2.4933e+00,  1.0333e+00,\n",
      "        -1.8180e+00, -2.3552e+00, -1.7840e+00, -9.9210e-01, -8.1094e-01,\n",
      "        -6.6695e-01, -2.7468e+00,  1.1345e+00, -2.1592e+00, -1.3791e+00,\n",
      "         1.8430e+00, -2.9918e+00, -1.2772e+00,  1.7859e+00, -3.6326e-01,\n",
      "        -4.3477e+00, -2.0654e+00,  9.8350e-01, -9.7478e-01, -1.9561e-01,\n",
      "        -2.1853e+00, -3.6678e-01,  1.9233e+00, -9.3653e-01,  1.6782e+00,\n",
      "         1.8106e+00, -9.4103e-01, -4.6398e+00,  7.5250e-02, -5.8307e-01,\n",
      "        -1.2273e+00, -2.0893e+00, -9.8659e-01, -6.5044e-01, -1.2412e-01,\n",
      "        -2.5234e-02, -7.2079e-01, -2.8790e+00, -9.8019e-01, -2.4758e+00,\n",
      "         1.3246e-01,  1.7147e+00, -8.2939e-01,  2.1882e+00, -2.9776e+00,\n",
      "        -2.1056e+00, -1.3892e+00,  1.0546e-01, -3.0730e+00, -1.4806e+00,\n",
      "        -1.6423e+00, -2.3788e+00, -1.6419e+00, -1.0564e+00, -2.4633e+00,\n",
      "        -2.8360e+00, -1.7405e+00, -1.6979e+00, -6.0627e-01, -3.6597e-01,\n",
      "        -9.1737e-01, -1.3702e+00, -3.6543e-01, -2.1964e+00, -3.3647e-01,\n",
      "        -2.8720e-01,  3.4876e-01,  1.3514e+00, -8.1380e-01, -1.7549e+00,\n",
      "        -2.3322e+00, -1.8778e+00, -1.7442e+00, -2.5536e+00, -4.7147e+00,\n",
      "        -1.0222e+00, -1.5628e+00, -8.1371e-01,  2.8799e-02,  6.0131e-02,\n",
      "        -1.5198e+00, -8.0292e-01,  2.7120e+00,  2.1820e-01, -1.0177e+00,\n",
      "         7.7227e-02,  2.1803e+00, -3.9907e-01, -1.1428e+00, -2.4347e+00,\n",
      "        -1.1615e+00, -1.3680e+00, -1.1695e+00,  3.6558e+00, -1.7257e+00,\n",
      "        -8.1347e-01, -1.3277e+00, -1.2834e+00, -1.6096e+00,  2.2480e+00,\n",
      "         2.0505e-02, -7.7338e-01,  8.2871e-02, -1.9131e+00, -1.1963e+00,\n",
      "        -7.1921e-01, -1.7774e+00, -5.5974e-01, -1.3586e+00, -1.6587e+00,\n",
      "        -1.9502e+00, -3.7858e+00, -1.7139e+00, -5.8564e-01, -1.4449e+00,\n",
      "        -1.4842e+00,  6.1636e-01,  2.4858e+00,  6.2416e-01, -4.0966e-01,\n",
      "        -1.6447e-01, -2.6867e-01, -1.2415e+00, -6.7792e-01, -6.4402e-01,\n",
      "        -3.2285e-02,  1.5506e+00, -1.0372e+00, -1.4474e+00, -6.4825e-01,\n",
      "         1.6978e+00, -2.7682e+00,  2.3478e+00, -2.7220e+00, -9.2085e-03,\n",
      "        -6.0858e-01, -1.9489e+00, -1.3581e-01, -2.6350e+00, -9.8619e-01,\n",
      "        -6.2931e-01, -2.4097e+00,  2.7786e+00, -1.2535e-01, -1.3435e+00,\n",
      "        -7.8129e-01, -1.0587e+00, -8.0187e-01,  1.4845e+00, -3.3232e-01,\n",
      "        -1.4269e-01, -6.0279e+00, -2.1636e+00, -6.0266e-01, -5.6934e-01,\n",
      "         1.1740e+00, -1.8604e+00,  2.3776e-02, -5.1033e-01, -1.7396e-01,\n",
      "         7.3405e-04,  1.7442e+00,  2.5188e+00, -1.1463e-01, -9.2406e-01,\n",
      "         9.5320e-01, -3.7432e-01,  1.9136e+00,  2.1090e+00, -7.7489e-01,\n",
      "        -8.8727e-01,  1.8718e+00, -1.1487e-01, -1.4352e+00, -3.6170e-01,\n",
      "        -4.4840e-01,  1.8504e+00,  1.6592e+00,  3.5015e+00,  8.4229e-01,\n",
      "        -5.0276e-01, -7.9944e-01, -1.3134e+00, -1.4819e+00, -2.3352e+00,\n",
      "        -4.0677e-01,  1.7565e-01, -7.4646e-01, -1.9879e+00, -6.5045e-01,\n",
      "        -2.3354e+00, -1.5810e+00, -2.6062e-02, -1.2607e+00, -2.1334e+00,\n",
      "        -1.0510e+00, -9.8456e-01,  2.2657e+00, -4.4037e-01, -4.8848e-01,\n",
      "        -2.4181e-02, -3.0123e+00, -5.1532e-02, -2.5967e+00, -1.1201e+00,\n",
      "        -1.3590e-01,  2.7707e+00, -1.0549e+00,  3.2210e-02, -2.7611e-01,\n",
      "        -1.0909e+00,  2.3628e+00, -6.1731e-01, -1.7914e-01,  2.0007e+00,\n",
      "        -6.8510e-01, -8.0366e-01, -5.1634e-01, -2.1848e+00, -1.6484e+00,\n",
      "        -5.6261e-01, -2.0620e+00, -7.8226e-04, -5.5762e-01,  2.1883e+00,\n",
      "         1.5876e+00, -1.6651e+00, -8.8492e-01, -1.5517e+00, -3.4368e+00,\n",
      "        -1.8897e+00, -3.2633e-01, -9.9199e-01, -3.3061e-01, -2.0679e+00,\n",
      "        -1.4595e+00, -4.4090e+00,  8.6700e-01, -8.8314e-02, -1.4327e+00,\n",
      "        -9.7306e-01, -1.2786e-01,  2.6243e+00,  1.5275e+00, -1.7725e+00,\n",
      "        -1.2593e+00, -1.1836e+00, -1.8093e+00, -6.8100e-01, -4.0375e-01,\n",
      "        -9.0430e-01, -1.2880e+00, -5.3567e-01,  2.6773e+00, -1.8066e+00,\n",
      "        -3.2544e-01, -2.2974e+00,  1.7244e+00,  1.2369e-01, -4.9307e-01,\n",
      "        -1.4013e+00, -2.6082e+00,  1.8549e+00, -4.7148e-01, -1.9720e+00,\n",
      "        -4.0636e-01, -5.6968e-01,  1.9545e+00, -3.9294e+00, -4.3409e-01,\n",
      "        -1.7786e+00,  8.9080e-01,  3.1457e+00, -7.2781e-01, -2.1432e+00,\n",
      "         2.1978e+00, -1.0728e+00, -8.3238e-01, -5.1832e-01, -1.4932e+00,\n",
      "        -6.1896e-01, -5.9648e-01, -3.6674e+00, -2.6160e+00, -1.3117e+00,\n",
      "         2.3638e+00,  1.6984e-01,  3.8134e-01, -9.5627e-01, -1.6982e-01,\n",
      "         2.4175e+00, -1.9158e+00, -1.2303e+00, -7.9999e-01,  4.2352e-01,\n",
      "        -1.8268e-01, -1.1998e+00, -1.0833e-01,  8.0989e-01, -2.6777e-01,\n",
      "        -7.2336e-01, -5.1332e-01, -3.1458e+00, -1.2689e+00, -1.5822e+00,\n",
      "        -7.5257e-01], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0541]],\n",
      "\n",
      "         [[ 0.1219]],\n",
      "\n",
      "         [[ 0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         [[ 0.0424]]],\n",
      "\n",
      "\n",
      "        [[[-0.0634]],\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0358]],\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[-0.0597]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1161]],\n",
      "\n",
      "         [[-0.0601]],\n",
      "\n",
      "         [[ 0.0080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[ 0.1312]],\n",
      "\n",
      "         [[-0.1583]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0099]],\n",
      "\n",
      "         [[-0.1532]],\n",
      "\n",
      "         [[-0.0336]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1117]],\n",
      "\n",
      "         [[ 0.0427]],\n",
      "\n",
      "         [[-0.0993]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0466]],\n",
      "\n",
      "         [[-0.0770]],\n",
      "\n",
      "         [[-0.0356]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0422]],\n",
      "\n",
      "         [[ 0.1340]],\n",
      "\n",
      "         [[-0.0039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319]],\n",
      "\n",
      "         [[-0.0836]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0052]],\n",
      "\n",
      "         [[ 0.0786]],\n",
      "\n",
      "         [[ 0.0979]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 576, 1, 1])\n",
      "\n",
      "Layer: features.13.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.3645215928554535\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.3616737723350525\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.3.weight\n",
      "Weights: tensor([2.3462, 1.1076, 2.4558, 1.1446, 2.7596, 3.4581, 3.4509, 2.4032, 2.4825,\n",
      "        2.9053, 1.0885, 2.1729, 1.5070, 1.1521, 1.6025, 1.9701, 1.8116, 3.4066,\n",
      "        1.2077, 0.8244, 2.5042, 1.8505, 2.4262, 1.0967, 2.0292, 3.0289, 4.0606,\n",
      "        1.7235, 1.8096, 2.5487, 2.2635, 0.8900, 3.2766, 1.0540, 1.0154, 3.1115,\n",
      "        3.6768, 1.2845, 2.5682, 2.9025, 2.3743, 2.5410, 1.1457, 3.5237, 2.5571,\n",
      "        1.3600, 1.5969, 1.6582, 1.2767, 1.2771, 0.9937, 3.1546, 2.6688, 1.0845,\n",
      "        2.8863, 1.1163, 2.4055, 0.9251, 3.3920, 3.5508, 2.0892, 1.4950, 4.3684,\n",
      "        1.2598, 2.7995, 1.8211, 2.1045, 2.3494, 1.4068, 3.2438, 1.1187, 2.9958,\n",
      "        1.7708, 2.6674, 2.0745, 2.1259, 4.0351, 2.3139, 1.6170, 3.1082, 1.7424,\n",
      "        3.4872, 1.0737, 2.8217, 2.7398, 2.1692, 2.7343, 3.6734, 3.4890, 2.8258,\n",
      "        1.1770, 3.1165, 1.5946, 2.7876, 1.9006, 1.5863], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.13.conv.3.bias\n",
      "Weights: tensor([-2.8477e-07,  2.4400e-07, -7.1327e-07,  7.1594e-07,  1.0720e-07,\n",
      "        -8.2925e-07, -1.0257e-06,  2.6274e-07, -4.2308e-07,  2.0229e-06,\n",
      "        -1.4904e-07, -3.1578e-07, -1.0084e-06, -1.4149e-06, -7.6040e-07,\n",
      "        -1.2408e-06, -1.7556e-07, -3.0746e-07,  5.9444e-07, -1.1849e-06,\n",
      "        -7.9539e-08,  6.5606e-07,  5.9720e-08, -1.2160e-06,  7.6969e-07,\n",
      "        -3.4021e-08,  1.3479e-06, -2.5036e-07,  4.5764e-07,  4.0439e-07,\n",
      "         8.4799e-07, -1.1779e-07, -2.7320e-07,  4.5151e-08,  1.4502e-06,\n",
      "        -4.9933e-07,  2.7697e-07,  1.4250e-06, -1.1621e-06,  4.6229e-08,\n",
      "         3.7765e-07,  1.9208e-07,  1.5204e-08,  1.1692e-06,  3.6242e-08,\n",
      "         6.8967e-08,  1.8790e-07,  8.3298e-07,  2.3598e-07, -7.6212e-07,\n",
      "         2.6862e-07,  5.1627e-08,  1.0294e-06, -2.1595e-07,  2.6765e-07,\n",
      "         3.0125e-07,  5.9335e-07,  8.2671e-07, -2.1458e-07, -4.9420e-07,\n",
      "         6.1114e-07, -2.5923e-07, -6.0342e-07,  1.3453e-07, -7.1573e-07,\n",
      "        -2.6431e-07, -2.2532e-07, -7.6041e-08,  9.7670e-07,  2.3076e-07,\n",
      "         6.5309e-07, -9.7937e-07, -1.1313e-06, -2.4312e-07,  5.6558e-07,\n",
      "         2.4265e-07, -2.0282e-07, -1.1125e-06,  3.7599e-07, -1.1835e-07,\n",
      "         8.3440e-07, -5.4145e-07, -3.7260e-07,  4.9687e-07, -3.6257e-08,\n",
      "         5.3101e-07, -6.3533e-07,  3.3939e-07, -1.0574e-06,  3.5952e-07,\n",
      "         9.1234e-08, -6.9317e-07,  5.7544e-07,  3.4277e-07, -5.2252e-07,\n",
      "         1.4133e-07], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.13.conv.3.output_quantizers.0.min\n",
      "Weights: -29.089599609375\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.13.conv.3.output_quantizers.0.max\n",
      "Weights: 26.289306640625\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.0420]],\n",
      "\n",
      "         [[ 0.0087]],\n",
      "\n",
      "         [[ 0.1079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1354]],\n",
      "\n",
      "         [[ 0.0197]],\n",
      "\n",
      "         [[-0.0812]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0451]],\n",
      "\n",
      "         [[ 0.0258]],\n",
      "\n",
      "         [[-0.1136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0341]],\n",
      "\n",
      "         [[ 0.0764]],\n",
      "\n",
      "         [[ 0.0496]]],\n",
      "\n",
      "\n",
      "        [[[-0.0148]],\n",
      "\n",
      "         [[ 0.1136]],\n",
      "\n",
      "         [[-0.0937]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0805]],\n",
      "\n",
      "         [[ 0.1227]],\n",
      "\n",
      "         [[ 0.1125]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1093]],\n",
      "\n",
      "         [[-0.2128]],\n",
      "\n",
      "         [[ 0.1439]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1404]],\n",
      "\n",
      "         [[-0.1311]],\n",
      "\n",
      "         [[-0.0320]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0632]],\n",
      "\n",
      "         [[ 0.0876]],\n",
      "\n",
      "         [[ 0.0468]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1252]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[-0.0605]]],\n",
      "\n",
      "\n",
      "        [[[-0.0240]],\n",
      "\n",
      "         [[-0.1722]],\n",
      "\n",
      "         [[-0.1315]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0463]],\n",
      "\n",
      "         [[ 0.1351]],\n",
      "\n",
      "         [[-0.1088]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 96, 1, 1])\n",
      "\n",
      "Layer: features.14.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.7068509459495544\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.701328694820404\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.0.0.input_quantizers.0.min\n",
      "Weights: -34.29917907714844\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.0.0.input_quantizers.0.max\n",
      "Weights: 36.95182800292969\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.0.1.weight\n",
      "Weights: tensor([2.3564, 1.4216, 1.0730, 1.4022, 1.3710, 1.4293, 1.4185, 1.3027, 1.4130,\n",
      "        1.3311, 1.3191, 1.4113, 1.2747, 1.0053, 1.4259, 1.2154, 1.1302, 1.2267,\n",
      "        1.3232, 1.3284, 1.4337, 1.3051, 1.3990, 1.4093, 1.3401, 1.3844, 1.9727,\n",
      "        1.3013, 1.3551, 1.1941, 1.5024, 0.5222, 1.2384, 1.4325, 1.2058, 1.4279,\n",
      "        1.3983, 1.3026, 1.0540, 1.4732, 1.3778, 1.3901, 1.4568, 1.5218, 1.4718,\n",
      "        1.0022, 1.3717, 1.3377, 1.3713, 1.4852, 1.4249, 1.3064, 1.5656, 1.1684,\n",
      "        1.3656, 1.3477, 0.6932, 1.1874, 1.4241, 1.4892, 1.2960, 1.1630, 1.2862,\n",
      "        1.5485, 1.1312, 1.4476, 1.3067, 1.2690, 1.3403, 1.2310, 1.1948, 1.2423,\n",
      "        1.5635, 1.3756, 0.4785, 1.2122, 0.5295, 1.4623, 0.8721, 1.4561, 0.4390,\n",
      "        1.2483, 1.4136, 1.1361, 1.3081, 1.1800, 1.2295, 1.2424, 1.3688, 1.4074,\n",
      "        1.1948, 1.3129, 1.3603, 1.4925, 1.4193, 1.0988, 1.3899, 1.4507, 1.0844,\n",
      "        1.2817, 1.4150, 1.1058, 1.4426, 1.4253, 1.4132, 1.4159, 1.6060, 1.3100,\n",
      "        1.3476, 1.2674, 1.3672, 1.5110, 1.2883, 1.5067, 1.2841, 1.4899, 1.4334,\n",
      "        1.3855, 1.6114, 0.8302, 1.5419, 1.4114, 1.4523, 1.3651, 1.3601, 1.4237,\n",
      "        1.3363, 1.3261, 1.3882, 1.3285, 1.0259, 1.3320, 1.3653, 1.3355, 1.3479,\n",
      "        1.3401, 1.2767, 1.3933, 1.2188, 1.4936, 1.2552, 0.6871, 1.3590, 1.2860,\n",
      "        1.2496, 1.6373, 1.1882, 1.3599, 1.2927, 1.4607, 1.3265, 1.1265, 1.2643,\n",
      "        1.1878, 1.3715, 1.4342, 1.2323, 1.4502, 1.4564, 1.1215, 1.3104, 1.6134,\n",
      "        1.3446, 1.1151, 1.4064, 0.9598, 1.3266, 1.2202, 1.2144, 1.3854, 1.3979,\n",
      "        1.3392, 1.1440, 1.2470, 1.1975, 1.2051, 1.0848, 1.2490, 1.4455, 1.2341,\n",
      "        1.4706, 1.2437, 0.5199, 1.2636, 1.2707, 1.3501, 1.4520, 1.3951, 1.2270,\n",
      "        1.2033, 1.2506, 1.4054, 1.4800, 1.2849, 1.5049, 1.4475, 0.3038, 1.1964,\n",
      "        1.4659, 1.1929, 1.2374, 1.2768, 1.2003, 1.3752, 1.1471, 1.3622, 1.3266,\n",
      "        1.4330, 1.2888, 1.3993, 1.3772, 1.5267, 1.3910, 1.2903, 1.3029, 1.5058,\n",
      "        1.3757, 1.3818, 1.3361, 1.1896, 1.2991, 1.0523, 1.3204, 1.3894, 1.4457,\n",
      "        1.3217, 0.6394, 1.4972, 1.0556, 1.4418, 1.2779, 1.5012, 1.2154, 1.2132,\n",
      "        1.4342, 1.4043, 1.3906, 1.2259, 1.3852, 1.3120, 1.3462, 1.3420, 1.4428,\n",
      "        1.3740, 1.2764, 1.3271, 1.2265, 1.2731, 1.2410, 1.4500, 1.2849, 1.5326,\n",
      "        1.3222, 1.1772, 1.2962, 1.3841, 1.3519, 1.1618, 1.3807, 1.4657, 1.1396,\n",
      "        1.3782, 0.9145, 1.1072, 1.3771, 1.3772, 1.3308, 1.7655, 1.3672, 1.3081,\n",
      "        1.3098, 1.3553, 1.2528, 1.4568, 1.3583, 1.4124, 1.2515, 1.5640, 1.4663,\n",
      "        1.5605, 1.1288, 0.7277, 1.4291, 1.3485, 1.3815, 1.3451, 1.1760, 1.4667,\n",
      "        1.2254, 1.3559, 1.2814, 1.5720, 1.2544, 1.4385, 1.4132, 1.4345, 1.5702,\n",
      "        1.3332, 1.3924, 1.3793, 1.3607, 1.5877, 1.4202, 1.5201, 1.3696, 1.6242,\n",
      "        1.3854, 1.4302, 1.2323, 1.3300, 1.3511, 1.2625, 1.3803, 1.3015, 1.4689,\n",
      "        1.4747, 1.3021, 1.3806, 1.4127, 1.2383, 0.9783, 1.5705, 1.4674, 1.5295,\n",
      "        1.4553, 0.9005, 0.9594, 1.2859, 1.3520, 1.6811, 1.2870, 1.3256, 1.5175,\n",
      "        2.0189, 1.0479, 1.3470, 1.5070, 0.9112, 1.4808, 1.3419, 1.3066, 1.2576,\n",
      "        1.3504, 1.3048, 1.1900, 1.2782, 1.3606, 1.3238, 1.5535, 0.4894, 1.1846,\n",
      "        1.2435, 1.3480, 1.3401, 1.4668, 1.3572, 1.3068, 1.2117, 1.1357, 1.4794,\n",
      "        1.3654, 0.5265, 1.4739, 1.4440, 1.3169, 1.1131, 1.3206, 1.3978, 1.6959,\n",
      "        1.2976, 1.6524, 1.3884, 1.3297, 1.3072, 1.4793, 1.3783, 1.2113, 1.5819,\n",
      "        1.3528, 1.5422, 1.3378, 1.1855, 1.5036, 1.4622, 1.5910, 1.1941, 1.3845,\n",
      "        1.3648, 1.1353, 1.2849, 1.4462, 1.3367, 1.4897, 1.2578, 1.5065, 1.3540,\n",
      "        1.3600, 1.4022, 1.1574, 0.6093, 1.3333, 1.5123, 1.3359, 1.2570, 1.1534,\n",
      "        1.5420, 1.4986, 1.4389, 1.3378, 1.3426, 1.4373, 1.3376, 1.5204, 1.4918,\n",
      "        0.9839, 1.3268, 1.7428, 1.3781, 0.1206, 1.6226, 1.4761, 1.2004, 1.2442,\n",
      "        1.3682, 1.4086, 1.4955, 1.0334, 1.2674, 1.3791, 1.1966, 1.4596, 1.5586,\n",
      "        1.2744, 1.3062, 1.2959, 1.4277, 1.5926, 1.4060, 1.3111, 1.6124, 1.2870,\n",
      "        1.4870, 1.2614, 1.1520, 1.4978, 0.7258, 1.2868, 1.4157, 0.8648, 1.4752,\n",
      "        1.4396, 1.2722, 1.4040, 1.5826, 1.1605, 1.3389, 1.2400, 1.5271, 1.3068,\n",
      "        1.2494, 1.2471, 1.2810, 0.8182, 1.3549, 1.5657, 1.4624, 1.4233, 1.4425,\n",
      "        1.4573, 1.2161, 1.4169, 1.4052, 1.3872, 1.3332, 1.4121, 1.1796, 1.3096,\n",
      "        1.3122, 1.3705, 1.2153, 1.3476, 1.4871, 1.4318, 1.2830, 1.2328, 1.2596,\n",
      "        1.2728, 1.2763, 1.2829, 0.6421, 1.5856, 1.2611, 1.4546, 1.4451, 1.4394,\n",
      "        1.2572, 1.2453, 1.3898, 1.2413, 1.4246, 1.3169, 1.6353, 1.1059, 1.4122,\n",
      "        1.4290, 1.3489, 1.3574, 1.2449, 1.2075, 1.3509, 1.3469, 1.5916, 1.3645,\n",
      "        1.2387, 1.5605, 1.5013, 1.3942, 1.2417, 1.1489, 1.3536, 1.3334, 1.4491,\n",
      "        1.5045, 1.2843, 1.0921, 1.4106, 0.9561, 1.1331, 1.3108, 1.3351, 1.2667,\n",
      "        1.4005, 1.4798, 1.2770, 1.0619, 1.1484, 1.4279, 1.6502, 1.3340, 1.5491,\n",
      "        1.0422, 1.2876, 1.4748, 1.5050, 1.2217, 1.4460, 1.2971, 1.3734, 1.3617,\n",
      "        1.4544, 1.1492, 1.3761, 1.2131, 1.3761, 1.5853, 1.4031, 1.0697, 1.4208,\n",
      "        1.3810, 1.2511, 1.3414, 1.3732, 1.4364, 1.3024, 1.4720, 1.6459, 1.4447,\n",
      "        1.1722, 1.4499, 1.3937, 1.2372, 1.2797, 1.4006, 1.3369, 1.2158, 1.3756],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.0.1.bias\n",
      "Weights: tensor([-3.1667, -1.1090,  0.7313, -1.2462, -1.0639, -0.4178, -1.1329, -1.1084,\n",
      "        -0.9609, -1.1443, -1.1076, -0.4417, -1.0455, -1.3613, -1.2978, -1.1138,\n",
      "        -1.8160, -0.5823, -1.8566, -1.3436, -1.4768, -0.9689, -1.3219, -1.2645,\n",
      "        -1.4269, -0.6804, -0.5877,  0.8673, -1.1518, -0.9923, -1.1916, -0.1131,\n",
      "        -1.3774, -1.8567,  1.1159, -0.7646, -1.6433, -0.7945, -1.5174, -0.7256,\n",
      "        -0.9475, -1.1487, -1.0939,  0.0289, -1.3178,  0.8545, -0.2715, -0.5574,\n",
      "        -0.7145, -0.8401, -1.3017, -1.4551, -0.9280, -0.9599, -1.2300, -1.8869,\n",
      "         1.2088, -0.5868, -1.2961, -1.4131, -0.8564, -1.0733, -1.4909, -1.4301,\n",
      "        -1.9328, -0.7686, -0.8887, -1.5181, -1.1642,  0.4866, -1.2942, -1.6594,\n",
      "        -1.2006,  0.4666,  1.8238, -0.5499, -0.2043,  0.3510,  1.5696, -1.3016,\n",
      "         1.7042, -1.6040, -0.9855, -1.1126, -1.5323, -1.6804, -1.4199, -1.4532,\n",
      "        -1.0089, -1.2694, -2.0194, -1.4371, -1.6170, -1.3002, -1.6117, -0.9242,\n",
      "        -0.2876,  0.0903,  0.8441, -1.4307, -1.3416, -0.3728, -1.1125, -2.4441,\n",
      "        -0.3616, -0.8687, -1.8897, -1.2868, -1.2125, -1.7862, -1.6396, -1.2642,\n",
      "        -1.4300,  0.1499, -0.3720, -1.0042, -0.8221,  0.4041, -0.7846,  1.2548,\n",
      "        -0.3712, -1.2656, -1.7190, -0.6805, -1.3841, -1.6996, -1.0967, -1.5444,\n",
      "        -0.9629, -1.7399, -1.2423, -1.4698, -1.7275, -1.8737, -1.3083, -1.7423,\n",
      "        -1.8565, -1.9044, -1.0050, -0.4843, -0.5660,  1.6788, -1.5358, -1.2960,\n",
      "        -1.2101, -1.8073, -2.0096, -0.8897, -2.4372, -0.7681, -0.9076, -2.0483,\n",
      "        -2.3113, -1.1362, -1.3170, -1.6869, -1.6668, -0.3226, -1.4634, -1.1351,\n",
      "        -0.7044, -1.2994, -1.3541, -1.3001, -1.3372,  1.2186, -0.5827, -0.8823,\n",
      "        -0.8317, -1.7779, -0.7237,  0.6886,  0.0496, -0.6887, -1.2588, -1.4540,\n",
      "         1.4637, -2.0997, -1.3250, -1.6699, -1.2297, -1.4034,  1.1551, -1.3735,\n",
      "        -1.5353, -1.6374, -0.9993, -2.1690, -1.7022, -1.5738,  0.8541, -0.6833,\n",
      "        -0.7646, -0.6280, -1.3090, -0.6542,  1.3408, -1.3380, -1.5115, -1.3482,\n",
      "        -2.1626, -1.4316, -1.3444, -1.1075, -1.8234, -0.4628, -0.0087, -0.7009,\n",
      "        -0.9384, -1.0279, -1.3963, -1.5443, -1.5226, -0.7685, -1.4181, -1.3029,\n",
      "        -1.3066, -1.7270, -0.9460, -1.5698, -0.8247, -1.0925, -1.0823, -1.6031,\n",
      "        -0.6464, -0.8502,  0.0043, -1.2547, -1.7468, -2.2750, -1.4390, -0.8368,\n",
      "        -1.3313, -0.8864, -0.9625, -1.8189, -1.3622, -0.8658, -1.0498, -1.1157,\n",
      "        -0.8368, -0.6305, -1.1846, -0.9125, -1.3907,  0.4753, -1.6969, -1.0007,\n",
      "        -1.6301, -1.4375, -0.1233, -0.5438, -1.2398, -1.1088, -0.9825, -1.1043,\n",
      "        -1.5703, -1.0363, -1.6892, -1.8028, -1.0003, -1.7893,  1.3390, -1.3321,\n",
      "        -1.7055, -1.7865, -0.9318, -1.5530, -0.9922, -0.5113, -1.8229, -1.5902,\n",
      "        -1.3392, -1.3695, -1.5734, -0.9528, -1.0917, -1.5785,  0.1975, -0.2571,\n",
      "        -1.8918,  1.0290, -1.0796, -1.4656, -1.4087, -1.5879, -0.9801, -1.6498,\n",
      "        -1.5068, -1.2324, -1.7274,  0.2238, -1.7064, -1.0206, -0.7347, -1.5752,\n",
      "        -1.3402, -1.4481, -1.2668, -1.5322, -1.6167, -1.5908, -1.0865, -1.8227,\n",
      "         0.2200,  0.7607, -1.2336,  0.0558, -1.1291, -0.7861, -0.0686,  0.5523,\n",
      "        -0.6757, -1.5472, -0.4845, -0.9428, -1.4642, -0.8681, -0.9960, -0.4569,\n",
      "        -0.5789, -1.2274, -1.6015, -0.2180, -0.9216,  1.3984,  0.6082, -1.3098,\n",
      "        -1.1101, -1.0695, -1.6842,  0.1626, -1.0935, -2.5382, -0.8639, -1.1381,\n",
      "        -1.5455, -1.0605, -1.1676, -1.5392, -1.6334, -1.4384, -0.0698, -1.7321,\n",
      "         0.0791, -1.6406,  0.6839, -1.2504, -2.1143, -0.1756, -0.9530, -1.2006,\n",
      "         0.6066, -1.8997, -0.7349, -1.7033, -0.9875, -2.0152, -1.4565, -1.1373,\n",
      "        -1.3649,  1.2461, -1.5227, -0.4721, -0.6384, -1.1232, -0.6613, -0.8417,\n",
      "        -0.1377, -1.3204, -0.9560, -1.1547, -0.9943, -1.8574, -0.4706, -1.0232,\n",
      "        -0.6236, -1.2460, -1.5845, -0.8850, -1.3689, -1.0995, -0.8793, -1.0071,\n",
      "        -0.8220,  0.7788, -1.0918, -1.2340, -1.7951, -1.3052, -1.6507, -1.3822,\n",
      "         0.2808, -0.7682, -0.7775, -0.0479, -1.3094, -0.6880, -1.3737, -0.3614,\n",
      "        -0.8089, -0.9416, -1.6358,  0.2179,  0.4214, -1.1872, -0.7794, -1.9789,\n",
      "        -1.4786, -1.4477, -1.6508, -1.4678, -1.2074, -1.3257, -1.3137, -1.0466,\n",
      "        -1.3045,  0.1041,  4.0237, -1.6904, -1.3791, -1.5638,  0.3159, -0.8842,\n",
      "        -1.4721, -0.9342, -1.5902, -1.0991, -1.4367, -0.9218, -0.8777, -1.5475,\n",
      "        -0.6052, -1.5555, -1.3053,  0.6291, -1.3878, -0.2922, -1.1518, -1.3218,\n",
      "        -0.7601, -0.3137, -1.0712, -1.3559, -0.3167,  1.1487, -1.7676, -0.6587,\n",
      "         1.6231, -1.4661,  0.1506, -1.6311, -0.5598, -0.8635, -1.5113, -1.5471,\n",
      "        -1.5569, -1.4794, -1.6118, -1.6534, -1.0469, -1.3042, -0.4372, -2.2710,\n",
      "        -0.6157, -1.5726, -1.5130, -0.1949, -1.5245, -1.2279, -2.5278, -2.1371,\n",
      "        -0.8589, -1.7278, -1.2750, -1.7398, -2.2238, -1.2673, -1.4950, -1.9617,\n",
      "        -2.3627, -0.4941, -0.9143, -0.9477, -1.8758, -1.1012, -0.7250, -0.4693,\n",
      "        -1.5347,  1.4242, -2.2665, -1.8267, -1.4940, -1.6327, -1.0162, -1.6260,\n",
      "        -1.6751, -1.1344, -1.3836, -0.9766, -0.9213, -1.8294, -1.3602, -1.4935,\n",
      "        -0.0698, -1.0641, -1.5921, -1.6079, -1.9283, -1.3107, -1.4516,  0.2265,\n",
      "        -0.6294, -1.6899, -1.6344, -0.9438, -0.7797, -1.1586, -0.8405, -1.1842,\n",
      "        -1.4313, -1.3911, -1.1788, -1.7048, -1.8113, -1.3104, -1.7446, -1.8136,\n",
      "        -1.4541, -1.4503, -1.0314, -1.0331, -1.7015, -1.3233, -0.7930, -1.3256,\n",
      "        -2.2280, -0.1797, -1.4332, -0.6877,  0.7968, -1.8370, -0.3970, -0.0313,\n",
      "         0.6468, -1.2072, -1.1446, -0.6529, -1.7878, -0.4251, -1.5979, -1.9917,\n",
      "        -1.3104, -0.7977, -1.5776, -1.2578,  0.9486, -2.0112, -1.0274, -1.1449,\n",
      "        -1.3627, -0.9864, -1.2512, -0.9667, -1.4365, -3.0756, -1.4986, -1.2347,\n",
      "        -1.7826, -1.7071, -1.5288, -1.9485, -1.0512,  0.3681, -1.5320, -1.7683],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0868,  0.0807,  0.0655],\n",
      "          [ 0.0968,  0.1190,  0.0803],\n",
      "          [ 0.0732,  0.0793,  0.0413]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0680,  0.1089,  0.0714],\n",
      "          [ 0.1101,  0.1984,  0.1180],\n",
      "          [ 0.0635,  0.1244,  0.0736]]],\n",
      "\n",
      "\n",
      "        [[[-0.0664, -0.0966, -0.0724],\n",
      "          [-0.0935, -0.1498, -0.1070],\n",
      "          [-0.0643, -0.1027, -0.0668]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0741, -0.1025, -0.0630],\n",
      "          [-0.0934, -0.1247, -0.0955],\n",
      "          [-0.0762, -0.0912, -0.0687]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0672,  0.1088,  0.0680],\n",
      "          [ 0.1084,  0.1742,  0.1107],\n",
      "          [ 0.0642,  0.1044,  0.0693]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0764,  0.1160,  0.0727],\n",
      "          [ 0.1118,  0.1719,  0.1198],\n",
      "          [ 0.0741,  0.1121,  0.0849]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 1, 3, 3])\n",
      "\n",
      "Layer: features.14.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.5041566491127014\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.5002179145812988\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.1.1.weight\n",
      "Weights: tensor([0.8642, 0.5685, 0.6013, 0.5244, 0.4927, 0.5738, 0.5502, 0.4916, 0.4808,\n",
      "        0.5081, 0.5092, 0.5848, 0.5012, 0.6260, 0.5022, 0.5647, 0.4085, 0.9866,\n",
      "        0.4931, 0.4930, 0.4943, 0.5262, 0.4858, 0.5491, 0.5660, 0.5487, 0.7488,\n",
      "        1.3358, 0.5756, 0.5594, 0.5771, 1.9306, 0.4798, 0.4944, 0.8171, 0.5401,\n",
      "        0.4965, 0.5241, 0.4280, 0.5559, 0.5070, 0.5456, 0.8561, 0.5784, 0.5124,\n",
      "        0.7685, 0.5808, 0.5610, 0.5484, 0.5782, 0.6242, 0.4747, 0.5546, 0.5712,\n",
      "        0.5127, 0.4553, 0.5349, 0.5629, 0.5102, 0.6490, 0.5033, 0.5267, 0.4707,\n",
      "        0.6058, 0.3775, 0.5514, 0.5518, 0.4595, 0.5291, 0.7187, 0.4883, 0.4361,\n",
      "        0.5138, 1.2296, 2.0168, 0.6100, 2.1563, 1.1074, 1.6090, 0.4836, 1.5690,\n",
      "        0.5196, 0.5229, 0.5217, 0.5952, 0.4860, 0.4763, 0.4780, 0.6426, 0.4565,\n",
      "        0.4252, 0.4952, 0.4726, 0.6129, 0.4697, 0.4716, 0.5505, 0.6350, 0.7283,\n",
      "        0.4807, 0.5429, 0.5437, 0.6089, 0.3599, 0.6397, 0.4939, 0.7377, 0.5085,\n",
      "        0.6130, 0.4489, 0.4733, 0.5375, 0.5651, 0.6421, 0.5370, 0.5715, 0.5049,\n",
      "        0.6534, 0.5999, 1.1673, 0.6953, 0.5683, 0.5114, 0.6617, 0.4937, 0.4469,\n",
      "        0.4836, 0.4863, 0.5484, 0.4103, 0.4724, 0.4916, 1.7947, 0.7127, 0.5303,\n",
      "        0.4846, 0.3896, 0.4476, 0.5894, 0.4833, 0.6214, 1.1264, 0.5573, 0.5231,\n",
      "        0.4399, 0.6605, 0.3865, 0.4852, 0.3524, 0.5081, 0.6111, 0.4050, 0.3768,\n",
      "        0.6532, 0.5250, 0.4701, 0.4701, 0.6304, 0.4798, 0.5747, 0.5183, 0.5465,\n",
      "        0.7043, 0.5398, 0.4856, 0.8669, 0.8752, 0.5407, 0.4835, 0.4776, 0.5189,\n",
      "        0.6787, 1.2388, 0.5127, 0.5300, 0.5121, 1.4925, 0.4441, 0.5441, 0.4893,\n",
      "        0.5335, 0.5844, 1.1370, 0.5283, 0.4497, 0.4701, 0.5692, 0.4326, 0.4527,\n",
      "        0.4681, 1.7458, 0.5092, 0.5807, 0.5624, 0.5410, 0.6516, 2.0036, 0.6252,\n",
      "        0.5404, 0.4373, 0.3420, 0.5084, 0.5071, 0.5157, 0.4061, 0.5276, 0.5263,\n",
      "        0.6789, 0.4702, 0.5919, 0.4866, 0.5101, 0.6830, 0.6785, 0.5086, 0.4812,\n",
      "        0.4917, 0.5327, 0.4943, 0.4758, 0.4796, 0.4242, 0.5199, 0.5191, 0.4931,\n",
      "        0.5582, 1.4455, 0.5093, 0.3762, 0.5105, 0.5034, 0.5296, 0.4407, 0.5436,\n",
      "        0.5535, 0.4969, 0.5009, 0.4989, 0.4544, 0.5157, 0.5165, 0.5292, 0.5281,\n",
      "        0.4868, 0.4533, 0.6792, 0.4898, 0.5513, 0.4483, 0.4729, 0.5915, 0.4931,\n",
      "        0.5105, 0.5044, 0.4830, 0.4815, 0.4467, 0.5739, 0.5758, 0.4605, 0.6817,\n",
      "        0.4985, 1.3626, 0.4332, 0.5318, 0.4854, 0.4901, 0.5484, 0.5493, 0.5079,\n",
      "        0.4359, 0.4908, 0.4733, 0.4835, 0.4913, 0.4688, 0.5354, 0.5142, 1.5072,\n",
      "        0.7744, 0.4205, 0.6701, 0.5409, 0.4798, 0.4587, 0.4619, 0.5080, 0.4538,\n",
      "        0.4846, 0.5215, 0.4490, 0.8188, 0.4395, 0.4655, 0.5854, 0.4752, 0.6035,\n",
      "        0.4545, 0.5001, 0.4385, 0.5266, 0.5532, 0.4789, 0.5435, 1.0128, 0.5425,\n",
      "        0.5429, 0.9153, 0.5128, 0.5083, 0.5436, 1.5463, 0.5943, 0.4856, 0.6434,\n",
      "        0.6060, 0.5340, 0.5658, 0.4957, 0.4728, 0.4640, 0.5335, 0.4831, 0.7003,\n",
      "        0.5246, 0.7043, 1.1870, 0.5726, 0.5327, 0.5037, 0.4650, 0.9204, 0.5650,\n",
      "        0.7810, 0.7639, 0.4804, 0.5990, 0.5256, 0.5504, 0.4750, 0.4886, 0.5009,\n",
      "        0.5936, 0.4862, 0.9605, 0.4605, 1.8715, 0.6025, 0.4018, 1.6114, 0.4795,\n",
      "        0.4916, 1.5614, 0.4588, 0.5499, 0.8004, 0.6040, 0.4163, 0.4688, 0.5673,\n",
      "        0.4820, 1.6566, 0.5683, 0.5095, 0.5879, 0.5987, 0.5306, 0.5526, 1.0983,\n",
      "        0.4954, 0.4960, 0.5436, 0.5195, 0.4578, 0.6050, 0.5058, 0.5119, 0.4889,\n",
      "        0.5009, 0.6057, 0.5170, 0.5291, 0.5753, 0.5302, 0.5169, 0.8672, 0.5057,\n",
      "        0.5382, 0.7900, 0.4910, 0.4289, 0.5783, 1.5051, 0.4810, 0.5339, 0.5558,\n",
      "        0.5619, 0.5081, 0.5578, 1.7051, 0.4972, 0.6405, 0.4873, 0.5280, 0.7944,\n",
      "        0.5450, 0.5436, 0.5242, 0.5296, 0.4948, 0.4822, 0.5195, 0.4752, 0.4907,\n",
      "        0.5320, 0.5419, 0.5338, 1.2384, 1.9983, 0.4880, 0.4853, 0.4739, 0.4820,\n",
      "        0.5247, 0.4981, 0.5272, 0.5195, 0.4960, 0.5281, 0.5273, 0.6117, 0.5180,\n",
      "        0.5171, 0.4408, 0.6284, 0.8474, 0.7502, 0.7996, 0.6032, 0.5661, 0.5519,\n",
      "        0.6610, 0.6193, 0.5066, 0.7977, 0.7558, 0.4641, 0.6237, 0.6460, 0.5176,\n",
      "        0.6229, 0.5136, 0.6882, 0.6344, 0.4859, 0.5124, 0.4164, 0.5274, 0.5377,\n",
      "        0.5389, 0.4446, 0.4670, 1.2659, 0.4610, 0.7225, 0.5259, 0.5814, 0.7276,\n",
      "        0.4867, 0.4858, 0.4292, 0.4975, 0.7283, 0.4593, 0.5009, 0.4167, 0.3662,\n",
      "        0.5116, 0.4657, 0.4241, 0.5289, 0.5669, 0.5046, 0.5067, 0.4175, 0.4972,\n",
      "        0.5074, 0.5159, 0.4382, 1.3880, 0.6021, 0.4905, 0.4719, 0.4817, 0.4997,\n",
      "        0.5121, 0.4080, 0.4992, 0.5234, 0.5198, 0.5184, 0.5207, 0.4696, 0.5626,\n",
      "        0.9320, 0.4871, 0.4610, 0.4508, 0.4517, 0.5482, 0.5107, 0.8016, 0.5436,\n",
      "        0.4385, 0.5523, 0.5309, 0.5328, 0.4743, 0.6850, 0.4833, 0.5222, 0.5872,\n",
      "        0.5921, 0.4295, 0.3804, 0.5065, 0.4934, 0.3403, 0.4637, 0.5083, 0.5231,\n",
      "        0.5003, 0.4830, 0.5010, 0.4961, 0.4758, 0.3805, 0.7579, 0.4817, 0.6178,\n",
      "        0.5967, 0.4550, 0.5532, 0.8073, 1.0307, 0.5124, 0.6010, 0.5042, 0.4624,\n",
      "        0.5700, 0.4991, 0.4739, 0.4820, 0.5755, 0.5080, 0.5053, 0.8567, 0.4337,\n",
      "        0.5105, 0.5460, 0.5038, 0.5120, 0.5375, 0.5201, 0.6339, 0.5638, 0.5596,\n",
      "        0.4852, 0.5195, 0.4686, 0.4263, 0.4300, 0.6920, 0.6378, 0.4596, 0.4783],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.1.1.bias\n",
      "Weights: tensor([ 4.5179e+00,  4.1448e-01,  6.3932e-01,  1.7313e-02,  4.1130e+00,\n",
      "         3.5327e+00,  2.7680e-01,  2.9978e-01,  4.0071e+00,  2.2830e+00,\n",
      "         1.9074e-01,  1.1020e+00,  3.2337e+00, -2.7406e-01,  4.3997e+00,\n",
      "         3.2549e-01,  1.2057e-01,  1.0543e+00, -1.3214e-02,  2.2881e-01,\n",
      "         2.6640e-01,  3.6545e+00,  2.6350e-01,  2.8496e-01,  2.7199e-01,\n",
      "         3.8891e+00,  1.2748e+00, -4.5832e-01,  3.8903e-01,  2.1468e-01,\n",
      "         3.7285e+00, -5.2277e-01,  2.1874e-01,  2.2707e-01,  4.1634e-01,\n",
      "         3.4710e+00,  2.0863e-01,  4.1691e+00,  1.3955e-01,  3.8035e+00,\n",
      "         3.7145e+00,  4.1569e+00, -5.5171e-01,  7.3166e-01,  2.9793e-01,\n",
      "         9.6225e-01,  3.2189e+00,  3.3972e+00,  2.9275e+00,  3.3158e+00,\n",
      "         5.3723e-02,  2.3647e-01,  4.3738e-01,  2.6817e-01,  4.6242e-02,\n",
      "         1.8223e-01,  1.7502e+00,  3.1634e-01,  2.8224e-01,  1.0437e-01,\n",
      "         3.4684e+00,  2.7351e-01,  1.7163e-01,  2.5670e+00,  1.0455e-01,\n",
      "         1.7690e+00,  3.5434e+00,  1.9669e-01,  1.3597e-01,  4.8793e-01,\n",
      "         2.3292e-01,  1.7487e-01,  2.6351e-01, -1.9437e-01, -8.6828e-01,\n",
      "         2.5246e+00,  2.2023e+00,  3.1790e-02, -1.3745e+00,  3.3940e+00,\n",
      "        -1.4316e+00,  1.9887e-01,  3.2719e+00,  4.6049e+00, -4.7013e-01,\n",
      "         1.9146e-01,  2.1279e-01,  1.7857e-01,  2.5207e-01,  3.1023e+00,\n",
      "         1.3481e-01,  2.3498e-01,  2.2483e-01,  2.4783e+00,  2.4561e-01,\n",
      "         3.5463e+00,  2.4029e+00,  9.9869e-01,  1.2280e+00,  2.3176e-01,\n",
      "         3.0405e-01,  2.1899e-02, -8.3019e-02, -3.8510e-01,  7.6767e-01,\n",
      "         3.1126e+00, -7.0762e-02,  2.7667e-01,  3.4034e-01,  1.8447e-01,\n",
      "         2.2115e-01,  4.3863e+00,  1.3922e-01,  2.7009e+00,  8.8260e-01,\n",
      "         4.1704e-01,  3.2032e+00,  5.9472e-01,  3.7600e+00, -4.7009e-01,\n",
      "         5.5367e-01,  2.9814e-01,  2.4220e-01,  3.6408e-01,  2.5379e-01,\n",
      "         1.8962e-01,  2.8074e-01,  2.7381e-01,  1.5407e+00,  1.6961e-01,\n",
      "         1.8935e-01,  2.2445e-01, -1.1388e+00,  9.5352e-02,  3.3404e+00,\n",
      "         2.2390e-01,  1.2217e-01,  1.5674e-01,  1.9396e-01,  1.9206e+00,\n",
      "         1.2993e+00,  9.4830e-01,  1.9056e+00,  2.5393e-01,  4.5131e+00,\n",
      "         6.0723e-02,  1.1165e-01,  3.7239e+00,  8.4568e-02,  2.5873e+00,\n",
      "         1.4257e+00,  9.4602e-02,  9.3613e-02,  6.4790e-02,  2.7904e-01,\n",
      "         1.9859e-01,  4.2976e+00,  3.5580e+00,  2.6433e-01,  2.4989e+00,\n",
      "         3.5218e+00,  2.1408e+00, -1.0404e+00,  2.3425e-01,  2.8465e-01,\n",
      "         1.5917e-01, -2.9006e-01,  1.9821e-01,  3.2712e+00,  2.2681e-01,\n",
      "         1.3158e+00,  4.5736e-01, -1.8084e+00,  4.3215e+00,  1.8238e-01,\n",
      "        -7.7081e-02, -6.6359e-01,  1.3678e-01,  1.4062e-01,  1.8447e-01,\n",
      "         3.3025e-01,  1.0515e-01,  8.7393e-01,  2.2544e-01,  1.8499e-01,\n",
      "         1.9595e-01,  1.9883e+00,  1.3343e-01,  3.0637e-02,  1.9525e-01,\n",
      "        -9.0173e-01,  3.1818e+00,  9.2961e-01,  3.6996e+00,  3.4337e-01,\n",
      "         1.2016e+00, -2.1339e+00, -1.2630e-01,  2.8079e-01,  3.9778e+00,\n",
      "         8.6608e-02,  2.2955e-01,  5.1290e+00,  3.1071e-01,  1.1663e-01,\n",
      "         2.5868e+00,  1.5947e+00,  1.4448e+00,  2.3563e+00,  3.9710e-01,\n",
      "         1.4259e-01,  3.5426e-01, -2.4100e-01,  1.2113e+00,  2.0642e-01,\n",
      "         2.8404e-01,  2.6471e-01, -6.3143e-01,  2.4277e+00,  4.3847e-01,\n",
      "         3.3530e+00,  3.9795e+00,  4.4001e+00,  9.2920e-02,  1.4276e+00,\n",
      "         3.5472e+00,  1.9770e+00,  3.3465e-01, -1.2306e-01,  8.0348e-02,\n",
      "        -1.9054e-02,  3.2575e+00,  2.0020e-01,  3.7895e-01,  3.9798e+00,\n",
      "         2.1386e-01,  4.4956e-01,  3.2746e+00,  1.9268e+00,  3.6778e+00,\n",
      "         3.6008e+00,  2.1279e+00,  2.9134e-01,  4.1245e+00,  2.1431e-01,\n",
      "         9.4790e-01, -2.5009e-02,  3.5597e-01,  1.8147e-01,  4.7286e+00,\n",
      "         1.3347e+00,  1.1541e+00,  5.0280e-01,  3.7816e+00,  4.4386e+00,\n",
      "         3.6542e+00,  2.2619e-01,  1.7159e-02,  1.4174e-01,  1.2298e-01,\n",
      "         1.5912e+00,  4.7688e-01, -6.9780e-01,  1.7237e-01,  2.3883e-01,\n",
      "         1.4879e-01,  3.0384e+00,  1.8594e+00,  4.0435e+00,  1.9841e+00,\n",
      "         1.8740e-01,  2.1697e-01,  4.3318e+00,  4.7999e+00,  1.5003e-01,\n",
      "         3.0280e+00,  1.6735e-02,  6.2181e-02, -3.0984e-01,  7.1625e-01,\n",
      "         1.0092e-01,  2.8401e+00,  3.2547e-01,  1.9374e-01,  2.0590e+00,\n",
      "         2.1228e-01,  3.6565e+00,  1.5252e-01,  1.8919e-01,  1.1510e-01,\n",
      "         1.0157e-01,  4.2769e-01,  1.7210e-01,  2.1877e+00,  3.2197e+00,\n",
      "         3.1880e-01,  3.4695e-01,  2.3411e-01,  4.5317e+00,  2.1310e-01,\n",
      "         2.6258e-01,  2.8943e-01,  2.8523e+00,  3.1409e-01, -8.9582e-04,\n",
      "         1.1789e+00,  3.3062e-01,  2.9909e-01,  2.7318e-01,  3.0273e+00,\n",
      "         1.0122e+00, -4.2109e-01,  5.3088e-01, -6.7000e-02,  6.7973e-01,\n",
      "         4.1974e+00,  3.2047e-01,  3.9270e-01,  4.4665e+00,  2.3860e+00,\n",
      "         1.3119e+00, -1.2647e-01,  2.3752e-01,  8.8927e-01,  4.2374e-01,\n",
      "         2.3873e+00, -7.5090e-01, -1.0608e-01,  3.1507e-01,  3.7607e-01,\n",
      "         2.1085e-01,  4.1418e-01,  3.8852e-01,  2.1854e-01,  9.6967e-02,\n",
      "         2.8783e-01, -3.9702e-01, -3.0782e-02,  1.6101e+00,  2.3155e-01,\n",
      "         1.8971e-01,  4.6223e+00,  2.1615e+00,  2.0473e-01,  2.1241e-01,\n",
      "         4.2796e+00, -7.8173e-01,  3.3647e-01,  1.5535e-01, -9.9451e-01,\n",
      "         3.1587e+00,  4.7192e+00, -6.1404e-01,  1.3484e-01,  2.3874e+00,\n",
      "        -8.0200e-02,  1.3124e+00,  1.1946e-01,  9.9330e-01,  4.7832e-01,\n",
      "         1.2263e-01, -1.6013e+00,  6.7593e-02,  1.0494e+00,  2.9072e+00,\n",
      "         1.0104e-01,  3.3508e+00,  3.8914e+00,  8.8043e-03,  2.1170e-01,\n",
      "         2.0475e+00, -1.9273e-02,  3.4805e-01,  1.8640e-01,  5.5210e-01,\n",
      "         4.3036e+00,  2.8915e+00,  2.8660e+00,  2.2555e-01,  1.8872e+00,\n",
      "         5.1529e-02,  2.2175e-01,  1.1373e+00,  4.3621e+00,  2.4560e+00,\n",
      "         1.3866e-01,  3.6298e+00,  4.8465e+00,  1.4266e+00,  2.4618e-01,\n",
      "         2.0153e-01,  2.6031e-01, -1.3933e-01,  3.1357e+00,  4.3346e-01,\n",
      "         1.0588e+00, -2.1044e-01,  1.9706e+00, -2.6652e-01,  1.3599e+00,\n",
      "         2.1108e+00,  1.6475e+00,  2.0293e-01,  8.4983e-01,  2.7677e-01,\n",
      "         3.8913e+00,  3.2655e+00,  5.5344e-02,  2.6697e-01,  2.4226e-01,\n",
      "         1.9674e-01,  2.6326e-01,  2.8897e-01,  1.7385e-01, -8.2049e-02,\n",
      "         2.2541e-01,  4.1394e-01, -1.2249e-01,  4.2644e-01,  2.1140e-01,\n",
      "         2.7098e-01, -3.4804e-03,  1.0452e+00,  1.4099e+00,  2.4111e-01,\n",
      "         4.2343e+00, -4.9592e-02,  2.9423e-01,  1.0718e-01,  4.0472e-01,\n",
      "         5.0099e-01,  4.0335e+00,  1.2854e+00,  6.0550e-02, -9.6672e-02,\n",
      "         3.8074e-01,  1.2641e+00,  5.8814e-01,  5.1020e-02,  3.8404e-01,\n",
      "         3.4701e+00,  7.8934e-01,  3.5838e-01,  1.8232e-01,  6.0372e-01,\n",
      "         3.0327e-01,  1.8033e-01,  1.3305e+00,  5.1845e-01,  2.9718e-01,\n",
      "         7.2420e-01,  1.8537e-01,  8.4117e-01,  9.5265e-01,  1.8235e-01,\n",
      "         1.2384e-01,  1.6536e-01,  3.0712e-01,  2.2409e-01,  2.0446e-01,\n",
      "         3.2388e+00,  3.9781e+00,  6.3683e-01,  1.3103e-01,  1.1395e+00,\n",
      "         2.6419e-01,  2.3591e-01,  5.2350e-01,  2.8407e-01,  2.3391e-01,\n",
      "         1.1379e-01,  2.8123e-01, -3.5974e-01,  1.9013e-01,  9.0286e-02,\n",
      "         1.4602e-01,  7.9142e-02,  2.3663e+00,  2.1731e-01,  6.8793e-02,\n",
      "         1.2837e-01,  1.8920e+00,  3.6709e-01,  3.4852e+00,  7.8255e-02,\n",
      "         1.2994e-01,  3.9169e+00,  2.8637e+00,  1.9669e-01, -8.1528e-01,\n",
      "         2.8847e-02,  1.6882e-01,  2.2848e-01,  1.5782e-01,  3.4101e+00,\n",
      "         2.1697e-01,  1.5551e-01,  3.8305e+00,  2.3235e-01,  3.2938e+00,\n",
      "         4.2289e+00,  2.4658e-01,  1.7797e-01,  1.6226e+00,  3.3058e-01,\n",
      "         3.6690e+00,  1.9401e-01,  8.5858e-02,  1.5254e-01, -1.4770e-01,\n",
      "         2.4126e-01,  8.4269e-01,  4.5082e+00,  1.5810e-01,  1.1337e-01,\n",
      "         3.2606e+00,  3.5512e+00,  4.4051e+00, -1.2405e-01,  4.2454e+00,\n",
      "         2.4659e-01,  2.0331e-01,  4.1692e-01,  1.5962e-01,  9.1859e-02,\n",
      "         4.5565e+00,  1.1165e-01,  1.0462e-01,  2.1267e-01,  2.4739e-01,\n",
      "         3.9284e+00,  3.6273e+00,  2.1817e-01,  2.2235e-01,  4.9646e-01,\n",
      "         4.5155e-02,  1.2342e-01,  5.7926e-01, -1.1728e-02,  7.9537e-01,\n",
      "         9.2940e-01,  1.6360e-01,  1.0819e+00,  4.9086e-01,  2.8910e-02,\n",
      "         3.3715e+00,  3.9593e-01,  2.2056e+00,  1.5803e-01,  1.3873e+00,\n",
      "         2.2171e-01,  1.9144e-01,  2.8184e-01,  3.9046e-01,  1.3127e-01,\n",
      "         4.4284e+00,  1.9475e-01,  1.6808e-01,  3.4326e+00,  2.9205e-01,\n",
      "         2.8100e-01,  4.9617e+00,  2.9361e-01,  3.8072e+00,  2.9838e-02,\n",
      "         1.0513e-01,  2.6799e-01,  2.3399e-01,  2.3928e-01,  4.3448e-02,\n",
      "         1.8496e-01,  1.2442e-01, -7.3402e-01,  6.8459e-01,  1.6391e-01,\n",
      "         3.1666e-02], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0538]],\n",
      "\n",
      "         [[ 0.0405]],\n",
      "\n",
      "         [[ 0.0310]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         [[-0.0269]],\n",
      "\n",
      "         [[-0.0111]]],\n",
      "\n",
      "\n",
      "        [[[-0.0052]],\n",
      "\n",
      "         [[ 0.0305]],\n",
      "\n",
      "         [[ 0.3187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1080]],\n",
      "\n",
      "         [[-0.0410]],\n",
      "\n",
      "         [[ 0.0302]]],\n",
      "\n",
      "\n",
      "        [[[-0.0942]],\n",
      "\n",
      "         [[-0.1312]],\n",
      "\n",
      "         [[-0.0033]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1046]],\n",
      "\n",
      "         [[-0.0644]],\n",
      "\n",
      "         [[-0.0594]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1040]],\n",
      "\n",
      "         [[-0.1640]],\n",
      "\n",
      "         [[ 0.0098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0592]],\n",
      "\n",
      "         [[ 0.1085]],\n",
      "\n",
      "         [[ 0.0100]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0261]],\n",
      "\n",
      "         [[ 0.1327]],\n",
      "\n",
      "         [[ 0.0102]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0175]],\n",
      "\n",
      "         [[ 0.0348]],\n",
      "\n",
      "         [[-0.0980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0061]],\n",
      "\n",
      "         [[ 0.0018]],\n",
      "\n",
      "         [[ 0.0378]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0545]],\n",
      "\n",
      "         [[ 0.2397]],\n",
      "\n",
      "         [[-0.0068]]]], device='cuda:0')\n",
      "Shape: torch.Size([160, 576, 1, 1])\n",
      "\n",
      "Layer: features.14.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.6911465525627136\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.685746967792511\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.3.weight\n",
      "Weights: tensor([2.0001, 3.0690, 2.1995, 2.6506, 2.4443, 3.0268, 2.7616, 4.2054, 2.7950,\n",
      "        3.5043, 2.4131, 2.4065, 2.5563, 2.1848, 2.3045, 2.2772, 3.2411, 2.0874,\n",
      "        4.5582, 2.2123, 3.4077, 2.7890, 2.5905, 2.2312, 2.7587, 2.5490, 3.6211,\n",
      "        2.8622, 2.8162, 2.5381, 3.1120, 2.5798, 2.7786, 2.4798, 2.3162, 3.8977,\n",
      "        2.3651, 3.3775, 2.2783, 2.8029, 2.2384, 2.9567, 2.9893, 3.8085, 2.3301,\n",
      "        2.7076, 2.6217, 2.7108, 3.9463, 2.2933, 2.2586, 2.2421, 2.2483, 2.4748,\n",
      "        2.4606, 2.3461, 2.3457, 2.8188, 2.3376, 1.9580, 2.5647, 2.7695, 2.4796,\n",
      "        2.9853, 2.5451, 2.3056, 2.2633, 2.4383, 3.2932, 1.7793, 2.0911, 3.3688,\n",
      "        2.7705, 2.5582, 2.0668, 2.4369, 2.7557, 2.4616, 2.0222, 3.5438, 2.7680,\n",
      "        2.4652, 3.3052, 2.4949, 2.3305, 2.7112, 3.7348, 2.4240, 2.4292, 2.4307,\n",
      "        2.5798, 2.3785, 2.3208, 3.4096, 2.7397, 2.8142, 3.3101, 2.8058, 2.5114,\n",
      "        2.4586, 2.3392, 2.6736, 2.1785, 2.3646, 2.0859, 2.7855, 2.2522, 2.6208,\n",
      "        2.6276, 2.7167, 2.4414, 2.3090, 1.9961, 2.9135, 2.4276, 3.3626, 2.3305,\n",
      "        3.0630, 3.6676, 3.1886, 2.5065, 1.9672, 3.1328, 2.4882, 2.3008, 2.1660,\n",
      "        2.6977, 3.1456, 2.2368, 2.4529, 2.9223, 2.6659, 3.0190, 3.3405, 3.3434,\n",
      "        2.2128, 3.1375, 4.0217, 2.4894, 2.8488, 2.3746, 2.4647, 3.7627, 2.7561,\n",
      "        2.0635, 3.1380, 2.3772, 3.2165, 2.3424, 1.9993, 2.1463, 2.2593, 2.5559,\n",
      "        2.5494, 2.3325, 2.1285, 2.3695, 2.4301, 2.3888, 2.5819],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.14.conv.3.bias\n",
      "Weights: tensor([ 1.1784e-03, -2.4988e-04,  8.9454e-05, -3.3950e-04,  2.2312e-04,\n",
      "        -1.0689e-03,  1.9809e-04,  3.3180e-04, -1.8088e-04, -8.7599e-04,\n",
      "        -1.1255e-04,  1.4259e-05, -3.7005e-04, -3.9558e-04,  7.5409e-04,\n",
      "        -6.3099e-04, -5.1123e-04,  8.5052e-04,  1.0185e-03, -3.5606e-05,\n",
      "        -1.0598e-04, -3.3975e-05, -4.2180e-04, -7.6880e-05, -2.9648e-04,\n",
      "        -1.5112e-03,  1.3728e-04,  4.2894e-04,  4.6910e-04,  5.2243e-05,\n",
      "         1.4319e-04, -7.6321e-04,  5.2145e-04, -7.9943e-05,  1.3844e-03,\n",
      "        -8.1506e-04, -9.1879e-05, -1.2169e-04, -4.1312e-04,  3.6780e-04,\n",
      "         5.9343e-04,  2.0095e-04,  1.0860e-04,  1.0628e-05,  1.4055e-03,\n",
      "         1.0320e-03,  3.7948e-05,  1.1553e-04,  2.1829e-07, -2.0294e-03,\n",
      "         7.7212e-05,  8.6975e-04, -8.0371e-04,  2.5960e-04,  6.7046e-04,\n",
      "        -2.6918e-04, -7.0511e-05, -4.7571e-05, -4.6849e-04,  7.7162e-04,\n",
      "        -4.9834e-04, -5.2130e-05, -1.2490e-04, -1.8343e-04, -1.5826e-05,\n",
      "         5.1195e-04, -4.0874e-04, -1.9817e-04, -3.2194e-04,  4.3598e-04,\n",
      "        -1.0136e-03, -6.9143e-05,  1.2401e-05,  3.4226e-05,  1.1688e-03,\n",
      "         6.3362e-06,  9.9703e-04,  4.8798e-04, -7.5100e-04, -5.2428e-04,\n",
      "        -1.5707e-05,  4.8960e-04,  2.0340e-04,  2.2366e-04, -7.9977e-04,\n",
      "         6.1548e-05,  8.2423e-04,  2.3376e-04,  4.7247e-04, -3.7435e-04,\n",
      "         2.3088e-04,  4.0327e-04, -2.8730e-04,  9.9384e-04, -2.4178e-04,\n",
      "         1.2356e-04,  1.0230e-03, -2.6112e-04,  1.5219e-04, -3.9729e-04,\n",
      "         4.7102e-04,  1.8307e-04, -2.6768e-04,  6.9568e-04,  7.7717e-04,\n",
      "        -4.8341e-04, -1.0065e-03,  1.9398e-04, -1.5876e-04,  6.5772e-04,\n",
      "         1.9242e-04,  1.5973e-03, -6.6664e-04, -4.8910e-04, -5.5301e-04,\n",
      "         2.0193e-04,  2.8869e-04,  5.7576e-05,  2.8756e-04,  4.1104e-04,\n",
      "         9.6192e-04,  5.6796e-04,  6.6531e-05, -9.8169e-05, -1.9765e-04,\n",
      "         1.1040e-04,  1.8131e-04, -6.1046e-04,  4.1388e-04, -4.3122e-04,\n",
      "        -4.0890e-04, -9.2789e-06,  2.3050e-04, -6.1154e-04, -1.9268e-04,\n",
      "         1.5158e-04, -3.8079e-06, -2.0966e-04, -8.2658e-05, -6.4799e-04,\n",
      "        -3.6372e-04, -5.4580e-04,  1.8475e-04, -3.4798e-04, -1.2524e-05,\n",
      "         4.6109e-04,  1.0103e-03,  2.8322e-04,  7.4059e-04, -2.2497e-04,\n",
      "         1.0309e-03,  4.5232e-04, -9.7320e-04,  4.5137e-04,  2.9859e-04,\n",
      "         7.5383e-04, -2.4530e-04, -2.1087e-04,  2.2084e-04, -5.7706e-05],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.14.conv.3.output_quantizers.0.min\n",
      "Weights: -20.478240966796875\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.14.conv.3.output_quantizers.0.max\n",
      "Weights: 20.12468719482422\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.1637]],\n",
      "\n",
      "         [[ 0.1007]],\n",
      "\n",
      "         [[ 0.0238]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0128]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         [[ 0.0010]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0423]],\n",
      "\n",
      "         [[ 0.0739]],\n",
      "\n",
      "         [[-0.0259]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0304]],\n",
      "\n",
      "         [[ 0.0006]],\n",
      "\n",
      "         [[-0.0271]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1068]],\n",
      "\n",
      "         [[ 0.0122]],\n",
      "\n",
      "         [[-0.0824]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0384]],\n",
      "\n",
      "         [[-0.0298]],\n",
      "\n",
      "         [[-0.0015]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0474]],\n",
      "\n",
      "         [[ 0.0182]],\n",
      "\n",
      "         [[-0.0461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         [[-0.0323]],\n",
      "\n",
      "         [[ 0.1116]]],\n",
      "\n",
      "\n",
      "        [[[-0.0394]],\n",
      "\n",
      "         [[ 0.0967]],\n",
      "\n",
      "         [[-0.0718]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[ 0.0280]],\n",
      "\n",
      "         [[ 0.0714]]],\n",
      "\n",
      "\n",
      "        [[[-0.0532]],\n",
      "\n",
      "         [[-0.0462]],\n",
      "\n",
      "         [[-0.0181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1215]],\n",
      "\n",
      "         [[ 0.0516]],\n",
      "\n",
      "         [[-0.0750]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 160, 1, 1])\n",
      "\n",
      "Layer: features.15.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.40666458010673523\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.40348750352859497\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.0.1.weight\n",
      "Weights: tensor([0.8292, 1.0355, 1.0685, 1.0883, 0.8745, 0.9857, 0.4964, 1.8508, 1.3904,\n",
      "        1.0921, 1.0437, 1.1786, 1.0305, 1.0580, 0.8881, 0.7123, 1.2003, 1.1495,\n",
      "        1.0589, 1.0121, 0.8826, 1.3076, 0.7295, 0.8358, 1.0355, 1.1838, 1.2922,\n",
      "        0.7406, 1.1302, 0.7588, 1.0840, 1.2810, 1.3287, 0.9400, 0.5667, 1.0350,\n",
      "        2.0158, 0.5527, 0.6153, 1.0201, 0.5425, 0.8175, 1.0565, 1.2594, 1.3252,\n",
      "        0.5758, 1.0735, 0.9372, 0.4473, 0.8202, 0.4651, 0.9589, 1.1051, 1.0101,\n",
      "        0.9262, 0.8399, 0.8903, 0.4278, 0.6923, 0.7172, 0.7232, 0.8649, 0.9421,\n",
      "        1.1016, 0.7030, 1.7546, 0.8715, 1.4500, 0.6928, 1.0567, 1.2959, 0.7759,\n",
      "        1.0428, 1.3530, 0.9943, 1.4577, 0.9548, 1.1398, 1.0148, 1.0111, 1.4477,\n",
      "        1.0126, 2.3637, 1.0003, 1.1492, 1.1188, 1.2836, 0.8963, 1.0719, 0.9000,\n",
      "        0.9005, 1.2558, 0.8464, 1.1113, 0.7262, 0.8567, 0.5043, 0.3584, 0.9463,\n",
      "        1.0226, 0.8563, 0.9553, 1.3180, 0.8571, 0.3848, 1.1391, 0.4420, 0.4852,\n",
      "        1.1916, 1.0870, 0.8386, 0.8656, 0.7350, 0.7015, 0.8970, 1.1483, 0.9831,\n",
      "        0.7224, 1.0491, 1.0714, 1.1731, 0.5465, 0.6164, 0.8417, 0.8030, 1.3082,\n",
      "        1.0011, 1.1867, 0.8833, 1.2977, 1.2159, 0.8691, 0.3677, 1.1923, 0.7205,\n",
      "        1.3267, 0.7628, 0.8536, 1.0349, 1.1788, 0.9483, 0.6403, 0.3664, 1.1204,\n",
      "        1.1991, 1.0806, 3.2005, 0.4203, 1.0482, 1.1357, 0.8348, 0.8147, 0.7592,\n",
      "        0.7775, 0.7013, 1.1102, 0.6400, 1.0294, 1.2218, 0.9439, 0.9158, 1.0979,\n",
      "        1.1312, 0.9125, 1.1464, 1.9350, 0.9496, 1.1890, 0.5879, 0.8056, 1.0713,\n",
      "        0.5958, 0.7150, 0.9887, 0.9508, 1.0590, 0.7428, 0.7988, 0.4686, 1.1727,\n",
      "        0.6342, 0.9082, 0.8930, 0.6307, 0.5744, 1.0083, 0.9097, 0.8642, 1.1704,\n",
      "        1.0852, 0.8705, 1.2162, 1.0655, 1.1141, 0.4544, 1.0684, 1.2022, 0.8010,\n",
      "        0.5369, 0.8922, 0.3044, 0.8670, 0.7299, 0.7810, 0.7119, 1.1785, 0.8222,\n",
      "        1.1877, 0.9916, 0.9861, 1.0281, 1.1179, 0.5592, 1.0089, 1.0306, 0.9192,\n",
      "        0.5268, 0.7791, 0.7814, 1.0385, 1.0758, 1.0779, 1.1805, 0.3602, 1.1296,\n",
      "        1.1056, 0.9926, 0.8231, 0.8743, 1.2993, 1.2732, 1.3448, 0.8413, 0.7898,\n",
      "        2.1195, 1.2266, 1.1807, 1.1307, 1.1062, 1.0431, 1.0297, 0.5460, 0.3564,\n",
      "        0.8329, 1.1696, 1.2907, 0.7292, 0.9523, 1.0374, 0.9083, 1.0129, 1.1859,\n",
      "        1.2251, 0.8294, 0.8269, 1.0924, 0.7689, 0.7156, 0.9427, 1.1961, 1.0458,\n",
      "        1.0304, 0.4299, 1.4197, 1.0238, 1.1973, 1.0217, 1.0363, 1.0148, 1.2022,\n",
      "        1.0301, 0.8414, 0.8442, 1.2238, 1.1768, 0.1478, 1.4123, 0.7810, 1.0290,\n",
      "        0.4203, 1.3472, 1.0979, 1.1808, 1.1153, 0.9180, 1.6862, 1.1845, 0.5583,\n",
      "        0.8129, 0.3678, 0.9385, 0.9982, 2.7353, 0.8346, 1.0232, 1.0381, 1.1710,\n",
      "        0.5935, 0.6899, 1.2937, 1.0543, 0.6415, 0.8138, 0.9220, 0.6609, 0.9613,\n",
      "        1.0426, 1.0360, 0.7531, 0.8237, 1.1479, 1.0455, 0.9486, 1.0039, 1.0756,\n",
      "        0.6398, 0.9284, 1.0991, 1.2652, 1.6397, 1.1359, 0.3712, 1.7186, 0.7159,\n",
      "        1.0213, 1.0056, 0.9161, 0.9416, 0.9207, 0.9929, 1.0782, 0.9372, 1.0303,\n",
      "        0.7847, 0.8998, 0.7678, 1.3885, 1.1207, 1.3358, 1.1701, 0.5505, 0.7783,\n",
      "        1.1867, 1.2458, 0.8077, 0.7431, 1.7497, 0.9562, 0.8743, 0.9374, 1.1346,\n",
      "        1.0667, 0.8855, 0.6682, 1.1994, 0.4023, 0.7545, 1.3283, 1.2622, 1.1508,\n",
      "        1.0815, 1.2976, 0.8615, 0.9774, 0.7325, 0.8400, 0.7888, 0.6894, 0.9776,\n",
      "        1.0763, 0.7566, 0.8429, 0.7097, 1.3245, 0.9987, 1.0960, 1.3129, 0.5382,\n",
      "        0.8135, 0.8448, 1.1301, 0.8683, 0.7974, 1.1924, 1.1174, 1.0312, 0.9107,\n",
      "        0.8330, 0.9889, 1.0437, 0.5073, 0.7021, 0.9201, 1.1720, 0.7464, 1.1947,\n",
      "        1.0758, 1.0038, 1.1653, 1.1837, 0.4711, 1.0244, 1.1584, 1.1270, 1.3541,\n",
      "        0.8297, 1.2523, 0.9791, 0.8879, 0.9913, 0.9694, 0.7062, 1.1018, 1.0625,\n",
      "        0.9942, 0.3356, 0.8830, 1.2108, 1.2986, 0.4544, 0.5733, 1.3813, 1.0333,\n",
      "        1.0628, 1.1484, 1.1396, 0.7495, 1.2046, 1.0449, 0.9446, 1.0918, 0.9440,\n",
      "        1.3106, 1.0033, 1.0207, 1.1386, 1.0961, 1.0344, 1.1742, 1.2487, 0.7809,\n",
      "        1.5483, 1.0764, 0.5204, 0.7374, 1.0812, 1.1202, 0.9227, 0.8657, 0.6475,\n",
      "        0.9548, 0.8191, 0.8334, 0.8825, 0.3691, 0.8011, 0.5882, 0.4997, 0.7732,\n",
      "        1.2546, 1.2298, 1.2562, 0.2260, 0.8148, 0.3891, 1.4424, 0.9997, 0.9407,\n",
      "        0.7728, 1.4227, 0.7421, 0.9611, 0.8935, 0.7417, 0.9303, 0.9884, 1.0828,\n",
      "        1.5166, 0.8085, 0.9704, 1.1978, 0.9754, 1.0096, 0.8377, 1.3091, 1.0003,\n",
      "        1.0153, 0.9981, 1.1002, 0.9497, 1.2170, 1.4187, 1.1157, 1.1563, 1.0896,\n",
      "        1.2437, 1.1079, 1.2410, 0.5849, 1.2726, 0.9843, 0.7775, 1.1180, 0.9228,\n",
      "        1.0016, 1.2323, 0.8149, 0.7815, 0.7303, 1.0789, 1.0987, 0.7976, 0.7961,\n",
      "        0.8711, 0.9429, 0.8107, 1.0869, 0.9138, 0.8497, 1.0966, 0.8343, 0.8350,\n",
      "        1.3008, 1.0129, 0.8519, 1.1286, 1.1695, 0.8414, 0.8551, 0.9870, 1.1461,\n",
      "        0.6001, 0.9453, 0.4191, 0.7944, 0.8905, 0.9061, 1.5987, 1.0262, 0.7911,\n",
      "        1.2356, 1.1561, 0.8104, 1.1190, 1.1592, 0.7383, 0.3471, 0.6674, 0.9475,\n",
      "        2.8096, 1.0079, 1.2762, 0.4647, 0.6416, 0.9583, 0.9798, 0.9255, 0.5615,\n",
      "        0.9465, 1.0865, 0.4705, 1.0313, 0.6988, 1.1421, 1.0756, 0.9501, 2.9064,\n",
      "        1.1094, 0.8592, 0.5560, 0.9056, 1.0706, 0.8825, 0.9615, 0.9141, 0.5927,\n",
      "        1.0213, 1.1661, 1.1692, 0.8888, 0.9725, 0.4896, 1.0347, 1.2234, 0.8012,\n",
      "        0.5028, 1.0801, 0.8840, 0.5402, 0.9131, 0.8416, 0.7425, 1.2979, 0.9082,\n",
      "        0.8046, 0.7872, 0.9427, 1.0992, 1.2449, 0.9766, 1.2645, 1.0151, 1.1416,\n",
      "        0.4656, 0.8564, 0.8799, 0.4978, 0.4714, 1.5031, 0.7768, 0.9096, 1.2805,\n",
      "        1.2050, 1.0140, 1.0443, 1.0427, 0.7332, 1.0707, 1.0143, 1.0951, 1.0525,\n",
      "        1.2506, 1.0745, 0.8682, 1.1376, 0.8219, 1.1106, 1.1620, 0.8749, 0.9093,\n",
      "        0.9357, 1.1437, 0.8065, 0.9625, 0.9459, 1.2097, 1.0492, 1.0925, 0.7867,\n",
      "        1.2906, 1.2541, 0.8417, 1.5814, 1.1281, 1.1158, 0.8081, 1.1547, 0.8972,\n",
      "        0.6666, 0.9844, 1.2223, 0.7816, 0.9043, 0.8538, 0.8011, 0.6640, 1.3841,\n",
      "        0.9204, 1.0168, 1.1553, 0.7046, 0.4312, 1.0027, 0.8692, 2.3911, 1.0386,\n",
      "        1.0293, 1.1466, 1.0829, 1.2589, 1.0156, 1.1134, 1.3931, 1.2565, 0.8071,\n",
      "        1.2428, 0.9477, 0.9941, 0.7023, 1.2305, 1.0162, 1.0633, 0.8925, 0.5904,\n",
      "        0.8565, 0.5966, 0.8606, 0.6477, 1.0905, 1.0358, 0.8794, 1.1926, 1.0189,\n",
      "        1.3083, 0.7618, 1.1646, 0.9745, 0.7744, 1.2801, 0.8683, 1.2077, 1.0627,\n",
      "        0.8545, 1.0952, 0.4821, 1.2256, 0.9180, 1.0190, 0.6074, 1.3862, 0.7630,\n",
      "        0.9390, 0.8962, 0.8439, 1.0936, 0.6650, 0.8547, 1.0561, 0.4483, 0.3783,\n",
      "        0.5449, 0.7972, 0.9756, 0.8209, 1.4859, 0.7770, 1.0368, 1.0704, 0.8948,\n",
      "        1.3206, 0.7500, 0.6177, 1.2803, 1.1653, 0.4166, 0.7215, 1.0306, 0.7952,\n",
      "        1.1465, 0.8966, 0.8651, 1.4774, 0.3889, 0.3435, 0.7722, 1.2739, 1.0804,\n",
      "        1.0570, 1.2841, 1.1268, 0.6882, 0.3983, 1.2590, 0.8563, 1.1012, 1.4122,\n",
      "        0.7886, 0.8944, 1.0953, 0.5596, 1.1298, 0.7828, 1.3562, 1.2171, 1.0085,\n",
      "        0.8564, 0.6987, 1.0024, 0.5736, 0.8073, 0.7197, 0.8862, 0.8289, 1.5017,\n",
      "        0.7914, 0.8943, 1.0470, 0.7845, 0.8503, 0.8146, 1.2081, 1.1950, 0.6602,\n",
      "        0.9979, 0.5760, 1.1005, 0.7479, 0.6817, 1.1113, 1.1150, 1.1036, 0.8204,\n",
      "        1.3189, 0.5647, 1.4760, 1.0822, 1.0675, 0.8181, 1.1316, 0.6986, 0.9832,\n",
      "        0.9950, 1.0425, 0.9811, 1.1510, 0.8577, 1.1479, 0.8613, 0.7529, 0.6787,\n",
      "        0.8668, 1.0864, 0.9958, 1.0666, 0.8813, 0.8778, 0.9051, 0.8900, 1.1730,\n",
      "        2.1593, 1.2655, 0.6442, 0.4628, 0.9106, 0.9021, 0.9105, 0.8503, 1.2053,\n",
      "        1.3029, 0.9186, 0.8869, 1.5370, 0.6579, 1.1723, 0.9513, 1.0699, 0.8174,\n",
      "        0.7563, 1.2615, 0.8689, 0.8835, 0.9652, 0.3347, 0.4164, 1.0959, 1.3052,\n",
      "        0.8257, 3.2416, 0.7388, 0.8366, 0.8696, 0.9023, 0.9479, 1.0594, 0.8293,\n",
      "        1.0178, 0.7477, 1.3888, 1.1957, 0.7149, 1.1755, 0.8160, 0.8408, 0.8251,\n",
      "        0.8907, 1.2082, 0.6212, 0.9801, 0.3207, 1.1548, 0.7074, 0.8152, 0.4077,\n",
      "        1.2629, 0.6774, 0.7251, 1.0905, 0.8174, 0.7705, 0.9827, 0.8950, 1.1130,\n",
      "        0.7859, 0.8829, 0.9000, 0.8509, 1.2702, 1.2398, 1.0030, 1.1741, 0.7980,\n",
      "        0.6672, 0.9084, 0.9424, 0.9202, 0.7368, 0.3297, 1.0061, 0.8325, 0.4011,\n",
      "        1.0033, 1.2756, 0.9727, 1.2138, 1.0927, 0.7069, 1.1011, 0.8379, 0.8128,\n",
      "        1.0414, 0.4382, 0.4177, 0.5457, 0.3977, 1.3575, 0.7294, 1.2716, 1.0030,\n",
      "        1.0511, 0.8465, 0.9965, 0.5704, 0.4760, 0.3432, 0.8923, 1.0531, 0.8300,\n",
      "        0.9591, 1.1114, 1.0854, 0.3974, 1.2208, 0.8500, 1.0252, 1.4998, 1.1802,\n",
      "        0.7644, 1.0941, 1.1653, 0.9396, 0.8516, 0.9546, 1.2563, 1.2032, 0.5335,\n",
      "        1.0260, 1.2238, 1.1098, 1.2479, 1.5821, 0.6681, 1.2572, 1.0611, 1.1902,\n",
      "        0.6385, 1.2403, 1.3060, 1.4068, 1.2677, 0.7125], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.0.1.bias\n",
      "Weights: tensor([ 1.6540e+00,  5.7923e-01,  4.5722e-01,  4.0107e-01,  4.1945e-01,\n",
      "        -3.1043e-01,  1.6277e+00,  1.3534e+00, -1.5859e+00, -1.1258e+00,\n",
      "        -8.5753e-01,  1.0415e+00,  5.8811e-01,  1.8223e-01,  5.4537e-01,\n",
      "         9.2545e-01, -4.5911e-01, -1.0847e+00, -7.6483e-01,  6.3605e-01,\n",
      "         9.9208e-01,  2.0917e-01,  5.4133e-01,  9.0339e-01,  5.2176e-01,\n",
      "        -5.9087e-01, -5.9429e-01,  1.0862e+00, -6.3782e-01,  9.1577e-01,\n",
      "        -3.1240e-01, -5.4074e-01,  3.5327e-01, -2.5610e-01,  1.2922e+00,\n",
      "         6.6710e-01, -7.9351e-01,  1.6042e+00,  8.0498e-01,  5.4664e-01,\n",
      "         1.0869e+00,  1.1828e+00,  2.8610e-01, -4.4288e-01, -4.9615e-01,\n",
      "         1.4671e+00, -9.1449e-01, -1.6311e-01,  1.5746e+00,  9.7036e-01,\n",
      "         1.6340e+00, -1.2506e+00,  1.9832e-01,  7.0880e-01,  6.4380e-02,\n",
      "         8.6031e-01,  2.5443e-01,  1.6782e+00,  7.6070e-01,  1.0671e+00,\n",
      "         9.5269e-01,  2.6707e-01,  9.6529e-01,  5.6449e-01,  7.9519e-01,\n",
      "         2.8522e-01,  1.8791e-01, -2.2313e+00,  1.5082e+00, -7.0388e-01,\n",
      "         7.4580e-01,  1.2371e+00,  8.7045e-02, -8.9550e-02, -8.9352e-01,\n",
      "         4.2991e-01,  6.8599e-01, -5.7589e-01,  3.7336e-01,  5.0311e-01,\n",
      "        -6.8907e-01,  2.5866e-01, -6.2139e-01, -7.1218e-01, -8.7089e-01,\n",
      "        -2.4817e-01, -4.8067e-01,  3.1233e-01,  6.2725e-01,  6.7389e-01,\n",
      "         3.9578e-02,  2.9321e-01,  7.1606e-01,  6.0110e-01,  7.1649e-01,\n",
      "        -5.2483e-01,  1.4396e+00,  1.2105e+00,  3.5815e-01,  6.9601e-01,\n",
      "         1.6406e-01,  3.5093e-01, -3.9210e-01,  8.9042e-01,  1.5646e+00,\n",
      "         4.3610e-01,  1.1301e+00,  1.8915e+00,  8.3863e-01, -7.9966e-01,\n",
      "         8.5110e-01,  2.9490e-01,  1.4776e+00,  9.8034e-01,  5.7795e-03,\n",
      "        -6.7218e-01,  7.9682e-01,  1.0021e+00,  1.5064e-01,  7.4156e-01,\n",
      "        -2.3334e-01,  1.3399e+00,  9.7890e-01,  7.1803e-01,  1.6210e+00,\n",
      "        -5.1009e-01,  7.3622e-01,  4.1350e-01, -4.8198e-02,  2.3201e-01,\n",
      "         6.6580e-01,  6.2392e-01,  1.5720e+00,  4.8576e-02,  9.8472e-01,\n",
      "        -4.0751e-01,  9.9916e-01,  8.6773e-01, -4.0787e-02, -1.2271e+00,\n",
      "         6.3085e-01, -1.6072e-01,  1.2385e+00,  1.2449e+00, -2.6549e-01,\n",
      "        -9.9464e-01,  5.9015e-01,  1.2788e+00, -1.0579e+00,  1.8898e-01,\n",
      "         7.3636e-01,  2.5389e-01,  1.0914e+00,  9.2913e-01,  8.4567e-01,\n",
      "         3.0651e-01,  2.1543e-01,  5.2855e-01,  4.2756e-01,  6.1152e-01,\n",
      "         8.9443e-01,  3.2739e-01,  2.7988e-01,  7.8058e-01, -6.9426e-01,\n",
      "         1.0997e+00,  6.2505e-01, -4.8714e-01,  3.2373e-01,  8.3128e-01,\n",
      "         5.2902e-01,  1.3510e+00,  1.2210e+00, -4.7137e-01, -1.1626e+00,\n",
      "         4.8405e-01,  9.1280e-01,  1.1160e+00,  1.2746e+00, -2.2658e-02,\n",
      "         9.9069e-01,  6.6992e-01, -5.5859e-01,  9.8314e-01,  1.2577e+00,\n",
      "         6.8433e-01,  5.8398e-01,  9.1120e-01, -7.7793e-01, -4.2460e-01,\n",
      "         4.7031e-01, -2.7103e-01, -1.1375e-01,  1.2506e+00,  1.3377e+00,\n",
      "        -9.0353e-01,  2.9250e-01,  9.7648e-01,  1.2909e+00,  6.3163e-01,\n",
      "         1.3568e+00,  4.1961e-01,  1.0263e+00,  1.0421e+00,  8.9632e-01,\n",
      "        -6.6376e-01, -3.2954e-01,  3.3452e-01,  5.5262e-01,  7.2465e-01,\n",
      "         5.9642e-01,  6.3679e-02,  1.3344e+00,  6.0411e-01,  6.8610e-01,\n",
      "         7.7338e-01,  1.5566e+00,  7.3704e-01,  8.1491e-01,  4.9041e-01,\n",
      "         5.3990e-01,  2.0764e-01, -1.6612e+00,  1.2211e+00, -5.8438e-01,\n",
      "        -3.0342e-01, -4.9151e-02,  6.1061e-01,  9.0037e-01, -1.5377e-01,\n",
      "        -1.0260e+00, -3.2385e-01, -3.7706e-01,  9.2514e-01,  1.5977e+00,\n",
      "         7.0704e-02, -1.2794e+00,  5.6550e-01, -8.7753e-01, -7.6686e-01,\n",
      "        -2.4977e-01,  1.0891e+00,  1.6332e+00,  9.8332e-01, -1.2371e+00,\n",
      "        -1.9744e-01,  7.1444e-01,  2.1662e-01,  8.6798e-02,  9.2023e-01,\n",
      "         1.6217e-01, -3.6144e-01,  5.0611e-01,  7.8855e-01,  2.9904e-01,\n",
      "         4.0091e-01,  7.9400e-01,  9.9679e-01,  4.5771e-01,  1.3356e-01,\n",
      "         2.5465e-01,  4.0817e-01,  1.7512e+00, -5.3251e-01,  6.8974e-01,\n",
      "         3.2274e-01,  7.0006e-01, -1.7073e+00,  6.6714e-01, -1.0542e+00,\n",
      "         6.0531e-01, -6.4744e-01,  3.9136e-01,  7.3225e-01,  1.9573e-01,\n",
      "        -1.0875e+00, -5.0936e-01,  1.0466e+00,  7.3972e-01,  1.2384e+00,\n",
      "        -1.9956e+00, -8.6540e-01,  5.4826e-01,  5.5575e-01,  7.8854e-01,\n",
      "         6.8259e-01,  2.1035e-03,  1.5236e+00,  1.4427e-01,  1.4973e+00,\n",
      "         6.7848e-01,  9.5119e-01,  1.4416e+00,  3.2934e-01,  6.3992e-01,\n",
      "         5.0695e-01, -9.4199e-01,  1.1011e+00,  1.4203e+00, -5.7252e-01,\n",
      "         1.2981e-01,  1.2951e+00,  8.6834e-01,  3.6484e-01,  1.7099e+00,\n",
      "         6.6454e-01,  3.7259e-01,  9.4294e-01,  8.7928e-01,  8.8702e-01,\n",
      "        -3.6134e-01,  1.5262e-01,  5.5136e-01,  4.2363e-02,  6.4006e-01,\n",
      "         1.4531e+00,  1.1486e+00,  4.9314e-01, -6.6687e-01, -1.0717e-01,\n",
      "        -3.0746e-01,  1.2774e+00,  9.0033e-01,  9.1278e-01,  6.5959e-01,\n",
      "         6.6334e-01,  8.5381e-01,  7.1528e-01,  7.8545e-01,  4.7277e-01,\n",
      "         6.6720e-01, -1.7567e-01, -3.8335e-01,  8.1504e-01,  8.6482e-01,\n",
      "         6.1964e-01, -3.3281e-01, -1.3630e+00, -3.3471e-01, -7.6504e-01,\n",
      "        -2.6938e+00,  1.0826e+00,  1.3246e+00,  2.5796e-01,  3.9152e-01,\n",
      "         1.1046e+00, -5.0192e-01,  7.9416e-01,  7.9334e-01,  7.5284e-01,\n",
      "         4.5865e-01, -1.1034e+00,  8.0134e-01,  1.6247e+00, -1.2014e+00,\n",
      "         1.5821e+00,  9.4996e-01,  1.1476e+00, -5.8474e-01,  4.8785e-01,\n",
      "         6.0977e-01,  6.0025e-01,  1.0102e+00,  4.7217e-01,  1.1238e+00,\n",
      "         8.2497e-01,  9.3710e-01,  1.1051e+00,  6.0986e-01, -1.1766e+00,\n",
      "         7.2130e-01,  1.0949e+00,  1.1708e+00, -7.5940e-02,  4.0897e-01,\n",
      "         2.2270e-01, -1.0705e+00,  1.7203e+00,  8.5081e-01,  9.1766e-01,\n",
      "         7.0242e-01,  1.1211e+00,  8.1597e-01, -1.5520e+00, -2.2763e-01,\n",
      "         5.4440e-01,  9.0853e-02,  6.9931e-01, -6.5098e-01,  9.2137e-01,\n",
      "         1.3516e+00,  1.1140e+00,  1.1021e+00,  7.0761e-01,  5.7819e-01,\n",
      "        -1.1620e-01,  7.8819e-01,  8.0562e-01,  6.0173e-01, -5.2713e-01,\n",
      "         1.6689e+00,  3.4108e-01, -1.2797e+00,  5.5726e-01, -6.8087e-01,\n",
      "         8.7446e-01, -5.0500e-01,  1.0109e-01,  1.0734e+00,  8.1537e-01,\n",
      "         2.9148e-01,  9.2661e-01, -3.5180e-01,  5.5219e-01,  7.8048e-01,\n",
      "         1.6153e+00,  1.8172e-01, -6.2763e-01, -9.6533e-01,  1.3747e+00,\n",
      "         1.4199e+00, -5.2350e-01,  1.2774e+00,  7.2079e-01, -5.3346e-01,\n",
      "         2.6831e-01,  2.1471e-01,  3.3242e-02,  6.0973e-01,  7.7627e-01,\n",
      "        -8.6060e-01,  9.3886e-01,  2.0211e-01,  7.0079e-01,  1.4122e+00,\n",
      "        -9.2937e-02, -1.1339e-01, -7.4264e-01,  1.8141e+00,  3.7795e-01,\n",
      "         9.2504e-01, -2.7291e-01, -1.2664e+00,  6.6039e-01,  8.7899e-01,\n",
      "        -1.3528e+00,  6.8461e-01,  1.1194e-01,  9.0252e-01,  1.4387e+00,\n",
      "         6.3523e-01,  9.6737e-02,  7.4116e-01, -8.5806e-02,  1.6394e+00,\n",
      "         9.9061e-01,  1.6170e+00,  1.4351e+00,  1.0046e+00, -1.1266e+00,\n",
      "        -8.6065e-01,  2.5689e-01, -1.1927e+00,  1.0160e+00,  1.6010e+00,\n",
      "        -1.0593e+00, -4.3782e-01, -1.4495e+00,  7.8279e-01, -6.1225e-01,\n",
      "         9.7737e-01, -3.1448e-01,  7.5820e-01,  5.5790e-02,  8.4336e-01,\n",
      "         1.4250e+00,  9.2688e-01, -1.4812e+00,  2.2627e-01, -7.5578e-01,\n",
      "         4.7199e-01, -2.7702e-01,  1.3502e-02, -2.7684e-01, -1.2901e+00,\n",
      "         6.6287e-01,  1.9965e-01,  9.0940e-02, -4.6322e-01,  6.7775e-01,\n",
      "        -2.9140e-01, -1.7586e+00, -9.7554e-01, -8.9916e-01, -6.6173e-01,\n",
      "        -1.1462e+00, -3.8764e-01,  2.3110e-01,  1.2620e+00,  1.0606e+00,\n",
      "        -8.7965e-01,  9.5021e-01, -3.9696e-01, -6.9572e-01,  8.0280e-01,\n",
      "        -3.1718e-02, -5.3944e-01, -2.5231e-01,  1.9147e+00,  5.8990e-01,\n",
      "        -1.2095e+00,  7.9126e-01,  1.0209e+00,  9.1689e-01,  8.0398e-01,\n",
      "         9.4359e-01, -1.2648e+00,  7.6612e-01,  9.4321e-01,  4.8211e-01,\n",
      "         8.8933e-01,  8.5992e-01,  1.2575e+00,  6.8628e-01,  4.8330e-01,\n",
      "         5.0170e-01, -6.6179e-02,  7.0419e-01,  8.2440e-01,  1.0490e-02,\n",
      "        -1.7380e-01,  9.9235e-01,  1.0241e+00,  1.3846e+00,  8.8473e-01,\n",
      "         4.6652e-01, -1.0454e-01,  1.1995e+00,  5.3446e-01,  9.6429e-01,\n",
      "         7.7584e-02, -4.3346e-01, -2.9969e-01, -6.5458e-01,  5.6289e-01,\n",
      "         3.9711e-01,  1.3465e+00,  1.1488e+00,  5.6972e-01,  3.7770e-01,\n",
      "        -9.6767e-01, -1.3031e+00,  1.1461e+00,  8.0084e-01,  5.3760e-01,\n",
      "         6.3371e-01, -1.6533e+00,  2.1365e+00,  7.7976e-01, -1.7224e-01,\n",
      "         1.8325e+00,  9.0906e-01,  1.0153e+00,  3.9513e-01,  5.1834e-01,\n",
      "         1.1311e+00,  9.2125e-01,  2.1563e-01, -1.5991e-01,  1.4554e+00,\n",
      "         1.2036e+00, -3.1430e-01,  4.3086e-02,  1.0693e+00, -1.6405e-01,\n",
      "         5.4535e-01,  7.9199e-01, -1.2992e+00,  3.5415e-01,  9.5366e-01,\n",
      "         8.0361e-01,  1.6681e+00, -9.8974e-01, -9.3574e-01,  7.0405e-01,\n",
      "         1.1559e+00, -7.1095e-01,  1.1599e-01,  1.1056e+00, -7.7539e-01,\n",
      "         9.3812e-01,  1.1919e+00, -3.3101e-01, -2.0813e-01,  9.5160e-01,\n",
      "         8.2445e-01, -6.7447e-01, -5.4425e-01,  4.1633e-01,  6.2243e-01,\n",
      "         5.0643e-01,  1.6354e-01,  5.1972e-01,  1.6502e+00,  8.7069e-01,\n",
      "         5.1166e-01,  1.5476e+00,  1.2734e+00, -5.5736e-01,  9.1783e-01,\n",
      "         7.6301e-01, -7.5567e-02,  2.9676e-01,  1.4648e-01,  6.6533e-01,\n",
      "        -9.9710e-01,  5.0831e-01, -9.0683e-01,  7.1366e-01, -1.5960e-01,\n",
      "        -1.3689e+00, -5.8402e-02,  4.3025e-01,  9.1750e-01,  4.0797e-01,\n",
      "         8.6344e-01,  1.0664e+00,  3.6592e-01,  8.3750e-01,  9.6878e-01,\n",
      "         1.1987e+00, -3.3599e-01,  1.0918e+00,  7.1827e-01,  7.0230e-01,\n",
      "         8.4488e-01,  1.3785e-01,  4.9902e-01,  6.1571e-01, -9.5229e-01,\n",
      "         6.2337e-01,  2.6190e-01,  3.0381e-01,  8.5923e-01,  1.9343e-01,\n",
      "         7.6898e-01, -5.2607e-01, -3.9735e-01,  1.2689e+00,  4.2232e-02,\n",
      "        -2.6883e-01,  8.8556e-01,  3.3043e-02,  6.7951e-01, -3.6018e-01,\n",
      "         1.0828e+00, -3.2535e-01,  6.9675e-01,  7.2426e-01, -1.6270e+00,\n",
      "         8.5068e-01,  1.7766e+00,  9.6485e-01,  1.0313e+00,  1.5407e+00,\n",
      "         3.4670e-01,  1.8376e-01,  1.5065e-01, -1.4995e+00,  2.1595e-01,\n",
      "         7.0442e-01, -6.5956e-01, -4.6595e-01, -1.1835e-01,  9.7328e-01,\n",
      "        -6.4016e-01, -3.1389e-01,  9.9216e-01,  9.4822e-02,  9.9614e-01,\n",
      "         6.7761e-01,  5.2022e-01,  8.4013e-01,  1.1358e+00,  9.0491e-01,\n",
      "         1.1619e+00,  2.1599e-01,  2.8779e-01,  5.9661e-01,  1.0193e+00,\n",
      "         5.9883e-01,  7.0291e-01, -5.1679e-01, -4.5725e-01,  9.9896e-01,\n",
      "         6.4309e-01,  2.6071e-01,  4.1327e-01, -1.5762e+00,  8.3896e-01,\n",
      "        -6.2695e-01, -1.2982e+00,  8.3705e-01,  4.2978e-01,  1.1966e+00,\n",
      "        -2.6212e-01,  8.2140e-01,  1.0626e-01,  1.0357e+00, -9.2935e-01,\n",
      "         1.0062e+00,  4.9386e-01,  1.5737e+00,  9.4750e-01,  6.2702e-01,\n",
      "         9.6768e-01,  6.1246e-01,  5.4833e-01,  1.9470e+00,  1.2924e+00,\n",
      "         1.3381e+00,  1.6217e-01,  1.0071e-01,  9.4637e-01, -1.2877e+00,\n",
      "         9.6947e-01, -6.0351e-01,  6.6861e-01,  7.1240e-01,  4.9459e-02,\n",
      "         5.5673e-01,  1.1424e+00, -5.6736e-01, -3.9942e-01,  1.7209e+00,\n",
      "         3.8326e-01,  2.7324e-01,  9.2103e-01, -1.2811e-01,  6.0507e-01,\n",
      "        -8.6124e-01, -4.2364e-01,  1.3511e+00,  1.5340e+00,  5.4136e-01,\n",
      "        -2.5639e-01,  5.5498e-01,  5.7668e-01, -3.6814e-01,  6.6720e-03,\n",
      "         9.8257e-01,  1.6990e+00, -1.8367e-01,  9.3918e-01, -1.3577e+00,\n",
      "        -5.1255e-01,  1.0278e+00,  9.7543e-01, -5.3113e-01,  9.7291e-01,\n",
      "        -1.0718e+00,  1.0881e+00,  8.6916e-02, -4.9870e-01, -1.1933e+00,\n",
      "         9.6587e-01,  1.2935e+00,  5.9537e-01,  8.1989e-01,  5.6183e-01,\n",
      "         9.9165e-01,  9.2783e-01,  1.4071e-01, -5.8845e-01,  8.9880e-01,\n",
      "         8.4104e-01, -1.8396e-01,  8.5750e-01,  7.2599e-01,  1.3004e+00,\n",
      "         8.2414e-01, -9.5132e-01,  1.0833e+00, -5.0205e-01,  1.3112e+00,\n",
      "        -3.1228e-02,  9.8207e-01,  1.4148e+00,  5.3522e-01, -5.8025e-01,\n",
      "         3.8521e-01,  7.6366e-01, -1.1687e-01,  7.0102e-01, -3.7903e-01,\n",
      "        -4.6806e-01,  1.3369e-01,  9.4359e-01, -2.8070e-01,  1.2048e-01,\n",
      "         7.0264e-01,  8.0967e-01, -4.9675e-01,  4.0729e-01, -1.3570e+00,\n",
      "         8.2750e-01,  4.8914e-01,  6.6422e-01,  1.0621e+00,  7.3969e-01,\n",
      "        -9.9458e-02,  2.4365e-01,  1.0282e+00, -1.1313e+00, -4.4149e-01,\n",
      "        -1.0370e+00,  3.1828e-01,  9.9129e-01, -3.2736e-01, -4.5351e-01,\n",
      "         2.3180e-01,  1.4074e+00,  1.6561e+00,  5.1490e-01,  9.2548e-01,\n",
      "        -4.8532e-01, -9.5988e-01,  7.6457e-02,  4.8828e-01,  9.0430e-01,\n",
      "         1.0011e+00, -2.3853e-01,  9.6987e-01, -1.3114e+00,  1.9051e-01,\n",
      "         4.9271e-01,  8.5917e-01,  8.3048e-01, -5.0095e-01, -4.8982e-02,\n",
      "         7.5670e-01,  8.1517e-01,  1.3435e+00,  1.3644e+00,  6.4444e-01,\n",
      "         4.1807e-02,  8.2943e-01,  1.0544e+00,  9.2456e-01,  8.6674e-01,\n",
      "         7.9598e-01,  6.4868e-01,  3.0967e-01, -6.1481e-01,  9.8672e-01,\n",
      "         2.3103e-01,  8.8581e-01, -2.3274e-01,  2.9472e-01,  1.0344e+00,\n",
      "        -6.4992e-01,  1.0950e+00,  8.5755e-01,  6.6338e-01,  5.0632e-01,\n",
      "        -7.9878e-01,  9.9111e-01,  8.7456e-01,  1.6403e+00, -9.0369e-02,\n",
      "         3.8327e-01,  7.8807e-01,  1.4082e+00, -4.1361e-01,  8.9731e-01,\n",
      "         5.1985e-01, -4.2773e-02,  7.4299e-01,  9.8055e-01, -4.4043e-01,\n",
      "         2.2821e-01, -6.7591e-01,  9.2765e-01,  8.4950e-01,  9.2187e-01,\n",
      "         8.3858e-01, -1.3358e+00, -3.3566e-01,  7.2407e-01,  1.2512e-01,\n",
      "         7.9587e-01, -9.4150e-02,  7.0685e-01,  7.6837e-01,  9.6738e-01,\n",
      "         1.7241e+00,  1.6727e+00,  3.4840e-01,  8.8164e-01,  1.4987e+00,\n",
      "         8.8394e-01, -1.5153e-01,  9.9823e-01,  4.5172e-01,  7.1792e-01,\n",
      "         1.1798e+00,  4.0197e-01,  1.0188e+00,  1.1400e+00,  5.3810e-01,\n",
      "         1.3362e+00,  1.4183e+00,  1.2898e+00,  1.6936e+00, -3.2164e-01,\n",
      "         6.6417e-01,  4.9352e-02, -6.0948e-01,  5.5249e-01,  9.6409e-01,\n",
      "         3.0724e-01,  1.2946e+00,  1.6407e+00,  1.4422e+00,  8.3034e-01,\n",
      "         8.5928e-01,  7.8416e-01,  7.9069e-01,  2.8302e-01,  4.3151e-01,\n",
      "         1.6440e+00, -1.2761e+00, -1.5590e-01,  4.6261e-01, -3.3184e-01,\n",
      "        -1.0087e-01,  9.0674e-01,  1.4386e-01,  2.4455e-01,  3.4275e-01,\n",
      "         9.2332e-01,  5.6605e-01,  2.5490e-02,  6.4873e-01,  1.4835e+00,\n",
      "        -5.5858e-01, -1.0892e-01, -3.1968e-02, -8.8636e-01, -7.8553e-01,\n",
      "         1.2785e+00,  6.1254e-01,  1.1297e+00,  6.1079e-01,  7.5188e-01,\n",
      "        -6.9280e-01,  2.7884e-01, -4.0409e-01,  1.0024e+00,  5.8424e-01],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0380, -0.1183, -0.0411],\n",
      "          [-0.1239, -0.1101, -0.1265],\n",
      "          [-0.0360, -0.1312, -0.0325]]],\n",
      "\n",
      "\n",
      "        [[[-0.0713, -0.1253, -0.0719],\n",
      "          [-0.1454,  0.3327, -0.1306],\n",
      "          [-0.0649, -0.1280, -0.0676]]],\n",
      "\n",
      "\n",
      "        [[[-0.1218, -0.0145, -0.1334],\n",
      "          [-0.0714,  0.5582, -0.0589],\n",
      "          [-0.1455,  0.0019, -0.1474]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0504, -0.0937, -0.0453],\n",
      "          [-0.1124, -0.0190, -0.1093],\n",
      "          [-0.0461, -0.1054, -0.0457]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0671, -0.0462, -0.0816],\n",
      "          [ 0.1705,  0.0365, -0.2395],\n",
      "          [ 0.0772, -0.0764, -0.0797]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0161,  0.0739,  0.0277],\n",
      "          [ 0.0881,  0.2311,  0.0769],\n",
      "          [ 0.0224,  0.1056,  0.0196]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 1, 3, 3])\n",
      "\n",
      "Layer: features.15.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.7000111937522888\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.6945423483848572\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.1.1.weight\n",
      "Weights: tensor([2.2242, 0.5895, 0.5883, 0.5168, 1.7971, 0.6650, 1.8510, 1.0000, 0.5614,\n",
      "        0.2687, 0.3730, 1.7257, 0.8211, 0.9912, 1.1574, 1.0807, 0.7061, 0.2652,\n",
      "        0.3666, 0.7892, 0.9951, 0.8145, 1.3474, 0.8578, 0.6624, 0.6259, 0.4652,\n",
      "        1.5314, 0.7927, 1.2560, 0.6946, 0.9146, 1.0300, 0.7416, 0.6672, 0.9259,\n",
      "        4.7266, 1.7009, 1.0367, 0.8269, 1.3637, 1.2553, 1.0431, 0.3917, 0.7527,\n",
      "        1.6738, 0.3635, 1.0675, 1.0818, 1.1068, 1.1604, 0.3950, 0.7762, 0.8772,\n",
      "        0.5994, 0.8840, 1.1867, 1.8361, 1.0845, 1.5268, 1.1511, 1.0919, 0.8320,\n",
      "        0.8304, 0.9784, 0.7302, 0.8211, 2.0060, 2.0837, 0.4362, 2.3074, 1.7367,\n",
      "        1.5320, 1.5172, 0.4744, 0.8172, 0.7782, 0.7662, 0.9733, 0.5057, 0.7306,\n",
      "        0.6666, 4.2057, 0.6605, 0.4136, 0.5568, 0.5904, 1.6434, 0.7451, 0.7825,\n",
      "        0.8836, 1.8876, 0.9167, 0.9150, 1.2504, 0.6337, 1.4563, 1.2068, 0.9164,\n",
      "        1.4413, 1.1186, 1.0876, 0.7109, 0.9958, 1.4923, 0.8714, 0.7460, 1.4061,\n",
      "        0.9207, 0.3305, 0.9786, 1.0436, 1.9855, 0.9426, 1.0259, 0.6170, 0.6230,\n",
      "        1.2265, 0.6051, 1.5378, 0.8413, 1.1564, 1.2969, 0.9192, 2.5696, 0.7999,\n",
      "        1.2697, 1.0221, 0.6643, 1.0756, 0.8471, 0.8458, 2.0195, 0.8398, 1.0056,\n",
      "        0.9909, 1.4441, 0.8017, 0.9710, 0.2592, 0.7601, 1.6279, 1.0442, 2.1975,\n",
      "        0.7707, 0.2449, 3.8262, 1.0800, 0.4618, 1.1159, 1.1240, 1.5043, 1.8060,\n",
      "        0.9055, 0.9153, 0.5545, 1.0867, 0.9236, 1.2575, 1.0426, 1.4243, 1.0274,\n",
      "        0.7670, 0.9764, 0.7542, 1.5433, 2.0148, 0.2926, 1.0756, 1.7940, 0.5512,\n",
      "        1.7666, 1.4860, 0.7494, 0.2088, 0.7748, 0.7508, 0.7775, 1.0995, 1.4575,\n",
      "        1.0536, 0.7304, 0.5857, 1.6092, 1.4213, 0.7113, 1.2334, 0.8480, 0.8546,\n",
      "        1.1352, 0.8817, 1.2684, 1.4288, 0.7667, 1.2921, 0.3957, 1.2899, 1.0712,\n",
      "        1.2648, 0.9046, 1.3586, 1.3195, 1.3220, 0.8190, 0.8084, 0.8104, 0.6595,\n",
      "        0.8890, 0.9445, 0.9170, 0.6710, 0.7744, 1.6588, 0.7722, 1.1128, 0.5591,\n",
      "        1.9167, 1.4791, 1.3551, 0.5348, 1.1914, 0.9040, 0.2988, 1.2062, 0.4829,\n",
      "        0.7587, 0.7592, 0.9959, 0.7222, 0.5043, 0.7644, 4.2998, 0.8169, 0.4921,\n",
      "        0.9989, 0.6245, 0.3044, 1.5753, 0.4438, 0.3698, 1.2820, 1.3229, 1.7853,\n",
      "        1.1942, 0.3137, 1.0156, 0.9901, 0.9975, 1.2571, 1.2546, 1.5642, 0.5069,\n",
      "        1.3257, 0.9795, 1.1743, 0.7203, 0.9588, 0.9772, 1.1540, 0.6798, 0.8838,\n",
      "        0.7386, 1.2537, 0.6524, 1.0685, 0.8138, 0.7644, 0.2166, 0.7753, 0.4068,\n",
      "        0.8457, 0.5506, 0.9211, 1.5803, 1.1412, 0.3503, 0.6634, 1.0412, 0.9970,\n",
      "        1.1229, 0.9434, 0.5188, 0.9555, 0.8256, 1.0697, 0.9804, 0.8934, 1.1180,\n",
      "        1.6573, 1.2155, 0.7276, 0.8355, 0.8959, 1.0515, 0.7699, 0.7149, 0.2886,\n",
      "        0.8589, 1.5543, 0.8002, 0.8166, 1.2897, 1.2680, 1.7481, 1.0850, 0.9113,\n",
      "        1.1302, 1.1760, 1.3096, 0.9016, 1.0292, 0.8330, 1.0403, 1.2245, 0.6323,\n",
      "        1.9282, 0.7657, 0.8970, 0.7766, 1.3055, 0.8654, 1.1809, 1.3989, 1.0253,\n",
      "        0.9863, 0.8411, 0.9959, 0.9578, 0.7794, 1.2267, 1.4410, 1.1488, 0.8175,\n",
      "        1.1871, 0.9536, 0.7844, 0.5607, 0.3407, 1.5307, 0.3591, 2.4352, 1.6960,\n",
      "        0.9864, 0.8917, 1.4591, 1.4843, 3.8589, 1.4573, 1.2953, 0.8924, 1.3552,\n",
      "        0.3955, 0.9455, 1.9592, 0.4942, 1.6931, 1.1904, 1.0832, 0.6531, 0.8661,\n",
      "        0.5702, 1.3480, 1.0720, 1.4454, 0.7579, 1.1344, 0.5655, 1.5620, 0.9816,\n",
      "        0.2976, 0.9745, 0.9344, 1.5138, 0.9171, 1.9844, 0.7071, 0.6212, 2.4300,\n",
      "        0.9774, 1.4996, 1.6749, 1.4790, 1.9585, 0.3366, 0.7277, 0.6412, 1.2099,\n",
      "        1.0827, 0.8072, 0.7033, 1.7140, 0.6886, 0.6177, 0.8309, 0.7252, 0.8810,\n",
      "        1.7162, 0.7838, 1.4456, 0.2997, 1.3810, 0.9614, 0.5366, 1.1435, 1.1061,\n",
      "        0.8989, 1.0367, 1.1642, 1.3645, 1.0600, 1.8877, 1.0618, 0.3928, 0.6234,\n",
      "        0.7225, 1.8058, 1.2773, 0.6892, 0.4625, 1.9393, 1.8957, 0.9092, 1.8028,\n",
      "        0.7875, 0.4062, 0.6998, 0.9333, 0.3699, 0.8942, 0.7485, 0.2399, 1.0366,\n",
      "        1.5203, 0.8883, 2.2714, 0.3719, 0.8618, 0.5293, 2.8217, 1.2614, 1.2779,\n",
      "        3.9921, 0.2770, 1.4114, 0.9782, 0.3704, 1.3555, 1.0271, 0.6713, 1.7135,\n",
      "        0.8746, 1.2206, 1.0841, 0.8519, 1.2783, 1.2741, 2.1724, 1.4669, 0.7930,\n",
      "        0.5021, 0.8723, 1.4568, 0.8783, 0.8465, 1.6265, 0.5608, 0.6479, 0.2041,\n",
      "        1.6437, 1.1318, 1.0521, 0.9787, 1.0969, 1.3020, 1.2624, 2.1266, 0.7836,\n",
      "        0.6857, 1.7790, 0.3516, 0.4877, 0.8613, 0.6028, 0.8401, 0.3001, 0.7788,\n",
      "        0.7128, 1.0425, 0.4351, 0.5761, 0.9143, 0.4357, 0.2473, 0.3814, 0.2841,\n",
      "        0.3809, 0.9491, 0.7138, 1.1255, 1.2619, 0.3769, 1.0591, 0.7724, 0.4053,\n",
      "        0.7197, 0.4683, 0.5999, 0.6862, 2.6458, 0.6821, 0.4097, 0.9423, 0.6328,\n",
      "        0.8783, 1.2140, 0.6364, 0.2680, 2.3316, 0.7878, 0.9304, 1.0477, 1.0048,\n",
      "        0.9530, 0.6020, 1.0498, 0.8874, 1.5276, 0.7239, 0.8615, 1.2586, 0.8158,\n",
      "        1.7195, 1.5332, 1.6796, 1.0208, 0.9324, 3.5476, 1.0737, 1.1467, 0.9395,\n",
      "        1.1952, 0.4520, 0.7504, 0.7429, 0.5797, 1.3638, 1.4545, 1.6165, 0.7687,\n",
      "        0.7269, 0.5442, 0.2409, 1.3299, 1.6172, 0.5699, 1.0189, 0.2554, 2.3219,\n",
      "        0.7619, 0.7542, 1.5014, 1.2859, 1.2191, 0.5240, 1.0349, 1.4001, 0.9595,\n",
      "        0.7224, 0.8189, 1.3540, 1.0951, 0.8680, 0.9705, 1.3730, 1.2877, 1.1250,\n",
      "        1.5253, 0.2626, 1.9107, 0.7794, 1.4012, 1.5160, 0.3183, 0.2795, 0.6397,\n",
      "        1.3209, 0.4307, 0.9044, 1.2960, 0.4107, 1.1657, 0.9695, 1.1545, 0.7523,\n",
      "        0.7284, 0.8218, 0.3254, 0.8725, 1.4840, 0.7816, 1.0743, 1.1603, 1.1186,\n",
      "        1.5887, 1.2136, 1.1848, 1.9067, 1.4287, 0.9075, 1.2831, 0.6978, 0.7711,\n",
      "        1.2149, 0.8637, 1.0247, 0.4389, 1.3356, 0.5220, 0.8905, 1.1098, 0.2733,\n",
      "        0.8953, 0.7371, 0.7612, 1.3831, 0.9074, 0.7411, 1.0112, 1.1113, 1.1615,\n",
      "        1.0907, 0.4196, 0.9838, 1.4501, 1.1422, 1.1769, 1.2724, 0.9245, 1.1313,\n",
      "        0.2671, 1.1018, 1.0147, 0.8180, 1.3254, 0.9382, 1.7572, 0.5247, 0.8301,\n",
      "        0.7176, 0.5463, 0.4811, 0.8436, 1.1682, 0.8489, 0.5828, 1.4474, 1.4084,\n",
      "        0.7593, 0.8166, 0.5881, 1.2516, 1.4315, 1.3799, 0.6354, 1.2476, 1.2758,\n",
      "        1.4765, 0.4500, 0.3959, 0.7032, 0.7918, 0.5671, 1.0084, 0.5606, 0.9584,\n",
      "        0.4008, 0.6850, 2.1470, 1.0025, 1.3932, 0.8739, 0.6968, 0.6240, 1.3785,\n",
      "        0.9280, 1.4708, 0.8473, 0.9349, 0.5599, 1.4562, 2.1373, 1.3795, 0.8057,\n",
      "        0.5872, 1.4991, 0.7483, 1.1366, 0.8622, 0.4296, 1.2573, 0.7080, 0.2447,\n",
      "        0.7449, 0.8362, 1.3695, 0.4930, 0.3798, 0.8766, 0.7623, 0.2811, 1.5519,\n",
      "        1.7446, 1.2807, 1.1065, 0.4747, 0.9985, 0.8483, 1.0862, 1.5209, 1.4526,\n",
      "        1.7684, 1.0362, 0.9358, 1.5934, 0.5939, 1.1317, 0.8420, 0.9121, 1.1300,\n",
      "        0.8517, 2.0521, 0.7042, 0.4987, 0.2856, 2.1519, 1.0553, 1.0520, 1.2248,\n",
      "        0.7277, 1.0057, 0.3045, 2.0022, 1.5863, 1.4296, 1.0665, 0.4296, 0.9442,\n",
      "        0.5721, 1.0654, 0.7500, 0.7612, 1.7007, 0.9448, 1.1867, 0.2402, 0.4119,\n",
      "        1.5038, 0.8543, 0.4132, 1.6233, 0.2934, 0.9296, 0.9905, 0.8163, 0.2699,\n",
      "        1.1134, 1.5940, 0.6597, 0.6814, 1.4883, 1.3257, 1.4329, 1.0040, 0.5961,\n",
      "        1.1433, 0.8095, 0.8702, 1.0805, 1.1960, 1.0354, 1.4751, 0.2840, 1.4621,\n",
      "        0.5844, 1.7015, 0.5031, 1.1070, 0.9525, 1.1008, 0.9298, 0.7153, 0.9150,\n",
      "        1.5335, 1.6177, 1.4168, 0.7180, 0.8424, 0.6397, 0.8516, 1.4714, 0.7905,\n",
      "        1.1055, 0.3831, 1.1416, 0.2511, 0.7644, 1.4561, 0.8146, 1.0512, 1.2883,\n",
      "        0.9921, 0.8408, 1.0520, 0.2482, 0.7450, 0.4416, 1.6716, 0.8817, 0.7934,\n",
      "        3.7200, 0.5461, 1.8981, 1.4026, 1.6141, 1.4255, 0.6435, 0.3873, 1.0904,\n",
      "        1.1081, 1.1239, 0.9629, 0.9216, 0.9685, 0.2403, 0.9770, 0.7085, 1.2517,\n",
      "        0.8808, 0.6181, 0.8583, 0.8805, 0.9059, 1.1898, 1.0636, 1.0667, 1.5798,\n",
      "        1.0931, 0.8911, 1.0500, 1.3152, 0.9874, 0.8952, 1.1723, 0.4826, 2.2672,\n",
      "        1.2415, 1.0718, 0.4927, 1.1007, 0.8403, 0.7143, 0.7845, 1.2347, 1.3995,\n",
      "        1.0770, 6.2227, 1.1626, 0.5366, 1.6747, 0.6678, 1.4350, 0.7621, 1.1946,\n",
      "        0.4950, 2.5807, 1.2306, 0.4035, 1.5024, 1.1448, 0.6042, 1.3441, 1.0506,\n",
      "        1.2789, 0.9065, 1.7993, 1.1705, 0.6172, 0.8090, 0.8590, 0.6046, 0.9624,\n",
      "        0.9297, 0.8684, 2.0158, 0.8020, 0.9677, 1.8314, 1.2001, 0.8695, 1.7677,\n",
      "        0.8280, 0.7756, 1.0533, 1.3981, 1.1745, 2.0074, 1.1121, 0.9547, 0.9815,\n",
      "        0.8112, 1.4092, 1.6707, 1.6891, 1.5949, 0.4514, 0.9497, 1.3576, 0.4755,\n",
      "        0.7135, 1.2566, 1.1827, 1.5693, 1.1922, 1.3381, 0.6963, 1.9961, 0.8372,\n",
      "        1.0678, 0.7280, 0.9026, 1.5697, 0.3377, 0.9034, 0.5717, 0.8900, 0.7768,\n",
      "        0.9754, 0.8296, 0.6845, 1.6078, 0.7893, 1.0806, 0.8865, 1.3772, 1.0096,\n",
      "        0.5654, 0.5661, 1.0266, 0.6809, 0.4507, 1.0664, 0.9942, 0.6565, 0.8869,\n",
      "        1.6112, 0.2883, 1.6410, 0.6010, 0.8696, 1.4772], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.1.1.bias\n",
      "Weights: tensor([-2.8789e+00,  2.0656e-01,  1.7321e+00,  4.8485e-01, -4.2535e+00,\n",
      "        -8.6060e-01, -2.0075e+00, -7.7766e-01,  7.9610e-01,  1.9413e+00,\n",
      "         1.3599e+00, -1.1935e+00, -3.8536e-01, -1.7935e+00, -1.5526e+00,\n",
      "        -8.1959e-01, -1.0050e+00,  1.7437e+00,  1.6724e+00, -2.5836e-01,\n",
      "        -6.1100e-01, -1.8756e-01, -1.9039e+00, -3.2842e-01, -8.8920e-02,\n",
      "         2.0268e-01,  3.9735e-01, -1.1879e+00, -2.5040e+00, -1.1172e+00,\n",
      "        -5.7651e-01, -2.2166e+00, -5.5003e-01, -1.3524e+00,  2.2385e-01,\n",
      "        -2.8236e-01, -2.3370e+00, -2.0549e+00, -7.8270e-01, -3.9403e-01,\n",
      "        -1.2389e+00, -7.9318e-01, -1.7064e+00,  9.9155e-01,  1.4480e+00,\n",
      "        -1.6553e+00,  1.6123e+00, -3.3679e+00, -9.9525e-01, -7.5626e-01,\n",
      "        -9.2331e-01, -3.7687e-01, -8.5641e-01, -5.3402e-01, -3.3269e-01,\n",
      "        -5.9287e-01, -6.2264e-01, -2.6235e+00, -9.7360e-01, -1.3019e+00,\n",
      "        -7.6613e-01, -2.3055e+00, -3.2283e-01, -1.7678e-01, -4.5356e-01,\n",
      "        -3.7699e-01, -1.6704e+00,  4.1053e-01, -2.6904e+00, -4.0556e-01,\n",
      "        -1.1897e+00, -1.8815e+00, -4.9932e+00, -3.2252e+00, -5.1234e-01,\n",
      "        -1.4525e-01, -5.1354e-01, -1.7549e+00, -1.9330e+00,  6.0148e-01,\n",
      "         1.1822e-01, -5.9474e-01, -2.5548e+00, -1.2488e+00,  4.5078e-01,\n",
      "         1.8661e+00,  1.7836e-01, -1.2915e+00, -3.6587e-01, -2.8793e-01,\n",
      "        -1.5190e+00, -1.0469e+00, -5.5817e-01, -2.3494e-01, -1.7499e+00,\n",
      "        -1.4132e+00, -1.5826e+00, -1.2237e+00, -4.7373e-01, -9.5555e-01,\n",
      "        -2.1915e+00, -6.2495e-01,  6.0008e-02, -8.8102e-01, -1.6211e+00,\n",
      "        -3.1723e-01,  1.5922e+00, -2.0458e+00, -8.3903e-02,  5.9247e-01,\n",
      "        -5.5867e-01, -4.8358e-01, -1.4476e+00, -2.9856e-01, -5.5931e-01,\n",
      "        -1.0371e+00,  3.8928e-01, -9.3359e-01, -6.9542e-01, -9.9921e-01,\n",
      "        -1.3826e+00, -8.9238e-01, -1.0850e+00, -1.1581e+00, -2.4029e+00,\n",
      "        -2.2810e-02, -9.4852e-01, -6.3023e-01, -1.0313e+00, -6.1930e-01,\n",
      "         5.2681e-02, -6.4595e-01, -3.0518e+00, -2.0791e-01, -5.8481e-01,\n",
      "        -2.5834e+00, -1.6482e+00, -2.8771e-01, -1.8593e+00,  2.2491e+00,\n",
      "        -2.1113e-01, -9.6806e-01, -7.3582e-01, -2.8582e+00, -5.5745e-02,\n",
      "         1.5733e+00, -2.5007e+00, -1.0412e+00, -7.8566e-01, -2.0879e+00,\n",
      "        -8.2383e-01, -3.4412e+00, -2.7804e+00, -4.5938e-01, -3.9845e-01,\n",
      "         7.8715e-01, -2.8132e+00, -4.8651e-01, -6.8695e-01, -1.5162e+00,\n",
      "        -1.5664e+00, -7.0797e-01, -2.6180e-01, -6.6939e-01, -9.7207e-01,\n",
      "        -1.0822e+00, -4.1180e+00,  8.9840e-01, -2.4061e+00, -4.0400e+00,\n",
      "         1.6508e-01, -2.0673e+00, -1.3732e+00, -1.5007e+00,  2.0457e+00,\n",
      "        -2.5311e-01, -1.2183e-01,  7.2162e-02, -9.4546e-01, -7.7000e-01,\n",
      "        -4.4339e-01, -2.4051e-01, -1.0870e+00, -2.2694e+00, -1.3438e+00,\n",
      "        -2.7621e-01, -2.1698e+00, -5.1046e-01, -2.0598e+00, -3.2872e+00,\n",
      "        -6.8313e-01, -3.8226e+00, -4.5849e+00, -1.4163e-01, -1.3159e+00,\n",
      "         4.3638e-01, -6.6812e-01, -9.7513e-01, -9.3911e-01, -5.4096e-01,\n",
      "        -1.1517e+00, -8.6978e-01, -1.1133e+00, -3.0936e-01, -3.0337e-01,\n",
      "        -1.6669e+00, -1.5485e+00, -2.9868e-01, -8.9522e-01, -3.3223e-01,\n",
      "        -3.2380e-01, -7.7904e-01, -1.7688e+00, -3.0301e-01, -7.3713e-01,\n",
      "         1.4098e+00, -2.5587e+00, -2.9554e+00, -1.6933e+00,  1.9066e+00,\n",
      "        -6.0348e-01, -4.5390e-01,  2.4318e+00, -1.1608e+00,  1.3553e+00,\n",
      "        -1.1783e+00, -1.5080e+00, -6.6570e-01, -1.3856e-01,  1.6599e+00,\n",
      "        -1.1626e+00, -2.2292e+00, -2.4132e+00,  1.8593e+00, -6.7837e-01,\n",
      "         8.5203e-03,  7.3496e-01, -1.2188e+00,  2.8118e-01,  1.8491e+00,\n",
      "        -3.9185e+00, -1.3235e+00, -2.7685e+00, -9.8078e-01,  1.9884e+00,\n",
      "        -2.5094e-01, -1.3142e+00, -1.8059e+00, -2.9604e+00, -1.4832e+00,\n",
      "        -8.1100e-01,  1.9352e+00, -7.3760e-01, -8.1818e-01, -2.3823e+00,\n",
      "        -2.7557e-01, -6.7368e-01, -4.4917e-01, -6.2019e-01, -2.0490e-01,\n",
      "        -1.1378e+00, -2.1920e-01, -1.2339e+00,  1.0326e-01, -6.1978e-01,\n",
      "        -1.9347e-01, -7.4273e-02,  2.0438e+00, -1.9197e-01,  4.6282e-01,\n",
      "        -5.1153e-01, -1.0297e+00, -1.4607e+00, -1.1268e+00, -4.3440e-01,\n",
      "        -6.2181e-01,  1.4728e-01, -6.9962e-01, -4.8738e-01, -1.0834e+00,\n",
      "         1.5067e+00, -5.2618e-01, -2.1168e-01, -3.3187e-01, -1.1168e+00,\n",
      "        -6.3107e-01, -2.5075e-01, -7.7032e-01, -5.4068e+00, -1.4055e+00,\n",
      "        -2.3953e-01, -3.7364e-01, -4.3385e-01, -1.9517e+00, -2.1475e-01,\n",
      "        -6.8328e-01,  1.0613e+00, -2.6190e-01, -1.3988e+00,  1.9250e-02,\n",
      "        -8.2294e-01, -6.8413e-01, -9.9744e-01, -4.4076e+00, -3.8665e-01,\n",
      "        -4.2608e-01, -8.2620e-01, -1.3743e+00, -9.6813e-01, -4.5663e-01,\n",
      "        -2.5423e+00, -1.3374e+00, -1.2121e+00, -2.9977e+00, -1.2320e-01,\n",
      "        -2.4526e+00,  2.4875e-01, -3.4024e-01, -2.3044e+00, -1.1266e+00,\n",
      "        -2.0409e+00, -7.8946e-01, -2.1748e+00, -5.2993e-01, -8.0772e-01,\n",
      "        -2.8966e-01, -8.9291e-01, -4.2516e-01, -2.5441e-01, -8.1373e-01,\n",
      "        -8.7342e-01, -4.1225e-01, -1.7255e+00, -1.4637e+00, -9.5855e-01,\n",
      "        -5.1723e-01,  2.0100e-01, -3.2780e-01, -4.0949e+00,  1.7644e+00,\n",
      "        -2.7916e-01, -1.7047e+00,  2.5995e-01, -2.9014e-01, -3.1319e+00,\n",
      "        -1.2453e+00, -2.0518e+00, -9.6368e-01, -1.6617e+00, -5.6628e-01,\n",
      "        -9.1397e-01, -2.2689e-01, -5.5104e-01, -2.0228e+00, -3.5610e-01,\n",
      "        -1.9769e+00, -8.4741e-01, -8.9030e-01,  2.3361e-01, -5.9145e-01,\n",
      "         1.6069e+00, -8.9268e-01, -4.8362e-01, -1.7915e+00,  2.4508e-01,\n",
      "        -1.6151e+00,  6.0015e-01, -1.4464e+00, -9.7514e-01,  1.8544e+00,\n",
      "        -4.5095e-01, -3.5244e-01, -1.3246e+00, -2.6619e-01, -4.9030e+00,\n",
      "        -1.7329e-01, -8.3823e-01, -3.0524e+00, -6.0322e-01, -9.6698e-01,\n",
      "        -4.2311e+00, -2.0191e+00, -4.2522e+00,  1.3729e+00, -9.1555e-01,\n",
      "         1.7969e-01, -2.9311e+00, -1.4508e+00, -3.2016e-01,  1.2299e-01,\n",
      "        -3.3316e+00,  2.4022e-01,  2.0352e+00, -2.5652e-01, -1.7686e-01,\n",
      "        -9.3060e-01, -1.3888e+00, -1.6337e-01, -9.2371e-01,  6.6747e-01,\n",
      "        -1.4991e+00, -1.7344e+00, -1.4694e+00, -6.7509e-01, -3.0767e+00,\n",
      "        -3.4290e-01, -2.3040e+00, -2.8511e+00, -1.8283e+00, -8.0081e-01,\n",
      "        -5.1670e+00, -5.7117e-01,  6.9530e-01,  2.4810e-01, -1.9172e-01,\n",
      "        -2.8203e+00, -6.4872e-01, -8.2229e-01,  3.9774e-01, -2.3996e+00,\n",
      "        -2.2298e+00, -2.4681e+00, -1.4561e+00, -1.8534e-01,  7.3672e-01,\n",
      "        -3.1280e-01, -1.8336e+00,  7.0286e-01, -2.2117e-01, -2.2267e-01,\n",
      "         1.1975e+00, -7.3317e-01, -8.3460e-01, -5.7542e-01, -2.2419e+00,\n",
      "         6.8942e-01, -1.5596e+00, -1.0148e+00, -3.6638e+00, -6.2041e-01,\n",
      "        -2.3565e+00, -2.2575e+00,  2.1631e+00, -3.1162e+00, -4.1441e-01,\n",
      "         2.2245e+00, -6.1218e-01, -2.6879e+00,  1.3214e-01, -1.8466e+00,\n",
      "        -3.8617e-01, -5.5875e-01, -9.1957e-01, -1.6247e+00, -1.5392e+00,\n",
      "        -7.3050e-01, -2.8312e+00, -1.6775e+00, -1.3602e-01, -5.0020e-01,\n",
      "        -1.5122e+00, -7.5014e-01,  1.0861e-01, -2.3309e-01, -2.1951e+00,\n",
      "         3.7597e-01, -1.0457e+00,  2.2237e+00, -3.1847e+00, -4.0316e-01,\n",
      "        -4.8118e-01, -2.4255e+00, -6.1392e-01, -3.2088e+00, -9.6936e-01,\n",
      "        -2.6243e+00, -3.6983e-01,  4.9991e-01, -5.1420e-01,  1.2249e+00,\n",
      "         9.8244e-01, -2.1853e+00, -6.7389e-02, -2.3225e+00,  1.7397e+00,\n",
      "        -3.0689e-01, -6.5268e-01, -4.7262e-01,  8.2964e-03,  3.1270e-01,\n",
      "         6.6271e-01,  8.5763e-01,  1.4830e+00,  1.7907e+00,  1.3615e+00,\n",
      "         6.8042e-01, -2.5975e+00, -3.4693e-01, -8.8616e-01, -1.6154e+00,\n",
      "         2.1267e+00, -7.6307e-01, -1.5031e+00, -1.8553e-01, -1.4549e-01,\n",
      "         7.4270e-01, -5.7733e-01, -1.3638e+00, -3.7763e+00, -2.6155e-01,\n",
      "        -5.5943e-01, -3.5610e-01,  2.0687e+00, -4.7974e-01, -6.1749e-01,\n",
      "         4.8119e-01,  2.2515e+00, -5.0024e+00, -2.7325e-01, -1.2552e+00,\n",
      "        -6.7613e-01, -5.1907e-01,  2.7185e-01,  1.9565e+00, -5.9811e-01,\n",
      "        -3.5356e-01, -7.5986e-01, -1.7115e-01, -3.7285e-01, -3.2983e+00,\n",
      "        -1.0362e+00, -3.2428e+00, -2.2732e+00, -1.8402e+00, -6.0109e-01,\n",
      "        -8.1121e-01, -1.9980e+00, -1.0641e+00, -8.0001e-01, -4.5050e-01,\n",
      "        -4.9876e-01,  1.7826e+00, -1.8029e+00, -2.0994e+00,  7.6306e-01,\n",
      "        -3.2098e+00, -1.4898e+00, -1.3929e+00, -4.4374e-01, -2.7137e-01,\n",
      "         1.5396e+00,  9.4311e-01, -1.1908e+00, -3.2690e+00,  2.0087e+00,\n",
      "        -1.1112e+00,  3.8463e-01, -3.7141e+00, -2.2680e-01, -9.6274e-01,\n",
      "        -2.1649e+00, -1.9576e+00, -7.6261e-01,  1.3054e+00, -1.2817e+00,\n",
      "        -1.4768e+00, -2.7409e-01, -5.2625e-01, -1.7409e+00, -1.3698e+00,\n",
      "        -6.4039e-01, -1.9599e+00, -2.1032e+00, -1.4393e+00, -5.9757e-01,\n",
      "        -1.9924e+00, -9.9858e-01,  2.0370e+00, -4.4619e+00,  4.3123e-04,\n",
      "        -9.5276e-01, -1.8903e+00,  7.7846e-01,  1.8843e+00,  1.8638e+00,\n",
      "        -1.3100e+00,  3.5896e-01, -1.6370e+00, -9.5372e-01, -5.5944e-01,\n",
      "        -8.3830e-01, -6.0701e-01, -2.3812e+00, -1.0484e+00, -9.6616e-02,\n",
      "        -3.0442e-01,  1.3196e-01, -2.0121e+00, -6.9236e-01, -1.2953e-01,\n",
      "        -8.1718e-01, -2.7132e+00, -6.0971e-01, -2.1341e+00, -9.3534e-01,\n",
      "        -2.1983e+00, -1.8572e+00, -1.5427e+00, -8.4860e-02, -2.2615e+00,\n",
      "        -1.4674e-02, -5.9586e-02, -5.7987e-01, -6.9252e-01, -8.2046e-01,\n",
      "        -4.4530e-01, -2.7779e+00, -6.8701e-01, -1.3539e+00, -3.4530e+00,\n",
      "         3.6201e-01, -1.5759e-01, -2.8381e-01, -1.4001e-01, -8.3507e-01,\n",
      "        -5.7111e-01,  1.0115e-01, -5.9008e-01, -7.2415e-01, -8.4900e-01,\n",
      "        -6.8357e-01,  1.0689e+00, -3.8495e-01, -1.0508e+00, -6.5602e-01,\n",
      "        -4.8409e-01, -5.7689e-01, -8.1935e-01, -1.0599e+00,  1.2735e+00,\n",
      "        -4.9219e-01, -2.1097e+00, -1.0187e+00, -7.7531e-01, -1.2676e+00,\n",
      "        -3.7223e+00,  2.3637e-01, -2.0717e+00,  4.1990e-01,  5.9130e-01,\n",
      "         4.7872e-01, -3.7854e-01, -4.7758e-01, -3.1282e-01, -8.8900e-01,\n",
      "        -1.3586e+00, -3.8930e+00, -2.1622e-01, -4.5132e-01,  8.7838e-01,\n",
      "        -1.4784e+00, -1.7915e+00, -1.1509e+00,  8.3270e-01, -7.4391e-01,\n",
      "        -2.5653e+00, -7.2263e-01,  1.7643e+00,  2.9783e-02, -7.7820e-01,\n",
      "        -2.1885e-01, -1.0316e+00, -6.8179e-01,  2.4966e+00, -3.4451e-01,\n",
      "         6.0152e-01,  8.5909e-01, -2.1366e+00, -2.3793e+00, -2.1301e+00,\n",
      "        -3.0380e-01, -1.6324e-01,  9.8643e-01, -1.2687e+00, -7.6117e-01,\n",
      "        -1.4917e+00, -1.7339e+00, -1.8810e+00,  2.5401e-01, -1.2066e+00,\n",
      "        -4.8173e+00, -9.4645e-01, -1.7178e+00,  2.9590e+00, -2.1597e+00,\n",
      "        -2.1243e-02, -5.5538e-01, -1.6830e+00,  8.5943e-01, -7.1583e-01,\n",
      "        -1.1820e+00,  2.5684e+00, -1.2003e-01, -2.6219e-01, -1.2860e+00,\n",
      "         2.0830e+00,  7.0545e-01, -1.8026e+00, -1.4390e-01,  1.0953e+00,\n",
      "        -1.4685e+00, -4.0054e+00, -1.1538e+00, -9.1595e-01,  1.3429e+00,\n",
      "        -8.1435e-01, -3.5236e-01, -5.4932e-01, -2.1612e+00, -1.6113e+00,\n",
      "        -1.8279e+00, -1.9787e+00, -1.6274e+00, -1.3123e+00,  5.2060e-01,\n",
      "        -6.3145e-01, -2.4349e+00, -6.5293e-01, -6.2434e-01, -2.0530e-01,\n",
      "        -5.0941e+00,  1.8349e-01,  2.5546e-01,  5.9956e-01, -3.1157e+00,\n",
      "        -5.5222e-01, -5.0955e-01, -8.3195e-01, -7.1492e-01, -1.0880e+00,\n",
      "         4.4073e-01, -9.2837e-01, -1.8266e+00, -1.6681e+00, -1.9471e+00,\n",
      "         2.0823e+00, -4.5528e-01,  7.3141e-01, -2.0890e+00, -6.7149e-01,\n",
      "         1.2429e-01, -2.2075e+00, -1.4553e-01, -9.2618e-01,  2.0872e+00,\n",
      "         8.3059e-01, -1.2969e+00, -5.6055e-01,  6.5513e-01, -2.0903e+00,\n",
      "         2.0720e+00, -4.5535e-01, -2.5652e-01, -9.9345e-01,  2.3773e+00,\n",
      "        -7.6120e-01, -1.3446e+00, -2.1030e-01,  4.8769e-01, -3.6190e+00,\n",
      "        -1.1556e+00, -1.0853e+00, -5.3123e-01,  2.4976e-01, -1.3864e+00,\n",
      "        -2.0305e-01, -1.5719e+00, -7.7112e-01, -1.6010e+00, -3.9068e-01,\n",
      "        -1.7697e+00,  8.6288e-01, -1.3459e+00, -7.4672e-01, -1.9049e+00,\n",
      "        -2.4548e-01, -5.9181e-01,  1.1824e-02, -7.2569e-01, -2.9538e+00,\n",
      "        -2.6017e-01, -4.3535e-01, -2.7410e+00, -3.6822e+00, -3.3616e+00,\n",
      "        -1.2738e+00, -1.3514e+00,  3.2350e-01, -1.9176e+00, -6.3564e-01,\n",
      "        -2.7572e-01, -7.5871e-01,  2.3393e+00, -7.6319e-01,  1.9796e+00,\n",
      "        -2.6202e-01, -1.0086e+00, -8.1251e-01, -6.6462e-01, -1.7527e+00,\n",
      "        -2.5792e+00, -1.6985e-01, -1.2181e+00,  1.7304e+00, -1.3742e+00,\n",
      "         2.4262e+00, -4.2261e+00, -5.5843e-01, -1.9250e+00, -2.3559e+00,\n",
      "         1.0719e+00, -2.4169e+00, -1.6030e+00, -3.5457e+00, -1.1545e+00,\n",
      "        -9.9285e-01,  7.6851e-01, -1.9802e+00, -4.5258e-01, -5.4922e-01,\n",
      "        -6.7421e-01, -8.4806e-02, -4.5465e-01,  1.1448e+00, -4.4578e-01,\n",
      "        -2.0756e-01, -9.6530e-01, -3.5571e-01,  2.4824e-01, -1.9667e+00,\n",
      "        -5.3181e-01, -4.4217e-01, -1.2888e+00, -5.6563e-01, -6.8182e-01,\n",
      "        -9.0546e-01, -8.1025e-01, -3.6123e-01, -7.1470e-01, -1.4716e+00,\n",
      "        -4.0535e-01, -1.1713e+00, -7.6085e-01,  2.5774e+00, -4.9111e+00,\n",
      "        -6.8714e-01, -7.6617e-01,  2.3308e+00, -5.0002e-01, -2.1778e-01,\n",
      "         1.1048e-01,  3.3571e-02, -7.8506e-01, -2.0634e+00, -1.3558e+00,\n",
      "        -3.7257e+00, -1.1964e+00,  1.3321e+00, -2.4070e+00, -4.1949e-01,\n",
      "        -3.5788e+00, -3.2281e-01, -1.2669e+00,  2.4512e-01, -5.6968e+00,\n",
      "        -2.5001e+00,  1.0233e+00, -2.3116e+00, -8.1443e-01, -8.9200e-01,\n",
      "        -3.5894e+00, -1.6675e+00, -1.7801e+00, -3.5539e-01, -3.0957e+00,\n",
      "        -7.2394e-01, -5.6492e-01, -3.0778e-02, -2.7691e-01,  3.7819e-01,\n",
      "        -5.0868e-01, -2.5203e+00, -7.6316e-01, -1.6667e+00, -2.2055e-01,\n",
      "         2.2814e-01, -2.9720e+00, -6.1991e-01, -3.9426e-01, -2.2437e+00,\n",
      "        -4.3060e-01,  1.4699e-01, -5.0033e-01, -9.5865e-01, -7.8568e-01,\n",
      "        -2.7772e+00, -2.0612e+00, -4.9049e-01, -4.3270e-01, -3.3562e-01,\n",
      "        -1.3909e+00, -2.1421e+00, -1.7401e+00, -2.2957e+00,  4.1467e-01,\n",
      "        -1.4964e+00, -2.3939e+00, -5.0262e-01, -2.9258e-01, -1.2618e+00,\n",
      "        -6.0519e-01, -1.4554e+00, -1.2789e+00, -1.4154e+00, -1.7375e-01,\n",
      "        -4.1368e+00, -2.2754e-01, -5.0843e-01, -1.3647e-01, -3.7505e-01,\n",
      "        -2.1930e+00,  1.0109e+00, -2.1553e+00,  1.7114e+00, -6.9834e-02,\n",
      "        -4.1618e-01, -7.9950e-01, -9.7084e-02, -1.1181e-01, -4.1422e+00,\n",
      "        -2.2165e-01, -1.6181e+00, -1.9955e-01, -8.6922e-01, -6.3160e-01,\n",
      "        -5.9978e-01,  7.8008e-01, -2.1301e+00, -9.4169e-01,  1.8044e+00,\n",
      "        -6.3295e-01, -7.9699e-01,  2.9738e-01, -1.6438e-01, -3.4849e+00,\n",
      "         1.0780e+00, -9.3029e-01,  2.0392e-01, -3.3680e-01, -2.8975e+00],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.2.weight\n",
      "Weights: tensor([[[[-0.2272]],\n",
      "\n",
      "         [[ 0.0415]],\n",
      "\n",
      "         [[-0.0017]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1849]],\n",
      "\n",
      "         [[ 0.0578]],\n",
      "\n",
      "         [[-0.0678]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0904]],\n",
      "\n",
      "         [[ 0.0973]],\n",
      "\n",
      "         [[-0.0611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         [[ 0.0058]],\n",
      "\n",
      "         [[ 0.0595]]],\n",
      "\n",
      "\n",
      "        [[[-0.0285]],\n",
      "\n",
      "         [[ 0.0246]],\n",
      "\n",
      "         [[ 0.0811]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0683]],\n",
      "\n",
      "         [[-0.0209]],\n",
      "\n",
      "         [[ 0.0525]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0109]],\n",
      "\n",
      "         [[ 0.0670]],\n",
      "\n",
      "         [[ 0.0560]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0557]],\n",
      "\n",
      "         [[-0.0031]],\n",
      "\n",
      "         [[-0.0570]]],\n",
      "\n",
      "\n",
      "        [[[-0.1238]],\n",
      "\n",
      "         [[ 0.0472]],\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0066]],\n",
      "\n",
      "         [[ 0.0504]],\n",
      "\n",
      "         [[-0.0147]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0160]],\n",
      "\n",
      "         [[-0.0191]],\n",
      "\n",
      "         [[-0.0080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0047]],\n",
      "\n",
      "         [[-0.0416]],\n",
      "\n",
      "         [[-0.0199]]]], device='cuda:0')\n",
      "Shape: torch.Size([160, 960, 1, 1])\n",
      "\n",
      "Layer: features.15.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.564486563205719\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.5600765347480774\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.3.weight\n",
      "Weights: tensor([4.1007, 1.2737, 2.8637, 1.3691, 1.9483, 1.4831, 1.6949, 0.9279, 1.7290,\n",
      "        1.2234, 2.4084, 1.9626, 1.5683, 2.7622, 2.6831, 2.5816, 0.9477, 2.5015,\n",
      "        1.1736, 2.3006, 1.1139, 1.6150, 1.5968, 2.4600, 1.6956, 3.0962, 1.2282,\n",
      "        1.2531, 1.2108, 2.0988, 1.2288, 1.9227, 1.5812, 1.6211, 3.2189, 1.0721,\n",
      "        2.0699, 0.9473, 2.3596, 1.3639, 2.9150, 2.0776, 1.6745, 1.0755, 2.5590,\n",
      "        3.9001, 2.7860, 1.6183, 0.9864, 3.3164, 2.9515, 2.9806, 2.9637, 1.7790,\n",
      "        2.4916, 2.2305, 1.9942, 1.2538, 2.8781, 3.2415, 2.4917, 1.4832, 2.0671,\n",
      "        1.2411, 1.7759, 2.2709, 2.4568, 1.7596, 1.1267, 4.3622, 3.5939, 1.0888,\n",
      "        2.0889, 1.7450, 2.8761, 1.7259, 1.4957, 1.9370, 3.3132, 0.9676, 1.4314,\n",
      "        1.7414, 1.1676, 1.8560, 2.5611, 1.5380, 4.6520, 2.6145, 1.9974, 1.9655,\n",
      "        1.6949, 2.0825, 2.3652, 1.2734, 1.4588, 1.3459, 1.0894, 1.4432, 2.0117,\n",
      "        2.2145, 2.6910, 1.6275, 2.8713, 2.3444, 2.7749, 1.4793, 2.5572, 1.6333,\n",
      "        1.8035, 1.6336, 2.1399, 2.7765, 2.5529, 1.3580, 1.7425, 0.9752, 2.0832,\n",
      "        1.4221, 0.9866, 1.0272, 2.5018, 4.0539, 1.2777, 1.8545, 3.6204, 2.7409,\n",
      "        1.5492, 3.0657, 2.2134, 2.0952, 1.5525, 2.0036, 1.1674, 1.0353, 1.0284,\n",
      "        2.4982, 1.2361, 1.0788, 1.9909, 1.1345, 2.0058, 2.1505, 1.1375, 1.6332,\n",
      "        3.5422, 1.4261, 2.3812, 1.0764, 3.3506, 3.5374, 3.2310, 3.1007, 2.7008,\n",
      "        1.8103, 2.2889, 2.5295, 3.1108, 1.6676, 2.0589, 1.7691],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.15.conv.3.bias\n",
      "Weights: tensor([ 1.3007e-03, -2.4517e-04,  2.1623e-04, -2.8150e-04,  2.3198e-04,\n",
      "        -7.8201e-04,  1.1438e-04,  4.7655e-04, -3.9122e-05, -8.0464e-04,\n",
      "        -1.0645e-04,  1.1385e-05, -2.3353e-04, -3.8314e-04,  6.6152e-04,\n",
      "        -6.0227e-04, -3.0568e-04,  6.6401e-04,  7.4072e-04,  5.2545e-05,\n",
      "         7.1765e-05,  4.4370e-05, -3.6061e-04,  6.6429e-05, -2.8675e-04,\n",
      "        -1.3217e-03,  2.0435e-04,  4.3402e-04,  2.7545e-04,  8.5032e-05,\n",
      "         5.4612e-05, -7.8290e-04,  5.2272e-04,  1.7653e-07,  1.2982e-03,\n",
      "        -5.6593e-04,  3.8656e-05,  4.9760e-06, -1.8998e-04,  3.7871e-04,\n",
      "         5.4047e-04,  3.1344e-04,  1.2373e-04, -6.2295e-05,  1.2011e-03,\n",
      "         9.8611e-04,  9.3487e-05,  1.2333e-04, -2.0981e-04, -1.6628e-03,\n",
      "         1.6155e-04,  9.3874e-04, -6.8728e-04,  3.5570e-04,  6.1561e-04,\n",
      "        -1.8652e-04, -1.4172e-04, -2.3704e-04, -4.6230e-04,  8.0459e-04,\n",
      "        -4.2735e-04,  9.3075e-05, -2.9755e-04, -6.4669e-05, -1.1611e-04,\n",
      "         4.2159e-04, -3.0281e-04, -6.5091e-05, -1.9624e-04,  4.5712e-04,\n",
      "        -1.0430e-03, -1.9855e-04,  3.0890e-04, -1.4645e-04,  1.0258e-03,\n",
      "         1.5630e-05,  8.1571e-04,  1.9854e-04, -7.5144e-04, -6.6644e-04,\n",
      "         7.9508e-05,  3.3137e-04,  8.3917e-05,  1.8150e-04, -6.6068e-04,\n",
      "         8.9798e-05,  5.6289e-04,  2.2134e-05,  2.1230e-04, -3.3620e-04,\n",
      "         9.1939e-05,  2.6941e-04, -2.4029e-04,  9.1141e-04, -3.3688e-04,\n",
      "        -9.4868e-05,  9.1344e-04, -2.0892e-04,  2.7027e-05, -4.1934e-04,\n",
      "         4.9366e-04,  1.3471e-04, -4.1218e-04,  6.3904e-04,  7.3611e-04,\n",
      "        -3.8731e-04, -7.7264e-04,  3.3012e-04, -5.9810e-05,  4.5572e-04,\n",
      "         1.3163e-04,  1.4767e-03, -4.9010e-04, -2.5704e-04, -6.2909e-04,\n",
      "         1.8513e-04,  3.1919e-04,  4.7118e-06,  1.9698e-04,  4.3150e-04,\n",
      "         8.1865e-04,  4.8618e-04,  8.6137e-05, -1.8175e-04, -1.3947e-04,\n",
      "         1.4513e-04,  2.5268e-04, -5.0885e-04,  3.6288e-04, -3.2576e-04,\n",
      "        -4.6843e-04,  8.6053e-05,  3.3047e-04, -5.1243e-04,  9.2878e-06,\n",
      "         1.2962e-04,  4.9822e-05, -4.2581e-06, -1.4158e-04, -4.7980e-04,\n",
      "        -2.6200e-04, -4.4181e-04,  1.2736e-04, -2.3192e-04, -1.2334e-04,\n",
      "         5.1344e-04,  8.2786e-04,  1.4751e-04,  6.2538e-04, -4.0931e-04,\n",
      "         8.5219e-04,  5.2457e-04, -8.9732e-04,  3.6770e-04,  2.2034e-04,\n",
      "         7.1903e-04, -1.1045e-04, -1.8283e-04,  2.2770e-04,  2.7114e-05],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.15.conv.3.output_quantizers.0.min\n",
      "Weights: -19.49102020263672\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.15.conv.3.output_quantizers.0.max\n",
      "Weights: 18.746347427368164\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.0902]],\n",
      "\n",
      "         [[ 0.0531]],\n",
      "\n",
      "         [[ 0.0743]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0690]],\n",
      "\n",
      "         [[-0.0804]],\n",
      "\n",
      "         [[-0.0065]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0426]],\n",
      "\n",
      "         [[ 0.0088]],\n",
      "\n",
      "         [[-0.0895]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1358]],\n",
      "\n",
      "         [[ 0.0483]],\n",
      "\n",
      "         [[ 0.0479]]],\n",
      "\n",
      "\n",
      "        [[[-0.0731]],\n",
      "\n",
      "         [[ 0.0360]],\n",
      "\n",
      "         [[ 0.0358]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1007]],\n",
      "\n",
      "         [[ 0.0324]],\n",
      "\n",
      "         [[-0.0420]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1775]],\n",
      "\n",
      "         [[ 0.0110]],\n",
      "\n",
      "         [[-0.0027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0508]],\n",
      "\n",
      "         [[-0.0131]],\n",
      "\n",
      "         [[-0.0218]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0431]],\n",
      "\n",
      "         [[-0.0888]],\n",
      "\n",
      "         [[ 0.0302]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         [[ 0.0278]],\n",
      "\n",
      "         [[-0.0446]]],\n",
      "\n",
      "\n",
      "        [[[-0.0717]],\n",
      "\n",
      "         [[ 0.0907]],\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0757]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[ 0.1169]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 160, 1, 1])\n",
      "\n",
      "Layer: features.16.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.7491134405136108\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.7432609796524048\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.0.0.input_quantizers.0.min\n",
      "Weights: -24.77951431274414\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.0.0.input_quantizers.0.max\n",
      "Weights: 22.721572875976562\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.0.1.weight\n",
      "Weights: tensor([0.4779, 1.3182, 1.1399, 1.1358, 0.6078, 0.8985, 0.3980, 1.2337, 1.1414,\n",
      "        1.2004, 0.8836, 1.1211, 1.2230, 1.4693, 0.8749, 0.4156, 0.5872, 0.6708,\n",
      "        0.9666, 0.8279, 0.7847, 1.2694, 0.3650, 0.6075, 0.9984, 1.1235, 2.0898,\n",
      "        0.9432, 1.4150, 0.5402, 0.3980, 1.0005, 1.1787, 0.8954, 0.9401, 0.3219,\n",
      "        1.0609, 1.0784, 1.0981, 1.2487, 0.8108, 0.8585, 1.1979, 0.4768, 1.1445,\n",
      "        1.0446, 1.0187, 1.2716, 1.1317, 1.1327, 1.1274, 1.2589, 0.8930, 0.7290,\n",
      "        0.5141, 1.2661, 1.1446, 0.5550, 1.1548, 1.2236, 1.2897, 1.2425, 1.3018,\n",
      "        0.3614, 1.1342, 1.2097, 0.7189, 0.5548, 0.9257, 1.3845, 1.3413, 0.4226,\n",
      "        1.1035, 1.2076, 1.0921, 0.9491, 0.6037, 1.3752, 0.4843, 0.5507, 0.5161,\n",
      "        0.5624, 0.7736, 1.2049, 0.6214, 1.6103, 0.3731, 0.6852, 1.2173, 0.7676,\n",
      "        0.9115, 0.7257, 0.9939, 0.6186, 0.4736, 1.2583, 1.1289, 1.0671, 0.6869,\n",
      "        1.1864, 0.4450, 0.9542, 0.4524, 1.1265, 0.4565, 0.9870, 1.2112, 1.2261,\n",
      "        1.1196, 1.1305, 1.0517, 0.8598, 0.9979, 1.0125, 1.0934, 1.0992, 0.8366,\n",
      "        1.1286, 1.2107, 0.9648, 1.1101, 1.2716, 0.4305, 1.0062, 0.7932, 0.5333,\n",
      "        0.5062, 1.1655, 1.2739, 2.1918, 0.8251, 0.8012, 0.4658, 0.5503, 1.3452,\n",
      "        1.1551, 1.2800, 1.1531, 1.2868, 1.1788, 0.3737, 1.0834, 2.0130, 1.3722,\n",
      "        0.6906, 1.0759, 0.5134, 0.8629, 1.2366, 0.3354, 1.7572, 1.2840, 0.9297,\n",
      "        1.0390, 0.4699, 1.3364, 1.0300, 0.9555, 1.2195, 1.1524, 1.1426, 0.4255,\n",
      "        1.0279, 1.1190, 1.1091, 1.5757, 0.6616, 1.3170, 1.1710, 0.5282, 0.9286,\n",
      "        1.1597, 0.2741, 0.9254, 0.8057, 1.1262, 1.1436, 0.4567, 1.3714, 1.0793,\n",
      "        0.5839, 1.0720, 0.4478, 1.0732, 1.3314, 0.8490, 1.0237, 1.2351, 0.9828,\n",
      "        1.0302, 1.0787, 1.1937, 0.4954, 1.2696, 1.4471, 0.9913, 0.5336, 1.2519,\n",
      "        1.3569, 1.0635, 1.0700, 1.3331, 1.0757, 1.0155, 1.8776, 1.2193, 2.9230,\n",
      "        1.0792, 0.9018, 1.2069, 0.7790, 0.5128, 1.7891, 1.4599, 1.1281, 0.9520,\n",
      "        0.4990, 0.9986, 0.8263, 1.0693, 0.4939, 1.1007, 0.7643, 0.5709, 1.0559,\n",
      "        0.6808, 2.1853, 1.2741, 0.9788, 1.0689, 1.2145, 0.7916, 1.1183, 1.4411,\n",
      "        1.0651, 1.4168, 0.4063, 0.7982, 0.4226, 1.0048, 1.2919, 0.6127, 0.4655,\n",
      "        0.9268, 1.2922, 0.7815, 0.7927, 1.1542, 1.0218, 1.0065, 1.1150, 1.1799,\n",
      "        1.0133, 1.6437, 1.0968, 1.1707, 1.1292, 1.2781, 1.0672, 1.1578, 0.6255,\n",
      "        1.1115, 1.0751, 1.1265, 0.5407, 1.0078, 0.8306, 1.3658, 2.6768, 1.0623,\n",
      "        1.2211, 0.9956, 0.8919, 1.4235, 1.2548, 1.0986, 1.1181, 0.2884, 1.0317,\n",
      "        0.4074, 0.4221, 1.3611, 2.8940, 0.7973, 1.2268, 0.8204, 0.9590, 0.5024,\n",
      "        1.1508, 1.4320, 0.4530, 0.4915, 0.4030, 1.5532, 0.7214, 1.1289, 0.7660,\n",
      "        1.3406, 1.0638, 0.7725, 1.0655, 1.0587, 1.7213, 0.5136, 1.0256, 1.1064,\n",
      "        1.0478, 0.5787, 1.2281, 0.9276, 0.9606, 0.8940, 1.0516, 0.3259, 0.9658,\n",
      "        1.1520, 1.3205, 1.6178, 0.8517, 1.1486, 0.9798, 0.9498, 1.0520, 1.1404,\n",
      "        1.2055, 1.7736, 1.0090, 1.1433, 0.6163, 0.9522, 0.4089, 0.9851, 0.7643,\n",
      "        1.1532, 0.9965, 0.9778, 1.2259, 1.1181, 0.8907, 0.9553, 1.4024, 1.2796,\n",
      "        1.0634, 1.0895, 1.1538, 0.6324, 0.5577, 0.4595, 1.0811, 0.4546, 1.1902,\n",
      "        1.0877, 1.0416, 0.9904, 1.1216, 0.4673, 1.1877, 0.9097, 1.1000, 1.2011,\n",
      "        1.1650, 0.8406, 1.2320, 1.1046, 1.0075, 1.2365, 1.1713, 1.0229, 1.3013,\n",
      "        1.0720, 0.9008, 1.0419, 0.4817, 0.8373, 1.1354, 1.6970, 1.2443, 0.3309,\n",
      "        1.1530, 0.4406, 0.3575, 0.9190, 2.1571, 1.1016, 1.0930, 1.7113, 0.9277,\n",
      "        0.4006, 0.9277, 1.1847, 0.8938, 1.1702, 1.8253, 1.0364, 0.6015, 1.2097,\n",
      "        1.3124, 1.1528, 1.5165, 1.2044, 0.8822, 1.1705, 1.1080, 0.9953, 0.6784,\n",
      "        1.1946, 1.2702, 1.4993, 0.7091, 1.1578, 0.7233, 1.3525, 1.1749, 0.7136,\n",
      "        1.5658, 0.5704, 0.9979, 1.0292, 1.7009, 0.4668, 1.0075, 1.3481, 1.4127,\n",
      "        1.0351, 0.8314, 0.7512, 0.3818, 1.2399, 0.5021, 0.9705, 1.1815, 0.8077,\n",
      "        1.0730, 0.4484, 1.0656, 1.1617, 1.1535, 1.0484, 1.0604, 1.0953, 1.1222,\n",
      "        0.3617, 1.1043, 1.0637, 1.1055, 0.8870, 1.0733, 0.8328, 1.1464, 1.2169,\n",
      "        0.9380, 1.0517, 0.5496, 1.1996, 0.4371, 0.9819, 0.7533, 1.1348, 1.1960,\n",
      "        0.4952, 0.4839, 0.4696, 1.2378, 0.7728, 2.0430, 0.3541, 0.9389, 0.6116,\n",
      "        1.1614, 1.0910, 0.7170, 1.2289, 1.4280, 1.2033, 1.2377, 1.1788, 0.9992,\n",
      "        1.0623, 1.0829, 1.1265, 1.1920, 0.8766, 1.0068, 1.2680, 0.8908, 0.9196,\n",
      "        1.1504, 1.0934, 1.1535, 1.5143, 1.1532, 0.4738, 0.5980, 1.3443, 1.1016,\n",
      "        0.4631, 1.1228, 1.2788, 0.9972, 1.0600, 1.1794, 0.9713, 0.8974, 1.2612,\n",
      "        1.0953, 0.7686, 0.6159, 2.0851, 1.1496, 1.0956, 0.4548, 1.1498, 1.0489,\n",
      "        1.0508, 0.9323, 0.6992, 1.1339, 1.0337, 1.0338, 0.9431, 1.4019, 0.7463,\n",
      "        1.2125, 1.0208, 0.9677, 0.9665, 1.1854, 0.7044, 0.8908, 1.0015, 1.1403,\n",
      "        1.1714, 1.2396, 0.8160, 1.5195, 1.2546, 0.8292, 1.0235, 0.3911, 0.9016,\n",
      "        0.9523, 1.1321, 1.0153, 0.8417, 0.8743, 1.1226, 1.0840, 0.8425, 0.8553,\n",
      "        1.1454, 1.5530, 1.1494, 2.2321, 0.9932, 0.7010, 1.1331, 0.9415, 1.1730,\n",
      "        0.4656, 1.0610, 1.0141, 1.0124, 0.9923, 1.0585, 1.1980, 1.1274, 1.0305,\n",
      "        1.0301, 1.0231, 1.1404, 1.3447, 0.9455, 0.4656, 1.0646, 1.3212, 0.6351,\n",
      "        1.2876, 0.9117, 1.1867, 0.7472, 0.9605, 1.0931, 1.3958, 1.1946, 1.2857,\n",
      "        0.9998, 0.9240, 2.0681, 1.6266, 1.1743, 0.8768, 0.9806, 0.5403, 1.0468,\n",
      "        0.7636, 0.6957, 1.1709, 0.3121, 1.0623, 0.3708, 0.8847, 1.2705, 0.9210,\n",
      "        0.8829, 0.3377, 0.9868, 1.2499, 1.6807, 1.2726, 0.4293, 1.0781, 1.3587,\n",
      "        1.0494, 1.0281, 0.8512, 1.0478, 1.0342, 0.5192, 0.9883, 1.0336, 0.5270,\n",
      "        1.1072, 0.7338, 0.5274, 1.4036, 1.0387, 1.0072, 1.0112, 1.0735, 1.1058,\n",
      "        0.8827, 1.2159, 1.0497, 1.1883, 0.9500, 0.8838, 1.1779, 0.5925, 1.1148,\n",
      "        0.8049, 0.4664, 0.7269, 1.1260, 0.8480, 1.2656, 1.0230, 1.0351, 1.1495,\n",
      "        1.0876, 1.0175, 0.8920, 1.3280, 1.1471, 1.1569, 0.7615, 1.2784, 0.6988,\n",
      "        0.5433, 0.9583, 0.9348, 0.3394, 0.8672, 0.8852, 0.9710, 1.0926, 0.9614,\n",
      "        0.7228, 1.4800, 0.9545, 1.1043, 1.0417, 1.1869, 0.3554, 1.0475, 0.8996,\n",
      "        1.0658, 1.0012, 1.4675, 1.1206, 1.3246, 1.2878, 1.1333, 0.9898, 1.1138,\n",
      "        0.4715, 0.8897, 1.0040, 0.9821, 1.0428, 2.1757, 1.0629, 1.0151, 1.1784,\n",
      "        1.2953, 1.0160, 1.2181, 1.2133, 1.3984, 0.9272, 1.0154, 1.9489, 1.0472,\n",
      "        1.2327, 1.1597, 1.1309, 1.0366, 1.2346, 1.0887, 1.1240, 1.0099, 1.7490,\n",
      "        1.0187, 1.1774, 1.0285, 0.9054, 1.0534, 1.1234, 0.9817, 1.2269, 1.2206,\n",
      "        1.1104, 0.4353, 1.1481, 0.7875, 1.1467, 1.1295, 1.0169, 0.9853, 0.3378,\n",
      "        0.9272, 0.7992, 0.9514, 1.1891, 1.0885, 0.3990, 0.8655, 0.9743, 0.9222,\n",
      "        0.7150, 1.1933, 1.0288, 1.4334, 1.1989, 1.1690, 1.0700, 1.1255, 0.7672,\n",
      "        1.2982, 0.5764, 0.3965, 0.6852, 0.9557, 1.1180, 1.1998, 1.1007, 1.0967,\n",
      "        0.3799, 1.3664, 1.2441, 1.1269, 1.1058, 1.1065, 0.9309, 1.1792, 0.4352,\n",
      "        0.6679, 1.0675, 1.0428, 1.2175, 0.5088, 1.1177, 1.0357, 0.9168, 0.5232,\n",
      "        1.1103, 1.1158, 0.9746, 1.3920, 0.5762, 1.1561, 0.9448, 0.5806, 1.1424,\n",
      "        0.3924, 1.1273, 0.6964, 1.1505, 0.9264, 1.0849, 1.1576, 1.0318, 0.9264,\n",
      "        0.3758, 0.9584, 0.7590, 1.2049, 1.1293, 1.2957, 1.4700, 1.1020, 1.0827,\n",
      "        1.1313, 0.3386, 2.0246, 1.8259, 0.9630, 0.9879, 1.1682, 1.4908, 0.9274,\n",
      "        1.0432, 1.5031, 0.9635, 0.9033, 1.0019, 1.0393, 0.4454, 1.0457, 1.1037,\n",
      "        1.0164, 0.5293, 0.9330, 1.1173, 1.2367, 0.4661, 1.2051, 1.1779, 0.9849,\n",
      "        1.0432, 0.8659, 0.9682, 0.9672, 1.6265, 1.1207, 0.8449, 0.4131, 0.8343,\n",
      "        1.0352, 0.5912, 1.3110, 1.0714, 0.6043, 0.8795, 1.0543, 1.1158, 0.9190,\n",
      "        0.8003, 0.7100, 1.1119, 0.9163, 1.1404, 1.1437, 2.7286, 1.1553, 1.2087,\n",
      "        1.4879, 1.2475, 1.0094, 1.0284, 0.8368, 1.2197, 1.6030, 0.4655, 0.9342,\n",
      "        1.2740, 1.3147, 1.1390, 0.7885, 0.6380, 0.9756, 0.9620, 0.7294, 1.0515,\n",
      "        0.9678, 1.1611, 1.0106, 1.0945, 1.5068, 0.4638, 1.0732, 1.0620, 0.9474,\n",
      "        1.0021, 1.1078, 0.5706, 0.5867, 0.7163, 0.9600, 1.0624, 0.9668, 0.6330,\n",
      "        0.9720, 1.2511, 0.8303, 0.6984, 1.2239, 1.1190, 2.3352, 0.6905, 1.1480,\n",
      "        0.5445, 1.2089, 0.8772, 1.0076, 1.4128, 0.8794, 0.8658, 0.8041, 1.1208,\n",
      "        1.2031, 1.3455, 1.0741, 0.8070, 1.2188, 1.6700, 1.1909, 1.0544, 1.0084,\n",
      "        1.9537, 1.0861, 0.8364, 1.0275, 1.0678, 0.9863, 1.3593, 0.9643, 1.1331,\n",
      "        1.0667, 1.1501, 0.4306, 0.4416, 1.1448, 1.2427, 0.3970, 1.1823, 1.1207,\n",
      "        0.9112, 1.2715, 0.5886, 1.1110, 1.1540, 0.3809, 0.7176, 0.6656, 1.1003,\n",
      "        1.0452, 1.1996, 0.8798, 0.4368, 1.1534, 0.4451, 0.9807, 0.9349, 0.7816,\n",
      "        0.9444, 1.2987, 0.8133, 0.9596, 1.2454, 0.4950], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.0.1.bias\n",
      "Weights: tensor([ 1.6163, -0.0819,  0.0453, -0.8166,  1.5654,  0.8091,  1.5387, -0.1255,\n",
      "        -0.2437, -0.3431,  0.3251,  0.1045, -0.5733,  0.2115,  0.7856,  1.4833,\n",
      "         1.1114,  1.8012, -0.9852, -1.5820,  0.9434, -0.4790,  1.4331,  1.8070,\n",
      "        -0.8138, -0.2914,  0.1542,  0.4896, -0.4511,  1.0723,  1.2604, -0.6572,\n",
      "        -0.3705, -1.3226,  0.6356,  1.2498, -0.0495, -1.2252,  0.6189,  0.0301,\n",
      "         0.8201,  0.1040, -0.4055,  1.5747,  0.0694, -0.4779,  0.7363,  0.0960,\n",
      "        -0.2450,  0.3026, -0.7878, -0.6211,  0.9337,  0.9159,  1.5431, -0.2251,\n",
      "        -0.9401,  1.4758,  0.0032, -0.4945, -1.2176, -0.4192, -0.3916,  1.4319,\n",
      "        -0.2774, -0.5501,  0.9912,  1.6041,  0.8305, -1.6202,  0.5999,  1.4374,\n",
      "        -0.9630, -0.0580, -0.8052,  1.1875,  1.0620,  0.0690,  1.1314,  1.1430,\n",
      "         1.4298,  1.1095,  1.5662,  0.1606,  1.5859, -0.4805,  1.3969,  0.8796,\n",
      "         0.4699,  0.8366,  0.0840,  1.1703, -0.3104,  1.9513,  1.2202, -0.2515,\n",
      "         0.2456, -1.2262,  0.5608, -0.7929,  1.6738,  0.4710,  1.6856, -0.2247,\n",
      "         1.2943, -0.3640, -0.4350,  0.2039, -0.9151,  0.0974,  0.4497,  0.7072,\n",
      "        -0.6647, -0.2382,  0.1185, -0.4348,  0.8643, -0.6414,  0.1182,  0.2810,\n",
      "         0.1655, -0.5807,  1.2326,  0.5965,  1.5175,  1.1934,  1.5696, -0.0899,\n",
      "         0.3862, -2.0583, -0.2133,  0.2517,  1.3651,  1.3428, -0.5395, -0.7243,\n",
      "        -0.5714, -1.0177, -0.5014, -0.6696,  1.4410, -1.1690, -1.1121, -0.6943,\n",
      "         0.9523, -0.9217,  1.1502, -1.2896, -0.7499,  1.2751, -0.8007, -1.4026,\n",
      "         0.0843, -0.2405,  1.7098, -1.2435,  0.2378,  0.2737, -0.2518, -0.7704,\n",
      "        -0.1167,  1.4732,  0.2586,  0.0846,  3.1313, -0.0427, -1.4840, -0.4560,\n",
      "         0.1043,  1.3363, -0.5102, -0.3331,  1.4894, -0.2681,  1.1766, -1.4064,\n",
      "        -0.7179,  1.4918,  0.0336,  0.5504,  0.9977, -0.7710,  1.8896,  0.3290,\n",
      "        -0.2239, -0.7063, -1.2416,  0.0822, -0.1670, -0.1011, -0.6546, -0.8441,\n",
      "         1.2375, -0.9117,  0.3331, -0.2592,  1.5598, -1.1012, -0.3694, -0.2837,\n",
      "        -0.3764, -0.7623, -0.5873, -0.2319, -1.3990, -0.8700, -0.7176, -1.2409,\n",
      "        -0.2366, -0.0282,  0.8956,  1.1614, -0.0048, -0.6294, -1.4728,  0.0031,\n",
      "         1.1418,  0.0620,  0.6898, -0.4689,  1.9488, -0.9402, -0.9908,  1.0776,\n",
      "        -0.7878,  1.4506,  0.2762, -1.1857,  0.1044, -1.6561, -0.4258,  0.8835,\n",
      "        -0.1760, -2.1047,  0.4376, -0.6936,  1.3657,  1.1740,  1.2833, -0.5161,\n",
      "        -0.1962,  1.8895,  1.6273, -0.6522, -0.7736,  0.9549, -0.1459, -0.2308,\n",
      "        -1.0283, -1.0922,  0.4923, -0.8989, -0.2253, -0.5267, -1.2155, -0.1664,\n",
      "        -0.7948, -0.4300,  0.2994,  0.1042,  1.1962,  0.5704, -0.3719, -0.6585,\n",
      "         1.7359, -0.1108,  0.8646, -0.3405, -0.0626, -0.3119, -1.0314, -0.0464,\n",
      "         0.7207, -1.5098, -0.0751, -0.5546, -0.5143,  1.4908, -1.2021,  1.3740,\n",
      "         1.5853, -0.4512, -1.3664, -0.1448,  0.2190,  0.1067,  0.3247,  2.0359,\n",
      "        -0.8039,  0.7062,  1.5076,  1.2855,  1.3673, -1.5344,  1.0847, -0.0119,\n",
      "         0.7912, -1.0450, -1.3588,  0.9204, -0.2919,  0.5432,  0.6344,  1.4354,\n",
      "         0.5666, -0.2495, -0.5365,  1.2063, -0.2062,  0.2606, -0.7547,  1.3695,\n",
      "        -0.0811,  1.3325,  0.3411, -0.1062,  0.1320, -1.4253,  0.2416, -0.6629,\n",
      "         0.0540, -0.7635, -1.0526,  0.2492,  0.0782, -0.7671, -0.1585, -0.4996,\n",
      "         2.2518,  0.2198,  1.5232,  0.2299,  1.0291,  0.1536, -0.7631, -0.1554,\n",
      "        -0.9514, -0.3663,  0.8058, -0.5875, -0.4322, -0.2454, -0.8145, -1.5520,\n",
      "         0.1824,  1.0273,  1.4149,  1.0660, -0.4098,  1.3930, -0.4355,  0.5074,\n",
      "        -0.9695,  0.0122, -0.5999,  1.5066, -0.4423,  0.4764, -0.7625, -0.5984,\n",
      "        -0.9250,  1.3469, -0.2036, -0.3242,  0.3438, -0.1516, -0.2440,  0.5689,\n",
      "        -0.0688,  0.5006,  0.2629, -0.3955,  1.4264,  0.1127, -0.0106, -1.4787,\n",
      "         0.2524,  1.5152, -1.6139,  1.1780,  1.2619, -0.1671, -1.2192, -0.1159,\n",
      "        -0.2670, -1.0352,  0.8055,  1.6372,  0.0338, -0.0346, -0.0883, -0.3997,\n",
      "         0.0893, -0.1025,  1.4426, -0.6336, -0.7714,  0.0699, -1.2389, -1.1750,\n",
      "        -1.5103, -0.0658, -1.2080, -0.1825,  1.0157, -0.4633, -0.3998, -0.9807,\n",
      "         0.1651, -0.4169,  1.4147, -0.4015, -0.1725,  1.1313, -0.2061,  1.5602,\n",
      "         0.1460, -0.1497, -0.6424,  1.5693, -0.5487, -0.9633, -0.2653, -1.2613,\n",
      "        -0.0437,  0.8967,  1.4649, -0.5602,  1.6336, -0.8789, -0.1454, -1.2999,\n",
      "        -0.4107,  1.8670, -0.9041, -0.1706, -1.4048, -0.7355, -0.0933, -0.6492,\n",
      "        -0.8920,  1.6382, -0.4663, -0.3869, -0.0946, -0.3343,  0.0063,  0.8447,\n",
      "        -0.0991, -0.3138,  0.3072,  0.4260,  1.0626,  1.1005,  1.5258,  0.6224,\n",
      "         1.0707, -0.2325, -0.1849,  1.1417,  1.5275,  1.2340, -0.2466,  0.9535,\n",
      "        -1.5864,  1.7937, -0.0884,  0.9827,  0.2903, -1.1652,  0.9095, -0.6660,\n",
      "         0.8776, -0.2040, -0.1456, -0.7172,  0.0487, -0.1010,  0.0554, -0.4741,\n",
      "        -0.1559, -0.2778,  0.3664, -0.0933,  0.4380,  0.0663,  0.3212,  1.0615,\n",
      "         0.2980,  1.2125,  0.1584,  1.0629,  1.2610, -0.3047, -0.7056,  1.6580,\n",
      "         0.1564, -1.5370,  1.3402, -0.3713, -0.5371,  1.3356,  0.1173, -0.2179,\n",
      "         0.3242,  0.9654,  1.5936, -0.4234,  0.2571, -0.2166,  1.7707,  0.0625,\n",
      "        -0.3231, -1.4263,  0.0988,  2.1728, -1.1379, -0.1653, -0.6385, -0.3295,\n",
      "         0.2650,  1.0226, -0.7945, -1.4660, -0.2647, -0.6442, -1.5298,  1.4176,\n",
      "         0.1001,  0.1821,  0.3485, -0.4879,  0.2191,  0.9118, -0.0058, -0.2026,\n",
      "        -1.0459, -0.2265,  1.4180, -0.2542, -0.0307,  0.0114,  0.0173,  0.9268,\n",
      "         0.0432, -1.1151, -0.7554,  1.1240,  1.3393, -0.3840, -0.8974, -0.2229,\n",
      "        -0.8614,  0.0190,  1.0399, -0.4464,  0.1092, -0.7214,  1.0522, -0.5912,\n",
      "        -0.4137, -1.0599,  0.0737,  0.4001,  0.1057,  1.0850,  0.6086, -0.7679,\n",
      "         0.3461, -0.4192, -0.6128, -0.3495,  1.1279, -0.8766,  0.0366,  1.3318,\n",
      "        -0.5299,  0.4977, -0.2896,  0.9060, -0.5839,  0.2341, -0.2696, -0.0333,\n",
      "        -0.2171,  0.1047,  0.2419,  0.4809,  2.8383, -0.3753, -1.1279,  1.2129,\n",
      "         0.7800,  0.8244,  1.4772,  1.2012, -0.2075,  1.5492, -0.0877,  1.2009,\n",
      "         0.0192, -0.2204, -0.6697, -0.4385,  1.4975, -1.2303,  0.1472, -1.2972,\n",
      "        -0.4764,  1.2570,  0.3360, -1.1030, -0.1436, -0.0929,  1.3717,  0.7217,\n",
      "        -0.1811,  1.3528, -1.0382, -0.5932,  1.5596, -0.1594,  0.9649,  1.1714,\n",
      "        -0.3824, -0.2418, -0.6948, -0.7040, -0.6260, -0.5197,  0.8848, -0.7367,\n",
      "         0.4215,  0.2357, -1.0881,  0.3532, -0.0178,  1.1590, -0.6735,  0.9160,\n",
      "         1.4451,  1.0594,  0.3398,  0.6982, -0.5155, -0.7625, -0.2771, -0.2095,\n",
      "         0.3695, -0.8912, -0.0798, -0.3761, -0.6965, -0.0375,  0.8905, -0.3003,\n",
      "        -0.3761,  1.5513,  0.2032, -1.9060,  1.4399, -0.9672, -0.7354, -0.4080,\n",
      "        -0.0074,  0.7384,  0.9086, -0.4033, -0.6997, -0.3539, -1.0290, -0.2118,\n",
      "         1.5533, -1.3463, -0.0803,  1.1365, -0.9844, -0.7246, -0.3989, -1.1225,\n",
      "        -0.7013, -1.1126, -0.8310, -0.6855,  1.5720,  1.1343, -0.4168, -0.7226,\n",
      "        -0.0796, -1.4813, -1.0633, -0.8722,  0.0272, -0.6865,  1.6257, -1.2002,\n",
      "        -0.3972, -0.3041,  0.7312,  0.6334, -0.3338, -0.5597, -1.1272, -0.8866,\n",
      "        -0.4133,  0.7716,  0.3195, -0.4645, -0.2327,  0.6117, -0.5676, -0.7403,\n",
      "        -0.8290, -0.1377, -0.3106,  0.4595,  0.0580,  1.3019,  0.1158, -0.2187,\n",
      "        -0.2386,  1.4109,  0.2544,  1.2755, -0.2534,  0.1841, -0.5649,  0.8122,\n",
      "         1.4786,  1.1907,  0.7337, -0.5861, -0.4552, -0.3872,  1.5983,  0.0575,\n",
      "        -1.1681,  0.7546,  1.3397,  0.2857,  0.0129, -0.2961, -0.1768,  0.2142,\n",
      "        -0.4310, -0.6496,  0.9538, -0.9942,  1.7093,  1.7438,  0.8923,  0.4178,\n",
      "        -0.6317, -0.1072,  0.0441, -0.3335,  1.5694, -0.5095, -0.0919,  0.0090,\n",
      "        -0.0178, -0.0981,  0.2801, -0.8367,  1.5724,  0.7839, -0.6607, -0.7569,\n",
      "        -0.4657,  1.4708,  0.1203,  0.0780, -0.3794,  1.0937, -0.3614,  1.8005,\n",
      "        -0.5493, -1.3248,  1.4480, -0.3726,  0.6304,  1.6496, -1.0894,  1.2930,\n",
      "        -0.6285,  2.0177, -0.5641,  0.8223, -1.5559, -0.3537, -0.7932,  1.0351,\n",
      "         1.6397,  0.4508,  0.1583, -0.3141,  0.1325, -0.6868, -0.0156, -0.7837,\n",
      "         0.7432,  0.7911,  1.2373, -0.7295, -0.7833,  0.3127,  0.2112,  0.2934,\n",
      "        -0.0603,  1.1974,  0.2305,  0.1234, -0.5857,  0.7826,  0.0351,  0.2379,\n",
      "         1.2191,  0.6129,  0.5964,  0.5901,  1.1997,  0.6073, -0.5970, -0.2248,\n",
      "         1.2728,  0.1867, -0.3525,  0.0821,  0.4628,  0.8403, -1.0166,  0.1623,\n",
      "         0.1550, -0.5908,  1.1216,  1.3180, -0.0048, -0.4748,  1.4593, -0.9600,\n",
      "        -0.2116,  1.5260, -1.0583, -0.2036, -1.5837, -0.5280,  0.8042,  0.4265,\n",
      "        -0.8129,  0.8337, -2.2206, -0.2384, -0.6319, -0.3213, -0.1936, -0.8007,\n",
      "        -0.4418, -0.2037,  0.1147,  0.2814, -0.8441, -0.6969,  1.3081,  0.8556,\n",
      "        -0.3912,  0.0034,  0.1537,  1.3592,  0.9981, -0.1208, -1.3246, -2.1098,\n",
      "         0.0529,  0.3600,  0.3433,  0.1083,  0.5428,  0.2848,  1.8904, -1.7153,\n",
      "        -1.1757, -0.1808,  0.0085, -0.1440,  1.8542,  1.0831,  0.5081,  0.1895,\n",
      "         0.7442,  1.0106,  1.2944,  0.4996, -0.3796,  0.1440,  0.9379, -0.5580,\n",
      "         0.1634,  0.6368,  1.3699,  0.0518,  1.3747, -0.0706, -0.7155, -1.3630,\n",
      "        -0.3568,  0.1230,  0.8301,  2.0487,  0.2467, -0.0140,  0.4514, -0.3975,\n",
      "         0.9736,  0.3082, -0.6807, -0.1539, -0.4357,  0.1773, -0.6362, -0.4392,\n",
      "         1.2141, -0.2608, -0.2690,  0.1437,  0.6583,  0.3223,  0.2669, -0.6191,\n",
      "        -1.4324,  1.3166,  1.2256, -1.2668, -0.9815,  1.0828, -0.3688, -0.5047,\n",
      "        -1.3181, -1.3698,  1.6394, -0.4587, -1.1347,  1.3563,  0.9485,  1.3372,\n",
      "         0.4443, -0.1807, -0.2735,  0.9412,  1.3368, -0.5589,  1.3693, -1.3280,\n",
      "        -0.7487,  0.8100,  0.6251, -0.6755,  1.5288, -0.0524, -0.3208,  1.6337],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.1.0.weight\n",
      "Weights: tensor([[[[-4.1363e-02, -1.3195e-01, -4.5281e-02],\n",
      "          [-1.2346e-01, -2.0437e-01, -1.2630e-01],\n",
      "          [-5.0178e-02, -1.2943e-01, -3.5875e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6544e-02,  1.1429e-01,  7.0258e-02],\n",
      "          [ 9.5012e-02,  2.1150e-01,  9.1723e-02],\n",
      "          [ 5.9869e-02,  1.0497e-01,  6.1298e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3532e-02, -1.1209e-01,  5.4078e-02],\n",
      "          [ 6.0083e-02, -2.4694e-01,  5.9567e-02],\n",
      "          [ 1.3475e-01,  7.1601e-02,  1.3472e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.9753e-03, -6.5354e-02, -2.0659e-04],\n",
      "          [ 9.8032e-02, -7.6449e-02,  9.2812e-02],\n",
      "          [ 7.2093e-02,  2.1133e-01,  6.9919e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6794e-03,  1.8180e-02, -6.2801e-04],\n",
      "          [ 3.5133e-02,  3.4593e-01,  4.4540e-02],\n",
      "          [ 4.6515e-03,  2.1074e-02, -1.5895e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.5187e-02, -5.4358e-02, -3.8957e-02],\n",
      "          [-2.4544e-02, -3.2909e-01, -3.2197e-02],\n",
      "          [-2.7611e-02, -4.4227e-02, -2.3760e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 1, 3, 3])\n",
      "\n",
      "Layer: features.16.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.8033869862556458\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.7971104979515076\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.1.1.weight\n",
      "Weights: tensor([ 1.7071,  1.5717,  0.4975,  0.7091,  1.8164,  0.6050,  1.2321,  0.7936,\n",
      "         0.4376,  0.8503,  0.9153,  0.7931,  1.0560,  0.9002,  0.7333,  1.3895,\n",
      "         0.6751,  3.2077,  0.2021,  0.3051,  0.6225,  0.2777,  0.9488,  2.9465,\n",
      "         0.2306,  1.4310,  6.2203,  1.9656,  0.4634,  0.9435,  0.6919,  0.9751,\n",
      "         0.9003,  0.2600,  0.7153,  1.2509,  1.1251,  0.2052,  1.1181,  0.4029,\n",
      "         0.4156,  0.8850,  0.3823,  1.5161,  0.7898,  0.7099,  0.3903,  0.9087,\n",
      "         0.9846,  0.5547,  0.3279,  0.9124,  0.3590,  0.8674,  1.0979,  0.7597,\n",
      "         0.1977,  0.6267,  0.4834,  0.7536,  0.8856,  0.5176,  1.6318,  1.3166,\n",
      "         0.2648,  0.9291,  0.5013,  1.1717,  0.4836,  0.3205,  0.8441,  0.9385,\n",
      "         0.5800,  0.3091,  0.2456,  0.9600,  0.6840,  0.6784,  0.5581,  1.2191,\n",
      "         1.5058,  0.9080,  1.6408,  0.3424,  1.8270,  1.1479,  1.1610,  0.6360,\n",
      "         1.5346,  0.9981,  1.6242,  0.3582,  1.2085,  1.6803,  0.5609,  1.2194,\n",
      "         0.3420,  0.2326,  0.8250,  0.2391,  1.2709,  1.1933,  1.4963,  1.1496,\n",
      "         1.9635,  0.7701,  0.3158,  1.2971,  0.2412,  3.1152,  0.7522,  0.6683,\n",
      "         0.9460,  1.2747,  1.5042,  0.4327,  0.9490,  0.2088,  1.8902,  0.8729,\n",
      "         0.3464,  0.8349,  0.5925,  0.5677,  1.6645,  0.4144,  1.1199,  0.8102,\n",
      "         0.7746, 11.6891,  1.2331,  0.8560,  0.6511,  2.1531,  1.1384,  0.3069,\n",
      "         0.8784,  0.2436,  1.1423,  0.6866,  1.1982,  0.2072,  0.7121,  2.6437,\n",
      "         0.7894,  0.2339,  1.2068,  0.2380,  0.9226,  0.8309,  0.9093,  0.8270,\n",
      "         0.6925,  0.5036,  1.0293,  0.2144,  0.8292,  1.5255,  0.2633,  0.3093,\n",
      "         0.7944,  1.5715,  1.7330,  0.2463,  3.7406,  0.6606,  0.3602,  1.1041,\n",
      "         0.6947,  0.7107,  0.7048,  0.2603,  1.2618,  0.4445,  0.4701,  0.2896,\n",
      "         0.7500,  1.4072,  0.8316,  0.5464,  1.0291,  0.5358,  1.6445,  0.9348,\n",
      "         1.2896,  0.3690,  0.2579,  0.8942,  0.8417,  1.4697,  0.2866,  0.1826,\n",
      "         1.3928,  0.2539,  0.3535,  1.2796,  1.4897,  0.1786,  0.6275,  0.6711,\n",
      "         0.6684,  0.3174,  0.3303,  1.3975,  4.6843,  0.2389,  0.3186,  0.2138,\n",
      "         1.2915,  1.3311,  0.3455,  0.6968,  0.3557,  3.4576,  0.1946,  1.1763,\n",
      "         0.5707,  1.0202,  0.9815,  0.3059,  1.9665,  0.2893,  0.2931,  0.8599,\n",
      "         0.2361,  2.2902,  5.5631,  0.1826,  0.3296,  0.2396,  0.8583,  1.4691,\n",
      "         0.3075,  0.2924,  0.6155,  2.6420,  1.0047,  1.6574,  0.6883,  0.5320,\n",
      "         0.3140,  1.6534,  1.1904,  0.2507,  0.9332,  0.5594,  0.7403,  0.8438,\n",
      "         0.2476,  0.2767,  0.7674,  0.2854,  0.7737,  2.5735,  0.1711,  0.5557,\n",
      "         0.2890,  1.2385,  0.7596,  1.6398,  1.2150,  2.3387,  0.6275,  0.8212,\n",
      "         1.4285,  1.0784,  0.6330,  0.9273,  8.6420,  1.1580,  3.0701,  1.6918,\n",
      "         0.5932,  0.3419,  0.6467,  1.1847,  0.6508,  1.1451,  0.2138,  1.2106,\n",
      "         1.7541,  0.3759,  4.3086,  1.5874,  0.7448,  1.0956,  0.5239,  1.3261,\n",
      "         0.3881,  0.3860,  1.2119,  1.2750,  1.2821,  0.3252,  1.2680,  1.0028,\n",
      "         0.7155,  0.2454,  0.5831,  0.5672,  1.2247,  0.6462,  0.6470,  1.5372,\n",
      "         1.5814,  0.8506,  0.4833,  0.4540,  1.1335,  1.4155,  0.9402,  0.5300,\n",
      "         0.3529,  0.9849,  1.7009,  0.8030,  0.3380,  3.9186,  1.8091,  0.7515,\n",
      "         1.1230,  0.4060,  0.2232,  0.5297,  0.3056,  3.7899,  0.8064,  0.5154,\n",
      "         3.0860,  1.6273,  1.1403,  0.7720,  1.1898,  0.5000,  0.4317,  0.9033,\n",
      "         0.3170,  1.0092,  1.3291,  0.9192,  0.8698,  0.9735,  0.7321,  0.1377,\n",
      "         0.3469,  0.8683,  1.1462,  0.4578,  0.7148,  0.7900,  0.3158,  0.4072,\n",
      "         0.2906,  1.1300,  0.3808,  1.0371,  1.2390,  2.1465,  0.8478,  1.0323,\n",
      "         0.8447,  1.1828,  1.1709,  1.5679,  1.7415,  0.3264,  0.8932,  0.7014,\n",
      "         0.9482,  0.9132,  0.7986,  0.9222,  0.8569,  1.0773,  0.6867,  0.3599,\n",
      "         0.3427,  0.8813,  3.8509,  1.2221,  0.8056,  0.9337,  4.2985,  0.6649,\n",
      "         0.7994,  0.4121,  0.6189,  1.3851,  1.1401,  0.8845,  0.8514,  0.1861,\n",
      "         1.5038,  0.8670,  1.8252,  0.2494,  3.2648,  0.7952,  0.1982,  0.1824,\n",
      "         0.2356,  0.9016,  0.2381,  1.6464,  0.4886,  0.2238,  0.6539,  0.2814,\n",
      "         1.4311,  1.0136,  1.5090,  0.4689,  0.2768,  1.4760,  0.3909,  1.0490,\n",
      "         1.9811,  1.2464,  0.2971,  1.5150,  0.3449,  0.3443,  1.2707,  0.5148,\n",
      "         0.9166,  0.6587,  0.7154,  0.7798,  1.1901,  0.5989,  0.9714,  0.1468,\n",
      "         0.3064,  1.6019,  4.0584,  0.3653,  0.2212,  0.3146,  0.8043,  0.5890,\n",
      "         0.7715,  1.2956,  0.3502,  0.3313,  0.5446,  1.1273,  0.4059,  1.2493,\n",
      "         1.1926,  0.7641,  1.6331,  1.7136,  0.6637,  1.5723,  1.5631,  0.6627,\n",
      "         0.5943,  0.3335,  0.8679,  0.4810,  0.9534,  1.1324,  1.2077,  1.1065,\n",
      "         0.4383,  1.3496,  1.1742,  0.4417,  1.9551,  0.2340,  0.9001,  0.7877,\n",
      "         0.6151,  0.6937,  0.3594,  0.9143,  1.0262,  1.2768,  0.8081,  0.7579,\n",
      "         0.8007,  1.1510,  1.5227,  0.8944,  2.5713,  1.1290,  0.4566,  1.2526,\n",
      "         1.2068,  0.6563,  0.3120,  1.0347,  0.5421,  0.3379,  0.2236,  1.3104,\n",
      "         1.2961,  0.2643,  1.5769,  0.2708,  0.2848,  1.3954,  1.6047,  0.3271,\n",
      "         0.5723,  0.8479,  0.8386,  3.8724,  0.7792,  0.8936,  1.5083,  0.6144,\n",
      "         0.7532,  0.1999,  1.1823,  1.7650,  0.6061,  0.9046,  0.5003,  1.2084,\n",
      "         1.0839,  0.8990,  0.6993,  0.1563,  0.9581,  0.1500,  3.1111,  0.6728,\n",
      "         0.9866,  0.5656,  0.7720,  0.8385,  0.6712,  0.4934,  0.8448,  0.3203,\n",
      "         0.2191,  1.2425,  0.6868,  0.5237,  0.6894,  0.5957,  1.2693,  0.8669,\n",
      "         1.0038,  0.2153,  0.2264,  0.6342,  1.5735,  0.9297,  3.4635,  0.9798,\n",
      "         3.3893,  0.6142,  1.2559,  0.6648,  0.8027,  0.9461,  0.7206,  0.7472,\n",
      "         0.7876,  0.1670,  0.8062,  0.3727,  0.4395,  1.2104,  0.7412,  0.9143,\n",
      "         0.9126,  0.4329,  0.3482,  1.3703,  0.5530,  0.2293,  1.4831,  1.1503,\n",
      "         1.0181,  0.8053,  1.0121,  0.7011,  0.3155,  0.7316,  1.1368,  1.2217,\n",
      "         1.1730,  1.3446,  1.6949,  0.6794,  0.4753,  0.7325,  0.2306,  1.4535,\n",
      "         0.8786,  0.7532,  1.5819,  1.5303,  1.0933,  1.1216,  1.2915,  0.6685,\n",
      "         1.2142,  0.3344,  0.3381,  0.8438,  1.0098,  0.2278,  0.6924,  0.3424,\n",
      "         1.1654,  1.1335,  0.7650,  0.3276,  0.3032,  1.3613,  1.4306,  0.7898,\n",
      "         0.9919,  1.4142,  0.2294,  0.2733,  1.8753,  0.5239,  0.7997,  0.8873,\n",
      "         1.1882,  0.8764,  0.4780,  1.0689,  0.1627,  0.2504,  0.5799,  0.2555,\n",
      "         0.5951,  0.4960,  0.6828,  1.9151,  1.2737,  0.4606,  0.7157,  0.5378,\n",
      "         1.3662,  1.3204,  1.5504,  0.6647,  0.6195,  0.5986,  1.2038,  0.9637,\n",
      "         0.6593,  0.6920,  1.6180,  0.9187,  0.8631,  0.7643,  0.7421,  1.4185,\n",
      "         0.8802,  1.2329,  0.6566,  3.5034,  0.9075,  0.2299,  0.2227,  0.3484,\n",
      "         3.2193,  0.5723,  0.7325,  1.6111,  0.3667,  1.1544,  0.1674,  0.9065,\n",
      "         0.7147,  0.2181,  0.7378,  1.6980,  0.1769,  2.6863,  0.5246,  0.3203,\n",
      "         0.7653,  0.2211,  0.5270,  0.5129,  1.2313,  0.6641,  0.2481,  0.3211,\n",
      "         0.8571,  0.5962,  0.2215,  0.2409,  0.8628,  0.3248,  1.0537,  0.2312,\n",
      "         0.7662,  1.2132,  1.6856,  0.5958,  3.3437,  0.1770,  0.2662,  0.3434,\n",
      "         0.7961,  1.0368,  0.7072,  0.8695,  1.0158,  1.0020,  0.4817,  0.3005,\n",
      "         0.6425,  0.6714,  0.8847,  0.9600,  1.4487,  1.0942,  1.5435,  1.1490,\n",
      "         1.6354,  1.1519,  1.4430,  0.5280,  0.4861,  1.1458,  0.9577,  0.6495,\n",
      "         1.1888,  0.5234,  0.3865,  0.8257,  0.9608,  0.8420,  0.6660,  0.5642,\n",
      "         0.7093,  0.4090,  1.3225,  0.5954,  1.9698,  0.3227,  0.4867,  0.6266,\n",
      "         0.3177,  0.8164,  0.7229,  4.0965,  1.7136,  1.7362,  0.4882,  1.8581,\n",
      "         0.2515,  0.3415,  0.6554,  0.9193,  1.0588,  2.7511,  0.6093,  0.4775,\n",
      "         0.6334,  0.4932,  1.8915,  0.2252,  1.2633,  1.3817,  0.2298,  0.2687,\n",
      "         0.6517,  1.7617,  0.5395,  1.6051,  0.5414,  0.8443,  0.5290,  2.0347,\n",
      "         0.3963,  0.3648,  1.7554,  0.9357,  1.9058,  1.5723,  0.1987,  0.7013,\n",
      "         0.5596,  2.0878,  1.3219,  1.9952,  0.3428,  0.2154,  0.2793,  2.3415,\n",
      "         1.3518,  0.3752,  0.6552,  0.8642,  0.6185,  0.9658,  0.8464,  0.2461,\n",
      "         0.6702,  1.4000,  0.9315,  7.7121,  3.2894,  1.7937,  1.5981,  0.7784,\n",
      "         0.3022,  1.6009,  1.7080,  0.8095,  0.2731,  0.9860,  1.4429,  1.6230,\n",
      "         0.7129,  0.8656,  2.0518,  0.4799,  1.0678,  0.3597,  0.7099,  1.3391,\n",
      "         1.0566,  0.5867,  0.5427,  0.9579,  0.6836,  0.9583,  0.2842,  1.6669,\n",
      "         0.6816,  1.0297,  1.0042,  0.9484,  0.8549,  0.3764,  0.9265,  0.5201,\n",
      "         1.0681,  1.1496,  0.2369,  1.1872,  0.1968,  0.6544,  0.8984,  0.7934,\n",
      "         0.3029,  0.9317,  0.2201,  1.3177,  0.5771,  0.5054,  0.8066,  2.7376,\n",
      "         1.1827,  0.7280,  1.1235,  1.1059,  0.2180,  2.3714,  1.4716,  0.3479,\n",
      "         0.9493,  0.3167,  0.9000,  0.3841,  0.7518,  1.0113,  0.2238,  0.7863,\n",
      "         0.7138,  0.5372,  0.4433,  0.8251,  0.8511,  0.3312,  1.8807,  0.2556,\n",
      "         0.2361,  1.1301,  0.9232,  1.5491,  0.9164,  1.4187,  0.8637,  1.4955,\n",
      "         0.7341,  0.9661,  0.3814,  1.2516,  0.2699,  1.0903,  1.0220,  1.0257,\n",
      "         0.5559,  0.6249,  1.3740,  1.2895,  1.5285,  1.2341,  0.4751,  0.2662,\n",
      "         0.3843,  1.7780,  0.7502,  1.5735,  0.8143,  0.9366,  1.6979,  0.8473,\n",
      "         0.4292,  0.3509,  0.4856,  0.9024,  0.1806,  1.5272,  3.0266,  0.6457,\n",
      "         0.5894,  1.0479,  1.1554,  1.1259,  0.3695,  1.3816,  0.5367,  0.2255,\n",
      "         0.1428,  0.8587,  0.4882,  0.2010,  1.1284,  0.4365,  0.3657,  0.3016,\n",
      "         0.2846,  0.2484,  1.1890,  0.7124,  0.1850,  1.3031,  0.5553,  1.1804,\n",
      "         1.1042,  0.7570,  0.3195,  0.7986,  0.9819,  0.7817,  0.8368,  0.2125,\n",
      "         0.2342,  0.8858,  0.6232,  0.9961,  1.8214,  0.5480,  0.2625,  1.3418],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.1.1.bias\n",
      "Weights: tensor([-2.7901e+00, -4.2372e+00, -2.5770e-01, -2.6268e+00, -2.6233e+00,\n",
      "        -2.4007e-01, -1.9776e+00, -1.4387e+00, -8.3689e-02, -2.2629e+00,\n",
      "        -1.9199e+00, -1.4699e+00, -3.5208e+00, -1.9024e+00, -3.3222e-01,\n",
      "        -1.9570e+00, -5.3105e-02, -3.5752e+00,  9.7066e-01,  2.6896e-01,\n",
      "        -5.6178e-01,  1.6978e+00, -1.1183e+00, -3.1878e+00,  9.3124e-01,\n",
      "        -4.7359e+00, -4.6857e+00, -5.3739e+00,  4.3532e-01, -7.4190e-01,\n",
      "        -5.7689e-01, -3.5036e+00, -2.7261e+00,  8.9816e-01, -7.9739e-01,\n",
      "        -1.9633e+00, -3.0295e+00,  1.7724e-01, -2.0472e+00,  1.6154e-02,\n",
      "         1.1464e-01, -2.1799e+00, -7.9684e-01, -2.4241e+00, -1.6332e+00,\n",
      "        -1.8725e+00, -6.9956e-02, -2.4402e+00, -2.8206e+00, -1.6883e-01,\n",
      "        -3.4613e-01, -2.6942e+00,  1.5264e+00, -6.0199e-01, -1.0985e+00,\n",
      "        -1.3912e+00,  1.7686e+00, -5.0618e-01, -1.1626e-01, -1.3373e+00,\n",
      "        -3.1149e+00, -1.1119e+00, -4.6983e+00, -2.0133e+00,  1.1096e+00,\n",
      "        -2.6278e+00, -1.6795e-01, -1.5010e+00, -2.1363e-01,  4.2500e-01,\n",
      "        -1.7708e+00, -1.0248e+00, -2.2721e+00,  1.4098e+00,  6.8683e-01,\n",
      "        -8.3504e-01, -4.9729e-02, -1.1281e+00, -2.2952e-01, -1.5788e+00,\n",
      "        -2.0091e+00, -5.3981e-01, -2.3285e+00,  1.9262e+00, -2.6372e+00,\n",
      "        -5.1795e-01, -1.6908e+00,  3.2114e-02, -3.8180e+00, -1.2707e+00,\n",
      "        -4.6820e+00,  1.0560e+00, -3.2142e+00, -2.7479e+00, -8.7245e-02,\n",
      "        -2.7317e+00,  1.1020e+00,  1.8724e+00, -1.4363e+00,  1.6585e+00,\n",
      "        -1.9128e+00, -3.2955e+00, -2.4053e+00, -3.3880e+00, -2.1289e+00,\n",
      "        -2.0277e+00,  2.0624e+00, -2.8162e+00,  1.3960e+00, -2.6015e+00,\n",
      "        -1.0167e+00, -8.0351e-01, -2.1561e+00, -4.2899e+00, -4.0634e+00,\n",
      "        -2.2444e-01, -1.3010e+00,  7.9894e-01, -5.3751e+00, -1.7638e+00,\n",
      "         1.4971e+00, -1.9037e+00, -3.0276e-01, -1.6418e-01, -2.4063e+00,\n",
      "         1.5644e-01, -1.1946e+00, -2.0353e+00, -3.8055e-01, -4.2187e+00,\n",
      "        -4.1150e+00, -1.9323e+00, -4.6264e-01, -2.2264e+00, -3.2651e+00,\n",
      "         2.4001e+00, -2.4134e+00,  1.5905e+00, -3.3998e+00, -1.8446e+00,\n",
      "        -1.3567e+00,  1.6189e+00, -2.0124e+00, -1.3865e+00, -4.9968e-01,\n",
      "         2.4639e+00, -1.3712e+00,  2.0081e+00, -2.8320e+00, -9.4340e-01,\n",
      "        -2.4306e+00, -2.9179e+00, -5.8548e-01, -8.3869e-01, -1.3401e+00,\n",
      "         6.8959e-01, -1.8001e+00, -3.9842e+00,  8.8998e-01,  1.1502e+00,\n",
      "        -1.7197e+00, -2.4275e+00, -5.0493e+00,  1.2101e+00, -4.7876e+00,\n",
      "        -2.0923e-01,  4.6144e-01, -3.5394e+00, -4.5619e-01, -4.5296e-01,\n",
      "        -1.9490e+00,  1.0574e+00, -2.2937e+00, -6.1161e-01,  5.7718e-02,\n",
      "         5.1722e-01, -2.3911e+00, -2.2302e+00, -2.1223e+00, -2.1326e-01,\n",
      "        -1.1192e+00, -1.2883e+00, -3.1269e+00, -1.8153e+00, -3.3174e+00,\n",
      "        -4.1434e-01,  9.5043e-01, -2.2591e+00, -2.1317e+00, -4.5547e+00,\n",
      "         2.1984e-02,  1.4471e+00, -1.8254e+00,  1.2208e+00,  2.4425e+00,\n",
      "        -4.2266e+00, -1.9840e+00,  2.1736e+00, -5.2115e-01, -1.6110e+00,\n",
      "        -1.6863e+00,  2.8384e+00, -3.4460e-01, -4.1050e+00, -2.0522e+00,\n",
      "         6.3969e-01,  2.4332e+00,  1.7337e+00, -3.8020e+00, -3.3586e+00,\n",
      "        -1.1478e-02, -3.3412e-01,  2.1330e+00, -1.3325e+00,  1.4261e+00,\n",
      "        -3.3380e+00, -6.1278e-02, -2.5546e+00, -1.3940e+00,  1.0415e+00,\n",
      "        -3.6297e+00,  1.8916e+00, -2.2233e-01, -8.6412e-01,  8.7897e-01,\n",
      "        -2.2445e+00, -4.8478e+00,  1.7537e+00,  8.6776e-02,  1.5505e+00,\n",
      "        -2.5912e+00, -2.9505e+00,  1.3103e+00,  1.5968e+00, -6.7479e-01,\n",
      "        -1.8850e+00, -1.4377e+00, -3.3701e+00, -5.7725e-01, -2.2755e-01,\n",
      "         1.7683e+00, -2.9064e+00, -1.3936e+00,  1.2491e-02, -2.4036e+00,\n",
      "        -2.2748e-01, -3.1257e-01, -2.5267e+00,  1.7216e+00,  7.7692e-01,\n",
      "        -1.2553e+00,  1.9006e+00, -1.5054e+00, -1.5318e+00,  1.9368e+00,\n",
      "        -2.0905e-01,  2.7160e-01, -4.0330e+00, -1.1810e+00, -4.4605e+00,\n",
      "        -1.2311e+00, -6.1493e+00, -1.5174e+00, -2.8405e+00, -1.9562e+00,\n",
      "        -2.5049e+00, -4.8875e-01, -2.0439e+00, -6.2988e+00, -3.0729e+00,\n",
      "        -1.2225e+00, -5.2690e+00, -1.9355e-01,  3.6661e-01, -1.5133e-01,\n",
      "        -3.7002e+00, -1.5883e+00, -1.9517e+00,  1.8867e+00, -1.4238e+00,\n",
      "        -2.8970e+00,  1.9315e-01, -2.4345e+00, -4.2609e+00, -1.9239e+00,\n",
      "        -3.0475e+00, -2.2730e-01, -1.9042e+00, -7.3176e-01,  6.4587e-01,\n",
      "        -1.7078e+00, -1.4702e+00, -1.5735e+00,  3.5789e-01, -1.6562e+00,\n",
      "        -2.5516e+00, -4.6188e-01,  3.0186e-01,  1.2250e+00, -1.2783e-01,\n",
      "        -4.2490e+00, -2.5375e-01, -9.8664e-01, -1.7823e+00, -3.3848e+00,\n",
      "        -2.3334e+00, -8.6206e-01,  8.0980e-02, -3.0447e+00, -4.0435e+00,\n",
      "        -3.6754e+00, -9.8918e-02,  1.2246e-01, -1.2673e+00, -4.5878e+00,\n",
      "        -1.6091e+00,  1.8399e+00, -1.5527e+00, -5.4311e+00, -1.7849e+00,\n",
      "        -2.9971e+00, -2.4110e-01,  1.5687e+00, -1.6680e-01,  6.9738e-01,\n",
      "        -2.1456e+00, -3.9757e-01, -4.3987e-01, -5.8353e+00, -4.3703e+00,\n",
      "        -1.3741e+00, -1.6269e+00, -1.9172e+00, -7.2169e-02, -2.9874e-01,\n",
      "        -2.7310e+00, -8.9045e-02, -3.4996e+00, -1.5844e+00, -3.1110e+00,\n",
      "        -1.9390e+00, -2.5192e+00, -2.2710e+00,  1.8709e+00,  2.1584e+00,\n",
      "        -6.8986e-01, -1.2351e+00, -4.6789e-02, -1.7785e+00, -5.1528e-01,\n",
      "         1.6106e+00,  1.4010e-01,  1.1884e+00, -2.7483e+00,  1.8109e+00,\n",
      "        -1.3742e+00, -3.8367e+00, -5.8111e+00, -2.6140e+00, -3.2814e+00,\n",
      "        -2.3729e+00, -1.3296e+00, -3.1530e+00, -7.3798e-01, -4.5765e+00,\n",
      "         9.5137e-01, -2.5300e+00, -6.8127e-01, -2.3737e+00, -1.4461e+00,\n",
      "        -1.9114e+00, -2.5938e+00, -7.0925e-01, -2.7243e+00, -1.4514e+00,\n",
      "         3.0790e-01,  5.3322e-01, -1.0850e+00, -1.1561e+00, -1.5344e+00,\n",
      "        -7.5170e-01, -2.7486e+00, -1.9941e+00, -1.1650e+00, -1.5390e+00,\n",
      "         4.0276e-01, -2.5706e-01, -2.2537e+00, -3.1953e+00, -1.7327e+00,\n",
      "        -2.1243e+00,  1.2180e+00, -9.9923e-01, -9.6128e-01, -2.6623e+00,\n",
      "         1.0462e+00, -1.5039e+00, -8.3736e-01,  4.6794e-01,  1.4780e+00,\n",
      "         9.6832e-01, -2.1045e+00,  3.9359e-01, -5.5404e-01, -9.3849e-02,\n",
      "         1.8286e+00, -5.8126e-01,  9.7283e-01, -3.9743e+00, -2.9599e+00,\n",
      "        -2.1019e+00, -3.5179e-01, -1.3130e-02, -1.2596e+00,  2.0095e+00,\n",
      "        -8.0963e-01, -6.2289e+00, -3.7402e+00,  2.5941e+00, -1.9296e+00,\n",
      "        -2.6883e-01,  2.0273e-01, -3.1303e+00, -1.3099e+00, -2.6979e+00,\n",
      "        -2.9964e-01, -6.1638e-01, -1.7710e+00, -1.5914e+00, -1.4152e+00,\n",
      "        -2.5421e+00,  2.5728e+00,  2.0419e+00, -2.6591e+00, -1.8154e+00,\n",
      "         5.2418e-02,  8.7286e-01,  2.0004e+00, -2.2495e+00, -1.4137e+00,\n",
      "        -2.6638e+00, -1.9964e+00,  1.0102e-01,  1.9868e+00, -1.6630e-01,\n",
      "        -3.6898e+00,  1.2668e-02, -2.6510e+00, -3.5892e+00, -1.5336e+00,\n",
      "        -4.3131e+00, -4.3443e+00, -5.6595e-02, -1.5950e+00, -2.4667e+00,\n",
      "        -4.1053e-01, -2.2415e-01,  2.4039e+00, -2.0289e+00, -9.6288e-02,\n",
      "        -9.7849e-01, -1.4475e+00, -3.5171e+00, -1.3075e+00,  2.4330e-01,\n",
      "        -2.5451e+00, -3.2314e+00,  5.6235e-02, -5.1974e+00,  8.6595e-01,\n",
      "        -1.6385e+00, -1.8292e+00, -3.6186e-01, -7.3963e-01,  1.4923e+00,\n",
      "        -2.7592e+00, -2.9770e+00, -3.9994e+00, -1.4960e+00, -2.2515e+00,\n",
      "        -3.0795e-01, -4.0720e+00, -4.4978e+00, -2.0692e+00, -7.1995e+00,\n",
      "        -3.4361e+00,  2.5221e-01, -3.2592e+00, -2.8405e+00, -3.6662e-01,\n",
      "         1.3105e+00, -9.0819e-01, -2.2537e-01,  1.6567e+00,  7.5214e-01,\n",
      "        -1.9579e+00, -3.1107e+00,  2.0275e+00, -1.8882e+00,  7.8145e-01,\n",
      "         7.0531e-01, -1.6948e+00, -4.5721e+00,  3.7775e-01, -1.3596e-01,\n",
      "        -4.6118e-01, -6.0256e-01, -2.4868e+00, -1.2782e+00, -2.1485e+00,\n",
      "        -2.2230e+00, -2.8143e-02, -1.9953e+00,  2.2171e+00, -3.2979e+00,\n",
      "        -2.7319e+00, -1.6947e+00, -2.5510e+00, -1.8722e-01, -4.0492e+00,\n",
      "        -2.5362e+00, -8.0323e-01, -2.3639e+00,  2.2804e+00, -2.8216e+00,\n",
      "         7.5536e-01, -1.0249e+00, -2.1650e-01, -2.3850e+00, -1.7635e-01,\n",
      "        -3.2332e-01, -2.4883e+00, -1.1257e-01,  1.9593e+00, -3.6454e-01,\n",
      "         1.9881e+00,  4.0985e-01, -4.0349e+00, -7.4169e-01, -8.1657e-01,\n",
      "        -1.4910e+00, -1.0169e+00, -3.2549e+00, -6.8290e-01, -2.8005e+00,\n",
      "         1.8307e+00,  9.1882e-01, -2.4115e-01, -2.1039e+00, -2.8761e+00,\n",
      "        -1.5324e+00, -2.7944e+00, -2.0304e+00, -9.6621e-01, -1.3405e+00,\n",
      "        -1.5183e+00, -1.5637e+00, -2.6221e+00, -4.3452e-01, -1.9233e+00,\n",
      "        -2.0242e+00,  1.6837e+00, -1.7899e+00, -1.6092e-01,  2.8752e-01,\n",
      "        -3.1261e+00, -9.1396e-01, -2.9283e+00, -2.0261e+00, -5.5059e-01,\n",
      "        -3.2729e-01, -4.6139e+00, -1.5473e-01,  1.2834e+00, -3.3284e+00,\n",
      "        -1.1812e+00, -2.4776e+00, -1.3115e+00, -2.6637e+00, -4.0220e-01,\n",
      "        -1.2609e-01, -1.0132e+00, -3.0200e+00, -3.0455e+00, -3.0936e+00,\n",
      "        -3.7078e+00, -5.0898e+00, -9.1558e-01,  2.4575e-01, -1.7840e+00,\n",
      "         1.2460e+00, -1.5493e+00, -1.7820e+00, -6.8439e-01, -2.1784e+00,\n",
      "        -1.8686e+00, -3.1829e+00, -1.8464e+00, -3.7589e+00, -3.8107e-01,\n",
      "        -3.7832e+00,  3.8758e-01, -4.2345e-01, -3.5251e+00, -1.6037e+00,\n",
      "         2.1818e+00, -2.5239e-01,  2.1435e-01, -4.0219e+00, -1.3649e+00,\n",
      "        -1.8671e-01,  3.0188e-01,  9.0437e-01, -4.2679e+00, -1.6965e+00,\n",
      "        -4.8994e-01, -2.7190e+00, -2.1597e+00,  2.3390e+00,  1.4637e+00,\n",
      "        -2.9095e+00, -1.4549e-01, -1.1980e+00, -8.8818e-01, -2.8027e+00,\n",
      "        -2.8604e+00, -1.0443e+00, -3.0260e+00,  7.6987e-01,  1.0133e+00,\n",
      "        -1.8400e-01,  1.0810e+00, -7.7502e-01, -9.1917e-03, -1.7208e+00,\n",
      "        -5.0423e+00, -3.0600e+00, -5.0195e-02, -1.9618e+00, -2.3027e-01,\n",
      "        -1.7172e+00, -2.0892e+00, -1.3836e+00, -7.1391e-01, -1.0881e+00,\n",
      "        -5.8334e-01, -3.4307e+00, -2.0674e+00, -2.9062e-01, -2.1189e+00,\n",
      "        -4.9156e+00, -2.2899e+00, -3.5371e+00, -1.6685e+00, -2.5540e-01,\n",
      "        -4.5441e+00, -4.8813e-01, -1.4878e+00, -4.1993e-01, -1.4195e+00,\n",
      "        -1.0480e+00,  1.3449e-01,  1.2796e+00,  8.7203e-01, -2.8009e+00,\n",
      "        -2.4869e-01, -4.0239e-01, -4.9540e+00, -3.1026e-01, -3.5073e+00,\n",
      "         1.5932e+00, -1.9161e+00, -8.2103e-01,  3.7245e-01, -2.0542e+00,\n",
      "        -1.6974e+00,  1.7404e+00, -1.5604e+00, -1.0545e+00,  3.5865e+00,\n",
      "        -2.0625e+00,  2.1344e+00, -1.2033e+00, -1.1355e+00, -1.6099e+00,\n",
      "        -5.2452e-02,  7.7946e-02, -4.6157e-01, -1.9732e+00, -1.0121e+00,\n",
      "         1.9639e+00, -1.7733e-01, -2.1550e+00,  2.1971e+00, -1.0257e+00,\n",
      "         1.4960e+00, -1.8952e+00, -3.4800e+00, -4.1625e+00, -5.5395e-01,\n",
      "        -2.0270e+00,  6.2796e-01,  7.3199e-01, -5.4110e-01, -2.3546e+00,\n",
      "        -9.2520e-01, -2.4695e-01, -2.9224e+00, -3.3000e+00, -1.9823e+00,\n",
      "         3.3644e-03,  2.1766e+00, -2.9171e-01, -1.5000e+00, -2.6382e+00,\n",
      "        -2.2851e+00, -4.2868e+00, -1.1155e+00, -3.8985e+00, -3.4746e+00,\n",
      "        -5.0929e+00, -1.3843e+00, -3.7960e+00, -9.6932e-02, -7.0763e-01,\n",
      "        -7.5928e-01, -2.9867e+00, -4.2954e-01, -1.6988e+00, -9.2872e-02,\n",
      "         2.3274e-01, -2.4043e+00, -2.9412e+00, -2.3394e+00, -7.1529e-01,\n",
      "        -2.3914e-01, -2.5468e+00,  1.4409e+00, -1.7596e+00, -1.2699e-01,\n",
      "        -5.9428e+00,  8.8083e-01, -1.3369e-01, -8.2796e-02,  2.1314e+00,\n",
      "        -2.6756e+00, -4.0886e-01, -1.7476e+00, -2.3211e+00, -3.4215e+00,\n",
      "        -6.4154e-02, -4.8691e+00,  1.9467e-01,  1.8761e+00, -9.6136e-01,\n",
      "        -2.9261e+00, -1.4721e+00, -1.0755e+00, -1.3994e+00, -7.1301e-01,\n",
      "        -2.6129e-01, -7.8235e-01, -5.7038e+00,  8.5063e-01, -1.7618e+00,\n",
      "        -3.3237e+00,  1.8787e+00,  1.7379e+00, -1.6399e+00, -2.5693e+00,\n",
      "        -1.7747e-01, -4.6490e+00, -1.1812e+00, -7.3622e-01, -8.2602e-02,\n",
      "        -2.8962e+00, -6.4097e-01, -3.1680e-02, -2.4919e+00, -2.4327e+00,\n",
      "        -4.6724e+00, -2.0194e+00,  1.2551e+00, -6.0087e-01, -9.0048e-01,\n",
      "        -4.7269e+00, -4.6031e+00, -5.1371e+00,  1.7576e+00,  7.8656e-01,\n",
      "         2.0536e+00, -5.7109e+00, -2.2907e+00, -1.2456e-02, -1.0971e+00,\n",
      "        -2.1339e+00, -5.7602e-01, -2.2391e+00, -1.7711e+00,  1.0031e+00,\n",
      "        -9.2485e-01, -1.0957e+00, -1.0744e+00, -4.4569e+00, -1.6846e+00,\n",
      "        -5.2583e+00, -4.5659e+00, -1.4619e+00,  1.9639e-01, -1.9995e+00,\n",
      "        -4.6899e+00, -1.9869e+00, -1.1633e-01, -1.5346e+00, -4.7248e+00,\n",
      "        -4.1817e+00, -1.8754e-01, -6.9516e-01, -5.4616e+00,  1.1348e-01,\n",
      "        -1.2714e+00, -7.5417e-02, -1.9271e+00, -3.7681e+00, -1.0875e+00,\n",
      "        -2.0061e-01, -1.0068e+00, -2.1972e+00, -2.6606e-01, -1.0301e+00,\n",
      "         2.5468e+00, -4.7862e+00, -3.1970e-01, -3.4350e+00, -1.8785e+00,\n",
      "        -1.0784e+00, -1.9807e+00, -2.6435e-01, -8.6835e-01, -8.7121e-01,\n",
      "        -2.3590e+00, -1.2470e+00,  2.4771e+00, -3.5332e+00,  3.5575e-01,\n",
      "        -1.7765e+00, -6.4997e-01, -1.3976e+00,  5.5224e-02, -1.4167e+00,\n",
      "         1.4937e-01, -4.3030e+00, -2.7283e-01, -9.2415e-01, -1.6615e+00,\n",
      "        -1.2728e+00, -3.4141e+00, -1.8797e+00, -3.2489e+00, -2.7534e+00,\n",
      "         1.3081e+00, -1.5087e+00, -1.9515e+00,  1.6488e-01, -1.9323e+00,\n",
      "         7.9171e-02, -5.9317e-01,  7.2782e-01, -6.2029e-01, -2.6939e+00,\n",
      "         1.8374e+00,  6.4665e-01, -4.7876e-01, -6.9897e-01,  2.5425e-01,\n",
      "        -2.0496e+00, -5.8776e-01,  2.1667e+00, -3.6762e+00,  1.8418e+00,\n",
      "         1.8622e+00, -3.4868e+00, -2.3848e+00, -4.7977e+00, -8.5913e-01,\n",
      "        -1.3494e+00, -1.6916e+00, -4.0410e+00, -1.0355e+00, -6.9671e-01,\n",
      "         1.8475e-01, -1.9959e+00,  1.6280e+00, -2.9831e+00, -8.6323e-01,\n",
      "        -3.8186e+00, -1.3188e-01, -3.1735e-01, -1.4230e+00, -3.1759e+00,\n",
      "        -2.2403e+00, -3.4860e+00, -1.0299e+00,  2.6548e+00,  2.9324e+00,\n",
      "        -5.5744e+00, -4.4503e-01, -2.3033e+00, -1.9505e+00, -2.2138e+00,\n",
      "        -1.2720e+00, -2.9025e+00,  2.1372e-01,  1.1379e+00,  2.9380e-02,\n",
      "        -2.0611e+00,  3.6888e-01, -4.1077e+00, -2.2654e+00, -1.6613e+00,\n",
      "        -1.2600e-01, -2.7723e+00, -3.7648e+00, -2.6687e+00,  7.5806e-01,\n",
      "        -3.7688e+00, -9.9462e-02,  1.8723e+00,  6.6609e-01, -8.9563e-01,\n",
      "         8.2681e-03,  1.3516e+00, -3.9613e+00,  7.8282e-03,  2.8332e-02,\n",
      "         3.1610e-01,  2.0236e+00,  2.1679e+00, -1.9395e+00, -1.9777e+00,\n",
      "         1.7846e+00, -1.6620e+00, -4.0551e-02, -1.1508e+00, -1.9732e+00,\n",
      "        -2.0870e+00,  3.5060e-01, -8.7135e-01, -9.3870e-01, -2.2069e+00,\n",
      "        -6.6295e-01,  2.2249e+00, -2.1073e-01, -6.4969e-01, -2.0456e-01,\n",
      "        -3.8444e+00, -2.6696e+00, -3.9768e-01,  1.6206e-01, -1.7660e+00],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0064]],\n",
      "\n",
      "         [[-0.0493]],\n",
      "\n",
      "         [[ 0.0077]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0260]],\n",
      "\n",
      "         [[-0.0230]],\n",
      "\n",
      "         [[-0.0521]]],\n",
      "\n",
      "\n",
      "        [[[-0.0745]],\n",
      "\n",
      "         [[-0.0461]],\n",
      "\n",
      "         [[-0.0035]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0059]],\n",
      "\n",
      "         [[ 0.0696]],\n",
      "\n",
      "         [[ 0.0314]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1389]],\n",
      "\n",
      "         [[-0.0691]],\n",
      "\n",
      "         [[ 0.0247]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0117]],\n",
      "\n",
      "         [[-0.0764]],\n",
      "\n",
      "         [[ 0.0890]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0987]],\n",
      "\n",
      "         [[ 0.0955]],\n",
      "\n",
      "         [[-0.0370]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         [[ 0.0201]],\n",
      "\n",
      "         [[ 0.0142]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0784]],\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0563]],\n",
      "\n",
      "         [[ 0.0494]],\n",
      "\n",
      "         [[ 0.0142]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0700]],\n",
      "\n",
      "         [[ 0.0574]],\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.0029]],\n",
      "\n",
      "         [[ 0.0037]]]], device='cuda:0')\n",
      "Shape: torch.Size([160, 960, 1, 1])\n",
      "\n",
      "Layer: features.16.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.6222838163375854\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.6174222230911255\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.3.weight\n",
      "Weights: tensor([4.1770, 1.3750, 2.9380, 1.5528, 2.3422, 1.7846, 1.8868, 1.4199, 1.9198,\n",
      "        1.6157, 2.6138, 2.2402, 2.0136, 3.5225, 3.2321, 3.0290, 1.6298, 2.6078,\n",
      "        1.6848, 2.3608, 1.4972, 1.7952, 1.7831, 2.7959, 1.4643, 3.3063, 1.5421,\n",
      "        1.5153, 1.5015, 2.0795, 1.4534, 2.3065, 1.8142, 1.8469, 3.3954, 1.6430,\n",
      "        2.3940, 1.3272, 2.2110, 1.6348, 2.7791, 2.0876, 1.8231, 1.5492, 2.5588,\n",
      "        4.1108, 3.0423, 1.8198, 1.5013, 3.3192, 2.8878, 3.6083, 3.9295, 1.7852,\n",
      "        2.5881, 2.2011, 2.1993, 1.2850, 2.9850, 3.1305, 2.3196, 1.5268, 2.8813,\n",
      "        1.6123, 2.1757, 3.0542, 3.1965, 2.0745, 1.5377, 4.0051, 3.5852, 1.4613,\n",
      "        2.2791, 2.0417, 3.3025, 2.2245, 1.5178, 1.6814, 3.1092, 1.3473, 1.5207,\n",
      "        2.0840, 1.4428, 2.0320, 3.1664, 1.8095, 4.9656, 2.4513, 2.2318, 2.4022,\n",
      "        2.0303, 2.3750, 2.7550, 1.5621, 1.5475, 1.4438, 1.2102, 1.5648, 2.2060,\n",
      "        2.6533, 3.0861, 1.8621, 3.2651, 2.7386, 2.8063, 1.9648, 2.7481, 1.9286,\n",
      "        1.9701, 1.7816, 3.2024, 4.1407, 3.2408, 1.5027, 1.9282, 1.4803, 2.8148,\n",
      "        1.5371, 1.4678, 1.3998, 2.7603, 3.8203, 1.8060, 1.9424, 4.1827, 2.9053,\n",
      "        1.5544, 2.3633, 2.5889, 1.6807, 1.9203, 2.2434, 1.4019, 1.2921, 1.5244,\n",
      "        2.7562, 1.3857, 1.5662, 1.8294, 1.4453, 2.4020, 2.1976, 1.5405, 1.8371,\n",
      "        3.8185, 1.6317, 3.0662, 1.4370, 3.2931, 3.0340, 3.4469, 2.9724, 3.3298,\n",
      "        1.9206, 2.5640, 3.2050, 3.0547, 1.9853, 2.0626, 2.0527],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.16.conv.3.bias\n",
      "Weights: tensor([ 3.4682e-04, -1.3780e-04,  3.3335e-04, -9.0408e-05,  9.4047e-05,\n",
      "        -5.4908e-04, -8.3256e-05,  3.6286e-04, -6.0185e-05, -7.1941e-04,\n",
      "        -8.6678e-05,  9.0329e-07, -3.7167e-05, -3.4093e-05,  4.8243e-04,\n",
      "        -3.6128e-04, -2.8973e-04,  4.1555e-04,  3.6208e-04,  1.3821e-05,\n",
      "        -3.8372e-05,  1.1180e-04, -1.1206e-04,  3.6017e-05, -1.7007e-04,\n",
      "        -7.5231e-04,  9.2172e-05,  2.0837e-04,  1.2037e-04, -1.0829e-04,\n",
      "         1.1458e-04, -5.1764e-04,  2.3367e-04,  6.4387e-05,  6.0126e-04,\n",
      "        -2.3102e-04,  2.0957e-04,  9.0441e-06, -3.4376e-04,  1.7996e-04,\n",
      "         3.1081e-04,  2.5533e-04,  3.6211e-05, -1.8024e-04,  7.8160e-04,\n",
      "         5.0005e-04,  8.2161e-05,  1.4182e-04, -4.6208e-05, -7.3464e-04,\n",
      "         1.5571e-04,  3.5057e-04, -4.1648e-04,  1.4829e-04,  4.7434e-04,\n",
      "        -1.5853e-04, -1.1153e-04, -2.4632e-04, -1.9664e-04,  4.2530e-04,\n",
      "        -2.4826e-04,  4.0465e-05, -1.2616e-04,  8.3958e-05,  3.6575e-05,\n",
      "         2.1308e-04, -3.2301e-04,  4.5229e-05, -1.3433e-04,  2.2394e-04,\n",
      "        -7.5279e-04, -4.4561e-06,  1.7849e-04, -1.5264e-04,  4.2220e-04,\n",
      "        -3.9005e-05,  4.2530e-04, -3.3016e-05, -2.9358e-04, -3.8267e-04,\n",
      "        -3.2631e-05,  1.2089e-04,  1.7529e-04,  6.3597e-05, -2.4780e-04,\n",
      "         8.7492e-05,  2.1045e-04,  1.6282e-04,  1.5502e-04, -1.8277e-04,\n",
      "         6.1941e-05,  3.8306e-05, -2.1893e-04,  4.2383e-04, -2.6847e-04,\n",
      "        -1.3573e-04,  5.7846e-04, -3.0186e-04, -9.7492e-05, -2.7174e-04,\n",
      "         2.5094e-04,  1.6142e-04, -9.5506e-05,  2.7317e-04,  2.5436e-04,\n",
      "        -1.8036e-04, -3.8656e-04,  2.4924e-04,  1.0208e-04,  1.5260e-04,\n",
      "         1.0478e-05,  9.6706e-04, -4.3459e-04, -1.3878e-04, -4.5736e-04,\n",
      "         1.9234e-04,  2.9861e-04,  1.0444e-04,  2.0183e-05,  2.3997e-04,\n",
      "         6.5722e-04,  1.2744e-04,  1.0233e-04, -1.2095e-04,  3.3711e-05,\n",
      "         3.5875e-04,  2.9552e-04, -6.3218e-05,  1.2921e-04, -1.8580e-04,\n",
      "        -3.1216e-04,  1.8303e-04,  1.8062e-04, -3.5565e-04, -1.6842e-04,\n",
      "         1.8831e-04,  5.1554e-06, -1.4670e-04, -1.8701e-04, -4.3747e-04,\n",
      "        -1.2587e-04, -1.1783e-04,  7.7015e-05, -1.4475e-04,  1.2159e-04,\n",
      "         3.0137e-04,  3.4761e-04,  2.2704e-04,  2.7623e-04, -1.6617e-04,\n",
      "         5.8136e-04,  2.0506e-04, -5.8385e-04,  6.6452e-05,  2.0238e-04,\n",
      "         1.6672e-04, -7.5126e-05, -1.7468e-04,  1.9897e-04,  8.1976e-05],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.16.conv.3.output_quantizers.0.min\n",
      "Weights: -25.117691040039062\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.16.conv.3.output_quantizers.0.max\n",
      "Weights: 26.195232391357422\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0097]],\n",
      "\n",
      "         [[ 0.0017]],\n",
      "\n",
      "         [[ 0.0357]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0469]],\n",
      "\n",
      "         [[ 0.0379]],\n",
      "\n",
      "         [[ 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0841]],\n",
      "\n",
      "         [[ 0.0753]],\n",
      "\n",
      "         [[ 0.0660]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0043]],\n",
      "\n",
      "         [[-0.0098]],\n",
      "\n",
      "         [[ 0.1263]]],\n",
      "\n",
      "\n",
      "        [[[-0.1442]],\n",
      "\n",
      "         [[ 0.0275]],\n",
      "\n",
      "         [[ 0.2205]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0251]],\n",
      "\n",
      "         [[-0.0580]],\n",
      "\n",
      "         [[ 0.0095]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1005]],\n",
      "\n",
      "         [[-0.0738]],\n",
      "\n",
      "         [[-0.0479]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0372]],\n",
      "\n",
      "         [[-0.0390]],\n",
      "\n",
      "         [[ 0.0284]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0623]],\n",
      "\n",
      "         [[-0.0989]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0367]],\n",
      "\n",
      "         [[ 0.0369]],\n",
      "\n",
      "         [[ 0.0450]]],\n",
      "\n",
      "\n",
      "        [[[-0.1218]],\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[ 0.0950]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0281]],\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         [[ 0.0095]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 160, 1, 1])\n",
      "\n",
      "Layer: features.17.conv.0.0.param_quantizers.weight.min\n",
      "Weights: -0.669044554233551\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.0.0.param_quantizers.weight.max\n",
      "Weights: 0.6638176441192627\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.0.0.input_quantizers.0.min\n",
      "Weights: -33.10298156738281\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.0.0.input_quantizers.0.max\n",
      "Weights: 30.859195709228516\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.0.1.weight\n",
      "Weights: tensor([1.2225, 1.0308, 0.9264, 1.2183, 1.1288, 1.1772, 1.2754, 1.0019, 1.1402,\n",
      "        1.2538, 1.1721, 1.2315, 1.3119, 1.3612, 1.3461, 1.1681, 1.0746, 1.3760,\n",
      "        1.5788, 0.9717, 1.2051, 1.4534, 1.0223, 1.1907, 1.2769, 1.6123, 1.0325,\n",
      "        0.8411, 1.6020, 0.4704, 1.2456, 1.3465, 1.1700, 1.2164, 1.2480, 0.7038,\n",
      "        1.1126, 1.1079, 0.9620, 1.1644, 0.9885, 1.0587, 1.1087, 1.1730, 1.1308,\n",
      "        1.2235, 1.1617, 1.0470, 1.3858, 1.1432, 1.2303, 1.5644, 0.8808, 0.7925,\n",
      "        1.3227, 1.7434, 1.2768, 1.2934, 1.0963, 1.1726, 1.1827, 1.1962, 0.9948,\n",
      "        1.1677, 0.9663, 1.1600, 1.2084, 1.2096, 1.0665, 1.0423, 0.9773, 1.1338,\n",
      "        0.5499, 0.5936, 1.1984, 1.1376, 1.0695, 1.0126, 1.2668, 1.3358, 1.1613,\n",
      "        1.2527, 1.2441, 1.0968, 1.0768, 1.1078, 1.2903, 1.1385, 1.1231, 1.1598,\n",
      "        1.1264, 0.9364, 1.1705, 1.2148, 0.9064, 1.0348, 0.9386, 0.9003, 1.0962,\n",
      "        1.3823, 1.3129, 1.3765, 1.1837, 1.1541, 1.1299, 1.1277, 0.8636, 1.4357,\n",
      "        1.2011, 1.2024, 0.8383, 1.2080, 1.1586, 0.9157, 1.0748, 0.9604, 1.1141,\n",
      "        1.1610, 1.1644, 0.9128, 1.1326, 1.2246, 1.3878, 1.3592, 0.9720, 1.0871,\n",
      "        1.0175, 1.1356, 1.0409, 1.1823, 1.1102, 1.1861, 1.0154, 1.3404, 1.0867,\n",
      "        1.3580, 0.9485, 0.5140, 1.3147, 1.4521, 1.0217, 1.1849, 1.1985, 1.1500,\n",
      "        0.5546, 1.1625, 1.0905, 1.3018, 1.1732, 1.3466, 0.9884, 1.3546, 1.2814,\n",
      "        1.0529, 1.1549, 1.2405, 1.1402, 0.9112, 0.9359, 0.6557, 1.5013, 1.1514,\n",
      "        0.5552, 1.1598, 1.1488, 1.0706, 0.7302, 0.7948, 1.4020, 1.5745, 1.1275,\n",
      "        1.3207, 1.0580, 1.0263, 1.0859, 1.3422, 1.1487, 1.2190, 1.1184, 1.6872,\n",
      "        0.5712, 1.7730, 1.1064, 1.1948, 1.8826, 1.2235, 1.0453, 0.6272, 0.9767,\n",
      "        1.4110, 0.8307, 1.0800, 1.1248, 0.9451, 1.1946, 1.8198, 1.0654, 1.2046,\n",
      "        1.2657, 1.2448, 1.0200, 0.8099, 1.3087, 1.1408, 1.1846, 1.1626, 1.0713,\n",
      "        1.0800, 1.0733, 1.1262, 1.1675, 1.0961, 1.1846, 1.0666, 1.2284, 1.2005,\n",
      "        1.2552, 1.1687, 1.3621, 1.7310, 1.1173, 1.1673, 1.0598, 1.2037, 1.1255,\n",
      "        1.3946, 1.3622, 1.7157, 1.1287, 1.0711, 0.6784, 1.0143, 2.0187, 1.1411,\n",
      "        1.2254, 1.2482, 0.9549, 0.9109, 1.3905, 1.1350, 1.1471, 1.6176, 1.1585,\n",
      "        1.3409, 1.0638, 1.1838, 0.9778, 1.0903, 1.2861, 0.7641, 1.2614, 1.0113,\n",
      "        1.0897, 1.2865, 0.9788, 1.1709, 1.1883, 1.2307, 1.3865, 1.1860, 1.1174,\n",
      "        1.1589, 1.0610, 1.5008, 0.9458, 1.1177, 1.0240, 0.9899, 1.3104, 1.0868,\n",
      "        1.3464, 1.0361, 0.9881, 1.1724, 0.9367, 1.2177, 0.9759, 1.1749, 1.1238,\n",
      "        0.9589, 1.3527, 1.0872, 2.0360, 1.2813, 1.2465, 1.0520, 1.1625, 2.8268,\n",
      "        1.2432, 1.8906, 1.5047, 1.0994, 1.4443, 1.1536, 1.1033, 1.2017, 1.2142,\n",
      "        1.3240, 1.0647, 1.2188, 1.2772, 1.1847, 0.8213, 1.1460, 1.3964, 0.9340,\n",
      "        0.5276, 0.9708, 1.2849, 1.0680, 1.2345, 1.1808, 1.1089, 1.1488, 0.8978,\n",
      "        1.2127, 1.0758, 1.1520, 1.0425, 1.4640, 0.9423, 1.0537, 0.6353, 1.2585,\n",
      "        1.3274, 1.0286, 1.2060, 1.1978, 1.1092, 1.0811, 1.1547, 0.9571, 1.3146,\n",
      "        1.0964, 1.8795, 1.0317, 1.0832, 1.4907, 1.3531, 1.0864, 0.9534, 0.9980,\n",
      "        1.1298, 1.0095, 1.2843, 1.1119, 1.0594, 1.2132, 1.0209, 0.9333, 1.0846,\n",
      "        1.3372, 1.2471, 1.2533, 1.2233, 1.1562, 1.2264, 0.7328, 1.1826, 1.4111,\n",
      "        0.9939, 0.9617, 1.0170, 1.1696, 1.2723, 0.9770, 1.2317, 1.1727, 1.2277,\n",
      "        0.8660, 1.2409, 1.2129, 1.3354, 1.3858, 1.1016, 1.1326, 1.1277, 0.5803,\n",
      "        1.3036, 1.1465, 1.1723, 1.2570, 0.9508, 0.8946, 1.2648, 0.9136, 1.0555,\n",
      "        0.9555, 1.1369, 0.7709, 1.2026, 1.2792, 1.2681, 1.1438, 0.9708, 1.0980,\n",
      "        0.4545, 1.1014, 1.0798, 0.9373, 1.3654, 1.0679, 1.3861, 1.0941, 1.2709,\n",
      "        1.0982, 1.0350, 1.1273, 1.8630, 1.4348, 1.2076, 1.0758, 0.4643, 0.4953,\n",
      "        1.1676, 1.1566, 1.2385, 1.1513, 1.0245, 0.9667, 1.3995, 1.0889, 1.1362,\n",
      "        1.4941, 1.1752, 1.3042, 1.1631, 0.9172, 1.1629, 0.9260, 1.3399, 1.1960,\n",
      "        1.3699, 1.0571, 1.2593, 1.0362, 1.1376, 1.0146, 1.1802, 1.2204, 1.1505,\n",
      "        1.2011, 1.0936, 1.0238, 1.2246, 1.3918, 1.2698, 1.9807, 1.1129, 1.1177,\n",
      "        1.1840, 1.2296, 1.2546, 1.3722, 1.1678, 0.8779, 1.2332, 1.2058, 0.7448,\n",
      "        1.1397, 1.1409, 1.1548, 1.1489, 0.8901, 1.1432, 1.5045, 1.2920, 1.1001,\n",
      "        0.9052, 1.3669, 1.1377, 1.4649, 1.2202, 1.1440, 1.1837, 1.1418, 1.1609,\n",
      "        1.4126, 1.2216, 0.9819, 1.1470, 0.8581, 0.5538, 1.3193, 1.2188, 1.1495,\n",
      "        1.3195, 1.2280, 1.2452, 1.0636, 1.0553, 1.3007, 1.7840, 1.2864, 1.1827,\n",
      "        1.3842, 0.6307, 1.3317, 1.2239, 1.1903, 1.2077, 1.2265, 1.1239, 1.2933,\n",
      "        0.9395, 1.2508, 1.1395, 1.1873, 1.1611, 1.0524, 1.1936, 1.1885, 1.8910,\n",
      "        0.9767, 1.2122, 1.2396, 1.1435, 1.2017, 1.3440, 1.1846, 1.3600, 0.9363,\n",
      "        0.8648, 1.0764, 1.0257, 1.0267, 0.7067, 1.1186, 1.4242, 1.0688, 1.1080,\n",
      "        1.2976, 1.1428, 0.9020, 1.0951, 1.2108, 1.1411, 1.0910, 0.8840, 1.1719,\n",
      "        1.2029, 1.0173, 1.0475, 1.2173, 1.2158, 0.9356, 1.2224, 1.3330, 1.8696,\n",
      "        1.0809, 0.8976, 1.6917, 1.0522, 1.0347, 1.0706, 0.9558, 1.1135, 1.2481,\n",
      "        0.9909, 1.1766, 1.2075, 1.1212, 1.4541, 1.2597, 1.1464, 1.0761, 1.2163,\n",
      "        1.1270, 1.1082, 1.2148, 0.9159, 1.0549, 1.0996, 0.6197, 1.2933, 1.3598,\n",
      "        1.0422, 1.1091, 0.4146, 1.3706, 1.1353, 1.0978, 1.5187, 1.2267, 1.4250,\n",
      "        1.0993, 1.2296, 1.1036, 1.1756, 1.0527, 1.0834, 1.1090, 1.1401, 0.7188,\n",
      "        0.9871, 1.2077, 1.1201, 1.0277, 1.2370, 1.0586, 1.1977, 0.9785, 1.1431,\n",
      "        1.7492, 1.3793, 1.1830, 1.0214, 1.2485, 1.0434, 0.9489, 1.0544, 1.1221,\n",
      "        1.2007, 1.1860, 1.1593, 1.1902, 1.1810, 1.1586, 1.2652, 1.1456, 1.1274,\n",
      "        0.9244, 0.9339, 2.0692, 1.0483, 1.1797, 1.1416, 1.2096, 1.0752, 1.1271,\n",
      "        1.2234, 1.2377, 0.9164, 1.1951, 1.1751, 1.1958, 1.1493, 1.2276, 1.1723,\n",
      "        1.3300, 0.9984, 1.8169, 1.1777, 1.2130, 0.9590, 1.0892, 0.5232, 1.2352,\n",
      "        1.1126, 1.2071, 0.9615, 1.0853, 1.1508, 1.1771, 1.3512, 1.0970, 1.0871,\n",
      "        1.0055, 1.2626, 1.1988, 1.1398, 1.1469, 1.2180, 1.4314, 1.1223, 1.1508,\n",
      "        1.0092, 1.2610, 1.0797, 1.2802, 1.0923, 0.9439, 1.0446, 1.3606, 1.1729,\n",
      "        1.0694, 1.1094, 1.1338, 1.1212, 1.4470, 1.2144, 1.0031, 1.3295, 1.2607,\n",
      "        1.2633, 1.1995, 1.0389, 0.9906, 1.2685, 1.2888, 1.1185, 1.2429, 1.7430,\n",
      "        1.0430, 1.0683, 1.8128, 1.0496, 1.2121, 0.5165, 1.0037, 0.9353, 0.8897,\n",
      "        1.3603, 1.1417, 1.2663, 0.7870, 1.1563, 1.2385, 1.2406, 1.2144, 1.8873,\n",
      "        1.0439, 0.9592, 1.0955, 1.1663, 1.4387, 1.1019, 1.0606, 1.0890, 1.5171,\n",
      "        1.5925, 1.4028, 0.9870, 1.6567, 1.0873, 1.1672, 1.1546, 1.0617, 1.0491,\n",
      "        0.9302, 1.1558, 0.5141, 0.9845, 1.3673, 1.1588, 1.3015, 1.2974, 1.2276,\n",
      "        0.9851, 1.0953, 1.0879, 1.0865, 0.6891, 0.9182, 1.1735, 1.1242, 1.4690,\n",
      "        1.0774, 1.1024, 1.1574, 1.2551, 1.1561, 1.2267, 1.1765, 1.1164, 1.1696,\n",
      "        1.1914, 1.2335, 1.0605, 1.1887, 1.1594, 0.9171, 1.2146, 1.5977, 1.1320,\n",
      "        1.1136, 1.1865, 1.3605, 1.0943, 1.1181, 1.1288, 1.0748, 1.2786, 1.1453,\n",
      "        1.3435, 1.2243, 1.0941, 1.0539, 1.1789, 1.2303, 1.1033, 0.6240, 1.6028,\n",
      "        1.1839, 1.3616, 1.1978, 1.1328, 1.3012, 1.1849, 1.3876, 1.2868, 1.2573,\n",
      "        1.3741, 1.3298, 0.9060, 1.3991, 1.1743, 1.4056, 1.3380, 1.3227, 1.2626,\n",
      "        1.1201, 1.0958, 1.2717, 1.0598, 1.2329, 0.9291, 0.9577, 1.3002, 1.1202,\n",
      "        1.2646, 1.1256, 1.4177, 1.2073, 1.0882, 1.2316, 1.1231, 1.1916, 1.0127,\n",
      "        1.2447, 0.7745, 1.0887, 0.9758, 1.4148, 1.7035, 1.2604, 1.4592, 1.1675,\n",
      "        0.8795, 1.2176, 1.1899, 1.1043, 1.0997, 1.3282, 1.0307, 1.2589, 1.2014,\n",
      "        1.2275, 1.2435, 1.1609, 1.0344, 1.2557, 1.1107, 1.1372, 1.2200, 0.9641,\n",
      "        0.9054, 0.9254, 0.6158, 1.4729, 1.0315, 1.2416, 1.0285, 1.1597, 1.1078,\n",
      "        1.1433, 1.4679, 1.1327, 1.0599, 1.1626, 1.2185, 1.0316, 1.2827, 1.2752,\n",
      "        1.1762, 1.1154, 1.1650, 1.1934, 1.2138, 0.8026, 1.0945, 1.2496, 1.1071,\n",
      "        1.1972, 1.2466, 1.0176, 1.1539, 0.4310, 1.0874, 1.7770, 1.1254, 1.1999,\n",
      "        1.1290, 1.2507, 1.1404, 1.0869, 1.1002, 1.1560, 1.1596, 1.0853, 1.3798,\n",
      "        1.1409, 1.0217, 0.8441, 1.4424, 1.1579, 1.0941, 1.2004, 1.1570, 1.1322,\n",
      "        1.4651, 1.0020, 1.1144, 1.1966, 0.9222, 1.1102, 1.2533, 1.1172, 1.3839,\n",
      "        1.1107, 1.0609, 1.1657, 1.0708, 1.3796, 1.1140, 1.0999, 1.1975, 1.0600,\n",
      "        0.8867, 1.2671, 1.1879, 1.3077, 0.9800, 1.3599, 1.2318, 1.4430, 1.0031,\n",
      "        1.3026, 1.0476, 1.0635, 1.1069, 1.1762, 1.0803, 1.1776, 0.6351, 1.1740,\n",
      "        1.2197, 1.0472, 1.2014, 1.2465, 1.3952, 1.4341, 1.1949, 1.1902, 1.0255,\n",
      "        1.1233, 0.9174, 1.0505, 0.9620, 1.1540, 1.2959, 0.9197, 1.3116, 0.9549,\n",
      "        1.0992, 1.1544, 1.2321, 1.0284, 1.4261, 0.7980], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.0.1.bias\n",
      "Weights: tensor([-8.7007e-01, -4.8041e-01, -3.9488e-01, -1.0840e+00, -1.0521e+00,\n",
      "        -7.4641e-01, -4.1211e-01, -8.4041e-01, -6.4251e-01, -8.1812e-01,\n",
      "        -7.2789e-01, -1.1881e+00, -7.7827e-01, -2.7047e-01, -1.1008e+00,\n",
      "        -7.6671e-01, -6.1463e-01, -1.0390e+00, -1.0081e+00,  7.7525e-01,\n",
      "        -9.6957e-01, -1.3609e+00, -1.0023e+00,  2.6909e-01, -7.9082e-01,\n",
      "         1.5269e+00, -6.9646e-01,  1.7012e+00, -7.5340e-01,  1.2071e+00,\n",
      "        -1.0402e+00, -1.1026e+00, -9.9138e-01, -6.9190e-01, -9.9332e-01,\n",
      "         5.9829e-01, -5.7349e-01, -7.0965e-01, -5.5946e-01, -1.2398e+00,\n",
      "        -4.3898e-01, -6.7281e-01, -1.0863e+00,  2.8440e-01, -7.5439e-01,\n",
      "        -1.1037e+00, -7.1672e-01, -7.5317e-01,  9.8112e-01, -4.6733e-01,\n",
      "        -5.9403e-01,  1.3605e-01, -5.2270e-01, -2.2031e-01, -1.0558e+00,\n",
      "        -8.0915e-01, -1.4952e+00, -4.9085e-01, -7.8576e-01, -1.2953e+00,\n",
      "        -8.8194e-01, -9.6047e-01,  9.1252e-01, -1.0554e+00, -6.3340e-01,\n",
      "        -6.4879e-01, -9.9140e-01, -1.1937e+00, -8.7861e-01, -9.6494e-01,\n",
      "        -3.3320e-01, -9.8288e-01,  1.3671e+00,  1.7486e+00, -9.4326e-01,\n",
      "        -3.3522e-01, -8.0245e-01, -7.3134e-01, -5.4505e-01, -1.1150e+00,\n",
      "        -1.0340e+00, -2.9841e-01, -1.2314e+00, -1.9096e-01, -7.2022e-01,\n",
      "        -1.3333e+00, -1.0699e+00, -1.1012e+00, -1.0339e+00, -1.0064e+00,\n",
      "        -9.8016e-01, -7.3287e-01, -7.3636e-01,  8.5526e-02, -4.4037e-02,\n",
      "         1.8607e-01, -8.9632e-02, -3.4198e-01, -1.1192e+00, -8.2071e-01,\n",
      "        -3.9943e-01, -4.7701e-01, -8.7289e-01, -1.0093e+00, -5.4000e-03,\n",
      "        -7.4473e-01, -5.7312e-01, -3.5808e-02, -5.0927e-01, -8.9860e-01,\n",
      "        -4.3826e-01, -1.4646e-01,  7.5926e-01, -1.3357e+00, -6.5477e-01,\n",
      "        -2.4842e-01, -1.0486e+00,  8.5209e-01,  4.8086e-01, -5.6006e-01,\n",
      "         6.4566e-01, -7.9509e-01, -8.2511e-01, -6.1725e-01, -1.0803e+00,\n",
      "        -7.2726e-01, -7.7145e-01, -1.2781e+00, -3.0576e-01, -1.5585e+00,\n",
      "        -9.1833e-01, -6.6179e-01, -9.0467e-01, -1.2178e+00, -1.2216e+00,\n",
      "        -8.7628e-01, -5.4967e-01,  1.3622e+00, -8.1755e-01, -9.5292e-01,\n",
      "        -4.1386e-01, -1.0978e+00, -4.1453e-01, -9.9352e-01,  1.3835e+00,\n",
      "        -6.5662e-01, -8.1551e-01, -7.6722e-01, -3.1247e-01,  3.0490e-01,\n",
      "        -2.2622e-02,  1.4351e-01, -6.3547e-01, -1.1562e+00,  7.7549e-02,\n",
      "        -8.2373e-01, -4.6235e-01, -1.6498e-01, -1.0329e+00,  1.1713e+00,\n",
      "        -1.1535e+00, -1.6001e+00,  1.5387e+00, -1.3711e+00, -1.1236e+00,\n",
      "         7.7802e-01, -3.6273e-01,  9.7933e-01, -1.1847e+00,  2.7919e-01,\n",
      "        -8.4495e-01, -2.2598e-01, -9.9886e-01, -7.4802e-01, -5.1104e-01,\n",
      "        -8.9318e-01, -1.0534e+00, -7.7348e-01, -9.4078e-01, -1.1755e+00,\n",
      "         1.3539e+00, -1.9585e-01, -8.6296e-01, -7.5446e-01, -1.1012e+00,\n",
      "        -8.7311e-01, -7.3291e-01,  1.2283e+00, -2.4039e-01, -7.4838e-01,\n",
      "        -8.7804e-02, -5.5860e-01, -9.2190e-01, -3.9560e-01, -9.9463e-01,\n",
      "        -4.5369e-01, -9.0233e-01, -8.0050e-01, -6.0245e-01, -1.3321e+00,\n",
      "        -7.0541e-01,  1.5524e+00, -8.5557e-01, -5.7699e-01, -1.1335e+00,\n",
      "        -7.0244e-01, -8.5731e-01, -1.1947e+00, -4.5258e-01, -7.1543e-01,\n",
      "        -8.0039e-01, -7.5565e-01, -7.0040e-01, -3.5678e-01, -4.5826e-01,\n",
      "        -1.0829e+00, -1.1594e+00, -6.1747e-01, -1.1799e+00, -8.2975e-01,\n",
      "        -1.2143e+00, -1.5229e+00, -1.2142e+00, -5.5775e-01, -9.8782e-01,\n",
      "        -1.0354e+00, -1.1674e+00,  1.8411e+00, -2.7947e-01, -9.1546e-01,\n",
      "         1.5370e+00, -6.7948e-01, -7.8440e-01, -8.3725e-01, -5.6790e-01,\n",
      "         4.9891e-01, -8.0191e-01, -9.6857e-01, -1.0965e+00, -1.2750e+00,\n",
      "        -8.6108e-01, -1.5099e+00, -1.2972e+00, -1.2284e-01, -7.8435e-01,\n",
      "        -7.7853e-01, -5.9243e-01, -9.1819e-01, -5.9724e-01,  1.0392e+00,\n",
      "        -7.1961e-01, -7.4948e-01, -7.8781e-01, -2.8313e-01, -7.7056e-01,\n",
      "        -6.3518e-01, -8.3860e-01, -8.4557e-01,  1.1386e-01, -1.1459e+00,\n",
      "        -9.5067e-01, -1.1367e+00, -8.5222e-01, -5.7608e-01, -7.2881e-01,\n",
      "        -8.4667e-01, -2.0918e-01, -4.9375e-01, -5.5328e-01, -7.9185e-01,\n",
      "        -3.7105e-01, -9.2154e-01, -5.2033e-01, -6.9296e-01,  1.0433e+00,\n",
      "        -1.0489e+00, -4.8048e-01, -4.0103e-01, -5.8024e-01,  1.3573e+00,\n",
      "        -6.4145e-01, -5.6518e-01, -3.2046e-01, -1.1292e+00, -8.3604e-01,\n",
      "        -6.6761e-01, -1.0207e+00, -1.4309e+00, -1.1961e+00, -1.4035e+00,\n",
      "         3.9862e-02, -1.1515e+00, -1.0802e+00, -7.9675e-01, -7.8732e-01,\n",
      "        -9.7887e-01, -5.5925e-01, -6.5280e-01, -5.3422e-01, -1.4946e+00,\n",
      "        -4.6016e-01, -1.1101e+00, -3.1886e-01, -1.1605e+00,  6.5122e-01,\n",
      "        -5.7268e-01,  1.3895e+00, -5.6506e-02, -1.3012e+00, -5.6216e-01,\n",
      "        -8.0027e-01, -1.0459e+00, -8.6712e-01, -4.5194e-01, -5.4588e-01,\n",
      "        -8.1242e-01,  5.3424e-01, -1.1249e+00, -7.9425e-01,  5.9849e-01,\n",
      "        -2.3146e-01, -1.3443e+00,  1.2787e+00, -7.5414e-01, -6.0842e-01,\n",
      "        -4.9262e-01, -8.9493e-01, -7.4211e-01, -4.2155e-01, -1.0704e+00,\n",
      "        -1.3014e+00, -7.8659e-01, -5.7214e-01, -1.2015e+00, -1.2861e+00,\n",
      "        -1.1093e+00,  2.0554e-01, -8.3689e-01, -1.0766e+00, -7.0501e-01,\n",
      "        -7.6212e-01, -3.8770e-01,  5.3828e-01, -8.9898e-01, -1.3691e+00,\n",
      "        -8.8655e-01, -8.7511e-01, -8.4498e-01, -1.2812e-01, -6.4580e-01,\n",
      "        -3.7022e-01, -5.6434e-01, -1.3828e+00, -1.0765e+00, -7.3411e-01,\n",
      "        -1.3407e+00, -9.2049e-01,  1.1123e+00, -7.6135e-01, -8.2910e-01,\n",
      "        -6.0494e-01, -8.0528e-01, -6.1469e-01, -7.5197e-01, -3.8817e-01,\n",
      "        -1.4723e-01, -4.1217e-01, -6.2019e-01, -5.1364e-01,  9.2885e-01,\n",
      "        -1.2180e+00, -6.6824e-01, -4.4785e-01, -9.6981e-01, -1.0888e+00,\n",
      "        -1.2671e+00, -1.2535e+00,  1.1647e+00, -6.2083e-01, -9.3097e-01,\n",
      "        -8.1980e-01, -9.4716e-01, -1.1382e-01, -1.8100e-01, -9.9823e-01,\n",
      "        -1.9452e-01, -7.5240e-01, -8.7709e-01, -8.4976e-01,  1.0351e+00,\n",
      "        -5.7279e-01, -2.6757e-01, -1.5428e+00, -1.1328e+00,  1.1254e-01,\n",
      "        -8.0132e-01,  1.2256e+00, -4.6071e-01, -1.4041e+00, -6.7351e-01,\n",
      "         1.8943e+00,  1.0495e+00, -1.1112e+00, -2.2161e-01, -4.5264e-01,\n",
      "        -7.3609e-01, -9.8826e-01, -1.0724e+00,  1.2904e+00, -1.2163e+00,\n",
      "         1.0129e-01, -9.0095e-01,  1.2489e+00,  1.2078e+00, -1.0114e+00,\n",
      "         5.9100e-01, -6.0782e-01, -1.2544e+00, -1.0638e+00, -2.8467e-02,\n",
      "        -1.2526e+00, -7.7422e-01, -4.3935e-01,  6.9557e-02, -7.7339e-01,\n",
      "        -9.5045e-01, -7.2053e-01, -7.1353e-01, -9.4575e-01,  1.6096e-01,\n",
      "        -6.4532e-01, -7.3376e-01, -6.6687e-01, -7.6235e-01,  1.2769e-01,\n",
      "        -1.3082e+00, -9.6715e-01, -6.5385e-01, -6.9240e-01,  1.5634e-02,\n",
      "        -8.3238e-01, -8.8397e-01, -1.0672e+00, -9.6628e-01, -1.0247e+00,\n",
      "        -2.9625e-01, -1.3296e-02, -1.2394e+00, -1.0636e+00, -6.3193e-01,\n",
      "        -1.1434e+00,  6.9823e-01, -5.6163e-01, -1.1708e+00, -6.7806e-01,\n",
      "         1.4222e+00, -9.7400e-01, -8.0020e-01, -2.5219e-01, -8.1897e-01,\n",
      "        -8.7378e-01, -1.1333e+00, -7.3476e-01, -8.8053e-01, -6.2699e-02,\n",
      "        -9.8575e-01, -1.2465e+00, -1.2385e+00, -2.7312e-01, -5.4973e-01,\n",
      "        -6.2511e-01, -8.4179e-01, -1.1485e+00, -7.4539e-01, -2.8541e-01,\n",
      "        -1.1456e+00, -1.0557e+00, -8.0273e-01, -1.0177e+00, -3.3927e-01,\n",
      "        -6.6803e-01,  5.8888e-01,  1.3236e+00,  1.2906e-01, -8.3115e-01,\n",
      "        -8.5767e-01, -9.7503e-02, -9.0530e-01,  2.3347e-01, -7.4270e-01,\n",
      "        -9.3015e-01, -3.5350e-02, -9.8496e-01,  8.2963e-02, -1.3290e+00,\n",
      "        -5.7949e-01,  1.1815e+00, -9.7422e-01, -7.9956e-01, -2.8604e-01,\n",
      "        -9.3768e-01, -2.2295e-01, -1.1936e-01, -9.7270e-01, -6.5197e-01,\n",
      "        -3.5886e-01, -6.7779e-01, -2.0287e-01, -9.0051e-01, -7.2788e-01,\n",
      "        -8.2416e-01,  1.2307e-01, -7.5160e-01, -8.6455e-01,  5.3431e-01,\n",
      "        -1.0078e+00, -7.6090e-01, -6.5442e-01, -9.2044e-01, -1.0340e+00,\n",
      "        -7.6056e-01,  6.9593e-02,  1.1570e+00, -1.2025e+00, -8.1045e-01,\n",
      "         1.5762e+00,  1.0355e+00, -7.3802e-01, -8.7857e-01, -2.7727e-01,\n",
      "        -1.2263e+00, -6.7678e-01, -9.9524e-01, -1.0119e+00, -4.6559e-01,\n",
      "        -6.0247e-01,  4.4470e-01, -5.3364e-01, -2.0897e-01, -9.5669e-01,\n",
      "        -1.4179e+00, -3.1756e-01, -8.0817e-01, -7.7342e-01, -9.0818e-01,\n",
      "        -1.2291e-01, -1.0499e+00, -6.3579e-01, -1.3413e+00, -7.2617e-01,\n",
      "        -3.7888e-02, -3.1723e-01, -3.6858e-01, -1.0628e+00, -1.2936e+00,\n",
      "         1.4439e-01, -7.5175e-01, -8.7679e-01, -9.4452e-01, -9.1185e-01,\n",
      "        -3.7743e-01, -6.8427e-01, -4.8270e-01, -4.6427e-01, -1.0187e+00,\n",
      "        -8.1989e-01, -7.0672e-01, -6.7032e-01, -1.3357e+00, -8.9167e-01,\n",
      "        -6.6680e-01, -8.6036e-01, -9.5876e-01,  1.4796e+00, -8.7902e-01,\n",
      "        -5.3537e-01,  5.7721e-01, -1.1307e+00,  1.2484e+00, -5.1061e-01,\n",
      "        -9.9787e-01, -7.4566e-01,  1.9463e-01, -1.5762e-01, -6.1983e-01,\n",
      "        -1.1995e+00, -1.0510e+00, -6.1314e-01,  1.1936e+00, -5.3323e-01,\n",
      "        -1.2398e+00, -5.3519e-01, -7.1303e-01,  5.7844e-01,  4.4322e-02,\n",
      "        -1.0782e+00, -7.4498e-01, -5.2612e-01, -4.8679e-01, -6.2347e-01,\n",
      "        -1.1906e-01, -1.0862e+00, -1.3553e+00,  2.8185e-01, -1.3553e+00,\n",
      "        -8.2809e-01, -2.0696e-01, -4.8617e-01, -2.5230e-01, -4.5957e-01,\n",
      "        -9.8299e-01,  6.4168e-01, -7.7739e-01,  3.0727e-01, -1.2787e+00,\n",
      "        -5.4346e-01, -5.8409e-01, -8.8162e-01, -7.9848e-01, -7.8904e-01,\n",
      "        -1.0398e-02,  8.0172e-01, -2.2951e-01, -1.1211e+00, -9.3402e-01,\n",
      "        -7.0589e-01, -1.0840e+00, -6.6688e-01, -6.9906e-01, -1.1256e+00,\n",
      "        -7.4277e-01, -7.8674e-01, -2.8906e-02, -2.5370e-01, -5.0291e-01,\n",
      "        -1.0972e+00, -6.2841e-01, -3.6407e-01, -1.2514e+00, -1.0861e+00,\n",
      "         8.1287e-02, -1.2341e-01, -1.0496e+00, -1.0644e+00, -8.2415e-01,\n",
      "        -1.0365e+00,  1.3288e+00, -5.9424e-01, -7.1404e-01, -5.4033e-01,\n",
      "        -8.7963e-01, -5.2149e-01, -7.0078e-01, -9.7678e-01, -6.4786e-01,\n",
      "        -3.6397e-01, -7.0006e-01, -9.9290e-01, -4.3363e-01, -5.3613e-01,\n",
      "        -9.1764e-01, -4.5087e-01, -1.3940e+00, -1.0072e+00, -7.5657e-01,\n",
      "        -8.3429e-01, -8.2408e-01, -3.9467e-01, -1.0125e+00, -7.7371e-01,\n",
      "         1.4873e+00, -1.0411e+00, -1.0349e+00, -7.4756e-01, -9.7777e-01,\n",
      "        -1.0262e+00, -1.0948e+00, -1.1392e+00, -3.9797e-01, -1.2393e-01,\n",
      "        -1.4584e+00, -8.1482e-01, -8.5643e-01, -1.2328e+00,  3.1607e-04,\n",
      "        -4.1837e-01, -1.0671e-01, -6.5056e-01, -4.7685e-01, -8.0500e-01,\n",
      "         6.9434e-01, -4.3879e-01, -6.2023e-01, -1.5536e-01, -1.0602e+00,\n",
      "        -5.5021e-01, -7.0980e-01, -6.2662e-01,  1.3323e+00, -4.7604e-01,\n",
      "        -5.2645e-01, -6.3433e-01, -8.3293e-01,  4.1350e-01, -8.5338e-01,\n",
      "         1.1553e+00, -7.8002e-01, -7.7313e-01,  5.0840e-01, -3.2096e-01,\n",
      "         8.2950e-01, -1.0117e+00, -5.0751e-01, -7.5923e-01, -8.4524e-01,\n",
      "        -1.2180e+00, -7.6912e-01, -1.2923e+00, -6.3148e-01, -9.0004e-01,\n",
      "        -2.3183e-01, -6.8277e-01,  1.1904e-01, -1.0615e+00, -8.2570e-01,\n",
      "        -3.8923e-01, -6.3869e-01, -6.4314e-01, -8.3839e-01, -9.2041e-01,\n",
      "        -6.9861e-01,  1.5037e+00, -4.9579e-01, -8.8492e-01, -6.4084e-01,\n",
      "        -8.5981e-02,  8.2541e-02, -6.8523e-01, -4.8327e-01, -6.2659e-01,\n",
      "        -4.5340e-01, -1.3787e+00, -3.0779e-01, -8.3912e-02, -8.2263e-01,\n",
      "        -1.1984e+00, -9.5331e-01,  1.3605e-01, -9.1783e-01, -9.6991e-01,\n",
      "        -7.7407e-01, -1.1557e+00, -9.0664e-01, -7.5820e-01, -6.6964e-01,\n",
      "        -1.1810e+00, -2.5609e-01, -1.3674e+00, -8.5312e-01, -9.7928e-01,\n",
      "        -7.7661e-01, -9.9744e-01,  5.6366e-01, -5.7008e-01, -3.1684e-01,\n",
      "        -1.0085e+00, -5.4843e-01, -9.1353e-01, -8.0671e-01, -5.2555e-01,\n",
      "        -7.6502e-01, -3.4291e-01, -7.6447e-01, -9.4081e-01,  3.5583e-01,\n",
      "        -1.2003e+00, -8.7628e-01, -8.6149e-01, -5.8954e-01, -7.5184e-01,\n",
      "        -3.6255e-01,  2.9214e+00, -1.6814e+00, -6.5614e-01, -7.6957e-01,\n",
      "        -1.4946e+00, -8.5269e-01,  4.6887e-01,  3.4996e-01, -7.7400e-01,\n",
      "        -5.8103e-01, -4.2580e-02, -3.0026e-01, -6.2726e-01, -4.3378e-01,\n",
      "        -2.9948e-02, -1.0037e+00, -2.6220e-01, -6.1995e-02, -9.1846e-01,\n",
      "        -9.5776e-01, -1.2310e+00, -1.0779e+00, -3.5398e-01, -1.2414e+00,\n",
      "        -1.1467e+00,  1.5563e+00, -4.0335e-01,  1.1315e+00, -1.2223e+00,\n",
      "        -1.1574e+00, -1.0923e+00, -7.3038e-01, -1.0891e+00, -1.1091e+00,\n",
      "        -1.3208e+00, -8.9400e-01, -7.6963e-01, -5.4631e-01, -1.0357e+00,\n",
      "         9.2335e-01, -1.2502e+00, -8.9445e-01, -1.1116e+00,  7.9903e-01,\n",
      "        -3.6437e-01, -9.2716e-01, -1.3485e+00,  5.7721e-01, -6.7214e-01,\n",
      "        -9.1139e-01, -6.1674e-01, -1.1362e+00, -1.3416e-03, -7.7286e-01,\n",
      "        -4.5785e-01, -6.5970e-01, -7.2355e-01, -8.8723e-01, -8.0770e-01,\n",
      "        -9.0912e-01, -6.0693e-01, -8.2711e-01, -1.1069e+00, -9.6960e-01,\n",
      "        -7.6480e-01, -5.1899e-01, -5.4280e-01,  1.6039e+00, -1.1548e+00,\n",
      "        -8.8935e-01, -4.6674e-01, -7.5294e-01, -1.1867e+00, -8.5284e-01,\n",
      "        -8.2388e-01, -6.9340e-01, -7.2715e-01, -1.1559e+00,  7.3237e-01,\n",
      "        -1.1956e+00, -1.0234e+00,  8.2745e-02, -6.4497e-01, -8.7165e-01,\n",
      "        -9.6508e-01, -9.1956e-01, -1.3222e+00, -1.0022e+00,  9.6649e-01,\n",
      "        -8.5816e-01, -1.0598e+00, -6.6324e-01,  2.7906e-01, -8.4632e-01,\n",
      "        -5.6552e-01, -5.7879e-01,  1.0889e+00, -9.5100e-01, -7.4023e-01,\n",
      "        -9.0626e-01, -2.1790e-01, -8.3817e-01, -1.6773e+00, -7.1517e-01,\n",
      "        -7.5572e-01,  1.4614e-01, -9.8426e-01, -5.1607e-01, -7.6655e-01,\n",
      "        -1.7402e+00, -7.9207e-01, -6.8897e-01, -2.0438e-01, -1.0678e+00,\n",
      "        -1.2826e+00, -8.3207e-01, -8.4067e-01, -1.0068e+00, -8.5198e-01,\n",
      "        -6.6772e-01, -8.7422e-01, -5.4337e-01, -9.5822e-01,  1.0017e+00,\n",
      "        -9.4836e-01, -9.5782e-01, -8.4735e-01, -8.1481e-01, -5.4998e-01,\n",
      "        -4.8486e-01, -9.8552e-01, -8.4593e-01, -3.6875e-01, -6.1053e-01,\n",
      "        -6.9147e-01, -5.2535e-01, -6.7843e-01, -4.3001e-01, -8.2579e-01,\n",
      "        -1.2099e+00, -4.3289e-01, -7.8390e-01, -2.1110e-01, -4.7325e-01,\n",
      "        -1.8447e-01, -5.9307e-01, -5.6624e-01, -1.9224e-01, -9.2398e-01,\n",
      "        -8.6332e-01, -4.6482e-01, -1.1265e+00, -1.0009e+00, -7.1501e-02,\n",
      "        -8.4673e-01, -1.0622e+00, -5.5951e-01, -8.6174e-01, -1.0917e+00,\n",
      "        -9.5259e-01, -9.2726e-02, -6.2837e-01, -6.5700e-01, -8.9124e-01,\n",
      "        -1.1094e+00, -5.7060e-01, -1.0382e+00, -2.9362e-01, -9.4134e-01,\n",
      "         2.3400e-01, -5.8797e-01, -1.2064e+00, -3.4123e-01, -3.8593e-01,\n",
      "        -8.1553e-01, -6.7636e-01, -1.7350e-01, -9.9678e-01,  1.0997e+00],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.0.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.0.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0374, -0.0797, -0.0440],\n",
      "          [-0.0817, -0.0449, -0.0802],\n",
      "          [-0.0510, -0.0868, -0.0536]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0798,  0.0697,  0.0811],\n",
      "          [ 0.0590,  0.0880,  0.0541],\n",
      "          [ 0.0738,  0.0610,  0.0756]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3262, -0.0494,  0.3328],\n",
      "          [ 0.0016, -0.3545, -0.0064],\n",
      "          [ 0.1280, -0.1280,  0.1204]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0448,  0.0889,  0.0493],\n",
      "          [ 0.0948,  0.1191,  0.0952],\n",
      "          [ 0.0618,  0.0951,  0.0663]]],\n",
      "\n",
      "\n",
      "        [[[-0.0515, -0.0787, -0.0486],\n",
      "          [-0.0708, -0.0692, -0.0806],\n",
      "          [-0.0520, -0.0780, -0.0599]]],\n",
      "\n",
      "\n",
      "        [[[-0.0661, -0.0871, -0.0677],\n",
      "          [-0.0844, -0.0619, -0.0910],\n",
      "          [-0.0737, -0.0904, -0.0691]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 1, 3, 3])\n",
      "\n",
      "Layer: features.17.conv.1.0.param_quantizers.weight.min\n",
      "Weights: -0.7045133709907532\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.1.0.param_quantizers.weight.max\n",
      "Weights: 0.699009358882904\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.1.1.weight\n",
      "Weights: tensor([0.7587, 1.0664, 0.9705, 0.6082, 0.7812, 0.7878, 0.6075, 0.7936, 0.8870,\n",
      "        1.0368, 0.5334, 0.5831, 0.6696, 0.7771, 1.0082, 1.1344, 0.5582, 0.6761,\n",
      "        1.9203, 1.5345, 0.7622, 0.9057, 0.9129, 0.8063, 0.8314, 2.3288, 0.5858,\n",
      "        2.2591, 1.3567, 1.4320, 0.6711, 1.4772, 0.9889, 0.9211, 0.8904, 1.0256,\n",
      "        0.5789, 0.5701, 1.1698, 0.7213, 0.9732, 0.5093, 0.7124, 1.1624, 0.4908,\n",
      "        0.6800, 0.5939, 0.8533, 1.3514, 1.1481, 1.0865, 1.4354, 0.9105, 1.0940,\n",
      "        1.2686, 1.3776, 0.7773, 2.0565, 0.7616, 0.7070, 0.5508, 0.5787, 1.5386,\n",
      "        0.6691, 0.8811, 0.7028, 0.5752, 0.5422, 0.8223, 0.7076, 1.4864, 0.5488,\n",
      "        1.5501, 2.5208, 0.6455, 0.8321, 0.6538, 0.6959, 1.1856, 0.3516, 0.5158,\n",
      "        0.8066, 0.7978, 1.1485, 0.8331, 0.5523, 0.5358, 0.5882, 0.5461, 0.5065,\n",
      "        0.6259, 0.7775, 0.7970, 0.9614, 0.9105, 1.4090, 1.4759, 1.0065, 0.6589,\n",
      "        1.3362, 0.8483, 1.2836, 0.5555, 0.6484, 1.7035, 0.5763, 0.9487, 1.3715,\n",
      "        0.8254, 0.7428, 0.9394, 0.6388, 1.2328, 0.5573, 0.8811, 0.9473, 0.6521,\n",
      "        1.6287, 1.4338, 0.9296, 1.3734, 0.5636, 0.5720, 0.5848, 0.7023, 0.9326,\n",
      "        0.6355, 0.4733, 1.2563, 0.6182, 0.6673, 0.9119, 0.6702, 0.9529, 0.6456,\n",
      "        0.5558, 1.0551, 1.6924, 0.6318, 0.9611, 1.0017, 0.4924, 0.5773, 0.7533,\n",
      "        1.6367, 0.5137, 0.8998, 0.6067, 2.0592, 1.3863, 2.5879, 1.5236, 1.9661,\n",
      "        0.6047, 1.9058, 0.5817, 0.6042, 0.9441, 0.5708, 1.8214, 0.5975, 0.5170,\n",
      "        2.0205, 0.7226, 0.7123, 1.5199, 0.9606, 1.2712, 1.3232, 1.4577, 0.8369,\n",
      "        0.8351, 0.6559, 1.1761, 1.2447, 1.4653, 0.7371, 0.5316, 0.5512, 1.3035,\n",
      "        1.6551, 1.1269, 0.6104, 0.9549, 0.6955, 0.8394, 0.9233, 1.5016, 1.3674,\n",
      "        1.2155, 0.9076, 0.8814, 0.6895, 1.0577, 0.7058, 1.0133, 0.6170, 0.6981,\n",
      "        0.6465, 0.8558, 0.7862, 1.1409, 1.1637, 0.9293, 0.7379, 0.8444, 0.6293,\n",
      "        0.6710, 1.0281, 0.6369, 0.8581, 0.8065, 1.2208, 0.8770, 0.9425, 0.8310,\n",
      "        0.6585, 0.6993, 1.0934, 3.5703, 0.6635, 0.6288, 0.6711, 0.9483, 0.5454,\n",
      "        0.6046, 1.2709, 2.3365, 1.0654, 0.7535, 1.9913, 0.9633, 1.0635, 0.5958,\n",
      "        0.5756, 1.5387, 0.6483, 0.6165, 0.9288, 0.6432, 0.5571, 1.1255, 0.6877,\n",
      "        1.0329, 0.6925, 0.5874, 0.8346, 0.9654, 0.5674, 1.7405, 0.9987, 0.7529,\n",
      "        0.7770, 1.7009, 0.7985, 1.7518, 0.5632, 0.7565, 1.1755, 0.5175, 0.8128,\n",
      "        0.5739, 0.8853, 1.2051, 0.7004, 1.0302, 0.9307, 1.0529, 0.8661, 0.5188,\n",
      "        0.8718, 0.7607, 1.1962, 0.5663, 1.7853, 0.7294, 1.5382, 0.9048, 1.0748,\n",
      "        1.3870, 0.7219, 0.5314, 1.5559, 0.5351, 0.8246, 0.9361, 0.5502, 1.8910,\n",
      "        1.0733, 1.0342, 1.4895, 0.6557, 1.2132, 0.8106, 1.0794, 0.8649, 1.0292,\n",
      "        1.0744, 1.1541, 0.4776, 0.6958, 0.6945, 1.2526, 0.7283, 0.7028, 0.9903,\n",
      "        1.3398, 1.2330, 0.7571, 0.7281, 1.0747, 0.8898, 0.7464, 0.8764, 0.6743,\n",
      "        0.5631, 1.3260, 0.5710, 0.8039, 1.3770, 0.8872, 0.6004, 1.7430, 1.1765,\n",
      "        0.6556, 0.9857, 0.7798, 0.8653, 0.8686, 0.5188, 0.5162, 0.7288, 0.7111,\n",
      "        0.4919, 0.6298, 0.7297, 1.1827, 1.9145, 0.5620, 0.5695, 0.7586, 0.9055,\n",
      "        1.4267, 0.8885, 0.8819, 0.5170, 0.8941, 0.5242, 0.9635, 0.8390, 1.7875,\n",
      "        0.7824, 0.5324, 0.7111, 0.5640, 0.6278, 0.7590, 1.7346, 0.5653, 1.0730,\n",
      "        1.1302, 0.7190, 0.7547, 1.0680, 0.8851, 1.0108, 0.5835, 0.5683, 0.5555,\n",
      "        0.8675, 0.5251, 1.6061, 0.6329, 1.2068, 0.8895, 0.6511, 0.5724, 0.7917,\n",
      "        1.4587, 0.9412, 1.1447, 0.5180, 1.0823, 0.9537, 0.7763, 1.3692, 0.9814,\n",
      "        0.7411, 0.8954, 1.7923, 0.5611, 1.0508, 0.5627, 0.5508, 0.9988, 0.6707,\n",
      "        1.1065, 0.5749, 0.5301, 0.8364, 1.5495, 1.8188, 0.8246, 1.7332, 1.0611,\n",
      "        0.8968, 0.4849, 0.7644, 1.5050, 0.9194, 1.0088, 0.7762, 1.5382, 1.6735,\n",
      "        0.5355, 2.1029, 0.6111, 0.5820, 0.7909, 0.9374, 0.8603, 0.7484, 0.5738,\n",
      "        1.3661, 0.8186, 1.0640, 0.5567, 1.0454, 0.6780, 1.6733, 0.6158, 0.5625,\n",
      "        1.4702, 0.6467, 1.0085, 0.6637, 0.5809, 0.5416, 1.2362, 0.8241, 0.8063,\n",
      "        0.9943, 0.7541, 0.7035, 0.5827, 0.4946, 1.0205, 0.7479, 0.7849, 0.8279,\n",
      "        0.7131, 1.6224, 0.6039, 0.5734, 0.5463, 2.1434, 0.8288, 0.5482, 0.8168,\n",
      "        0.5864, 0.8184, 0.6240, 0.5558, 0.7693, 1.0950, 1.0674, 0.5378, 0.8111,\n",
      "        1.0255, 0.8071, 1.1438, 0.7899, 0.7178, 0.5697, 1.7313, 0.5375, 0.5582,\n",
      "        0.6250, 0.7562, 0.8995, 1.0144, 1.6962, 1.7325, 1.1181, 0.8333, 0.6116,\n",
      "        1.1146, 0.9563, 0.8680, 0.8136, 0.6681, 0.8460, 0.7428, 2.0466, 0.8286,\n",
      "        1.7539, 1.8633, 0.5533, 1.2574, 0.8157, 0.9576, 0.7358, 1.1000, 0.8401,\n",
      "        0.7786, 1.2233, 0.5533, 1.4082, 0.5768, 1.0057, 0.5578, 1.3610, 2.5851,\n",
      "        0.6079, 1.5519, 1.0206, 1.0129, 0.5734, 0.6347, 0.7675, 0.6048, 1.5151,\n",
      "        1.7394, 0.6235, 0.5592, 1.3990, 1.0454, 0.5630, 1.2370, 1.0151, 0.6798,\n",
      "        1.2653, 0.8508, 0.5965, 1.1471, 0.5580, 1.2267, 0.5526, 0.9185, 0.6140,\n",
      "        0.6017, 1.0826, 0.8651, 0.5809, 1.0535, 0.9282, 0.5865, 0.9076, 0.9328,\n",
      "        0.8723, 1.2119, 1.1979, 1.0913, 0.6763, 0.5875, 1.5110, 0.9235, 0.7256,\n",
      "        0.7886, 0.6432, 0.7194, 0.5130, 0.7171, 0.6432, 0.5273, 0.8609, 0.5557,\n",
      "        0.5716, 0.5785, 0.7271, 0.7649, 0.5113, 0.6941, 1.8621, 0.7144, 1.4813,\n",
      "        1.2118, 0.5997, 1.3182, 1.4860, 0.5143, 0.5789, 1.7184, 1.2996, 0.7793,\n",
      "        0.5120, 0.7325, 0.5360, 2.8055, 1.0204, 0.6400, 1.5173, 0.5416, 1.5430,\n",
      "        1.2931, 0.5621, 0.9018, 1.0160, 0.9147, 0.9251, 0.5801, 0.6659, 0.6853,\n",
      "        1.0345, 1.2581, 0.5457, 1.0502, 0.8944, 0.8209, 1.0546, 0.5165, 1.5800,\n",
      "        0.5708, 1.2275, 0.5927, 0.5517, 1.2237, 0.5624, 0.6583, 0.9011, 0.9232,\n",
      "        0.9331, 1.1311, 2.4525, 0.7155, 1.0393, 0.6836, 0.8102, 0.7833, 0.6574,\n",
      "        0.5713, 0.6847, 1.2508, 0.5897, 0.5398, 0.6685, 0.7851, 0.7153, 0.8129,\n",
      "        0.5710, 2.0822, 1.1100, 1.1336, 0.7264, 0.7757, 0.7156, 1.6686, 0.6171,\n",
      "        0.5673, 0.5374, 0.7898, 0.9426, 0.9129, 0.9329, 0.9403, 0.8765, 0.8839,\n",
      "        0.4954, 1.4239, 1.5968, 0.5651, 1.5305, 0.5305, 0.9298, 0.9450, 0.8478,\n",
      "        0.6647, 0.5407, 0.6463, 0.9635, 3.5926, 0.7540, 0.6425, 0.8262, 0.5197,\n",
      "        0.6102, 0.7822, 0.7164, 0.5786, 0.9843, 0.5377, 0.7399, 1.7398, 0.8439,\n",
      "        0.8191, 0.5846, 1.3614, 0.7749, 0.6242, 0.6215, 1.7327, 0.6890, 0.9841,\n",
      "        0.9798, 0.6479, 1.5125, 0.7372, 0.5286, 1.3124, 1.3312, 1.0576, 0.8857,\n",
      "        0.5657, 0.9799, 0.9292, 1.6030, 0.5600, 0.9197, 1.5295, 0.8393, 2.1555,\n",
      "        0.5013, 1.1598, 0.7935, 1.0109, 1.4491, 1.0737, 0.5125, 1.0645, 0.7066,\n",
      "        1.0279, 0.7747, 1.6681, 0.7420, 0.7108, 0.5929, 0.5471, 0.7994, 0.7203,\n",
      "        0.7937, 0.6337, 1.5824, 0.9556, 0.6413, 0.7694, 0.8122, 1.3174, 0.8823,\n",
      "        0.9552, 1.0955, 2.1535, 0.6418, 1.3021, 1.4057, 0.7812, 0.6188, 1.6274,\n",
      "        0.9356, 0.4862, 0.8329, 0.5579, 0.9145, 0.6787, 1.4320, 0.6374, 0.4788,\n",
      "        2.0252, 0.7311, 0.6793, 0.8789, 0.5381, 0.7380, 1.2394, 0.8887, 1.1358,\n",
      "        0.8927, 0.6118, 1.8316, 0.6539, 0.7307, 0.8112, 1.2614, 0.9619, 0.6483,\n",
      "        2.0435, 0.6009, 0.7221, 0.6779, 0.6325, 0.5757, 0.8493, 2.5043, 0.8077,\n",
      "        0.5408, 0.7360, 0.6107, 0.5692, 1.9878, 1.2228, 0.6925, 0.6559, 0.9586,\n",
      "        1.1479, 0.6144, 1.2793, 1.6767, 0.6655, 0.9307, 1.2867, 0.7073, 0.5771,\n",
      "        0.7300, 0.7580, 0.8831, 0.5670, 0.6561, 2.5240, 1.1107, 2.1209, 0.6598,\n",
      "        0.9263, 0.7212, 0.6981, 0.7981, 0.5186, 0.6818, 0.7319, 0.6309, 0.7878,\n",
      "        0.6790, 1.1916, 0.6697, 0.6461, 0.6518, 1.5724, 0.6067, 0.9683, 0.6062,\n",
      "        2.1148, 0.5783, 0.5888, 0.7850, 0.6759, 1.2123, 0.8218, 1.8252, 0.5772,\n",
      "        0.6376, 1.0422, 1.0713, 0.6936, 0.6039, 0.8192, 0.5366, 0.5115, 1.0356,\n",
      "        1.1173, 0.9309, 1.8661, 1.2430, 0.7569, 0.6825, 0.7642, 0.6305, 0.5220,\n",
      "        1.0466, 0.9591, 0.8925, 0.6396, 1.7179, 0.8315, 0.6326, 1.1416, 0.7746,\n",
      "        0.9181, 0.7437, 0.5494, 0.7122, 0.5254, 1.4153, 0.9763, 1.0020, 0.8311,\n",
      "        1.0465, 1.0238, 1.1953, 0.9440, 2.2031, 0.6690, 0.7192, 0.9786, 1.6794,\n",
      "        0.7319, 0.6488, 0.9116, 0.6128, 0.9565, 1.2027, 1.1660, 0.8383, 0.6989,\n",
      "        0.6134, 0.7828, 1.0238, 0.4811, 0.6881, 0.8199, 0.5581, 0.8112, 0.7870,\n",
      "        1.3563, 0.8676, 1.1975, 0.5750, 1.8311, 0.7811, 0.6706, 0.5291, 0.6739,\n",
      "        1.2235, 0.9226, 0.5344, 0.6565, 1.1260, 0.5909, 0.8898, 0.5581, 1.5523,\n",
      "        0.9594, 0.6182, 0.6874, 1.3639, 0.8483, 1.3418, 0.8842, 1.1812, 0.8936,\n",
      "        1.9223, 0.9223, 0.7757, 0.7892, 0.5305, 0.7075, 0.5372, 1.3412, 0.8452,\n",
      "        1.1343, 0.9135, 0.6766, 0.7180, 0.7482, 0.9758, 0.5768, 0.7424, 0.7745,\n",
      "        0.6112, 0.8148, 0.5207, 1.3131, 0.5610, 1.3510, 0.7813, 1.0624, 0.7843,\n",
      "        0.8542, 0.5704, 0.9079, 0.8481, 0.6130, 1.5241], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.1.1.bias\n",
      "Weights: tensor([ 1.3612e+00, -1.4581e+00,  1.6107e+00,  1.1966e-01, -6.6897e-01,\n",
      "        -3.2968e-01,  2.8615e+00, -7.2919e-03, -8.2911e-01, -6.1160e-01,\n",
      "         2.7219e+00,  2.1528e+00,  1.3834e+00,  1.7660e+00,  7.4900e-02,\n",
      "        -1.4669e+00,  2.7132e+00,  1.5913e+00, -2.3653e+00, -2.6979e-01,\n",
      "        -4.1775e-01,  1.2268e+00, -1.7699e+00,  6.6138e-01,  1.0138e+00,\n",
      "        -1.2110e+00,  2.9969e+00, -1.9202e+00, -1.8954e+00, -5.6541e-01,\n",
      "         1.7380e+00, -2.6009e-01, -8.6394e-01, -7.6715e-01, -8.2517e-01,\n",
      "        -8.3704e-02,  2.8657e+00,  1.6965e+00, -1.8296e+00, -3.6655e-01,\n",
      "        -3.3773e-01,  2.7607e+00, -3.2329e-01,  1.8112e-01,  2.2468e+00,\n",
      "        -1.6934e-01,  1.8308e+00, -6.7473e-01, -2.5122e-01, -1.2947e+00,\n",
      "        -1.0776e+00, -7.7153e-02,  1.6801e+00, -1.1755e+00, -3.9835e-01,\n",
      "        -1.2373e+00, -1.8215e+00, -7.6795e-01, -2.9759e-01, -2.5959e-01,\n",
      "         2.7944e+00,  1.8411e+00, -2.0567e-01,  1.5234e-02, -3.5922e-01,\n",
      "         1.3357e+00,  3.1590e+00,  3.4765e+00, -6.1554e-01, -3.4262e-01,\n",
      "        -1.0704e+00,  3.3149e+00, -7.5551e-01, -2.5937e+00, -8.0624e-02,\n",
      "         4.5163e-01, -1.1910e-01, -2.5226e-01, -1.1624e+00,  1.7902e+00,\n",
      "         2.4029e+00,  8.6172e-01, -4.9098e-01, -1.4802e+00, -5.9383e-01,\n",
      "         1.1908e-01,  3.3327e+00,  1.0888e-03,  3.0821e+00,  3.0301e+00,\n",
      "        -5.7279e-02, -2.9757e-01, -4.0877e-01,  4.1786e-01,  2.8705e+00,\n",
      "         3.5812e-02, -1.5666e+00, -1.1561e+00, -3.2286e-01, -1.5782e+00,\n",
      "         7.6618e-01,  3.5763e-01,  3.4889e+00, -5.2898e-02, -2.9526e+00,\n",
      "         2.1606e+00, -1.0265e+00,  1.6601e-03,  9.5592e-01, -1.6767e-01,\n",
      "        -6.0979e-01,  1.2243e+00,  1.5288e-01, -1.2323e-01,  1.8327e+00,\n",
      "         3.5678e-02, -1.7683e-01, -3.4394e-01, -4.1182e-02, -9.6599e-01,\n",
      "        -8.8563e-02,  2.5892e+00,  2.0098e+00,  2.2309e+00, -9.8329e-02,\n",
      "        -1.0172e+00,  1.6540e+00,  3.8152e+00, -1.8638e+00, -1.8092e-01,\n",
      "        -1.6013e-01, -6.2437e-01, -1.2226e-01, -1.0490e+00, -3.8929e-01,\n",
      "         2.0753e+00, -9.8770e-01, -8.6939e-01,  1.6696e+00,  1.0155e+00,\n",
      "        -8.2252e-01,  3.0450e+00,  1.4655e+00, -4.8703e-01, -9.2438e-01,\n",
      "         2.0807e+00, -9.3019e-01,  1.5440e+00, -1.4108e+00, -1.0660e-01,\n",
      "        -2.4496e+00,  8.3537e-02, -1.5079e+00, -4.9279e-02, -3.2222e+00,\n",
      "         2.4822e+00,  1.7593e+00,  6.6853e-02, -1.7721e-01, -1.1072e+00,\n",
      "         2.1012e+00, -8.0953e-02, -1.6377e+00, -6.4959e-01, -2.7602e-01,\n",
      "        -3.0068e-01,  1.5234e+00, -1.7623e-01, -1.5283e-01,  3.1370e+00,\n",
      "        -5.5981e-01,  8.6045e-01, -3.4433e-01, -1.8293e+00, -1.6063e+00,\n",
      "        -3.0628e+00, -2.9981e-01,  2.4269e+00,  2.6461e+00,  9.8638e-01,\n",
      "        -9.3416e-01,  3.8410e+00,  1.5556e+00, -3.4631e-01,  1.0482e+00,\n",
      "        -6.8717e-01, -7.9012e-01, -7.1508e-01, -1.0464e+00, -1.2377e+00,\n",
      "         3.0849e+00, -6.5599e-01, -3.2198e-01, -1.3291e+00, -1.4213e-01,\n",
      "         6.0606e-01,  2.2621e+00, -3.4967e-01,  1.3444e+00, -1.4581e+00,\n",
      "        -6.1343e-01,  3.5413e+00, -1.9523e+00, -8.6813e-01, -4.9285e-01,\n",
      "        -6.0781e-01,  1.9912e-02, -2.9759e-01, -1.1798e+00,  1.4276e+00,\n",
      "        -9.0183e-01, -5.9997e-01, -1.6385e+00, -3.3684e-01, -9.6220e-01,\n",
      "        -4.8835e-01, -2.0436e-01, -1.3545e-01, -1.6612e+00, -1.0168e+00,\n",
      "        -2.8382e-01, -1.1007e-01, -5.1380e-02, -4.3392e-01,  2.9996e+00,\n",
      "         2.0201e+00,  1.1964e+00, -1.5390e+00, -1.1474e+00, -4.4637e-01,\n",
      "        -1.4178e+00, -1.1934e+00,  1.5670e+00,  2.4791e+00,  1.3343e+00,\n",
      "        -1.9749e-01,  2.6278e-02,  4.0344e-02, -8.0081e-01, -2.5013e-01,\n",
      "         3.1009e+00, -1.2223e+00, -4.4052e-01,  5.1411e-01, -2.7212e-01,\n",
      "         1.6172e+00, -3.6168e-01, -1.1249e+00,  2.0849e+00, -8.3719e-01,\n",
      "         8.6257e-01, -3.5003e-01, -4.0002e-01, -1.6957e+00, -2.8052e-01,\n",
      "        -1.7701e+00,  3.6354e+00,  1.2332e+00,  3.2731e-01,  2.8304e+00,\n",
      "        -3.8827e-01,  3.6190e+00, -5.4439e-01,  7.0811e-01,  1.5873e+00,\n",
      "        -5.0832e-01,  8.1512e-02,  8.1664e-04,  7.0744e-01,  2.4960e+00,\n",
      "         7.8672e-01, -4.8797e-01, -1.2983e+00,  2.4920e+00, -6.9507e-02,\n",
      "        -3.5180e-01, -2.0065e+00,  7.3922e-01, -1.0645e+00, -3.8677e-01,\n",
      "         1.8520e+00,  2.9491e+00, -1.8661e+00,  2.3204e+00,  8.8573e-01,\n",
      "        -8.8509e-01,  3.3309e+00, -1.8726e+00, -1.3883e+00,  2.8384e+00,\n",
      "         7.7064e-02, -1.2329e-01, -2.3607e+00, -5.2309e-01, -8.4040e-01,\n",
      "        -6.2683e-01, -1.0481e+00, -1.2631e+00, -1.1319e+00,  3.4985e+00,\n",
      "         1.2026e+00, -2.8553e-01, -1.4944e+00, -2.8606e-01,  7.3377e-01,\n",
      "        -1.3200e+00, -3.8551e-01, -1.5983e+00, -7.3831e-01, -2.5390e-01,\n",
      "        -1.3576e+00,  1.3198e-03, -6.0160e-01, -4.0921e-01, -9.4315e-02,\n",
      "         2.5038e+00,  1.1070e-01,  1.6386e-01, -4.8175e-01,  1.9640e+00,\n",
      "         2.3225e+00,  1.3091e-02, -9.6090e-01, -3.2102e-01,  1.6761e+00,\n",
      "        -9.7486e-01, -3.7567e-01,  8.8710e-01, -7.1554e-01,  2.8196e+00,\n",
      "         2.6708e+00, -1.8136e-01,  1.2826e+00,  4.4758e+00,  1.9672e+00,\n",
      "        -1.2443e-01,  1.7907e-01, -8.0427e-01,  3.3864e+00,  2.5101e+00,\n",
      "        -3.2428e-01,  2.1186e-02, -1.5530e-01, -1.0311e+00, -6.7175e-01,\n",
      "         2.5794e+00, -1.3950e+00,  2.0442e+00,  3.3366e+00, -7.0287e-01,\n",
      "        -6.1519e-01,  7.9781e-01,  7.7236e-02,  1.7443e+00,  2.7133e+00,\n",
      "        -2.6858e-01,  1.2501e+00, -8.6941e-01,  2.6201e+00,  1.3769e+00,\n",
      "        -1.5473e+00, -1.8152e-01, -3.3245e-01, -1.3976e+00,  7.8833e-01,\n",
      "        -2.5921e-01,  2.0400e+00,  2.9704e+00,  2.7967e+00,  5.1358e-01,\n",
      "         2.8392e+00, -1.1235e+00,  1.0194e+00, -1.4418e+00, -8.9359e-01,\n",
      "        -3.0048e-01,  3.0471e+00,  3.8079e-01,  2.2507e-01, -8.8708e-01,\n",
      "        -1.4143e+00,  2.7862e+00, -1.3153e+00,  2.4989e+00, -4.0791e-01,\n",
      "        -2.5079e+00, -1.2253e+00, -8.9878e-01, -6.9718e-01, -7.6701e-01,\n",
      "         2.5907e+00,  4.8933e-01, -9.6327e-03,  9.0343e-02,  2.6160e+00,\n",
      "        -7.2116e-02,  1.6218e-01,  3.0687e+00, -1.4265e-03, -6.4237e-01,\n",
      "        -8.9607e-01, -1.0061e+00, -4.8482e-01, -1.2013e+00,  4.9607e-01,\n",
      "        -8.6756e-01,  3.4741e+00, -6.2468e-01, -2.0578e+00, -9.6600e-01,\n",
      "         4.4822e-01, -5.8431e-01, -8.1272e-01, -9.5561e-01,  3.5423e+00,\n",
      "        -2.2197e-01,  3.0138e+00,  2.0470e+00, -7.6725e-01,  3.2042e+00,\n",
      "         1.2797e+00, -1.9322e-01,  2.4860e+00,  1.3267e-01, -2.4535e-01,\n",
      "        -1.2688e+00,  1.3759e+00, -1.2234e+00, -2.7105e-01, -2.3814e+00,\n",
      "         1.7489e+00,  2.3447e+00,  5.3102e-01, -4.3485e-02,  5.5479e-01,\n",
      "        -4.2871e-01,  2.0756e+00,  3.1207e+00, -1.5428e+00,  6.4229e-01,\n",
      "        -5.9041e-01, -1.0290e+00, -4.9755e-01, -1.1109e-01,  1.9137e+00,\n",
      "         2.7424e+00,  4.3710e-01,  2.1129e+00, -4.4037e-01, -3.3344e-01,\n",
      "        -3.3834e-01, -2.8485e-01,  1.6619e+00,  1.9493e+00,  2.6130e+00,\n",
      "        -1.4419e+00,  1.0285e+00,  2.5304e+00,  2.4350e+00,  1.8527e+00,\n",
      "        -5.1093e-01,  1.0713e-01,  1.8019e+00, -3.1901e-01, -9.5149e-01,\n",
      "        -8.6441e-01,  2.6737e+00, -9.8428e-01, -1.1026e+00,  1.1935e+00,\n",
      "        -1.6040e+00,  9.4047e-01, -3.4207e-01,  2.7886e+00, -2.6895e+00,\n",
      "         3.1098e+00,  2.1182e+00,  2.5493e+00, -2.0584e-01, -5.2711e-01,\n",
      "        -1.0625e+00, -2.2833e-01, -1.0686e+00,  3.9987e-01, -5.1431e-01,\n",
      "         1.6875e+00,  4.5465e-01, -1.2631e+00,  5.8445e-01, -2.9782e-01,\n",
      "        -2.0363e-01,  5.9190e-01,  3.8582e+00, -2.8443e+00, -5.2476e-01,\n",
      "         2.7781e-01, -1.1698e+00,  2.0599e+00, -1.5630e+00,  8.9582e-01,\n",
      "        -1.1626e+00,  7.9056e-01, -1.2215e+00, -7.2748e-01, -3.5238e-01,\n",
      "        -1.3142e+00,  1.8226e+00, -1.8033e+00,  2.8361e+00, -1.1494e+00,\n",
      "         3.1704e+00, -1.7313e+00, -5.3470e+00,  1.0121e-01, -1.5738e-01,\n",
      "        -1.6081e+00, -7.5735e-01,  2.0050e+00,  1.6509e+00,  5.7606e-02,\n",
      "         1.4009e+00, -1.8641e+00, -4.8647e-01, -8.6311e-02,  8.0940e-02,\n",
      "        -4.1174e-01,  3.2449e-01,  1.5968e+00, -1.4843e+00, -1.8346e-01,\n",
      "        -5.1082e-01, -1.0287e+00, -6.5500e-01, -1.7113e-01, -1.0996e+00,\n",
      "         3.3566e+00,  6.5597e-02,  3.0168e+00,  1.7524e-01, -6.7743e-02,\n",
      "         7.3173e-02, -9.2302e-01, -7.8335e-01,  2.2924e+00, -1.3288e+00,\n",
      "         7.7575e-02,  1.7860e+00,  1.0463e+00,  2.0312e+00, -1.1038e+00,\n",
      "        -1.3351e+00,  2.8198e-01, -1.5075e+00, -2.7841e-01, -1.8122e-01,\n",
      "        -1.9570e+00, -9.3537e-01, -2.6289e-01, -7.9157e-01, -4.0695e-02,\n",
      "         1.1081e+00,  2.9932e+00,  8.8522e-01,  1.3843e+00,  2.9665e+00,\n",
      "        -9.5727e-01,  3.5144e+00,  1.9116e+00,  1.3597e-01,  1.7972e+00,\n",
      "        -4.7913e-01,  2.9003e+00, -2.2984e-01, -1.2844e+00,  1.8899e+00,\n",
      "        -4.1327e-01,  1.1958e-01,  3.0923e-02, -1.1651e-01, -1.4314e+00,\n",
      "         3.1594e+00,  2.3780e+00, -2.7664e-01, -1.7475e+00,  1.3115e+00,\n",
      "         2.4655e-01, -3.5044e-01,  2.1113e+00, -1.8297e+00, -1.1087e+00,\n",
      "        -9.9829e-02, -1.5212e+00,  2.3628e+00, -4.4948e-01, -1.2155e+00,\n",
      "         1.9188e+00, -7.7816e-01, -1.0889e+00, -8.0812e-01, -7.5876e-01,\n",
      "         1.4348e+00,  1.0057e-01, -4.1049e-01,  4.3499e-01, -3.6414e-01,\n",
      "         3.2061e+00, -6.9293e-01, -5.6858e-01,  1.9224e-01, -1.4463e+00,\n",
      "         2.3658e+00, -3.3974e-01,  1.7170e+00,  1.3957e-01,  2.7401e+00,\n",
      "         1.6664e+00, -1.7369e+00,  3.4047e+00,  1.1343e+00, -6.2601e-01,\n",
      "         6.6805e-01,  2.2872e-01, -5.4435e-01, -5.6576e+00, -2.5126e-01,\n",
      "        -8.0014e-01, -2.5854e-01,  9.2482e-01, -3.6210e-01,  1.8531e+00,\n",
      "         2.2861e+00, -2.9500e-02, -6.9242e-01,  2.5382e+00,  1.6595e+00,\n",
      "        -3.5153e-02,  3.2955e+00,  1.6207e-02, -5.9805e-01,  2.3107e+00,\n",
      "        -2.8510e+00,  1.4486e+00, -6.3997e-01, -2.3957e-01, -5.3212e-01,\n",
      "        -3.2289e-01, -7.6050e-01,  2.0191e+00,  2.2691e+00,  2.8664e+00,\n",
      "        -7.7794e-01, -1.2298e+00, -1.0249e+00, -1.0115e+00,  7.4511e-01,\n",
      "         2.0119e-01, -6.5566e-01,  3.2685e+00, -2.2111e+00, -1.7637e+00,\n",
      "         3.0585e+00, -2.0839e+00,  3.6976e+00,  2.0589e+00, -7.6803e-01,\n",
      "        -4.8002e-01, -2.1268e-01,  1.3680e+00, -2.2101e-01, -8.8409e-01,\n",
      "        -2.7433e+00, -7.3310e-02, -2.1116e-01,  1.0108e+00,  2.6934e+00,\n",
      "         1.8324e-01, -5.5102e-01, -4.7406e-01,  2.7330e+00,  1.7914e+00,\n",
      "         1.1055e-02, -3.1515e-01, -5.9872e-01,  1.6499e+00,  7.0509e-01,\n",
      "         1.4999e+00, -1.7862e+00, -4.2784e-01,  1.6751e+00,  2.4284e+00,\n",
      "        -5.6564e-01,  1.3206e+00,  8.0587e-01,  3.1152e-01, -3.8162e-01,\n",
      "        -2.3918e+00,  1.3436e+00,  2.5397e+00, -4.4075e-01, -1.6574e+00,\n",
      "        -1.3146e+00, -6.6645e-01,  1.8572e+00,  3.3940e-01,  1.3196e+00,\n",
      "        -5.7763e-01,  1.6520e+00, -7.9059e-01, -1.9973e-01,  7.5620e-01,\n",
      "        -3.5685e+00,  3.2001e+00, -1.6207e+00, -4.2206e-01, -1.3511e+00,\n",
      "        -2.2452e-02, -1.5928e+00,  3.7997e+00, -5.5102e-01,  1.0380e+00,\n",
      "         3.5063e-01,  1.3918e+00, -2.2798e+00,  1.1646e+00, -2.6389e-01,\n",
      "         1.6539e+00,  2.0324e+00, -9.4660e-02, -1.1824e-01, -5.5950e-01,\n",
      "         1.9498e+00, -6.9491e-01, -1.0190e+00,  2.1081e+00, -1.7859e-01,\n",
      "         7.0710e-01,  2.0586e-01,  1.4852e+00, -8.4782e-01, -1.1726e+00,\n",
      "        -2.2889e+00, -3.4532e-01, -1.8030e+00, -1.9736e+00, -1.8118e-01,\n",
      "         4.0843e-02, -1.4087e+00,  2.6225e+00,  2.9756e+00, -8.5650e-01,\n",
      "         2.6463e+00, -9.9667e-01,  1.5259e+00, -2.4194e+00,  1.4721e+00,\n",
      "         2.8494e+00, -1.9958e+00, -4.6007e-01,  2.1858e+00, -7.4440e-01,\n",
      "         2.0101e+00, -3.5633e-01, -2.9955e-02,  8.4514e-01, -1.0201e+00,\n",
      "        -7.8239e-01,  1.9064e+00, -2.5018e+00, -4.3810e-02,  2.4750e+00,\n",
      "        -5.2080e-01, -1.8151e+00, -9.2955e-01, -1.2331e-01, -5.1146e-01,\n",
      "         4.5736e-02, -3.5504e-01, -2.0420e-01,  1.6542e+00,  2.1409e+00,\n",
      "        -5.0277e-01,  2.1685e-01,  1.3300e+00,  2.3531e+00,  1.2397e+00,\n",
      "        -2.5414e-02,  2.0403e+00, -4.9600e-01,  1.5962e-01,  1.4546e+00,\n",
      "         1.7370e+00,  4.0783e-01,  4.1097e-01,  1.7464e+00, -1.2419e+00,\n",
      "        -1.0191e-01, -2.1227e-01,  7.1643e-01,  1.4162e-01,  1.2842e+00,\n",
      "         1.9650e+00, -6.0583e-01, -5.9502e-01, -3.8868e-01, -3.0428e-02,\n",
      "         3.4434e-02, -1.9690e+00, -1.2923e+00, -1.0242e+00, -9.1736e-02,\n",
      "        -7.7134e-01, -5.7264e-01,  1.6698e+00, -7.3716e-01,  3.9366e+00,\n",
      "         1.7711e+00, -3.0052e-01,  2.8414e+00, -4.3783e-01,  3.3070e-04,\n",
      "        -1.0264e-01, -2.0695e-01, -8.8297e-02,  1.9835e+00, -2.9555e-01,\n",
      "         2.5530e+00, -3.6338e-01, -9.0099e-02, -7.4666e-01,  2.9481e+00,\n",
      "         1.5978e+00, -4.6199e-01, -2.8903e-01,  1.3783e-01, -5.7364e-01,\n",
      "        -1.6024e+00,  3.2721e+00,  1.5761e+00, -5.5855e-01, -8.9702e-01,\n",
      "        -3.0992e-01,  1.6643e+00, -6.4872e-01,  4.0943e+00,  3.1088e+00,\n",
      "        -4.9226e-01, -1.5756e+00, -9.1734e-01, -1.3183e+00, -2.2485e+00,\n",
      "        -5.4741e-01,  1.7179e+00, -4.6363e-01,  2.1230e+00,  2.6671e+00,\n",
      "        -1.0642e+00,  6.0945e-01, -1.0113e+00,  5.8231e-02, -4.7532e-01,\n",
      "        -7.9154e-01, -1.7060e-01,  2.9550e-01,  1.0027e+00, -9.3423e-01,\n",
      "        -4.4962e-01,  3.3124e+00, -4.1193e-01,  2.4519e+00, -2.6214e-01,\n",
      "        -8.4228e-01, -1.7479e-01, -5.4038e-01,  4.1966e-01, -1.0613e+00,\n",
      "        -1.5100e+00, -1.0039e+00, -3.3389e+00, -1.0138e-01,  8.3347e-01,\n",
      "        -6.8873e-01, -1.4933e+00, -2.7640e-01, -3.1441e-01, -1.0977e+00,\n",
      "         1.5740e+00, -3.6987e-01, -2.7199e-01,  1.1999e-01, -7.5947e-01,\n",
      "        -7.7273e-02,  1.4720e-01, -6.8978e-01,  1.7565e+00,  1.8444e+00,\n",
      "        -4.3870e-01, -7.4424e-01,  2.9132e+00, -5.8483e-01, -6.0143e-01,\n",
      "         5.9293e-01, -1.0403e+00, -1.6899e+00,  2.1354e+00, -8.1832e-01,\n",
      "        -9.8220e-02, -1.4241e-01,  2.4876e+00,  1.5645e+00, -1.4373e+00,\n",
      "        -7.4741e-01,  2.7101e+00, -3.9443e-02, -8.0224e-01,  2.0639e+00,\n",
      "        -3.2980e-01,  2.6575e+00, -1.1798e+00, -9.4915e-01,  2.1309e+00,\n",
      "        -3.5050e-01, -1.2180e+00, -3.1273e-01,  3.2632e-01,  6.5155e-01,\n",
      "         3.5122e-01, -5.9713e-01, -1.3647e+00,  1.2823e-01, -5.4141e-01,\n",
      "        -3.8496e-01,  1.4676e+00, -3.5638e-01,  2.9907e+00,  5.2175e-01,\n",
      "        -6.0225e-01, -1.1133e+00, -7.8676e-01,  1.3281e+00, -1.6679e-01,\n",
      "         1.3477e+00,  2.5180e+00,  2.7822e+00,  9.9954e-01, -3.4648e-01,\n",
      "        -8.7015e-02, -4.4609e-01,  4.2189e+00, -5.3846e-01,  2.4236e+00,\n",
      "         3.6758e-02, -4.4750e-01, -1.9632e+00, -3.9972e-02,  3.0201e-01,\n",
      "         2.5163e+00, -6.2884e-01,  9.0364e-02,  1.8523e+00, -5.7828e-01],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.1.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.1.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.2.weight\n",
      "Weights: tensor([[[[-0.0730]],\n",
      "\n",
      "         [[-0.1115]],\n",
      "\n",
      "         [[ 0.0360]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0826]],\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[-0.0478]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376]],\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[-0.1792]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1503]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[-0.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1230]],\n",
      "\n",
      "         [[-0.0447]],\n",
      "\n",
      "         [[ 0.0064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[-0.0642]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0545]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         [[-0.0136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0252]],\n",
      "\n",
      "         [[-0.1260]],\n",
      "\n",
      "         [[ 0.1013]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0480]],\n",
      "\n",
      "         [[-0.0107]],\n",
      "\n",
      "         [[-0.0183]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0914]],\n",
      "\n",
      "         [[ 0.0399]],\n",
      "\n",
      "         [[-0.0351]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0170]],\n",
      "\n",
      "         [[ 0.0420]],\n",
      "\n",
      "         [[-0.1040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0555]],\n",
      "\n",
      "         [[-0.0144]],\n",
      "\n",
      "         [[ 0.0324]]]], device='cuda:0')\n",
      "Shape: torch.Size([320, 960, 1, 1])\n",
      "\n",
      "Layer: features.17.conv.2.param_quantizers.weight.min\n",
      "Weights: -0.7995365262031555\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.2.param_quantizers.weight.max\n",
      "Weights: 0.7932901382446289\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.3.weight\n",
      "Weights: tensor([2.0997, 2.3501, 2.0975, 2.0840, 2.2689, 2.1707, 2.0478, 2.1034, 2.2229,\n",
      "        2.2575, 2.3291, 2.1630, 2.1499, 2.2988, 2.0962, 2.0990, 2.1443, 2.2327,\n",
      "        2.1570, 2.1169, 2.2002, 2.1186, 2.1057, 2.1018, 2.2704, 2.0499, 2.5515,\n",
      "        2.2089, 2.0757, 2.1090, 2.1943, 2.1196, 2.2852, 2.1379, 2.1092, 2.2696,\n",
      "        2.1809, 2.1484, 2.1548, 2.1028, 2.0968, 2.1264, 2.0294, 2.2025, 2.1333,\n",
      "        2.0593, 2.1518, 2.0779, 2.0908, 2.1288, 2.1184, 2.1336, 2.2105, 2.0712,\n",
      "        2.1533, 2.4576, 2.1617, 2.5691, 2.0904, 2.4347, 2.0480, 2.1241, 2.1132,\n",
      "        2.1749, 2.2247, 2.1309, 2.0916, 2.0485, 2.0984, 2.2191, 2.1322, 2.1173,\n",
      "        2.0714, 2.5145, 2.0877, 2.0870, 2.5766, 2.0989, 2.0725, 2.1561, 2.1959,\n",
      "        2.1340, 2.0584, 2.6102, 2.1185, 2.0304, 2.1545, 2.0475, 2.2402, 2.2299,\n",
      "        2.2215, 2.0758, 2.0969, 2.2440, 2.1207, 2.1253, 2.6521, 2.1763, 2.3153,\n",
      "        2.1377, 2.1752, 2.1843, 2.1186, 2.0781, 2.0438, 2.1649, 2.3639, 2.1702,\n",
      "        2.5182, 2.1061, 2.1844, 2.2463, 2.2147, 2.2579, 2.2200, 2.0596, 2.1904,\n",
      "        2.2365, 2.2848, 2.1153, 2.1187, 2.0953, 2.2802, 2.0718, 2.0794, 2.0946,\n",
      "        2.0985, 2.1557, 2.1356, 2.1666, 2.1791, 2.1284, 2.4955, 2.0024, 2.0482,\n",
      "        2.2878, 2.1199, 2.0794, 2.0782, 2.1353, 2.1516, 2.6806, 2.2556, 2.2250,\n",
      "        2.0807, 2.2981, 2.1040, 2.2671, 2.1884, 2.1016, 2.4998, 2.9493, 2.1977,\n",
      "        2.0818, 2.1222, 2.2132, 2.2133, 2.1224, 2.0696, 2.1448, 2.1046, 2.2274,\n",
      "        2.1585, 2.2109, 2.3310, 2.2450, 2.0847, 2.1535, 2.1182, 2.0715, 2.1150,\n",
      "        2.1223, 2.2013, 2.1173, 2.0698, 2.1985, 2.0591, 2.0856, 2.1492, 2.1087,\n",
      "        2.1255, 2.1582, 2.1539, 2.1297, 2.1382, 2.1514, 2.1663, 2.1545, 2.2590,\n",
      "        2.3771, 2.5504, 2.2019, 2.0621, 2.2981, 2.9265, 2.4147, 2.4635, 2.2865,\n",
      "        2.0711, 2.1095, 2.1289, 2.0450, 2.1147, 2.4937, 2.2396, 2.0974, 2.1513,\n",
      "        2.0547, 2.1554, 2.0902, 2.1117, 2.0988, 2.1667, 2.0688, 2.1813, 2.0871,\n",
      "        2.2603, 2.0952, 2.8831, 2.2839, 2.1099, 2.1480, 2.0930, 2.0597, 2.2453,\n",
      "        4.1119, 2.8073, 2.1591, 2.1091, 2.1374, 2.0817, 2.0908, 2.1125, 2.3781,\n",
      "        2.1571, 2.2223, 2.2264, 2.1000, 2.1025, 2.1951, 2.7233, 2.1006, 2.2223,\n",
      "        2.1726, 2.0763, 2.0699, 2.1648, 2.2990, 2.1629, 2.1034, 2.1681, 2.1144,\n",
      "        2.0961, 2.8421, 2.0972, 2.0938, 2.2313, 2.1416, 2.6339, 2.2152, 2.1601,\n",
      "        2.1836, 2.1412, 2.1457, 2.1640, 2.1070, 2.1725, 2.0901, 2.1398, 2.1326,\n",
      "        2.2038, 2.0924, 2.4771, 2.0133, 2.1479, 2.1326, 2.1298, 2.1396, 2.0593,\n",
      "        2.0883, 2.3135, 2.1199, 3.7568, 2.1863, 2.1480, 2.3684, 2.1404, 2.0723,\n",
      "        2.2841, 2.0521, 2.0992, 2.2620, 2.1073, 2.2883, 2.1213, 2.1007, 2.7023,\n",
      "        2.1148, 2.1033, 2.0513, 2.3512, 2.0712, 2.4376, 2.1533, 2.3549, 2.1412,\n",
      "        2.3335, 2.1605, 2.1525, 2.1116, 2.1446, 2.1204, 2.1206, 2.2174, 2.1093,\n",
      "        2.1008, 2.1310, 2.1179, 2.1530, 2.5544], device='cuda:0')\n",
      "Shape: torch.Size([320])\n",
      "\n",
      "Layer: features.17.conv.3.bias\n",
      "Weights: tensor([ 2.3470e-07, -4.3375e-06,  5.9915e-07,  1.3464e-06, -2.1303e-06,\n",
      "         8.0569e-07,  1.3114e-06, -9.6028e-07, -9.6011e-07, -1.2917e-06,\n",
      "         3.9069e-06,  9.5997e-07,  2.4035e-07, -1.9699e-07, -8.8980e-07,\n",
      "         1.3806e-06,  8.0579e-07, -2.1623e-06,  1.0374e-06,  1.5600e-06,\n",
      "        -5.7231e-07,  6.6681e-07, -8.6863e-07, -6.6899e-07,  1.0050e-06,\n",
      "        -1.2817e-06,  5.5471e-06,  1.8290e-06, -1.5945e-06,  4.3203e-07,\n",
      "        -2.2319e-06, -2.0674e-07, -5.0910e-06, -6.5491e-07, -3.0063e-07,\n",
      "         9.9739e-07, -6.3074e-07, -3.2691e-06, -1.3533e-06, -9.1251e-07,\n",
      "        -9.8658e-07,  1.3592e-06,  7.1932e-07, -2.1115e-06, -4.8499e-07,\n",
      "         1.1597e-06,  2.3174e-06, -4.9887e-07, -3.9462e-07,  1.8767e-07,\n",
      "         8.7762e-07, -1.1877e-06,  3.4507e-06,  6.5551e-07,  2.1193e-07,\n",
      "        -8.8026e-07, -3.2721e-07, -3.7043e-06, -1.7423e-07, -1.4898e-06,\n",
      "        -4.4614e-07,  7.5661e-07,  9.8600e-07,  4.5519e-07, -2.7407e-06,\n",
      "        -3.9109e-07, -1.4842e-06, -4.4029e-07, -1.0285e-06, -6.6177e-07,\n",
      "         2.1115e-07,  1.0009e-06,  1.2127e-06, -5.3947e-06,  1.4753e-06,\n",
      "         5.4616e-07,  5.0176e-06, -1.1087e-06, -1.4895e-06,  7.1702e-07,\n",
      "        -5.8833e-08,  1.3734e-06, -1.2076e-06,  4.5602e-06,  2.3537e-07,\n",
      "         7.9268e-07,  1.8918e-06,  1.8664e-06, -2.9002e-06,  1.9211e-06,\n",
      "        -2.2850e-06, -9.9747e-08,  5.3888e-07, -2.7694e-06,  1.2010e-06,\n",
      "         6.1381e-07, -3.5916e-06, -1.5972e-06,  3.4351e-06, -1.3014e-06,\n",
      "        -8.0027e-07,  2.5128e-06,  2.1826e-07,  7.1546e-08, -7.1366e-07,\n",
      "         1.7182e-06, -2.0250e-06,  5.7898e-07, -1.6469e-06, -1.0810e-06,\n",
      "        -1.4821e-06,  4.1470e-07,  1.6665e-06,  5.2718e-07, -1.9257e-06,\n",
      "        -1.5452e-06,  4.3677e-06, -1.8553e-06, -1.6233e-06,  9.0238e-08,\n",
      "         1.0989e-07, -1.3810e-06, -3.1943e-06,  2.0860e-07,  2.8254e-07,\n",
      "         5.3708e-07, -2.1459e-07, -1.0804e-06,  1.5085e-06,  8.3130e-07,\n",
      "        -8.1279e-07,  1.1531e-06, -7.9237e-08,  3.6651e-06, -1.0080e-06,\n",
      "         4.7506e-06,  1.7277e-07,  9.6104e-07,  7.2058e-07, -5.3148e-07,\n",
      "        -7.8146e-07,  3.7612e-07,  1.0578e-06, -3.0038e-06, -1.6283e-06,\n",
      "        -1.6374e-06, -1.0985e-06,  2.3923e-06, -7.3715e-07,  2.0854e-06,\n",
      "         2.2279e-06,  7.9412e-06, -2.4028e-06, -8.8342e-07,  7.3430e-07,\n",
      "         3.0134e-06, -1.5578e-06, -3.7246e-07, -7.9232e-07,  1.1712e-06,\n",
      "         1.9168e-06, -2.6310e-07, -4.2978e-06,  8.2528e-07,  9.5469e-07,\n",
      "         9.6557e-07, -4.1894e-07, -3.2758e-07,  1.2228e-06,  1.2405e-06,\n",
      "        -5.8992e-07, -1.5111e-06,  1.0637e-06, -6.3514e-07,  2.2522e-07,\n",
      "         4.6418e-07, -9.8048e-07, -7.8535e-07,  8.1447e-07, -5.9195e-07,\n",
      "         5.8919e-07,  1.3499e-06,  5.7600e-07,  3.8153e-07,  3.4492e-07,\n",
      "        -1.3974e-06, -1.4052e-06, -2.1195e-07,  3.1420e-06,  3.9576e-06,\n",
      "        -2.2742e-07,  1.8039e-06, -6.6738e-07, -4.6434e-07, -8.3817e-06,\n",
      "         1.2701e-06, -1.0735e-06, -5.6933e-07, -3.2007e-07, -8.7497e-07,\n",
      "        -7.1661e-07,  4.0771e-06, -7.1818e-07, -1.6768e-06, -5.5563e-07,\n",
      "        -6.2959e-07,  4.9914e-07, -4.0235e-06,  1.3047e-06,  5.0963e-07,\n",
      "         2.6750e-08,  1.8550e-06,  1.2023e-06,  2.9131e-07,  1.6690e-06,\n",
      "        -1.8330e-06,  1.4446e-06, -6.2570e-07,  8.7794e-06,  1.0381e-06,\n",
      "         2.0755e-07,  9.1790e-07, -1.4399e-06,  5.5219e-07, -1.7848e-06,\n",
      "         1.2225e-05,  1.4915e-06, -6.4929e-07, -3.8240e-08,  5.5057e-07,\n",
      "        -5.8242e-07, -4.9635e-07,  2.4773e-07,  8.5991e-07,  1.6944e-06,\n",
      "         2.4711e-06,  3.5879e-07, -3.8817e-07, -8.7023e-07,  1.3631e-06,\n",
      "        -1.3116e-06,  6.7915e-07, -1.2116e-06,  9.5260e-08,  7.9367e-08,\n",
      "        -1.8464e-07,  6.4646e-07, -2.8743e-06, -1.3700e-07, -3.2181e-06,\n",
      "         8.4600e-07,  3.3610e-07,  1.3817e-06,  6.3797e-06, -3.8336e-07,\n",
      "        -7.7952e-07, -1.2989e-07,  1.2214e-07,  8.1034e-07, -9.0381e-07,\n",
      "        -2.5213e-06, -4.0345e-07, -1.1255e-06,  1.0691e-06,  4.3110e-07,\n",
      "        -1.5333e-06,  5.4066e-07, -1.9988e-07, -1.9016e-06, -4.1119e-07,\n",
      "        -1.5995e-06,  2.0356e-06, -2.8742e-06,  2.7677e-06,  8.1113e-07,\n",
      "        -7.3807e-07, -5.4904e-07,  1.3343e-06, -5.2305e-07,  2.5440e-06,\n",
      "        -3.1623e-07,  1.1611e-06,  7.2345e-06, -1.7759e-06,  2.1388e-07,\n",
      "        -4.8484e-07,  1.3002e-06, -2.5207e-07, -2.7678e-06,  2.4762e-07,\n",
      "        -6.3246e-07,  2.1116e-07, -4.1300e-06, -2.2052e-06,  6.4271e-07,\n",
      "        -2.5188e-06, -3.6479e-06,  4.6466e-07,  4.1034e-07, -1.2004e-06,\n",
      "         3.2650e-06,  6.6602e-07, -1.9230e-06,  5.8200e-07, -2.1599e-06,\n",
      "        -2.6744e-06, -2.3687e-06, -1.0030e-07, -4.5833e-07,  7.5728e-07,\n",
      "         1.1909e-06, -7.1843e-07,  6.2217e-07,  2.0658e-06,  1.0208e-06,\n",
      "        -6.9387e-07,  7.8042e-07,  5.9316e-07,  5.4229e-07,  4.5152e-06],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([320])\n",
      "\n",
      "Layer: features.17.conv.3.output_quantizers.0.min\n",
      "Weights: -14.63361644744873\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.17.conv.3.output_quantizers.0.max\n",
      "Weights: 21.08059310913086\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.18.0.weight\n",
      "Weights: tensor([[[[ 0.0456]],\n",
      "\n",
      "         [[ 0.0229]],\n",
      "\n",
      "         [[-0.0672]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0022]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         [[-0.1942]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0343]],\n",
      "\n",
      "         [[-0.0669]],\n",
      "\n",
      "         [[ 0.0341]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[-0.0280]],\n",
      "\n",
      "         [[ 0.0235]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0421]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         [[ 0.0335]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0326]],\n",
      "\n",
      "         [[ 0.0287]],\n",
      "\n",
      "         [[ 0.0018]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0238]],\n",
      "\n",
      "         [[ 0.0562]],\n",
      "\n",
      "         [[ 0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0420]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         [[-0.0487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0202]],\n",
      "\n",
      "         [[ 0.0903]],\n",
      "\n",
      "         [[-0.0486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0016]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.0428]]],\n",
      "\n",
      "\n",
      "        [[[-0.0438]],\n",
      "\n",
      "         [[-0.0728]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0581]],\n",
      "\n",
      "         [[-0.0106]],\n",
      "\n",
      "         [[ 0.0109]]]], device='cuda:0')\n",
      "Shape: torch.Size([1280, 320, 1, 1])\n",
      "\n",
      "Layer: features.18.0.param_quantizers.weight.min\n",
      "Weights: -0.42877429723739624\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.18.0.param_quantizers.weight.max\n",
      "Weights: 0.4254244863986969\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.18.1.weight\n",
      "Weights: tensor([3.8923, 3.7667, 3.3817,  ..., 3.5836, 3.9387, 3.2627], device='cuda:0')\n",
      "Shape: torch.Size([1280])\n",
      "\n",
      "Layer: features.18.1.bias\n",
      "Weights: tensor([-5.1805, -5.2606, -4.3261,  ..., -4.9339, -5.5779, -4.2295],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([1280])\n",
      "\n",
      "Layer: features.18.2.output_quantizers.0.min\n",
      "Weights: 0.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: features.18.2.output_quantizers.0.max\n",
      "Weights: 6.0\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: classifier.1.weight\n",
      "Weights: tensor([[-0.0309,  0.0898,  0.0147,  ..., -0.0181, -0.0262,  0.1674],\n",
      "        [-0.0318, -0.0282, -0.0380,  ..., -0.0220,  0.0125, -0.0089],\n",
      "        [ 0.0143, -0.0222, -0.0077,  ..., -0.0173,  0.0577, -0.0649],\n",
      "        ...,\n",
      "        [ 0.0538,  0.0217, -0.0798,  ..., -0.0052, -0.0263, -0.0141],\n",
      "        [-0.0663, -0.0272,  0.0635,  ...,  0.0210, -0.0556,  0.0413],\n",
      "        [-0.0185,  0.0414, -0.0821,  ..., -0.0369, -0.0260, -0.0199]],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([1000, 1280])\n",
      "\n",
      "Layer: classifier.1.bias\n",
      "Weights: tensor([ 2.1759e-02, -3.8201e-02,  8.6484e-02,  1.3767e-01,  1.8519e-01,\n",
      "         5.6217e-02,  3.5687e-02, -4.7612e-02, -1.0376e-01, -7.7673e-02,\n",
      "         6.5267e-03, -3.6171e-02, -7.4770e-02,  4.9748e-02,  2.3051e-02,\n",
      "        -8.1528e-02, -4.4763e-02, -6.6116e-02,  9.5336e-02,  4.2249e-03,\n",
      "         8.4689e-02,  1.3176e-01,  7.1000e-02, -2.1138e-02, -6.4721e-02,\n",
      "        -3.1600e-02,  9.2663e-02,  3.5424e-02,  8.1185e-03, -2.2670e-02,\n",
      "        -1.3106e-02, -5.3038e-02,  2.8974e-02, -3.3529e-02,  4.0875e-02,\n",
      "        -5.2171e-02, -9.1241e-02,  1.7495e-02, -9.8909e-03, -1.1621e-01,\n",
      "        -2.3539e-02,  7.0240e-02,  1.4311e-02, -1.7219e-01,  8.9669e-03,\n",
      "        -7.8850e-03,  6.6452e-02, -1.5262e-01, -1.7436e-02,  4.4306e-02,\n",
      "         5.9609e-03, -2.5121e-01,  8.3942e-02,  2.7448e-03, -1.4524e-02,\n",
      "         5.3815e-02, -4.1285e-02,  2.3073e-02,  5.0124e-02,  6.0352e-02,\n",
      "         6.4563e-02, -6.4193e-02, -2.5406e-02, -1.0834e-01,  2.3466e-03,\n",
      "         9.8597e-02,  2.6912e-02,  4.6962e-02,  8.3510e-02,  7.0992e-03,\n",
      "         1.5721e-02, -3.8679e-02,  5.3070e-02,  6.4631e-02,  7.8723e-02,\n",
      "         7.1729e-02, -7.7484e-02,  6.2620e-02,  6.0857e-02, -5.1906e-02,\n",
      "        -1.0443e-02,  9.8344e-04, -4.5740e-02, -9.3690e-02, -4.9720e-02,\n",
      "         1.9576e-02, -5.1810e-02, -4.9939e-02, -1.1830e-01,  5.3034e-02,\n",
      "        -3.9437e-02, -1.1271e-01,  8.1097e-02, -1.1569e-01, -5.0654e-02,\n",
      "         7.6500e-02, -3.1321e-02, -2.6480e-02,  9.3492e-03, -3.3137e-02,\n",
      "        -2.5618e-02,  1.0236e-02,  8.7786e-02,  1.1769e-01, -3.1551e-02,\n",
      "        -1.0335e-02,  2.9418e-02,  7.1980e-02,  3.8963e-02,  6.4526e-03,\n",
      "         8.0937e-03,  2.3551e-01, -2.4858e-02, -1.4636e-01, -3.6966e-02,\n",
      "        -2.3484e-02, -5.8476e-03, -4.6393e-02, -3.7587e-02, -6.7214e-03,\n",
      "        -7.7484e-02, -8.3600e-02, -1.1597e-01, -1.3936e-01, -6.8658e-02,\n",
      "        -8.2619e-02,  3.8626e-02, -3.5660e-02, -2.8984e-02,  2.3736e-02,\n",
      "         4.9350e-02,  7.3211e-02,  2.6313e-02, -3.6207e-02, -6.9666e-02,\n",
      "        -8.3124e-02, -7.1829e-02,  6.6844e-02, -7.5483e-03, -3.7575e-03,\n",
      "         2.9821e-02,  4.6552e-02,  9.1609e-02,  5.1975e-02, -4.9553e-02,\n",
      "        -1.4043e-02,  1.9281e-03,  5.6804e-02,  5.7567e-02,  1.2884e-01,\n",
      "        -4.6818e-02, -9.1833e-02, -7.9148e-02,  6.7961e-02,  2.2747e-03,\n",
      "         2.9198e-02,  3.7929e-02, -4.9269e-02, -9.2705e-02,  5.0969e-02,\n",
      "        -1.7532e-01,  3.7426e-02,  6.7318e-02,  3.1232e-02, -1.3836e-01,\n",
      "        -8.6507e-02, -9.4722e-02, -1.2160e-01,  7.0386e-02, -1.9250e-02,\n",
      "        -9.8683e-05,  1.8012e-02, -2.3702e-02, -2.2758e-02,  1.5100e-02,\n",
      "        -1.0245e-01, -6.5812e-02, -4.6851e-02,  4.1509e-02, -1.3821e-02,\n",
      "         2.3694e-04, -3.4171e-02, -4.4291e-02,  1.4750e-02, -2.4416e-03,\n",
      "        -9.1880e-03, -7.9510e-02,  1.8713e-02, -7.1789e-02, -1.9625e-02,\n",
      "        -4.1965e-02, -8.0849e-03,  9.6346e-02, -4.2456e-02,  3.8668e-03,\n",
      "         7.6865e-02,  1.5238e-02, -3.6998e-03, -7.2717e-02,  6.0691e-02,\n",
      "         1.6882e-02,  2.0819e-02,  1.5493e-02,  3.0001e-02,  5.6379e-02,\n",
      "         4.4300e-02, -3.3139e-02, -2.9747e-02, -5.7565e-02,  7.2294e-03,\n",
      "        -5.7491e-02, -1.0030e-02, -4.7524e-02, -1.6543e-02, -1.2909e-02,\n",
      "        -2.4050e-02, -5.7157e-02,  2.6132e-02,  4.5742e-02, -7.1283e-02,\n",
      "        -1.5704e-02, -6.8699e-02,  3.3962e-02,  9.2513e-02, -1.5126e-02,\n",
      "         3.6705e-02, -1.9274e-02,  3.5817e-02,  3.7677e-02,  4.3234e-03,\n",
      "        -1.6532e-03, -1.3130e-02,  2.2826e-02,  4.6023e-02,  8.0874e-02,\n",
      "        -2.6528e-02,  4.1537e-02,  4.5623e-02,  1.7410e-02,  6.4491e-02,\n",
      "        -2.7972e-05,  2.5951e-02, -8.8895e-03,  3.7338e-03, -3.1510e-02,\n",
      "         6.6573e-02, -6.1966e-02,  4.0275e-02,  2.9269e-02, -1.5630e-02,\n",
      "         1.4343e-02,  3.0889e-02,  5.0117e-02, -6.1998e-02, -8.1080e-03,\n",
      "        -3.5373e-02,  2.2778e-03,  1.3711e-02,  5.4320e-02,  5.6836e-02,\n",
      "         3.4657e-02,  2.6575e-02, -9.1060e-02, -4.8084e-02, -5.1528e-02,\n",
      "        -3.4631e-02,  1.3081e-02, -8.5762e-02, -2.0387e-01,  1.1557e-02,\n",
      "         9.9856e-02,  1.2320e-02,  3.8506e-02,  5.4058e-02, -3.5820e-04,\n",
      "        -6.5856e-02,  2.9529e-02, -1.7874e-02,  2.9289e-02,  8.7353e-02,\n",
      "        -4.9136e-03,  3.5807e-02, -6.3528e-02,  1.6685e-02,  6.1764e-02,\n",
      "         2.1796e-02, -4.7948e-03, -2.9393e-03,  2.9731e-02,  1.1207e-01,\n",
      "         3.8425e-02, -7.0862e-02, -6.5369e-02, -7.6716e-03, -2.0744e-02,\n",
      "         1.0158e-02,  7.1974e-02,  9.1440e-02,  2.8697e-02,  2.6167e-02,\n",
      "        -8.2433e-03,  1.0477e-02, -1.8223e-02, -1.3806e-01, -1.3427e-03,\n",
      "         1.1035e-01, -7.2570e-02, -1.9594e-02, -1.7605e-02, -6.6978e-02,\n",
      "         5.7448e-02, -8.4071e-02,  3.1210e-04,  8.1264e-02,  2.3168e-02,\n",
      "         4.3522e-02, -7.4895e-02,  3.5869e-02,  1.1987e-01, -6.3634e-02,\n",
      "         4.7128e-02, -6.8041e-02, -4.3383e-02, -9.0246e-03,  1.8648e-02,\n",
      "        -1.5107e-03, -6.9079e-02, -9.4028e-02, -8.6315e-02,  1.0699e-01,\n",
      "         4.4169e-02, -6.3228e-03,  6.1734e-02, -2.1603e-02, -3.2142e-02,\n",
      "        -1.0470e-02,  1.1779e-01, -5.4961e-02, -1.3106e-01,  2.3816e-02,\n",
      "        -3.0674e-02, -7.7992e-02,  2.2358e-02,  2.5552e-02,  3.0577e-02,\n",
      "        -1.0091e-01,  8.4993e-03,  8.5013e-02, -8.6217e-02, -3.1999e-03,\n",
      "        -2.1920e-02,  4.7596e-02,  6.5499e-02,  6.0879e-02,  1.7218e-03,\n",
      "        -1.9187e-01, -2.2729e-02,  3.2150e-03,  7.8484e-02,  1.0896e-01,\n",
      "        -5.5114e-02,  3.2676e-02, -1.3837e-02, -5.4210e-02, -6.0103e-02,\n",
      "         3.8518e-02,  2.3118e-02,  5.5637e-02,  7.7218e-02,  9.7587e-02,\n",
      "        -1.6902e-02, -2.5875e-02,  4.7955e-03,  6.2340e-02,  2.0932e-02,\n",
      "        -7.0329e-03,  1.6159e-02, -8.9607e-02,  7.6677e-02,  1.1844e-01,\n",
      "        -3.2178e-02,  4.3110e-02, -8.8705e-03, -3.1841e-03, -2.5350e-02,\n",
      "         1.0359e-01,  1.2105e-01, -4.3323e-02,  4.3707e-02, -4.3305e-02,\n",
      "        -9.8725e-02, -1.7726e-02, -6.9717e-02,  1.0889e-02, -3.5041e-02,\n",
      "        -4.9308e-02, -7.8309e-02, -1.3301e-01,  1.7833e-02,  6.2831e-02,\n",
      "         9.8556e-03, -3.1123e-02, -8.7687e-03,  3.7695e-02,  5.2987e-02,\n",
      "         7.1595e-02, -7.9733e-04, -2.6659e-02, -2.0375e-01,  2.7824e-02,\n",
      "         1.6127e-02, -4.7017e-02, -5.1233e-02,  6.9227e-02,  1.2703e-02,\n",
      "         2.9774e-03,  1.1040e-01,  5.2093e-02,  9.0800e-02,  7.4486e-02,\n",
      "        -4.5281e-02,  9.8721e-03,  1.1958e-02, -1.5291e-02,  5.4391e-02,\n",
      "         7.8265e-02, -7.7085e-03,  3.7656e-03, -1.5114e-01,  8.7733e-02,\n",
      "         8.2804e-02,  5.2043e-02, -3.1355e-03, -5.6770e-02,  1.8722e-02,\n",
      "         2.8936e-02, -8.5516e-03,  4.2825e-02,  5.5554e-02, -2.5874e-02,\n",
      "         1.6024e-02,  4.0612e-02, -7.5031e-02, -1.5514e-02,  1.0229e-02,\n",
      "         1.2989e-01,  2.5244e-02, -1.2789e-01, -4.9721e-02, -3.5407e-02,\n",
      "        -5.1666e-02, -4.5894e-02, -1.4511e-02,  6.2196e-02,  1.0736e-02,\n",
      "         2.6042e-03, -1.0734e-01,  9.3253e-02,  4.0905e-02,  1.8040e-02,\n",
      "         4.7686e-02,  5.1363e-02, -4.4714e-02,  2.4218e-02, -3.2573e-02,\n",
      "         9.5893e-02, -6.2473e-03, -2.0327e-03, -3.0909e-04, -7.0400e-02,\n",
      "         4.7608e-02, -9.1080e-02, -6.2095e-02,  3.4302e-02, -1.3073e-02,\n",
      "         3.2697e-02, -1.1750e-01, -3.9678e-02, -2.4665e-02,  4.8345e-03,\n",
      "         3.4342e-02, -4.4545e-02,  1.5457e-03,  1.1384e-02, -6.1163e-02,\n",
      "        -5.4197e-03,  4.4379e-02,  2.7037e-02,  4.2701e-02,  4.7243e-02,\n",
      "        -7.4355e-02, -9.5610e-02, -3.4513e-04,  1.4558e-01,  7.1724e-04,\n",
      "         3.8392e-02, -5.1980e-02,  7.6596e-03, -1.0494e-01, -4.1825e-04,\n",
      "         2.0539e-01, -1.0602e-02, -3.3545e-02, -1.3269e-02, -2.9299e-02,\n",
      "        -1.6159e-02,  7.8544e-02, -6.0047e-02,  1.1704e-01, -3.1155e-02,\n",
      "         4.1310e-03,  6.4262e-03,  1.7818e-02,  1.7642e-02, -5.5694e-02,\n",
      "         1.9591e-02, -1.5116e-02, -5.4255e-02, -1.0799e-01,  8.0096e-02,\n",
      "        -3.7383e-02, -4.8735e-02,  7.5206e-03,  5.0670e-02, -7.0732e-02,\n",
      "        -9.8109e-02,  2.4151e-02,  2.5499e-02, -9.0664e-02,  9.2635e-02,\n",
      "         1.0295e-01, -8.3082e-02,  4.8536e-02,  1.1743e-01,  1.8717e-02,\n",
      "        -4.1570e-02,  4.9754e-02,  4.3435e-02, -3.2104e-02,  3.0354e-02,\n",
      "         1.1755e-03, -6.4568e-02,  2.8158e-02, -2.2090e-02, -8.8716e-02,\n",
      "        -4.7254e-02, -6.0459e-02,  3.0191e-02,  1.8739e-02,  4.4473e-02,\n",
      "        -5.6224e-02, -5.6793e-03,  4.6966e-03,  9.4855e-02,  1.3508e-02,\n",
      "        -8.4364e-02,  3.6586e-03,  7.2912e-02, -4.0470e-03,  8.4746e-03,\n",
      "        -1.5605e-01, -8.7538e-02, -1.1369e-01,  5.7046e-02, -4.0967e-02,\n",
      "        -7.8850e-03, -3.0861e-02, -1.7784e-02, -1.1933e-01, -9.9079e-02,\n",
      "        -7.1401e-02, -5.9642e-02,  6.4467e-02,  2.7444e-02,  7.7600e-02,\n",
      "        -4.7095e-03, -3.2259e-02, -4.9815e-02, -2.4038e-02, -6.1542e-02,\n",
      "        -3.2030e-02,  1.2647e-04,  8.8844e-02,  1.6196e-02,  9.0690e-04,\n",
      "        -4.9813e-02, -8.5015e-02,  4.8673e-02, -9.0798e-02, -4.6787e-02,\n",
      "        -1.2712e-02,  3.6751e-02, -2.3141e-02,  8.0363e-02, -7.0418e-02,\n",
      "        -2.6232e-02, -9.4983e-02,  6.1626e-02, -3.6305e-03, -4.1558e-02,\n",
      "         1.1837e-01,  2.5935e-02,  1.1315e-01, -1.0301e-01, -1.3866e-02,\n",
      "         8.7182e-02, -9.2959e-02,  1.0768e-01,  1.1268e-01, -1.0893e-01,\n",
      "        -1.5261e-02, -9.6170e-02, -1.0470e-01, -3.4821e-02, -8.4202e-02,\n",
      "        -2.6397e-03, -5.3756e-02,  1.0055e-01,  2.7442e-02, -2.9799e-02,\n",
      "         5.6761e-02,  4.1616e-02,  1.5896e-01,  4.4687e-02,  4.3399e-02,\n",
      "        -7.5085e-02,  6.9780e-02, -4.8791e-02, -1.5854e-02,  8.0413e-02,\n",
      "        -6.8915e-03, -2.4046e-02,  9.2444e-02,  4.5542e-02, -3.7568e-03,\n",
      "        -5.2385e-02, -1.6288e-02, -1.0512e-01,  6.1213e-02, -1.0220e-02,\n",
      "         1.5200e-01, -3.3409e-02, -5.2192e-02, -6.4991e-02,  2.0251e-01,\n",
      "         1.7485e-02,  7.7578e-02, -2.1579e-02,  1.7711e-01,  1.0416e-01,\n",
      "         1.0483e-01,  1.1128e-02,  4.8838e-02,  2.4974e-02, -4.5526e-02,\n",
      "         1.0087e-01, -7.3625e-03,  1.3869e-02, -2.5341e-02,  8.9742e-02,\n",
      "         1.6953e-02, -7.1514e-02,  1.7016e-02,  3.4162e-02,  3.8251e-02,\n",
      "         1.3468e-02, -9.0501e-04, -6.1143e-02, -5.4297e-03,  4.3234e-02,\n",
      "        -5.3631e-02, -4.7698e-02, -2.2575e-02,  8.3111e-02, -2.0549e-02,\n",
      "        -1.0866e-01, -1.5742e-01,  1.3322e-01, -5.5099e-02,  9.4562e-03,\n",
      "         1.2072e-01,  1.4985e-01,  5.6022e-02,  7.8961e-02, -7.9504e-02,\n",
      "         1.2549e-01, -5.3772e-02, -5.8687e-02, -5.3185e-02, -1.9522e-02,\n",
      "        -9.4153e-02, -6.6292e-02, -2.2187e-02, -4.9738e-02, -4.6311e-02,\n",
      "         4.5460e-02, -5.4092e-02,  2.7340e-02,  1.9418e-02, -4.6023e-02,\n",
      "         2.4003e-02,  5.4532e-02,  4.1836e-02, -1.9981e-02, -2.0242e-02,\n",
      "        -4.2995e-02, -2.7995e-02, -7.1998e-02,  4.7350e-02, -4.7205e-02,\n",
      "        -1.5801e-02, -7.0171e-02, -6.4111e-02,  8.0037e-02,  2.1058e-02,\n",
      "        -2.5234e-02,  5.5529e-02, -2.1639e-02,  6.6098e-02, -2.8537e-02,\n",
      "        -3.3965e-02, -2.2606e-02, -2.6984e-02, -8.0632e-02, -1.3393e-01,\n",
      "        -2.7979e-02,  6.3010e-02, -6.0645e-02, -7.4302e-02, -9.8073e-02,\n",
      "        -7.6732e-02,  2.1717e-03,  9.7566e-03,  8.5136e-02, -3.0419e-02,\n",
      "         1.0428e-02,  2.3635e-02,  1.3292e-02, -3.1691e-03,  5.7605e-02,\n",
      "        -1.0547e-01,  7.4959e-02,  7.8002e-02,  8.2632e-02,  3.0370e-02,\n",
      "         2.3103e-02,  6.5391e-02, -6.0195e-02, -1.1504e-01, -4.6636e-02,\n",
      "         7.0626e-02, -1.5607e-01, -7.6096e-02,  2.9304e-02, -7.7186e-03,\n",
      "         1.3368e-02, -5.4386e-02, -1.0961e-01, -8.0009e-02,  2.6333e-02,\n",
      "         1.1087e-01,  5.2759e-02,  4.8152e-02,  9.7065e-03,  3.7476e-02,\n",
      "         5.8032e-03, -1.2221e-01, -1.9149e-02,  1.8671e-01,  5.2131e-02,\n",
      "        -1.0432e-01, -7.4389e-02,  2.1806e-02,  3.1331e-02, -1.2556e-02,\n",
      "        -1.1358e-01,  2.0806e-02,  9.6195e-02, -1.2207e-01, -1.3307e-01,\n",
      "         1.5290e-02, -1.2306e-01,  4.7516e-02,  8.9312e-02,  6.2900e-02,\n",
      "         1.0541e-01, -2.3712e-02, -8.1403e-02, -7.8356e-02,  1.3234e-01,\n",
      "        -2.1572e-01, -9.9673e-02,  4.8654e-02, -6.1532e-02,  4.9032e-02,\n",
      "         1.2883e-02, -1.8990e-02,  6.5594e-02,  3.0963e-02,  1.0802e-01,\n",
      "        -8.7336e-02, -4.0793e-02, -4.1875e-02, -4.0262e-02, -1.1958e-02,\n",
      "         5.4002e-02, -1.8207e-02, -9.2747e-02, -3.0435e-02,  5.0732e-04,\n",
      "        -3.4509e-02, -1.3300e-01, -2.0584e-02, -3.4287e-03,  3.3798e-02,\n",
      "         7.6019e-02, -1.4586e-01, -6.5083e-02,  1.1133e-01, -2.0991e-02,\n",
      "        -9.6636e-02, -2.9523e-02, -5.6462e-02, -1.1754e-02,  4.6690e-02,\n",
      "         1.1320e-01, -1.0074e-01, -4.4988e-02, -1.0872e-02, -1.4765e-01,\n",
      "        -3.6564e-02, -2.6572e-03, -4.8331e-02, -3.4319e-02,  1.9803e-01,\n",
      "        -1.3178e-01,  4.5631e-02,  4.2718e-02,  1.0053e-01,  3.9020e-02,\n",
      "        -7.0034e-02,  2.3410e-02,  2.1263e-02, -3.7163e-02,  9.3094e-02,\n",
      "         2.4271e-02, -2.6040e-02,  1.3311e-02,  2.6087e-02, -4.6824e-02,\n",
      "        -1.1358e-01, -6.8842e-02, -1.8327e-03, -6.3799e-02,  4.0115e-02,\n",
      "        -5.0009e-02, -6.0691e-02, -1.5473e-01,  5.2722e-02, -4.2528e-02,\n",
      "         7.4972e-03,  2.7294e-02, -2.5042e-02, -9.8724e-03, -6.6574e-02,\n",
      "         1.5013e-02, -1.4917e-02, -8.4133e-02,  8.3032e-02,  3.3268e-02,\n",
      "         5.7603e-03,  5.1148e-03,  1.8273e-02, -3.2597e-02, -2.3411e-03,\n",
      "         2.0215e-02,  4.3740e-02, -4.7150e-02, -2.4824e-02, -2.1241e-02,\n",
      "         4.0492e-03,  8.1200e-02, -1.3477e-01, -4.4830e-02,  1.6292e-01,\n",
      "         2.0333e-01, -1.0446e-01, -4.2683e-02,  4.2209e-02, -3.5972e-03,\n",
      "        -8.8700e-03, -1.3101e-01,  1.7674e-02,  2.1332e-02,  9.0498e-02,\n",
      "         4.1140e-02,  5.9341e-02,  7.0453e-03,  5.3495e-03,  7.5509e-02,\n",
      "         6.0445e-02,  1.4946e-02,  9.3456e-02,  7.2941e-03,  1.7047e-01,\n",
      "         1.1177e-01,  5.5514e-02,  1.1050e-02,  1.7548e-01, -5.4500e-02,\n",
      "         1.2232e-02,  1.1792e-01,  3.8718e-02, -2.6624e-02,  5.7266e-02,\n",
      "        -9.7332e-02, -7.3740e-02, -8.5785e-02,  6.4664e-02,  4.0530e-02,\n",
      "        -2.6749e-02, -5.6534e-02,  9.1496e-02, -2.1283e-02, -5.4996e-02,\n",
      "         6.2924e-02, -1.1378e-02, -3.2570e-02, -1.0129e-01,  4.4521e-02,\n",
      "         1.0998e-01, -3.1790e-02, -3.5012e-02, -5.1933e-02, -4.7872e-02,\n",
      "         1.1166e-02, -2.3371e-03, -4.0132e-02,  5.0213e-02, -1.9110e-02,\n",
      "         7.4315e-03, -5.0644e-02, -1.4163e-02, -8.8041e-02,  2.1981e-02,\n",
      "         2.6356e-02, -1.4305e-03, -7.6577e-02,  4.3847e-02,  7.9371e-02,\n",
      "         6.0871e-02,  8.0120e-02, -1.4258e-02, -9.4902e-02, -5.1128e-02,\n",
      "        -2.3421e-02, -5.8587e-02,  3.9033e-02,  1.0619e-01,  3.4509e-02,\n",
      "        -1.0888e-01,  1.2591e-01, -7.0609e-02,  1.0308e-02,  1.9289e-02,\n",
      "        -8.1256e-02,  6.3079e-02,  1.1605e-01,  6.3520e-02,  1.8339e-02,\n",
      "         1.1817e-01, -1.2815e-03,  6.0986e-02,  1.3635e-01,  2.0476e-01,\n",
      "         6.9247e-02,  1.8607e-01,  2.8667e-01,  1.1520e-01,  1.5935e-01,\n",
      "         1.2082e-01, -1.5299e-02, -7.8271e-02,  9.7610e-03,  1.3395e-01,\n",
      "         6.7636e-02,  1.0475e-01, -4.2235e-02, -4.6976e-02, -5.1201e-03,\n",
      "        -2.0377e-02, -2.3326e-02, -1.9136e-02, -7.3393e-03, -3.2787e-02,\n",
      "         8.8231e-02,  5.1196e-02, -4.9468e-02, -3.9990e-02,  1.0419e-02],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([1000])\n",
      "\n",
      "Layer: classifier.1.param_quantizers.weight.min\n",
      "Weights: -0.5028939247131348\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: classifier.1.param_quantizers.weight.max\n",
      "Weights: 0.4989650547504425\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: classifier.1.output_quantizers.0.min\n",
      "Weights: -2.9322092533111572\n",
      "Shape: torch.Size([])\n",
      "\n",
      "Layer: classifier.1.output_quantizers.0.max\n",
      "Weights: 9.435017585754395\n",
      "Shape: torch.Size([])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for name, param in sim.model.named_parameters():\n",
    "    print(f\"Layer: {name}\")\n",
    "    print(f\"Weights: {param.data}\")  # Use .data to access the raw tensor\n",
    "    print(f\"Shape: {param.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: features.0.0.weight\n",
      "Weights: tensor([[[[-6.3108e-02, -1.8766e-01, -1.5188e-01],\n",
      "          [-4.9379e-01, -6.4248e-01, -5.8935e-01],\n",
      "          [-6.8005e-01, -9.7448e-01, -7.6317e-01]],\n",
      "\n",
      "         [[-1.6350e-02, -1.8482e-02,  6.2783e-02],\n",
      "          [ 3.5436e-02,  5.8980e-02,  1.0693e-01],\n",
      "          [ 1.6995e-01,  1.4699e-01,  1.8521e-01]],\n",
      "\n",
      "         [[ 1.1395e-01,  1.6316e-01,  1.0483e-01],\n",
      "          [ 4.0824e-01,  5.7489e-01,  4.7270e-01],\n",
      "          [ 5.7547e-01,  7.1503e-01,  5.3702e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9983e-03,  1.4297e-02,  5.9918e-02],\n",
      "          [ 5.5779e-03,  3.0330e-02, -4.5050e-02],\n",
      "          [ 1.2600e-01,  5.5075e-02, -9.2239e-01]],\n",
      "\n",
      "         [[ 4.2316e-03, -6.6995e-02, -7.4151e-02],\n",
      "          [ 1.4910e-02,  1.5604e-02, -6.8112e-02],\n",
      "          [ 2.4632e-02, -4.4099e-02, -7.3383e-01]],\n",
      "\n",
      "         [[-9.1925e-03, -3.3236e-02,  1.0019e-01],\n",
      "          [ 3.9586e-03,  5.4139e-02,  1.0663e-01],\n",
      "          [ 1.0968e-01,  3.5723e-02, -3.9510e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2649e-01, -1.5025e-01,  2.4107e-02],\n",
      "          [ 6.7298e-01, -7.3204e-01,  5.9724e-02],\n",
      "          [ 6.7486e-01, -7.4353e-01,  6.6735e-02]],\n",
      "\n",
      "         [[ 2.2576e-01, -2.8267e-01,  9.2581e-02],\n",
      "          [ 1.1130e+00, -1.1783e+00, -1.2675e-02],\n",
      "          [ 1.0229e+00, -1.0997e+00,  9.1427e-02]],\n",
      "\n",
      "         [[-1.0309e-03, -7.3701e-03,  1.4532e-02],\n",
      "          [ 3.5864e-01, -4.3105e-01,  4.8293e-02],\n",
      "          [ 3.4249e-01, -3.9095e-01,  6.2845e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9063e-01, -2.1703e-02,  2.1708e-01],\n",
      "          [-3.3194e-01,  8.8984e-02,  3.1595e-01],\n",
      "          [ 1.1153e-01, -2.0132e-02, -1.2743e-01]],\n",
      "\n",
      "         [[-4.1511e-01, -1.5042e-02,  3.6632e-01],\n",
      "          [-4.0987e-01,  1.4164e-01,  5.1298e-01],\n",
      "          [ 1.0206e-01, -1.4003e-01, -2.3454e-01]],\n",
      "\n",
      "         [[-1.2547e-01, -5.8624e-03,  1.6301e-01],\n",
      "          [-1.7890e-01,  2.7285e-02,  1.9681e-01],\n",
      "          [ 3.8072e-02, -1.1414e-02, -3.7176e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1460e-02, -1.5710e-01,  1.2891e-01],\n",
      "          [ 9.5111e-01, -1.0478e+00,  7.0390e-02],\n",
      "          [ 9.0578e-01, -9.9058e-01,  1.1389e-01]],\n",
      "\n",
      "         [[ 9.0173e-02, -2.4164e-01,  1.7184e-01],\n",
      "          [ 1.6654e+00, -1.8639e+00,  1.6213e-01],\n",
      "          [ 1.4305e+00, -1.6406e+00,  2.3614e-01]],\n",
      "\n",
      "         [[ 4.2059e-02, -9.9022e-02,  5.5216e-02],\n",
      "          [ 5.8131e-01, -6.1206e-01,  4.6993e-02],\n",
      "          [ 5.1095e-01, -5.6993e-01,  5.2198e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0025e-02, -8.9831e-02,  7.0567e-02],\n",
      "          [-6.2591e-02, -3.6622e-01, -7.4632e-02],\n",
      "          [ 3.9007e-02, -7.6280e-02,  5.9376e-01]],\n",
      "\n",
      "         [[ 5.3733e-04, -1.5370e-01,  7.3156e-02],\n",
      "          [-1.2556e-01, -8.1988e-01, -4.0643e-04],\n",
      "          [ 1.0827e-01, -1.8564e-01,  1.2043e+00]],\n",
      "\n",
      "         [[ 1.0083e-02, -6.6229e-02,  2.6713e-02],\n",
      "          [-6.2522e-02, -1.7091e-01, -3.7039e-02],\n",
      "          [ 3.3739e-03, -5.4554e-02,  3.1005e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.2633e-01, -3.1430e-01, -8.0592e-02],\n",
      "          [ 6.3337e-02, -1.2931e-02,  9.8636e-03],\n",
      "          [ 4.4366e-02, -1.0503e-01, -1.3218e-01]],\n",
      "\n",
      "         [[-1.5831e-02,  2.9931e-02,  2.7480e-02],\n",
      "          [ 7.9076e-02,  3.1479e-01,  1.3513e-01],\n",
      "          [-1.0124e-01, -1.1418e-01, -1.7459e-01]],\n",
      "\n",
      "         [[ 5.7943e-02,  5.3078e-01,  1.7641e-01],\n",
      "          [ 8.4426e-02,  8.2810e-01,  3.6864e-01],\n",
      "          [-1.0976e-01,  1.2883e-01, -7.3352e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4989e-01,  1.5511e-01,  1.8277e-02],\n",
      "          [-7.5067e-02, -3.9095e-01, -2.2539e-01],\n",
      "          [ 5.3553e-02, -3.2975e-02,  2.2271e-03]],\n",
      "\n",
      "         [[ 8.8964e-01,  3.7630e-01,  1.6020e-01],\n",
      "          [-7.6890e-02, -8.8736e-01, -4.3854e-01],\n",
      "          [ 5.7299e-02, -5.7675e-02, -4.6108e-02]],\n",
      "\n",
      "         [[ 2.8124e-01,  6.8133e-02,  5.7941e-02],\n",
      "          [-4.4408e-02, -2.3539e-01, -1.0597e-01],\n",
      "          [ 2.8994e-02, -3.2856e-02,  7.8189e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.6281e-02, -5.7937e-02, -4.3937e-02],\n",
      "          [ 9.0735e-03,  1.3916e-01, -7.9150e-03],\n",
      "          [-3.8555e-02, -1.2932e-02, -9.1438e-02]],\n",
      "\n",
      "         [[ 1.3477e-01,  5.7015e-01,  6.1717e-01],\n",
      "          [ 3.3894e-01,  1.0945e+00,  1.0415e+00],\n",
      "          [-4.4605e-02,  3.2533e-01,  2.4988e-01]],\n",
      "\n",
      "         [[-1.3150e-01, -5.3689e-01, -5.7689e-01],\n",
      "          [-2.8067e-01, -8.9386e-01, -9.0974e-01],\n",
      "          [ 3.0480e-02, -3.5946e-01, -3.3129e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.5202e-02,  6.7297e-02,  1.1581e-02],\n",
      "          [ 3.0848e-02, -2.2521e-01, -5.0964e-02],\n",
      "          [-2.1193e-02, -5.4927e-01, -2.2358e-01]],\n",
      "\n",
      "         [[ 3.6336e-02,  1.2003e-01,  1.0872e-01],\n",
      "          [ 3.4592e-02, -4.6312e-01, -1.8739e-01],\n",
      "          [-8.6748e-02, -8.6480e-01, -5.0257e-01]],\n",
      "\n",
      "         [[-3.2263e-02, -4.6266e-03, -4.2814e-02],\n",
      "          [ 4.0989e-03,  4.9871e-02, -1.6867e-02],\n",
      "          [-1.0984e-02, -1.5952e-02, -8.5527e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.6813e-03, -2.0950e-02,  1.0321e-01],\n",
      "          [ 2.8623e-02, -1.0510e-01,  5.4155e-01],\n",
      "          [-8.7686e-02, -3.9274e-01, -7.4930e-02]],\n",
      "\n",
      "         [[ 2.1687e-02, -3.2457e-02,  2.5844e-01],\n",
      "          [ 9.3187e-02, -3.0333e-01,  1.1068e+00],\n",
      "          [-1.3829e-01, -8.3726e-01, -1.5081e-01]],\n",
      "\n",
      "         [[ 1.2504e-02, -3.1581e-02,  9.7049e-02],\n",
      "          [-6.8633e-03, -5.2405e-02,  2.7689e-01],\n",
      "          [-5.0215e-02, -1.9690e-01, -5.2774e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.4322e-03, -7.7974e-02,  2.4713e-02],\n",
      "          [ 1.1972e-01, -5.5139e-02,  1.1026e-01],\n",
      "          [-4.9709e-01, -1.7255e-01,  8.3711e-02]],\n",
      "\n",
      "         [[ 2.4634e-02, -2.5033e-02,  6.3014e-02],\n",
      "          [ 1.0156e-01, -4.6482e-02,  4.3943e-02],\n",
      "          [-3.3659e-01, -6.3855e-02,  5.2790e-02]],\n",
      "\n",
      "         [[ 2.2542e-02, -3.1942e-02, -9.9265e-03],\n",
      "          [ 5.2683e-02, -2.3995e-02, -4.2422e-02],\n",
      "          [ 6.1511e-03,  1.0269e-01,  1.3343e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2030e-01, -4.2881e-03,  1.2525e-01],\n",
      "          [-9.6667e-03,  1.2808e-01,  1.6959e-01],\n",
      "          [ 6.4296e-02,  4.9177e-02, -1.4363e-01]],\n",
      "\n",
      "         [[ 9.3911e-02,  1.2769e-01,  6.7019e-02],\n",
      "          [ 9.2397e-02, -2.4380e-03, -2.1277e-01],\n",
      "          [ 2.4836e-01, -1.7409e-03, -4.7832e-01]],\n",
      "\n",
      "         [[-7.3533e-02, -8.3743e-02, -1.2825e-01],\n",
      "          [-4.9601e-02, -1.5993e-01, -4.0318e-01],\n",
      "          [ 1.4418e-02, -2.0640e-01, -6.8773e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9578e-17,  5.4964e-17,  4.0560e-17],\n",
      "          [ 3.4623e-17,  4.2001e-17,  2.8739e-17],\n",
      "          [ 1.5971e-17,  2.7824e-17,  2.8468e-17]],\n",
      "\n",
      "         [[ 1.7691e-17,  2.2488e-17, -4.6646e-18],\n",
      "          [ 1.7656e-17,  2.0812e-17,  6.3410e-18],\n",
      "          [ 3.1096e-18,  8.4611e-18, -8.3258e-18]],\n",
      "\n",
      "         [[ 6.7496e-19,  2.3360e-18, -8.8849e-18],\n",
      "          [-6.2217e-18, -5.7158e-18,  4.4253e-18],\n",
      "          [-8.3838e-18, -1.6980e-18, -2.4405e-18]]],\n",
      "\n",
      "\n",
      "        [[[ 4.6187e-02, -5.9923e-02,  3.3357e-02],\n",
      "          [-8.6558e-02, -1.1710e-01, -1.5908e-01],\n",
      "          [-5.5892e-02,  2.0884e-01,  5.9444e-01]],\n",
      "\n",
      "         [[ 4.0159e-02, -9.3325e-02,  1.3166e-01],\n",
      "          [-2.1915e-01, -7.3873e-02, -3.8949e-03],\n",
      "          [-1.3423e-01,  2.9179e-01,  8.0891e-01]],\n",
      "\n",
      "         [[ 1.4765e-02, -7.1611e-02,  1.8672e-02],\n",
      "          [-5.5121e-02, -8.8543e-02, -7.8880e-02],\n",
      "          [-2.5229e-02,  1.3414e-01,  4.6638e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4690e-01,  2.1926e-01,  5.3029e-02],\n",
      "          [ 5.8891e-01,  8.2946e-01,  3.0994e-01],\n",
      "          [ 1.0423e+00,  1.1847e+00,  4.2832e-01]],\n",
      "\n",
      "         [[-1.2859e-01, -1.7304e-01, -4.1763e-02],\n",
      "          [-3.4404e-01, -4.6775e-01, -1.9919e-01],\n",
      "          [-4.0979e-01, -4.8466e-01, -2.0872e-01]],\n",
      "\n",
      "         [[-3.0979e-02, -7.4061e-02, -9.7713e-03],\n",
      "          [-2.6998e-01, -4.3212e-01, -8.2540e-02],\n",
      "          [-6.1460e-01, -6.7769e-01, -1.6677e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1805e-01, -9.6279e-01, -1.5261e-02],\n",
      "          [ 2.9034e-01,  1.0530e+00,  1.5144e-01],\n",
      "          [-1.8623e-01, -5.6081e-02, -1.4682e-01]],\n",
      "\n",
      "         [[-1.3622e-01, -1.4321e+00, -3.8721e-02],\n",
      "          [ 5.2778e-01,  1.6753e+00,  3.5717e-01],\n",
      "          [-4.2408e-01, -2.0844e-01, -3.2538e-01]],\n",
      "\n",
      "         [[-5.3212e-02, -5.5743e-01,  4.5195e-03],\n",
      "          [ 1.4686e-01,  6.4422e-01,  6.7543e-02],\n",
      "          [-1.0445e-01, -5.5421e-02, -9.3682e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0820e-01, -1.3018e-01,  4.6164e-02],\n",
      "          [ 2.3627e-02, -8.5943e-01,  7.7085e-01],\n",
      "          [ 7.0663e-02, -7.7828e-01,  7.5455e-01]],\n",
      "\n",
      "         [[ 2.2331e-01, -2.4350e-01,  7.9593e-02],\n",
      "          [ 3.4355e-02, -1.2878e+00,  1.0858e+00],\n",
      "          [ 1.4973e-01, -1.1448e+00,  1.0338e+00]],\n",
      "\n",
      "         [[ 8.6060e-02, -5.7519e-02, -3.8344e-02],\n",
      "          [ 1.9714e-03, -5.3869e-01,  5.3752e-01],\n",
      "          [ 1.9351e-03, -4.7707e-01,  4.5895e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9196e-02,  2.1047e-02,  1.6275e-01],\n",
      "          [ 1.2301e-01, -3.2168e-01, -2.9806e-01],\n",
      "          [ 1.7663e-01, -2.0355e-01, -2.5371e-01]],\n",
      "\n",
      "         [[-8.7093e-04,  5.2870e-02,  3.3130e-02],\n",
      "          [ 5.4699e-02, -3.7649e-01, -4.6097e-01],\n",
      "          [ 5.2894e-02, -3.7830e-01, -4.9596e-01]],\n",
      "\n",
      "         [[-3.8744e-02,  6.8300e-02,  5.4475e-02],\n",
      "          [ 7.0257e-02, -1.4492e-01, -2.4585e-01],\n",
      "          [ 5.4091e-02, -7.7883e-02, -1.5300e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.4538e-01, -9.2383e-01, -6.9041e-01],\n",
      "          [ 7.7942e-01,  1.6503e+00,  8.7853e-01],\n",
      "          [-2.7195e-01, -4.9448e-01, -3.3044e-01]],\n",
      "\n",
      "         [[-7.6631e-01, -1.3475e+00, -8.6426e-01],\n",
      "          [ 1.1050e+00,  2.2459e+00,  1.1861e+00],\n",
      "          [-3.6525e-01, -6.6076e-01, -3.9021e-01]],\n",
      "\n",
      "         [[-2.8621e-01, -5.4791e-01, -3.4948e-01],\n",
      "          [ 4.2653e-01,  1.0436e+00,  5.5337e-01],\n",
      "          [-1.5862e-01, -4.0578e-01, -2.2147e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.8209e-03, -3.2519e-01, -2.8348e-01],\n",
      "          [ 3.3506e-01,  2.5524e-01,  1.1688e-02],\n",
      "          [ 3.6047e-02,  3.7303e-02, -1.7237e-02]],\n",
      "\n",
      "         [[-8.0229e-02, -7.2748e-01, -6.2011e-01],\n",
      "          [ 7.9651e-01,  6.2221e-01,  1.5411e-01],\n",
      "          [ 4.5067e-02, -3.5878e-02, -7.9207e-02]],\n",
      "\n",
      "         [[-1.9919e-02, -1.9552e-01, -1.5398e-01],\n",
      "          [ 2.3802e-01,  1.3166e-01,  5.4832e-03],\n",
      "          [-1.9837e-02,  3.2758e-02,  1.6308e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.3067e-02, -1.6271e-01, -1.6606e-01],\n",
      "          [-2.8478e-01, -4.1181e-01, -3.3369e-01],\n",
      "          [-3.9702e-01, -5.2222e-01, -2.9572e-01]],\n",
      "\n",
      "         [[ 1.1121e-01,  3.4395e-01,  1.6040e-01],\n",
      "          [ 5.5069e-01,  9.8467e-01,  6.0292e-01],\n",
      "          [ 7.9991e-01,  1.2273e+00,  8.4450e-01]],\n",
      "\n",
      "         [[-4.6157e-02, -2.0538e-01,  4.1712e-06],\n",
      "          [-3.1632e-01, -6.3407e-01, -2.7254e-01],\n",
      "          [-3.8782e-01, -8.0559e-01, -5.0330e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4390e-02,  2.1508e-02,  1.1723e-02],\n",
      "          [-5.4224e-01, -1.1592e+00, -2.9346e-01],\n",
      "          [ 5.1555e-01,  1.1812e+00,  2.5774e-01]],\n",
      "\n",
      "         [[ 2.3498e-02, -4.4873e-02,  1.0335e-01],\n",
      "          [-8.1933e-01, -2.0528e+00, -4.9998e-01],\n",
      "          [ 7.6768e-01,  2.0742e+00,  4.2068e-01]],\n",
      "\n",
      "         [[ 1.4207e-02, -6.9347e-04,  1.2788e-02],\n",
      "          [-2.6861e-01, -6.2116e-01, -8.1165e-02],\n",
      "          [ 2.2904e-01,  6.0848e-01,  7.8574e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.2633e-02,  2.2196e-01,  1.1862e-01],\n",
      "          [ 1.9674e-01,  3.6300e-01,  3.1765e-01],\n",
      "          [ 2.1826e-01,  4.0048e-01,  2.7987e-01]],\n",
      "\n",
      "         [[-2.1739e-01, -4.7843e-01, -2.5212e-01],\n",
      "          [-5.6329e-01, -9.9938e-01, -6.5538e-01],\n",
      "          [-6.8013e-01, -1.1713e+00, -8.6992e-01]],\n",
      "\n",
      "         [[ 1.1670e-01,  2.7000e-01,  1.9417e-01],\n",
      "          [ 3.5852e-01,  6.1727e-01,  4.1898e-01],\n",
      "          [ 5.2598e-01,  7.5598e-01,  4.6438e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1432e-02, -1.5728e-01,  5.9200e-02],\n",
      "          [ 6.8278e-01, -6.9446e-01,  1.2221e-02],\n",
      "          [ 6.4092e-01, -6.6526e-01,  5.0217e-02]],\n",
      "\n",
      "         [[ 1.9827e-01, -2.1453e-01,  3.2063e-02],\n",
      "          [ 1.1111e+00, -1.1431e+00,  5.5392e-02],\n",
      "          [ 9.3968e-01, -1.0102e+00,  5.1862e-02]],\n",
      "\n",
      "         [[-1.1294e-02, -7.6501e-03,  5.6847e-02],\n",
      "          [ 4.2223e-01, -5.3620e-01,  4.3200e-02],\n",
      "          [ 3.9580e-01, -4.2915e-01,  8.2356e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6184e-02,  7.2007e-01,  4.9063e-01],\n",
      "          [ 3.0464e-01,  1.4807e+00,  1.0120e+00],\n",
      "          [-1.2676e-01,  4.5031e-01,  2.0662e-01]],\n",
      "\n",
      "         [[-1.6664e-01, -6.7651e-01, -4.7091e-01],\n",
      "          [-2.4501e-01, -9.3582e-01, -7.6905e-01],\n",
      "          [ 4.0048e-02, -4.0938e-01, -3.6880e-01]],\n",
      "\n",
      "         [[ 4.9491e-02, -2.5192e-02,  1.6667e-02],\n",
      "          [ 1.5346e-02, -1.6299e-01, -4.1588e-02],\n",
      "          [ 2.2358e-02, -1.9023e-02, -5.6675e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.2617e-03,  1.1628e-01, -1.4966e-01],\n",
      "          [-1.7737e-01,  9.0415e-01, -7.7968e-01],\n",
      "          [-1.2917e-01,  8.8658e-01, -6.3615e-01]],\n",
      "\n",
      "         [[ 7.1681e-02,  2.6763e-01, -2.2828e-01],\n",
      "          [-1.8326e-01,  1.3076e+00, -1.2497e+00],\n",
      "          [-1.0383e-01,  1.2653e+00, -1.0593e+00]],\n",
      "\n",
      "         [[ 4.8256e-02,  1.3945e-02, -3.2131e-02],\n",
      "          [-1.8211e-01,  6.4112e-01, -5.2627e-01],\n",
      "          [-1.4267e-01,  6.3035e-01, -4.1425e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0104e-02,  4.6287e-03, -1.2321e-02],\n",
      "          [-3.4887e-01, -4.1664e-01, -6.7217e-02],\n",
      "          [-1.1803e-02, -1.4742e-01, -4.2432e-02]],\n",
      "\n",
      "         [[-9.2254e-05,  9.4569e-03,  5.5899e-02],\n",
      "          [-6.3504e-01, -7.9261e-01, -1.6051e-01],\n",
      "          [-2.0672e-02, -2.8181e-01, -5.8319e-02]],\n",
      "\n",
      "         [[ 1.4462e-02, -1.9225e-02, -1.5334e-02],\n",
      "          [-2.2606e-01, -2.8504e-01, -5.6084e-02],\n",
      "          [ 9.0715e-02, -6.5981e-02, -2.1934e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9810e-01,  1.4182e-01,  6.7656e-02],\n",
      "          [ 4.3522e-02,  7.6264e-01, -7.9007e-01],\n",
      "          [-5.5130e-02,  7.2790e-01, -6.8250e-01]],\n",
      "\n",
      "         [[-2.4072e-01,  2.1072e-01,  3.7873e-02],\n",
      "          [ 6.7277e-03,  1.4432e+00, -1.4762e+00],\n",
      "          [-4.0121e-02,  1.2931e+00, -1.2528e+00]],\n",
      "\n",
      "         [[-8.5257e-02,  6.9258e-02,  3.1450e-02],\n",
      "          [-1.6972e-02,  4.7712e-01, -4.4024e-01],\n",
      "          [-4.7878e-02,  4.2231e-01, -4.0366e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6781e-19, -1.5936e-17,  6.2832e-18],\n",
      "          [ 1.0562e-16,  1.0140e-17, -9.6849e-18],\n",
      "          [ 4.2576e-17, -1.6736e-17, -1.5269e-17]],\n",
      "\n",
      "         [[-9.3665e-19, -2.0997e-17,  1.0625e-17],\n",
      "          [ 1.1059e-16, -8.5305e-18,  5.7360e-18],\n",
      "          [ 4.4472e-17, -1.4536e-18,  1.5525e-17]],\n",
      "\n",
      "         [[ 2.3261e-17, -1.2886e-17,  5.6310e-18],\n",
      "          [ 1.4525e-16,  3.6420e-17,  1.8129e-17],\n",
      "          [ 7.3362e-17,  3.9671e-18, -1.4386e-17]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2752e-02, -5.8898e-02,  1.4701e-02],\n",
      "          [-2.6580e-02,  7.0509e-04, -1.7290e-02],\n",
      "          [-4.4236e-02,  5.6697e-01, -4.2755e-02]],\n",
      "\n",
      "         [[ 4.0966e-02, -1.0857e-02,  3.7020e-02],\n",
      "          [ 4.2369e-02, -3.4714e-02, -7.8123e-03],\n",
      "          [ 1.3258e-02,  5.0397e-01,  1.8258e-02]],\n",
      "\n",
      "         [[-1.1556e-02, -5.2486e-02, -2.6202e-03],\n",
      "          [-1.2290e-02,  1.7760e-02, -2.3098e-02],\n",
      "          [-7.0463e-04,  6.2742e-01,  3.9530e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7271e-03,  2.0321e-02, -4.8876e-02],\n",
      "          [ 4.2461e-01,  1.2307e+00,  2.3159e-01],\n",
      "          [-4.4056e-01, -1.2695e+00, -1.7976e-01]],\n",
      "\n",
      "         [[ 1.6891e-02, -3.7882e-03,  7.2732e-03],\n",
      "          [ 7.8612e-01,  1.9440e+00,  4.1202e-01],\n",
      "          [-8.1143e-01, -2.0023e+00, -3.2891e-01]],\n",
      "\n",
      "         [[ 1.2426e-02, -4.7324e-03, -1.8188e-02],\n",
      "          [ 2.3214e-01,  7.2258e-01,  1.2125e-01],\n",
      "          [-2.5964e-01, -7.1867e-01, -9.1978e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 3, 3, 3])\n",
      "\n",
      "Layer: features.0.1.weight\n",
      "Weights: tensor([1.0825, 4.8204, 1.4738, 0.6213, 2.9739, 1.3405, 0.8329, 1.5772, 0.4265,\n",
      "        1.1092, 1.2303, 0.4780, 3.4831, 0.3000, 1.1989, 0.8532, 3.5887, 1.0497,\n",
      "        1.2191, 1.1197, 1.2261, 0.8141, 1.6100, 1.0700, 1.3712, 0.3701, 0.9097,\n",
      "        1.1438, 1.5628, 0.4121, 3.2324, 1.5968], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.0.1.bias\n",
      "Weights: tensor([ 0.0590, -4.9566,  0.3007,  2.5982,  3.0160,  2.8810,  2.6893,  2.9803,\n",
      "         2.3208,  3.2837,  2.4797,  6.5129, -2.8342, -1.2568,  2.3335,  0.5338,\n",
      "         2.8048,  0.4600,  2.7009,  2.8078,  2.5135,  0.3663,  0.6951,  0.1422,\n",
      "         5.8098,  2.5753,  2.0864,  3.2367,  0.9298, -1.9115, -5.8667,  0.8266],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.1.conv.0.0.weight\n",
      "Weights: tensor([[[[ 8.5443e-02,  1.0032e+00, -1.4700e-01],\n",
      "          [ 1.3916e-02,  6.7163e-01, -2.7953e-01],\n",
      "          [-3.1885e-01, -5.1679e-01, -4.9956e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0335e-01,  7.1423e-02, -2.9735e-01],\n",
      "          [ 8.8945e-01,  4.1716e-01, -2.2317e-01],\n",
      "          [-4.6418e-01, -1.6449e-01, -1.6234e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1001e-02, -3.0135e-01, -1.2470e-01],\n",
      "          [ 5.9850e-02,  1.2607e+00, -8.5826e-02],\n",
      "          [-3.7885e-02, -2.4390e-01, -1.2187e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.1329e-02,  1.7918e-02,  6.9535e-03],\n",
      "          [ 1.1795e-01, -9.0861e-01, -7.9298e-02],\n",
      "          [-1.7618e-01,  8.6090e-01,  1.0088e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.4295e-02, -1.5054e-01, -8.4380e-02],\n",
      "          [ 9.2268e-03,  1.3897e+00, -5.2309e-02],\n",
      "          [-4.9429e-02, -1.8494e-01, -1.0474e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.4959e-02, -1.5435e-02,  2.7955e-02],\n",
      "          [ 1.1760e+00, -1.0571e+00, -6.1691e-02],\n",
      "          [-3.8607e-02, -6.7303e-02,  6.9350e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1566e-01,  7.1589e-02, -2.1001e-01],\n",
      "          [-1.4702e+00, -6.0055e-02,  1.4992e+00],\n",
      "          [-1.3169e+00, -1.3660e-01,  1.4259e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3407e-02, -7.2000e-02,  2.3293e-02],\n",
      "          [ 9.4520e-03, -1.1674e+00,  6.0358e-02],\n",
      "          [-3.5548e-02,  1.2426e+00, -9.4536e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.8866e-01, -6.2938e-02,  1.6370e-01],\n",
      "          [ 1.4687e+00,  1.3162e-01, -1.4877e+00],\n",
      "          [ 9.0463e-01, -7.3324e-03, -9.3306e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6515e+00, -3.2295e-02,  1.5447e+00],\n",
      "          [-3.0276e+00,  1.3104e-02,  3.3229e+00],\n",
      "          [-9.2209e-01,  4.2776e-02,  7.8151e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8697e-02,  4.7429e-03, -4.0908e-02],\n",
      "          [-1.1504e+00,  1.0937e+00,  7.1639e-02],\n",
      "          [-1.3848e-02,  4.5822e-02, -6.1518e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7714e-01, -6.1111e-02, -4.6014e-01],\n",
      "          [ 4.2587e-01,  1.5969e-01, -2.0393e-01],\n",
      "          [-3.7848e-02, -9.5468e-02, -5.7780e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.4411e-01,  1.7778e-01, -2.7842e-01],\n",
      "          [ 3.7785e-01,  2.2821e-01, -7.9396e-02],\n",
      "          [-3.8765e-01, -1.2349e-01, -1.0295e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2547e-17,  6.8476e-18, -2.3288e-17],\n",
      "          [ 5.3333e-17,  2.8721e-17, -3.7573e-17],\n",
      "          [ 1.7128e-17,  8.5286e-18, -3.2252e-17]]],\n",
      "\n",
      "\n",
      "        [[[-8.5163e-01, -1.6266e+00,  2.8374e-02],\n",
      "          [-2.1293e-01, -1.3969e-01,  1.7841e-01],\n",
      "          [ 1.1541e+00,  1.8968e+00, -2.3943e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4254e-01,  1.6161e+00, -1.3062e-01],\n",
      "          [-5.0432e-02,  5.3076e-01, -9.1056e-02],\n",
      "          [-1.8085e-01, -9.2565e-01, -2.8698e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2559e-02, -4.3727e-02,  2.0142e-02],\n",
      "          [ 2.8543e-01, -1.1714e+00,  3.0521e-01],\n",
      "          [ 2.2202e-01, -3.8132e-01,  2.6610e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5160e-01, -2.4966e-01, -6.2121e-02],\n",
      "          [ 1.1418e-01,  1.2268e+00, -1.7825e-02],\n",
      "          [-1.5606e-01, -2.1591e-01, -5.0242e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0871e-01,  1.4862e-01,  8.7118e-02],\n",
      "          [-8.8470e-01, -1.3666e+00,  3.2498e-01],\n",
      "          [ 4.7185e-01,  2.4698e-01,  8.9874e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.3296e-02,  5.7612e-02, -2.1130e-02],\n",
      "          [-1.8302e-02, -7.3717e-02,  2.6013e-02],\n",
      "          [ 8.7581e-02, -1.5098e+00,  2.6878e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2006e-03, -5.2485e-02,  2.7674e-02],\n",
      "          [ 1.2416e-02, -1.2057e+00,  7.3873e-02],\n",
      "          [-2.2537e-03,  1.2654e+00, -1.0702e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9115e-01,  8.7886e-01, -9.9702e-02],\n",
      "          [ 2.0659e-01,  5.6930e-01, -1.7283e-01],\n",
      "          [-6.2056e-01, -4.3000e-01, -1.0813e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.6553e-02, -1.0026e-01, -8.4674e-02],\n",
      "          [-1.9936e-01,  1.4638e+00, -2.4480e-01],\n",
      "          [-5.8807e-02, -4.9006e-02, -6.1104e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2019e-01,  7.6050e-01, -6.0416e-02],\n",
      "          [ 1.6566e-01,  5.8785e-01, -2.1086e-01],\n",
      "          [-6.0002e-01, -3.0928e-01, -1.5713e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5430e-02,  2.3638e-01,  7.0212e-02],\n",
      "          [ 1.1879e-01, -1.2487e+00,  2.3156e-02],\n",
      "          [ 9.3941e-02,  2.2081e-01,  4.8800e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.1901e-01,  2.3382e-02,  2.5616e-01],\n",
      "          [ 2.0157e+00, -1.1292e-01, -1.8618e+00],\n",
      "          [ 1.1497e+00, -5.2672e-02, -1.1123e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.3321e-01, -5.2005e-02,  2.1991e-02],\n",
      "          [ 1.2610e+00, -1.7072e-01, -1.3929e-02],\n",
      "          [-1.2928e-01, -6.0996e-02, -2.2575e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0476e+00, -3.0978e+00, -2.0043e+00],\n",
      "          [ 1.8272e-01,  6.6250e-01, -2.2211e-02],\n",
      "          [ 8.8813e-01,  2.4166e+00,  1.9718e+00]]],\n",
      "\n",
      "\n",
      "        [[[-1.2871e-01, -1.8781e-01, -6.0284e-02],\n",
      "          [ 1.0912e-01,  1.3016e+00, -6.0392e-02],\n",
      "          [-1.4083e-01, -2.4574e-01, -5.4686e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.2937e-17,  3.1581e-17,  4.4111e-17],\n",
      "          [-5.6233e-17,  1.7199e-16,  6.8477e-17],\n",
      "          [-7.8994e-18, -3.2047e-17, -7.7552e-17]]],\n",
      "\n",
      "\n",
      "        [[[-1.7230e-01,  2.2708e-01, -1.4950e-01],\n",
      "          [-9.7139e-02,  7.7846e-01, -8.8162e-02],\n",
      "          [-5.8989e-02, -1.9932e-01, -1.1193e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.8591e-02,  5.4870e-02,  9.3470e-02],\n",
      "          [ 1.9068e-01, -1.4928e+00,  2.3316e-01],\n",
      "          [ 8.0642e-02,  1.0242e-01,  8.6321e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 1, 3, 3])\n",
      "\n",
      "Layer: features.1.conv.0.1.weight\n",
      "Weights: tensor([0.6519, 0.4864, 0.9031, 0.9693, 2.3145, 6.2372, 1.7343, 7.2227, 3.7534,\n",
      "        6.2679, 6.5068, 3.1254, 0.4076, 0.6415, 2.0785, 0.7188, 1.2937, 0.7520,\n",
      "        0.8610, 0.8136, 8.8045, 0.7231, 1.1978, 0.5913, 0.8605, 2.9741, 0.8403,\n",
      "        8.2873, 1.3564, 0.8470, 0.3696, 1.2543], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.1.conv.0.1.bias\n",
      "Weights: tensor([ 0.1991,  0.4557,  0.2405,  2.9042,  3.0671,  2.8726,  3.1959,  3.1174,\n",
      "         2.6113,  2.3480,  3.1414,  0.6196,  0.5494, -0.9236,  3.1420,  0.6274,\n",
      "         2.7969,  0.4176,  2.9588,  3.1497,  2.4506,  0.4565,  0.5826,  0.3681,\n",
      "         0.1423,  2.4579,  2.4429,  3.2343,  0.9534, -0.9287,  1.0302,  5.3544],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.1.conv.1.weight\n",
      "Weights: tensor([[[[ 6.5831e-02]],\n",
      "\n",
      "         [[ 2.2735e-01]],\n",
      "\n",
      "         [[ 3.0291e-02]],\n",
      "\n",
      "         [[ 4.3289e-01]],\n",
      "\n",
      "         [[-1.8641e-02]],\n",
      "\n",
      "         [[-1.1605e-01]],\n",
      "\n",
      "         [[-1.0227e-03]],\n",
      "\n",
      "         [[-3.0987e-01]],\n",
      "\n",
      "         [[-1.4409e-02]],\n",
      "\n",
      "         [[-5.8532e-03]],\n",
      "\n",
      "         [[ 3.0491e-02]],\n",
      "\n",
      "         [[ 1.6556e-01]],\n",
      "\n",
      "         [[-1.1043e-01]],\n",
      "\n",
      "         [[ 2.6296e-17]],\n",
      "\n",
      "         [[ 3.7170e-01]],\n",
      "\n",
      "         [[-8.8819e-04]],\n",
      "\n",
      "         [[ 8.8885e-01]],\n",
      "\n",
      "         [[ 2.4126e-01]],\n",
      "\n",
      "         [[-1.3078e-01]],\n",
      "\n",
      "         [[ 3.8163e-01]],\n",
      "\n",
      "         [[ 5.1393e-02]],\n",
      "\n",
      "         [[-1.3926e-02]],\n",
      "\n",
      "         [[-8.9247e-01]],\n",
      "\n",
      "         [[ 6.3301e-03]],\n",
      "\n",
      "         [[ 5.1762e-02]],\n",
      "\n",
      "         [[ 2.7626e-02]],\n",
      "\n",
      "         [[ 1.3687e-01]],\n",
      "\n",
      "         [[-6.8765e-02]],\n",
      "\n",
      "         [[-1.3766e-01]],\n",
      "\n",
      "         [[ 3.6874e-17]],\n",
      "\n",
      "         [[-2.1122e-01]],\n",
      "\n",
      "         [[-9.8416e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3083e-02]],\n",
      "\n",
      "         [[ 1.0636e-01]],\n",
      "\n",
      "         [[-5.5089e-01]],\n",
      "\n",
      "         [[-7.2518e-02]],\n",
      "\n",
      "         [[-2.4052e-01]],\n",
      "\n",
      "         [[-2.4511e-01]],\n",
      "\n",
      "         [[-1.1781e-01]],\n",
      "\n",
      "         [[-1.7814e-01]],\n",
      "\n",
      "         [[-1.6745e-01]],\n",
      "\n",
      "         [[ 9.5221e-02]],\n",
      "\n",
      "         [[ 5.9568e-02]],\n",
      "\n",
      "         [[-7.5988e-03]],\n",
      "\n",
      "         [[-6.1008e-02]],\n",
      "\n",
      "         [[ 9.7702e-18]],\n",
      "\n",
      "         [[ 2.3303e-01]],\n",
      "\n",
      "         [[-9.4494e-03]],\n",
      "\n",
      "         [[-9.3311e-01]],\n",
      "\n",
      "         [[ 3.6155e-01]],\n",
      "\n",
      "         [[-2.3905e-01]],\n",
      "\n",
      "         [[-2.1183e-01]],\n",
      "\n",
      "         [[-4.3778e-02]],\n",
      "\n",
      "         [[-2.8650e-02]],\n",
      "\n",
      "         [[-4.7581e-01]],\n",
      "\n",
      "         [[ 1.7237e-02]],\n",
      "\n",
      "         [[ 3.9299e-01]],\n",
      "\n",
      "         [[ 1.0936e-01]],\n",
      "\n",
      "         [[ 8.3376e-01]],\n",
      "\n",
      "         [[ 5.7835e-02]],\n",
      "\n",
      "         [[-3.7655e-01]],\n",
      "\n",
      "         [[-6.6484e-17]],\n",
      "\n",
      "         [[-2.0839e-01]],\n",
      "\n",
      "         [[-5.2253e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.6309e-02]],\n",
      "\n",
      "         [[-1.2284e-01]],\n",
      "\n",
      "         [[-1.0494e-02]],\n",
      "\n",
      "         [[-3.1888e-02]],\n",
      "\n",
      "         [[-2.7149e-02]],\n",
      "\n",
      "         [[ 8.0823e-03]],\n",
      "\n",
      "         [[-6.1411e-02]],\n",
      "\n",
      "         [[-7.3772e-02]],\n",
      "\n",
      "         [[ 9.0169e-02]],\n",
      "\n",
      "         [[ 1.4061e-01]],\n",
      "\n",
      "         [[-1.0812e-03]],\n",
      "\n",
      "         [[ 1.8863e-01]],\n",
      "\n",
      "         [[-4.5377e-01]],\n",
      "\n",
      "         [[ 2.2029e-17]],\n",
      "\n",
      "         [[-3.2379e-01]],\n",
      "\n",
      "         [[ 1.0884e-01]],\n",
      "\n",
      "         [[ 7.0762e-02]],\n",
      "\n",
      "         [[-1.2901e-01]],\n",
      "\n",
      "         [[ 1.1202e+00]],\n",
      "\n",
      "         [[-7.3342e-02]],\n",
      "\n",
      "         [[ 6.2016e-02]],\n",
      "\n",
      "         [[-1.5451e+00]],\n",
      "\n",
      "         [[-1.9085e-01]],\n",
      "\n",
      "         [[ 1.4876e+00]],\n",
      "\n",
      "         [[-7.5468e-02]],\n",
      "\n",
      "         [[-6.0768e-02]],\n",
      "\n",
      "         [[-2.3226e-02]],\n",
      "\n",
      "         [[ 1.8126e-01]],\n",
      "\n",
      "         [[ 5.9385e-02]],\n",
      "\n",
      "         [[ 4.1560e-17]],\n",
      "\n",
      "         [[ 2.0230e-01]],\n",
      "\n",
      "         [[-2.3621e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6180e-02]],\n",
      "\n",
      "         [[-9.3069e-02]],\n",
      "\n",
      "         [[ 6.0585e-01]],\n",
      "\n",
      "         [[-2.4444e-01]],\n",
      "\n",
      "         [[ 4.2906e-01]],\n",
      "\n",
      "         [[ 9.6671e-02]],\n",
      "\n",
      "         [[ 2.3754e-01]],\n",
      "\n",
      "         [[-9.6197e-02]],\n",
      "\n",
      "         [[-2.4767e-02]],\n",
      "\n",
      "         [[-1.5549e-01]],\n",
      "\n",
      "         [[-6.3028e-02]],\n",
      "\n",
      "         [[-3.9198e-02]],\n",
      "\n",
      "         [[-1.0621e-02]],\n",
      "\n",
      "         [[-2.3131e-17]],\n",
      "\n",
      "         [[ 3.2039e-01]],\n",
      "\n",
      "         [[ 1.0602e-02]],\n",
      "\n",
      "         [[-3.4653e-01]],\n",
      "\n",
      "         [[-5.8286e-01]],\n",
      "\n",
      "         [[ 1.1895e-01]],\n",
      "\n",
      "         [[ 9.4472e-01]],\n",
      "\n",
      "         [[ 5.1004e-02]],\n",
      "\n",
      "         [[ 3.0067e-03]],\n",
      "\n",
      "         [[-8.4240e-02]],\n",
      "\n",
      "         [[ 1.5263e-02]],\n",
      "\n",
      "         [[-1.1991e+00]],\n",
      "\n",
      "         [[-3.6590e-02]],\n",
      "\n",
      "         [[-5.8643e-01]],\n",
      "\n",
      "         [[ 6.5958e-02]],\n",
      "\n",
      "         [[ 1.7309e-01]],\n",
      "\n",
      "         [[ 5.6598e-18]],\n",
      "\n",
      "         [[-2.2379e-01]],\n",
      "\n",
      "         [[ 2.1740e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.9298e-01]],\n",
      "\n",
      "         [[-1.2348e-01]],\n",
      "\n",
      "         [[-4.1473e-01]],\n",
      "\n",
      "         [[-1.1678e-01]],\n",
      "\n",
      "         [[-2.1214e-01]],\n",
      "\n",
      "         [[-1.1894e-02]],\n",
      "\n",
      "         [[ 1.0823e+00]],\n",
      "\n",
      "         [[-1.2160e-01]],\n",
      "\n",
      "         [[ 1.4030e+00]],\n",
      "\n",
      "         [[-1.0360e-01]],\n",
      "\n",
      "         [[-3.2732e-02]],\n",
      "\n",
      "         [[-1.3039e-01]],\n",
      "\n",
      "         [[ 2.0993e-01]],\n",
      "\n",
      "         [[ 4.4375e-18]],\n",
      "\n",
      "         [[ 3.0142e-02]],\n",
      "\n",
      "         [[ 2.7108e-01]],\n",
      "\n",
      "         [[-6.7393e-02]],\n",
      "\n",
      "         [[ 2.6563e-01]],\n",
      "\n",
      "         [[-5.1977e-02]],\n",
      "\n",
      "         [[-9.6476e-02]],\n",
      "\n",
      "         [[ 1.0028e-01]],\n",
      "\n",
      "         [[ 1.1880e-01]],\n",
      "\n",
      "         [[ 1.1193e-01]],\n",
      "\n",
      "         [[-1.0816e-01]],\n",
      "\n",
      "         [[ 2.7673e-01]],\n",
      "\n",
      "         [[ 4.3108e-01]],\n",
      "\n",
      "         [[-1.7900e-02]],\n",
      "\n",
      "         [[ 7.1261e-02]],\n",
      "\n",
      "         [[-3.2291e-01]],\n",
      "\n",
      "         [[-3.6724e-18]],\n",
      "\n",
      "         [[-5.2534e-02]],\n",
      "\n",
      "         [[ 1.9412e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2302e-02]],\n",
      "\n",
      "         [[-1.0545e-01]],\n",
      "\n",
      "         [[-5.9359e-01]],\n",
      "\n",
      "         [[ 5.0745e-01]],\n",
      "\n",
      "         [[-2.2783e-01]],\n",
      "\n",
      "         [[-1.7745e-01]],\n",
      "\n",
      "         [[-1.4324e-01]],\n",
      "\n",
      "         [[-5.2423e-02]],\n",
      "\n",
      "         [[-8.1088e-02]],\n",
      "\n",
      "         [[ 8.1023e-02]],\n",
      "\n",
      "         [[-4.0820e-02]],\n",
      "\n",
      "         [[ 1.1068e-01]],\n",
      "\n",
      "         [[-2.7420e-02]],\n",
      "\n",
      "         [[ 2.4230e-17]],\n",
      "\n",
      "         [[ 1.7100e-02]],\n",
      "\n",
      "         [[-3.7814e-02]],\n",
      "\n",
      "         [[ 1.4872e-01]],\n",
      "\n",
      "         [[ 1.4240e-02]],\n",
      "\n",
      "         [[ 6.1679e-01]],\n",
      "\n",
      "         [[ 1.7158e+00]],\n",
      "\n",
      "         [[-1.1615e-01]],\n",
      "\n",
      "         [[-2.2048e-02]],\n",
      "\n",
      "         [[ 9.6844e-01]],\n",
      "\n",
      "         [[ 1.1223e-02]],\n",
      "\n",
      "         [[ 3.4682e-01]],\n",
      "\n",
      "         [[ 9.8144e-02]],\n",
      "\n",
      "         [[ 2.2866e-01]],\n",
      "\n",
      "         [[ 1.7796e-02]],\n",
      "\n",
      "         [[-1.7014e-01]],\n",
      "\n",
      "         [[-2.5076e-17]],\n",
      "\n",
      "         [[ 5.2268e-02]],\n",
      "\n",
      "         [[ 1.0250e+00]]],\n",
      "\n",
      "\n",
      "        [[[-5.2759e-02]],\n",
      "\n",
      "         [[-4.6772e-01]],\n",
      "\n",
      "         [[ 6.4227e-02]],\n",
      "\n",
      "         [[-2.2886e-01]],\n",
      "\n",
      "         [[-2.1504e-02]],\n",
      "\n",
      "         [[-7.6024e-02]],\n",
      "\n",
      "         [[ 1.4228e-01]],\n",
      "\n",
      "         [[-7.7604e-02]],\n",
      "\n",
      "         [[-2.0975e-02]],\n",
      "\n",
      "         [[-1.0114e-01]],\n",
      "\n",
      "         [[ 6.2361e-02]],\n",
      "\n",
      "         [[ 4.1426e-01]],\n",
      "\n",
      "         [[-1.0777e-01]],\n",
      "\n",
      "         [[-1.4988e-17]],\n",
      "\n",
      "         [[ 7.4858e-01]],\n",
      "\n",
      "         [[ 1.2785e-01]],\n",
      "\n",
      "         [[ 3.1075e-02]],\n",
      "\n",
      "         [[ 5.6224e-03]],\n",
      "\n",
      "         [[ 1.5875e+00]],\n",
      "\n",
      "         [[-5.2594e-01]],\n",
      "\n",
      "         [[-1.7869e-02]],\n",
      "\n",
      "         [[ 5.7994e-02]],\n",
      "\n",
      "         [[ 1.4741e-01]],\n",
      "\n",
      "         [[-1.2731e-02]],\n",
      "\n",
      "         [[-1.5030e-01]],\n",
      "\n",
      "         [[-1.0126e-02]],\n",
      "\n",
      "         [[ 5.6472e-02]],\n",
      "\n",
      "         [[-7.0164e-01]],\n",
      "\n",
      "         [[-2.6149e-02]],\n",
      "\n",
      "         [[-3.1055e-18]],\n",
      "\n",
      "         [[ 3.6672e-01]],\n",
      "\n",
      "         [[ 4.4243e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2085e-02]],\n",
      "\n",
      "         [[-1.7531e-01]],\n",
      "\n",
      "         [[-8.4010e-01]],\n",
      "\n",
      "         [[-4.7240e-01]],\n",
      "\n",
      "         [[-4.0943e-01]],\n",
      "\n",
      "         [[ 3.6342e-01]],\n",
      "\n",
      "         [[-3.4715e-01]],\n",
      "\n",
      "         [[ 6.4749e-02]],\n",
      "\n",
      "         [[-5.9481e-02]],\n",
      "\n",
      "         [[ 1.8594e-01]],\n",
      "\n",
      "         [[-2.0674e-01]],\n",
      "\n",
      "         [[ 1.0277e-01]],\n",
      "\n",
      "         [[-5.1262e-03]],\n",
      "\n",
      "         [[ 7.0312e-18]],\n",
      "\n",
      "         [[ 1.5137e-01]],\n",
      "\n",
      "         [[-6.7204e-02]],\n",
      "\n",
      "         [[ 9.5743e-03]],\n",
      "\n",
      "         [[ 2.5047e-01]],\n",
      "\n",
      "         [[ 1.7607e-01]],\n",
      "\n",
      "         [[ 2.4320e-01]],\n",
      "\n",
      "         [[ 7.2173e-02]],\n",
      "\n",
      "         [[ 3.5486e-02]],\n",
      "\n",
      "         [[-5.0573e-01]],\n",
      "\n",
      "         [[-3.6048e-02]],\n",
      "\n",
      "         [[ 4.2133e-01]],\n",
      "\n",
      "         [[ 1.9576e-01]],\n",
      "\n",
      "         [[-1.1449e+00]],\n",
      "\n",
      "         [[-3.1745e-02]],\n",
      "\n",
      "         [[-4.1712e-01]],\n",
      "\n",
      "         [[ 3.1579e-17]],\n",
      "\n",
      "         [[ 1.1915e-01]],\n",
      "\n",
      "         [[-2.8083e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4794e+00]],\n",
      "\n",
      "         [[ 3.8379e-01]],\n",
      "\n",
      "         [[ 1.2690e-01]],\n",
      "\n",
      "         [[-1.9931e-01]],\n",
      "\n",
      "         [[ 7.4906e-02]],\n",
      "\n",
      "         [[ 1.8341e-02]],\n",
      "\n",
      "         [[-2.9859e-01]],\n",
      "\n",
      "         [[ 1.1047e-02]],\n",
      "\n",
      "         [[ 4.1864e-01]],\n",
      "\n",
      "         [[ 4.4059e-01]],\n",
      "\n",
      "         [[-3.1080e-02]],\n",
      "\n",
      "         [[-3.7603e-01]],\n",
      "\n",
      "         [[-3.8320e-01]],\n",
      "\n",
      "         [[-3.9904e-17]],\n",
      "\n",
      "         [[ 3.0595e-01]],\n",
      "\n",
      "         [[-1.7269e+00]],\n",
      "\n",
      "         [[-8.3832e-02]],\n",
      "\n",
      "         [[-1.6970e-01]],\n",
      "\n",
      "         [[-6.9706e-01]],\n",
      "\n",
      "         [[-3.2347e-03]],\n",
      "\n",
      "         [[-1.3613e-02]],\n",
      "\n",
      "         [[ 4.0613e-02]],\n",
      "\n",
      "         [[ 3.2812e-01]],\n",
      "\n",
      "         [[ 1.6647e-02]],\n",
      "\n",
      "         [[-9.2776e-02]],\n",
      "\n",
      "         [[-1.7230e-01]],\n",
      "\n",
      "         [[ 8.8241e-02]],\n",
      "\n",
      "         [[-2.0986e-01]],\n",
      "\n",
      "         [[ 1.0047e-01]],\n",
      "\n",
      "         [[-5.7438e-17]],\n",
      "\n",
      "         [[-1.0933e-01]],\n",
      "\n",
      "         [[ 3.4535e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.1189e-01]],\n",
      "\n",
      "         [[-1.8654e-01]],\n",
      "\n",
      "         [[-1.3033e-01]],\n",
      "\n",
      "         [[ 1.3786e-01]],\n",
      "\n",
      "         [[-8.8092e-02]],\n",
      "\n",
      "         [[-2.1625e-02]],\n",
      "\n",
      "         [[ 7.0936e-01]],\n",
      "\n",
      "         [[-1.3341e-02]],\n",
      "\n",
      "         [[-3.6951e-01]],\n",
      "\n",
      "         [[-7.9334e-01]],\n",
      "\n",
      "         [[ 6.1708e-02]],\n",
      "\n",
      "         [[ 4.4145e-01]],\n",
      "\n",
      "         [[-2.9724e-01]],\n",
      "\n",
      "         [[-5.8409e-19]],\n",
      "\n",
      "         [[-3.8139e-01]],\n",
      "\n",
      "         [[-1.0753e+00]],\n",
      "\n",
      "         [[ 6.0398e-02]],\n",
      "\n",
      "         [[ 2.6933e-01]],\n",
      "\n",
      "         [[ 1.1121e+00]],\n",
      "\n",
      "         [[-1.1882e-01]],\n",
      "\n",
      "         [[ 6.2004e-02]],\n",
      "\n",
      "         [[ 2.3762e-01]],\n",
      "\n",
      "         [[-1.5444e-01]],\n",
      "\n",
      "         [[-1.5153e-01]],\n",
      "\n",
      "         [[ 1.2307e-01]],\n",
      "\n",
      "         [[ 2.9357e-01]],\n",
      "\n",
      "         [[-1.2696e-01]],\n",
      "\n",
      "         [[ 2.2966e-01]],\n",
      "\n",
      "         [[-1.5268e-01]],\n",
      "\n",
      "         [[ 7.4061e-17]],\n",
      "\n",
      "         [[ 2.8052e-01]],\n",
      "\n",
      "         [[-2.5656e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5018e-02]],\n",
      "\n",
      "         [[ 1.3305e-02]],\n",
      "\n",
      "         [[ 3.9483e-01]],\n",
      "\n",
      "         [[ 3.5803e-01]],\n",
      "\n",
      "         [[ 3.0358e-02]],\n",
      "\n",
      "         [[-4.1929e-03]],\n",
      "\n",
      "         [[ 2.1909e-01]],\n",
      "\n",
      "         [[ 2.5503e-01]],\n",
      "\n",
      "         [[ 2.6888e-01]],\n",
      "\n",
      "         [[ 1.9605e-02]],\n",
      "\n",
      "         [[-3.9387e-02]],\n",
      "\n",
      "         [[-1.0709e-01]],\n",
      "\n",
      "         [[ 8.9207e-02]],\n",
      "\n",
      "         [[ 6.4679e-18]],\n",
      "\n",
      "         [[ 5.2283e-02]],\n",
      "\n",
      "         [[-1.9052e-02]],\n",
      "\n",
      "         [[-2.1635e-01]],\n",
      "\n",
      "         [[ 2.8509e-02]],\n",
      "\n",
      "         [[ 3.2104e-01]],\n",
      "\n",
      "         [[ 1.0168e+00]],\n",
      "\n",
      "         [[-3.5677e-01]],\n",
      "\n",
      "         [[ 1.8780e-02]],\n",
      "\n",
      "         [[-2.2160e-01]],\n",
      "\n",
      "         [[ 2.7486e-02]],\n",
      "\n",
      "         [[ 4.7647e-01]],\n",
      "\n",
      "         [[-5.0608e-02]],\n",
      "\n",
      "         [[ 2.5407e-02]],\n",
      "\n",
      "         [[-1.0171e-01]],\n",
      "\n",
      "         [[ 4.6801e-01]],\n",
      "\n",
      "         [[ 3.0209e-17]],\n",
      "\n",
      "         [[ 4.2267e-01]],\n",
      "\n",
      "         [[-9.4780e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0858e-03]],\n",
      "\n",
      "         [[-9.8850e-02]],\n",
      "\n",
      "         [[-8.7649e-01]],\n",
      "\n",
      "         [[ 2.0273e-01]],\n",
      "\n",
      "         [[-2.2941e-01]],\n",
      "\n",
      "         [[-1.4109e-02]],\n",
      "\n",
      "         [[ 1.8655e-01]],\n",
      "\n",
      "         [[-3.8349e-02]],\n",
      "\n",
      "         [[-3.6785e-02]],\n",
      "\n",
      "         [[-8.6221e-02]],\n",
      "\n",
      "         [[ 4.6289e-03]],\n",
      "\n",
      "         [[ 8.3266e-02]],\n",
      "\n",
      "         [[-3.2838e-02]],\n",
      "\n",
      "         [[-8.4601e-18]],\n",
      "\n",
      "         [[ 5.8801e-03]],\n",
      "\n",
      "         [[ 1.3072e-02]],\n",
      "\n",
      "         [[ 5.3346e-02]],\n",
      "\n",
      "         [[-1.8764e+00]],\n",
      "\n",
      "         [[-2.6884e-01]],\n",
      "\n",
      "         [[-1.2687e-01]],\n",
      "\n",
      "         [[ 7.1032e-03]],\n",
      "\n",
      "         [[ 1.7468e-02]],\n",
      "\n",
      "         [[-3.0496e-01]],\n",
      "\n",
      "         [[-2.8971e-03]],\n",
      "\n",
      "         [[ 3.7691e-01]],\n",
      "\n",
      "         [[-6.7386e-02]],\n",
      "\n",
      "         [[ 9.1708e-01]],\n",
      "\n",
      "         [[-1.0908e-02]],\n",
      "\n",
      "         [[ 9.5139e-01]],\n",
      "\n",
      "         [[-3.9619e-18]],\n",
      "\n",
      "         [[-6.9154e-02]],\n",
      "\n",
      "         [[ 3.3605e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3196e-02]],\n",
      "\n",
      "         [[-3.7312e-01]],\n",
      "\n",
      "         [[-3.6590e-01]],\n",
      "\n",
      "         [[ 6.2443e-02]],\n",
      "\n",
      "         [[ 1.1217e-01]],\n",
      "\n",
      "         [[-1.2633e-01]],\n",
      "\n",
      "         [[-7.8161e-02]],\n",
      "\n",
      "         [[ 2.9398e-01]],\n",
      "\n",
      "         [[ 2.2428e-01]],\n",
      "\n",
      "         [[ 4.6255e-02]],\n",
      "\n",
      "         [[ 1.8306e-01]],\n",
      "\n",
      "         [[-1.4801e-01]],\n",
      "\n",
      "         [[-5.4511e-02]],\n",
      "\n",
      "         [[-1.4938e-17]],\n",
      "\n",
      "         [[-2.7659e-01]],\n",
      "\n",
      "         [[-9.8176e-03]],\n",
      "\n",
      "         [[ 2.1005e-01]],\n",
      "\n",
      "         [[-1.4999e-01]],\n",
      "\n",
      "         [[ 1.7637e-01]],\n",
      "\n",
      "         [[ 1.2063e-01]],\n",
      "\n",
      "         [[-2.8176e-01]],\n",
      "\n",
      "         [[ 3.3598e-02]],\n",
      "\n",
      "         [[-1.1797e+00]],\n",
      "\n",
      "         [[-6.9036e-02]],\n",
      "\n",
      "         [[-8.4316e-01]],\n",
      "\n",
      "         [[-9.5390e-02]],\n",
      "\n",
      "         [[-5.1716e-02]],\n",
      "\n",
      "         [[-1.5118e-01]],\n",
      "\n",
      "         [[-5.9474e-01]],\n",
      "\n",
      "         [[ 1.7235e-17]],\n",
      "\n",
      "         [[-1.8186e-01]],\n",
      "\n",
      "         [[ 1.6760e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.0694e-02]],\n",
      "\n",
      "         [[ 4.3372e-01]],\n",
      "\n",
      "         [[-1.9337e-01]],\n",
      "\n",
      "         [[ 9.1684e-02]],\n",
      "\n",
      "         [[-8.3747e-02]],\n",
      "\n",
      "         [[ 2.2812e-02]],\n",
      "\n",
      "         [[ 4.9351e-01]],\n",
      "\n",
      "         [[ 1.6442e-01]],\n",
      "\n",
      "         [[-2.2929e-01]],\n",
      "\n",
      "         [[-5.7119e-01]],\n",
      "\n",
      "         [[-1.8205e-02]],\n",
      "\n",
      "         [[-2.3519e-01]],\n",
      "\n",
      "         [[-3.0015e-02]],\n",
      "\n",
      "         [[-3.6250e-17]],\n",
      "\n",
      "         [[ 3.4081e-01]],\n",
      "\n",
      "         [[ 1.1191e-01]],\n",
      "\n",
      "         [[-7.7989e-02]],\n",
      "\n",
      "         [[ 3.6005e-01]],\n",
      "\n",
      "         [[-1.6853e+00]],\n",
      "\n",
      "         [[ 1.5310e-01]],\n",
      "\n",
      "         [[-1.3770e-01]],\n",
      "\n",
      "         [[-6.3572e-01]],\n",
      "\n",
      "         [[ 1.4641e-01]],\n",
      "\n",
      "         [[ 5.5886e-01]],\n",
      "\n",
      "         [[ 2.7746e-01]],\n",
      "\n",
      "         [[ 1.7502e-01]],\n",
      "\n",
      "         [[-2.3129e-01]],\n",
      "\n",
      "         [[-2.9239e-01]],\n",
      "\n",
      "         [[-2.4926e-01]],\n",
      "\n",
      "         [[-1.2226e-16]],\n",
      "\n",
      "         [[-2.9055e-01]],\n",
      "\n",
      "         [[ 3.6800e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.0023e-02]],\n",
      "\n",
      "         [[ 8.3805e-02]],\n",
      "\n",
      "         [[-8.9322e-02]],\n",
      "\n",
      "         [[-1.1030e+00]],\n",
      "\n",
      "         [[-8.6432e-02]],\n",
      "\n",
      "         [[ 1.2373e-01]],\n",
      "\n",
      "         [[ 3.6443e-02]],\n",
      "\n",
      "         [[ 3.8042e-01]],\n",
      "\n",
      "         [[-1.0206e-02]],\n",
      "\n",
      "         [[-3.3718e-02]],\n",
      "\n",
      "         [[ 5.0136e-01]],\n",
      "\n",
      "         [[-1.4288e-02]],\n",
      "\n",
      "         [[ 1.8909e-02]],\n",
      "\n",
      "         [[-2.0096e-17]],\n",
      "\n",
      "         [[ 7.0578e-02]],\n",
      "\n",
      "         [[ 3.3702e-02]],\n",
      "\n",
      "         [[ 2.4623e-01]],\n",
      "\n",
      "         [[ 4.1874e-02]],\n",
      "\n",
      "         [[ 1.1963e-01]],\n",
      "\n",
      "         [[ 7.5208e-01]],\n",
      "\n",
      "         [[ 2.6306e-01]],\n",
      "\n",
      "         [[-1.4355e-02]],\n",
      "\n",
      "         [[ 1.1260e-01]],\n",
      "\n",
      "         [[ 1.3964e-03]],\n",
      "\n",
      "         [[ 3.9340e-01]],\n",
      "\n",
      "         [[-2.9790e-02]],\n",
      "\n",
      "         [[ 7.9440e-01]],\n",
      "\n",
      "         [[-1.0249e-02]],\n",
      "\n",
      "         [[ 9.6252e-02]],\n",
      "\n",
      "         [[ 5.7733e-17]],\n",
      "\n",
      "         [[-2.1212e-02]],\n",
      "\n",
      "         [[-1.4167e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5379e-02]],\n",
      "\n",
      "         [[-1.4224e-02]],\n",
      "\n",
      "         [[ 3.1387e-01]],\n",
      "\n",
      "         [[-7.5811e-02]],\n",
      "\n",
      "         [[ 1.4114e-01]],\n",
      "\n",
      "         [[-8.5587e-03]],\n",
      "\n",
      "         [[ 1.7943e-01]],\n",
      "\n",
      "         [[ 4.3236e-02]],\n",
      "\n",
      "         [[-3.1615e-01]],\n",
      "\n",
      "         [[ 3.3590e-01]],\n",
      "\n",
      "         [[ 3.5677e-02]],\n",
      "\n",
      "         [[-1.8669e-01]],\n",
      "\n",
      "         [[ 2.1232e-02]],\n",
      "\n",
      "         [[ 5.8804e-17]],\n",
      "\n",
      "         [[-2.2436e-02]],\n",
      "\n",
      "         [[ 2.0076e-02]],\n",
      "\n",
      "         [[ 4.7261e-02]],\n",
      "\n",
      "         [[-2.9307e-01]],\n",
      "\n",
      "         [[-1.5571e-03]],\n",
      "\n",
      "         [[-2.5982e-02]],\n",
      "\n",
      "         [[-4.0571e-02]],\n",
      "\n",
      "         [[-3.0982e-02]],\n",
      "\n",
      "         [[-3.9017e-02]],\n",
      "\n",
      "         [[ 3.7642e-02]],\n",
      "\n",
      "         [[-2.5220e-01]],\n",
      "\n",
      "         [[ 2.1428e+00]],\n",
      "\n",
      "         [[ 1.1642e-01]],\n",
      "\n",
      "         [[-4.8645e-02]],\n",
      "\n",
      "         [[ 2.1545e-01]],\n",
      "\n",
      "         [[-2.8057e-17]],\n",
      "\n",
      "         [[-5.7676e-03]],\n",
      "\n",
      "         [[ 3.8386e-03]]]], device='cuda:0')\n",
      "Shape: torch.Size([16, 32, 1, 1])\n",
      "\n",
      "Layer: features.1.conv.2.weight\n",
      "Weights: tensor([6.3647, 6.5710, 3.3553, 6.5215, 4.8815, 7.7959, 3.8385, 6.8555, 4.1766,\n",
      "        4.6549, 6.4026, 7.8247, 5.0895, 4.5356, 6.4430, 5.1102],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([16])\n",
      "\n",
      "Layer: features.1.conv.2.bias\n",
      "Weights: tensor([ 1.7123e-05, -2.7751e-05, -1.3899e-05, -1.0712e-05,  1.9244e-06,\n",
      "        -1.9829e-06, -1.2686e-05,  2.0950e-05,  4.7521e-06,  1.0942e-05,\n",
      "         1.2953e-05,  2.1889e-05, -1.9752e-05, -2.4471e-05,  1.4171e-06,\n",
      "         1.6800e-05], device='cuda:0')\n",
      "Shape: torch.Size([16])\n",
      "\n",
      "Layer: features.2.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.3426]],\n",
      "\n",
      "         [[-0.4564]],\n",
      "\n",
      "         [[-0.1110]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1685]],\n",
      "\n",
      "         [[-0.0453]],\n",
      "\n",
      "         [[ 0.0107]]],\n",
      "\n",
      "\n",
      "        [[[-0.0322]],\n",
      "\n",
      "         [[ 0.0079]],\n",
      "\n",
      "         [[ 0.6602]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3885]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         [[-0.0264]]],\n",
      "\n",
      "\n",
      "        [[[-0.0468]],\n",
      "\n",
      "         [[-0.0381]],\n",
      "\n",
      "         [[-0.1007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0481]],\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[ 0.1891]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0196]],\n",
      "\n",
      "         [[-0.0908]],\n",
      "\n",
      "         [[-0.0733]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4355]],\n",
      "\n",
      "         [[ 0.0169]],\n",
      "\n",
      "         [[-0.0293]]],\n",
      "\n",
      "\n",
      "        [[[ 0.9530]],\n",
      "\n",
      "         [[-0.3483]],\n",
      "\n",
      "         [[ 0.0339]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0953]],\n",
      "\n",
      "         [[-0.2472]],\n",
      "\n",
      "         [[ 0.1898]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0288]],\n",
      "\n",
      "         [[ 0.0049]],\n",
      "\n",
      "         [[ 0.7995]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4346]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         [[ 0.0118]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 16, 1, 1])\n",
      "\n",
      "Layer: features.2.conv.0.1.weight\n",
      "Weights: tensor([ 1.7247,  4.1887,  0.7494,  0.6663,  9.9635,  2.5291,  9.0602,  1.3370,\n",
      "         0.7550,  1.1049,  0.4882,  1.1830,  3.7646,  0.8134,  1.0003,  0.5323,\n",
      "         1.0350,  0.4374,  2.1823,  2.0356,  0.4916,  0.9686,  5.5052,  1.2162,\n",
      "         1.4870,  0.7033,  0.8449,  1.7252,  0.8037,  2.5920,  1.1668,  1.8728,\n",
      "         1.3435,  2.2484,  1.0678,  1.2182,  0.9369,  2.8466,  1.1962,  4.3305,\n",
      "         0.7859,  0.7134,  0.7853,  0.3656,  2.0253,  0.5066,  0.6290,  0.9783,\n",
      "         0.5842,  1.1166,  2.0352,  5.5462,  1.0852,  0.8550,  5.2345,  1.1235,\n",
      "         0.4552,  0.9469,  1.0367,  3.2726,  2.1687,  1.3887,  4.8131,  1.7548,\n",
      "         2.0701,  1.3905,  0.6339,  1.0525,  1.2559,  1.1783,  1.3257,  1.6706,\n",
      "         1.6592,  0.6895,  5.7948,  3.8543,  1.6495,  1.1311,  4.1170,  1.7610,\n",
      "         2.3540, 15.2547,  1.3815,  1.6941,  4.2721,  0.9249,  1.9517,  1.3350,\n",
      "         2.6972,  1.6992,  1.0109,  1.6386,  0.5449,  3.4082,  1.9390,  7.7758],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.0.1.bias\n",
      "Weights: tensor([ 2.6648,  1.0656,  0.5563,  2.2933,  2.5505, -0.2472,  2.3496, -0.0417,\n",
      "         0.9718,  2.9218,  5.9433,  2.2507,  2.8073,  0.2451, -0.0202,  2.2519,\n",
      "        -0.0470,  2.7474, -0.0414,  0.0610,  2.5959,  1.2214,  0.7869,  0.7366,\n",
      "         1.1480,  2.8393,  0.5980,  2.8556,  1.9898,  1.2269, -0.0754,  0.0632,\n",
      "         0.3786, -0.0381,  3.4157,  2.3872,  2.8776,  2.4608, -0.0638,  2.6482,\n",
      "         0.9673,  0.2847,  1.6630,  3.5481,  0.0507,  2.1501,  4.0111,  1.3801,\n",
      "         2.2180,  2.7637, -0.1436,  0.0754,  2.9416,  3.4455,  2.5550,  2.6879,\n",
      "         2.0186,  1.9961,  3.0597, -0.1987,  3.1346,  2.6214, -0.2483, -0.0686,\n",
      "         0.9592, -0.0347,  1.2207, -0.6273,  2.8937,  0.8233,  0.5382, -0.0295,\n",
      "         2.7192,  0.8603,  1.8965,  2.7345, -0.0776,  0.3284, -0.4123, -0.0574,\n",
      "        -0.5504,  2.9408,  3.9962,  3.4339,  4.9460,  0.9699,  0.8379, -0.0925,\n",
      "         0.1679, -0.1979, -0.8700, -0.1272,  3.2298, -0.2935, -0.0461, -0.0919],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.1.0.weight\n",
      "Weights: tensor([[[[-1.8443e-01, -2.5724e-01, -9.5347e-02],\n",
      "          [ 3.6125e-01,  5.7393e-01,  2.9340e-01],\n",
      "          [-9.7490e-02, -1.6637e-01, -1.1422e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0175e-02,  5.9562e-02,  2.5728e-02],\n",
      "          [-7.7576e-03, -1.0879e-01, -1.0682e-01],\n",
      "          [-2.3336e-01, -2.8364e-01, -1.6213e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7585e-02, -2.0966e-01, -1.5505e-02],\n",
      "          [ 6.5486e-02,  6.7997e-01,  3.9819e-01],\n",
      "          [-1.8469e-03, -2.4071e-01, -5.7320e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9437e-02, -6.2980e-02,  4.9549e-02],\n",
      "          [-1.5582e-01,  6.1941e-01, -2.9313e-01],\n",
      "          [ 1.4129e-01, -5.4622e-01,  2.7290e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6414e-01,  1.4690e-02,  1.7512e-01],\n",
      "          [-5.4443e-01, -9.5207e-03,  5.3700e-01],\n",
      "          [-1.6040e-01, -6.1250e-03,  1.4033e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5948e-01,  2.3380e-01,  1.5859e-01],\n",
      "          [ 2.1495e-01,  3.6795e-01,  2.7573e-01],\n",
      "          [ 1.0597e-01,  1.5579e-01,  1.3932e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2506e-02, -2.0453e-01, -9.4891e-02],\n",
      "          [-1.7996e-01, -3.4537e-01, -1.8327e-01],\n",
      "          [-9.6741e-02, -1.5630e-01, -9.1874e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4574e-02,  1.1895e-01,  1.9723e-01],\n",
      "          [ 7.3621e-02,  3.2703e-01,  4.2314e-01],\n",
      "          [ 4.5503e-02,  2.9531e-01,  2.8764e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.9451e-02, -2.4091e-01, -1.8478e-01],\n",
      "          [-1.4970e-01, -3.5666e-01, -1.9055e-01],\n",
      "          [ 1.2075e-01,  5.2274e-01,  4.6165e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.3893e-02, -1.7144e-01,  1.2910e-01],\n",
      "          [-1.4037e-01,  4.6024e-01, -3.2350e-01],\n",
      "          [ 7.2830e-02, -2.7382e-01,  2.0132e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7590e-01, -2.4140e-01,  8.5013e-02],\n",
      "          [-1.9427e-01, -1.8394e-01,  5.5550e-01],\n",
      "          [-4.1399e-02,  1.7406e-01,  4.4368e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6428e-01, -3.7046e-01, -2.8189e-01],\n",
      "          [-2.8182e-02,  1.2357e-01,  1.5820e-01],\n",
      "          [ 1.9776e-01,  3.5490e-01,  2.4783e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7906e-01, -3.6492e-01, -2.3282e-01],\n",
      "          [-1.1521e-02, -7.2736e-03,  2.5643e-02],\n",
      "          [ 1.4471e-01,  4.3509e-01,  2.4617e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2307e-01,  1.5311e-02, -1.5318e-01],\n",
      "          [ 2.3981e-01,  1.1212e-01, -3.6555e-01],\n",
      "          [ 1.3363e-01,  1.1364e-01, -2.1147e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4066e-02,  1.4693e-01,  2.8537e-01],\n",
      "          [ 2.4858e-02,  3.6846e-01,  5.8395e-01],\n",
      "          [ 2.3824e-02,  2.5721e-01,  4.1281e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4990e-01,  4.9075e-01, -3.2664e-01],\n",
      "          [ 1.1522e-01, -2.5519e-01,  1.6880e-01],\n",
      "          [ 3.9638e-02, -2.6960e-01,  1.6144e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5091e-01, -3.6035e-01, -2.5460e-01],\n",
      "          [-2.3755e-01, -5.2636e-01, -4.0691e-01],\n",
      "          [-1.3892e-01, -2.1655e-01, -1.5979e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8980e-02, -9.1439e-02,  3.6661e-02],\n",
      "          [ 3.5798e-01, -6.2869e-01,  2.4738e-01],\n",
      "          [ 3.1356e-01, -4.9230e-01,  1.5849e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.4897e-03,  2.2524e-01,  2.2280e-01],\n",
      "          [ 1.0227e-01,  3.7792e-01,  5.3631e-01],\n",
      "          [ 5.6323e-02,  2.5256e-01,  3.9371e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0970e-01,  1.0900e-01, -9.1141e-02],\n",
      "          [ 4.1786e-01,  2.6050e-01, -1.8480e-01],\n",
      "          [ 2.3796e-01,  2.3407e-01, -3.2036e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5411e-02, -3.3268e-01,  3.0939e-01],\n",
      "          [-8.4398e-02,  5.4583e-01, -5.0386e-01],\n",
      "          [ 4.9191e-02, -2.2330e-01,  1.9041e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8185e-01,  3.5363e-01,  2.2586e-01],\n",
      "          [-1.6487e-01, -3.6737e-01, -2.1013e-01],\n",
      "          [-2.5498e-02,  5.2223e-02, -2.2639e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.6521e-02, -1.5010e-01, -6.6369e-02],\n",
      "          [-2.3178e-01, -3.8416e-01, -1.4150e-01],\n",
      "          [-1.9551e-01, -2.9067e-01, -1.2052e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1718e-01, -1.3063e-01,  2.3976e-01],\n",
      "          [-1.7568e-01, -2.8733e-01,  4.5672e-01],\n",
      "          [-1.4254e-01, -1.5174e-01,  3.1421e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.8979e-02, -2.0796e-01, -2.8846e-01],\n",
      "          [ 2.4488e-04,  1.1016e-01,  9.9218e-02],\n",
      "          [-1.6072e-01,  4.6569e-01,  6.7172e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.6879e-02, -2.1220e-01, -9.5952e-02],\n",
      "          [-3.0997e-01, -4.3179e-01, -2.5946e-01],\n",
      "          [-2.1414e-01, -3.2550e-01, -1.9410e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2413e-01, -4.3817e-01, -2.2438e-01],\n",
      "          [-2.3347e-01,  2.3859e-01,  3.8458e-01],\n",
      "          [ 1.3699e-01,  3.5230e-01,  3.9368e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4866e-01,  2.8679e-03,  1.1821e-01],\n",
      "          [ 3.8855e-01, -2.9074e-02, -4.4824e-01],\n",
      "          [-2.7080e-01, -6.5110e-02,  2.7280e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0171e-01,  1.9035e-01, -2.8021e-01],\n",
      "          [ 8.2809e-02,  2.4612e-01, -5.2528e-01],\n",
      "          [ 7.3050e-02,  1.0156e-01, -3.0767e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0402e-01, -7.6626e-02, -3.1821e-02],\n",
      "          [-4.5154e-01, -2.8018e-01, -7.3102e-02],\n",
      "          [-2.0360e-01, -1.5420e-01, -7.6864e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9043e-02,  1.5258e-01,  2.2451e-01],\n",
      "          [ 3.9971e-02,  4.1465e-01,  4.9260e-01],\n",
      "          [ 2.9923e-02,  3.1183e-01,  3.7471e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.1794e-02,  1.7795e-01,  6.0928e-02],\n",
      "          [-7.3710e-02,  3.1512e-01,  1.6593e-01],\n",
      "          [ 2.0093e-02,  2.3833e-01,  1.6535e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9611e-01, -1.2899e-01, -5.0494e-02],\n",
      "          [ 4.1330e-01, -1.9627e-01, -6.3805e-02],\n",
      "          [ 1.9833e-01, -2.3857e-02, -1.2965e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4327e-01, -2.7494e-01, -1.9668e-01],\n",
      "          [-3.2851e-01, -4.9188e-01, -3.6122e-01],\n",
      "          [-1.9934e-01, -3.7935e-01, -2.7371e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2211e-01, -3.6623e-01, -3.8703e-02],\n",
      "          [ 3.2832e-01, -6.2017e-01, -7.5133e-02],\n",
      "          [ 6.5813e-02, -2.5518e-01, -9.6677e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3187e-01,  1.9641e-01,  3.2848e-02],\n",
      "          [-3.9901e-01,  3.2890e-01,  9.6587e-02],\n",
      "          [-2.5677e-01,  2.1237e-01,  8.8836e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4130e-02, -2.7551e-01,  2.3959e-01],\n",
      "          [-1.9265e-01,  6.5930e-01, -4.6679e-01],\n",
      "          [ 1.2896e-01, -3.1693e-01,  1.6895e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4746e-01, -2.0045e-02, -2.1396e-01],\n",
      "          [ 5.6203e-01, -1.8745e-03, -5.2021e-01],\n",
      "          [ 2.0336e-01,  2.9689e-02, -1.5971e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5913e-01,  3.3721e-01,  2.6574e-01],\n",
      "          [ 1.9313e-01,  3.8682e-01,  2.6792e-01],\n",
      "          [ 4.7948e-02,  1.3460e-01,  9.8264e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.3219e-02, -1.5708e-01, -1.5641e-01],\n",
      "          [-1.0087e-01, -3.9932e-01, -3.3464e-01],\n",
      "          [-8.1203e-02, -2.6770e-01, -2.6005e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1664e-02, -7.3078e-02, -2.9284e-01],\n",
      "          [ 9.1677e-02,  6.7136e-01,  3.7172e-01],\n",
      "          [-3.0643e-01, -3.9730e-01, -1.0753e-01]]],\n",
      "\n",
      "\n",
      "        [[[-4.8954e-02, -3.8683e-01, -3.8410e-01],\n",
      "          [ 6.0673e-02,  1.2305e-01,  3.3184e-02],\n",
      "          [-1.1377e-01,  5.6073e-01,  5.9268e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.1135e-02,  2.4692e-01, -1.6056e-01],\n",
      "          [-1.3565e-01,  4.6063e-01, -3.3516e-01],\n",
      "          [-8.4310e-02,  2.8162e-01, -1.9822e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5530e-02,  1.7582e-01,  3.7282e-01],\n",
      "          [ 2.2387e-02,  3.0925e-01,  5.7316e-01],\n",
      "          [ 2.2001e-02,  1.9365e-01,  3.6587e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0883e-02,  1.9780e-01,  9.3333e-02],\n",
      "          [ 1.3971e-01,  3.4927e-01,  1.7715e-01],\n",
      "          [ 1.2430e-01,  2.7050e-01,  1.5053e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.1140e-02, -1.5921e-01,  6.9742e-02],\n",
      "          [-3.6314e-01,  7.2204e-01, -3.1501e-01],\n",
      "          [ 2.8319e-01, -5.2464e-01,  2.5993e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8798e-01,  3.6908e-01,  2.3360e-01],\n",
      "          [ 2.4415e-01,  4.1559e-01,  2.5626e-01],\n",
      "          [ 9.4011e-02,  1.4295e-01,  5.9721e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5635e-02,  1.5367e-01,  8.7368e-02],\n",
      "          [ 1.5757e-01,  3.0185e-01,  2.9770e-01],\n",
      "          [ 8.5064e-02,  1.8149e-01,  1.3317e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.8343e-02,  2.7537e-01, -1.6641e-01],\n",
      "          [ 2.6203e-01, -7.0834e-01,  3.4951e-01],\n",
      "          [-1.6341e-01,  4.0708e-01, -1.9319e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4568e-01, -3.6181e-01,  2.1956e-01],\n",
      "          [ 6.7455e-02, -1.2125e-01,  7.1369e-02],\n",
      "          [-2.4259e-01,  5.8700e-01, -2.3630e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5154e-01,  3.0262e-01,  2.3808e-01],\n",
      "          [ 2.9219e-01,  5.4087e-01,  4.1261e-01],\n",
      "          [ 2.0751e-01,  3.6232e-01,  2.3781e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.6657e-02, -1.0654e-01, -8.3082e-02],\n",
      "          [-1.0866e-01, -3.5695e-01, -3.2384e-01],\n",
      "          [-7.3726e-02, -1.8221e-01, -1.5163e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6671e-01,  8.1198e-02, -2.4854e-01],\n",
      "          [-3.1769e-01, -3.1412e-01,  6.4342e-01],\n",
      "          [ 1.2531e-01,  1.7823e-01, -3.0401e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3431e-01, -1.3946e-02,  3.4058e-02],\n",
      "          [ 9.0866e-02, -4.3755e-01, -4.6675e-01],\n",
      "          [-5.2202e-02, -4.7553e-01, -5.6220e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8006e-01, -5.5236e-02, -2.6660e-01],\n",
      "          [ 4.6333e-01, -2.4823e-02, -5.0352e-01],\n",
      "          [ 2.4865e-01,  2.7517e-03, -2.4666e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3319e-01,  3.9027e-01, -4.7003e-02],\n",
      "          [ 4.7870e-01, -5.2083e-01,  2.2427e-02],\n",
      "          [-1.2419e-01,  8.3537e-02,  2.3675e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6094e-01, -1.2775e-01,  2.7526e-01],\n",
      "          [ 1.8510e-01, -2.5262e-01, -5.0334e-01],\n",
      "          [-1.8796e-02,  3.7895e-01,  1.9610e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5662e-01,  2.0165e-01,  1.1456e-01],\n",
      "          [ 2.3454e-02,  8.2308e-02,  2.1143e-01],\n",
      "          [-1.4463e-01, -4.9376e-01, -4.5556e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.7893e-02,  2.9219e-01, -1.8730e-01],\n",
      "          [-7.0436e-02,  5.3544e-01, -2.7460e-01],\n",
      "          [-1.9700e-02,  3.1822e-01, -1.8396e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7074e-02, -1.1443e-01, -5.0513e-02],\n",
      "          [-2.4905e-01, -1.8732e-01, -9.1637e-02],\n",
      "          [-1.4723e-01, -1.9738e-01, -8.8182e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0958e-02,  5.8653e-02,  1.1984e-03],\n",
      "          [-8.6233e-02, -2.9119e-01, -2.2656e-01],\n",
      "          [-1.5162e-01, -3.3271e-01, -2.0242e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2814e-02, -6.9034e-02,  6.3164e-02],\n",
      "          [ 2.3146e-01,  6.8355e-01,  2.4584e-01],\n",
      "          [-7.0936e-02, -2.2718e-01, -2.5433e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.7065e-02, -1.7017e-01, -1.3632e-01],\n",
      "          [-2.0581e-01, -4.8141e-01, -3.1561e-01],\n",
      "          [-1.2754e-01, -3.1105e-01, -2.2552e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.6258e-01, -3.1452e-01, -2.4419e-01],\n",
      "          [-3.0385e-01, -5.4714e-01, -4.0412e-01],\n",
      "          [-2.0453e-01, -3.6282e-01, -2.4638e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3764e-01,  2.0585e-01,  1.7119e-01],\n",
      "          [-1.2142e-01, -7.9279e-02, -2.3861e-02],\n",
      "          [-1.7875e-01, -4.2164e-01, -3.2082e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 9.0492e-02,  6.4712e-02, -2.0738e-02],\n",
      "          [ 3.3405e-01,  2.7804e-01, -1.9910e-01],\n",
      "          [ 1.8382e-01,  1.7538e-01, -2.3810e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8395e-01, -1.8051e-01, -1.9933e-02],\n",
      "          [-5.6086e-03,  3.8411e-01, -3.1618e-01],\n",
      "          [-1.4583e-01, -1.8083e-01,  3.8836e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0771e-02,  2.2745e-01,  1.7642e-01],\n",
      "          [ 1.7451e-01,  4.6989e-01,  3.7945e-01],\n",
      "          [ 5.3422e-02,  1.7825e-01,  1.4390e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7659e-01,  4.6864e-01,  3.4525e-01],\n",
      "          [-9.1141e-02, -3.6178e-01, -3.1909e-01],\n",
      "          [-8.4650e-02, -8.4309e-02,  3.7520e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8457e-02,  1.4598e-01,  6.6904e-02],\n",
      "          [ 2.1123e-01,  3.9055e-01,  2.1135e-01],\n",
      "          [ 1.4287e-01,  2.2613e-01,  1.0797e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.0479e-01,  9.7311e-02,  6.9448e-02],\n",
      "          [ 1.8973e-01,  2.5572e-01,  1.5598e-01],\n",
      "          [-1.8651e-01, -3.2158e-01, -1.8028e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9815e-02,  1.3926e-01, -9.6380e-03],\n",
      "          [ 4.1061e-02,  5.1406e-01, -1.1698e-01],\n",
      "          [ 1.0136e-01,  4.4064e-01,  5.5079e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2075e-02,  1.8388e-02,  4.5014e-02],\n",
      "          [-7.6733e-02, -2.8535e-01, -2.3702e-01],\n",
      "          [ 1.9185e-01,  5.0103e-01,  3.8408e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.3650e-02, -1.4294e-01, -1.3348e-01],\n",
      "          [-1.5555e-01, -3.9698e-01, -2.1404e-01],\n",
      "          [ 1.1655e-01,  3.8528e-01,  2.9314e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.8761e-02, -2.0506e-01, -1.0923e-01],\n",
      "          [-1.4768e-01, -3.7901e-01, -2.6238e-01],\n",
      "          [-4.3386e-02, -1.5421e-01, -1.3970e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8622e-01, -4.0944e-02, -2.5092e-01],\n",
      "          [ 4.4363e-01, -1.5038e-03, -4.3708e-01],\n",
      "          [ 2.1610e-01,  3.3031e-02, -1.9869e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3699e-01,  2.0247e-01,  1.9052e-01],\n",
      "          [ 2.4433e-01,  4.1936e-01,  3.8402e-01],\n",
      "          [ 1.4706e-01,  2.5063e-01,  1.8556e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1367e-01, -2.4623e-01, -4.1036e-01],\n",
      "          [-1.1153e-02,  1.8389e-01,  1.9350e-01],\n",
      "          [-1.9793e-01,  4.0965e-01,  6.7757e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2130e-02, -1.2980e-01, -1.1265e-01],\n",
      "          [-1.4634e-01, -2.0862e-01, -1.8155e-01],\n",
      "          [-7.9812e-02, -1.5335e-01, -1.2400e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7400e-01,  3.0228e-01,  1.7959e-01],\n",
      "          [ 2.9627e-01,  5.4663e-01,  4.0688e-01],\n",
      "          [ 1.8987e-01,  3.6853e-01,  3.0609e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1047e-02,  1.5038e-01,  1.2249e-01],\n",
      "          [ 1.3915e-01,  3.8367e-01,  3.0674e-01],\n",
      "          [ 1.2462e-01,  2.8242e-01,  1.9540e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.1602e-02, -2.1966e-01, -9.5104e-02],\n",
      "          [-1.0835e-01, -4.1997e-01, -2.0734e-01],\n",
      "          [-6.3506e-02, -2.4519e-01, -1.1520e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9197e-02, -1.9223e-02,  9.2073e-03],\n",
      "          [-1.5492e-01,  5.5895e-02,  1.0389e-01],\n",
      "          [-1.1167e-02, -3.8805e-01, -4.8559e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.2209e-02, -2.6266e-01, -2.2131e-01],\n",
      "          [-1.5540e-01, -2.4963e-01, -1.9201e-01],\n",
      "          [ 1.5796e-01,  5.7585e-01,  4.3814e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5278e-02,  1.9793e-01,  1.9949e-01],\n",
      "          [-1.9170e-03, -4.5099e-04, -1.1482e-01],\n",
      "          [-2.6390e-02, -3.1286e-01, -4.6755e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.5433e-02,  9.6400e-02, -4.4782e-02],\n",
      "          [-2.8308e-01,  4.7741e-01, -1.9588e-01],\n",
      "          [-1.9488e-01,  1.6312e-01, -3.9993e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.5921e-02, -1.2828e-01,  1.4585e-01],\n",
      "          [-1.4339e-01, -2.5685e-01,  4.1156e-01],\n",
      "          [-1.2018e-01, -1.7831e-01,  2.8822e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7742e-02, -1.8929e-01, -1.0727e-01],\n",
      "          [-1.8547e-01, -4.6418e-01, -3.4301e-01],\n",
      "          [-1.2256e-01, -3.4591e-01, -2.6809e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4570e-01, -1.7422e-01, -2.0412e-01],\n",
      "          [-4.7459e-02,  1.7810e-01,  1.5609e-01],\n",
      "          [-1.8567e-02,  3.6146e-01,  4.7401e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9862e-02,  2.7317e-01,  1.4058e-01],\n",
      "          [ 1.6430e-01,  5.3506e-01,  2.4512e-01],\n",
      "          [ 8.6946e-02,  3.4831e-01,  1.5966e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 8.8603e-02,  1.5227e-01,  1.2644e-01],\n",
      "          [ 1.8811e-01,  3.6936e-01,  2.5579e-01],\n",
      "          [ 8.7888e-02,  1.9393e-01,  1.1616e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7390e-01,  3.1331e-01,  2.1142e-01],\n",
      "          [ 2.8858e-01,  5.4540e-01,  3.9854e-01],\n",
      "          [ 1.7707e-01,  3.4809e-01,  2.8804e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9319e-01,  2.7881e-01,  9.5896e-02],\n",
      "          [ 3.7916e-01,  4.9554e-01,  1.6486e-01],\n",
      "          [ 2.3662e-01,  3.1106e-01,  1.0653e-01]]],\n",
      "\n",
      "\n",
      "        [[[-9.8036e-02, -1.4082e-01, -5.8639e-02],\n",
      "          [-2.5474e-01, -2.4524e-01, -1.4744e-01],\n",
      "          [-1.5995e-01, -1.5864e-01, -8.7619e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6946e-01,  3.0224e-01,  2.3848e-01],\n",
      "          [ 2.8642e-01,  5.4142e-01,  3.9161e-01],\n",
      "          [ 2.0536e-01,  3.6715e-01,  2.4917e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6545e-02,  7.6723e-02,  9.8602e-02],\n",
      "          [-6.5597e-02,  8.8207e-03, -3.6653e-02],\n",
      "          [-1.7955e-01, -2.6694e-01, -3.1255e-01]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 1, 3, 3])\n",
      "\n",
      "Layer: features.2.conv.1.1.weight\n",
      "Weights: tensor([1.3826, 0.4465, 1.0057, 1.1802, 0.8556, 0.8711, 0.6861, 0.8786, 0.9178,\n",
      "        1.2051, 0.7146, 1.0985, 1.1563, 0.4949, 0.7424, 1.0774, 0.7993, 1.3455,\n",
      "        0.9056, 0.8236, 1.1919, 1.0849, 1.6064, 0.9530, 0.7053, 1.2147, 0.7584,\n",
      "        1.1402, 1.3563, 1.7262, 0.7506, 0.5948, 0.8841, 1.0125, 1.4416, 1.8425,\n",
      "        1.0929, 0.8497, 0.6907, 0.7241, 0.9112, 0.5655, 1.2805, 1.6659, 0.7497,\n",
      "        1.1215, 2.4085, 0.9152, 1.2689, 1.1327, 0.9139, 1.7826, 1.1984, 0.9393,\n",
      "        0.8438, 1.1397, 1.1630, 1.3912, 1.2265, 1.4921, 1.2953, 1.5999, 0.9642,\n",
      "        0.9935, 0.5862, 0.6060, 0.9339, 0.6797, 1.4553, 0.8006, 1.0123, 0.8413,\n",
      "        1.3069, 1.3651, 0.7587, 0.7095, 0.9532, 0.6985, 1.1660, 0.9955, 0.7094,\n",
      "        0.7646, 0.7931, 0.9855, 0.5435, 0.7759, 1.0488, 0.7934, 0.5261, 0.9567,\n",
      "        0.6295, 0.9668, 1.6556, 0.6938, 0.9707, 0.4797], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.1.1.bias\n",
      "Weights: tensor([ 7.5620e-03,  7.4247e-01, -7.8194e-02,  2.6745e-04,  1.7465e+00,\n",
      "         8.8393e-01,  7.3902e-01,  8.1962e-01,  1.8966e-03, -6.3273e-03,\n",
      "         1.8983e+00,  2.1015e-01,  5.8337e-01,  1.2677e+00,  7.7360e-01,\n",
      "        -3.2448e-03,  5.1843e+00, -7.3580e-02,  1.6421e+00,  9.1868e-01,\n",
      "        -5.2219e-03, -2.1875e-02,  9.3169e-02,  2.5153e-02,  6.0127e-01,\n",
      "         1.9374e-01,  5.5692e-02, -7.3861e-03, -2.0706e-02, -2.8862e-02,\n",
      "         8.1430e-01,  1.3865e+00,  1.0753e-01,  3.4712e+00, -1.1026e-01,\n",
      "         1.3338e-01, -1.2485e-03,  3.0101e+00,  6.1986e-01,  1.9540e+00,\n",
      "        -7.2392e-03,  2.2067e-01,  2.0340e-02, -3.0140e-01,  2.5100e+00,\n",
      "         1.7716e-03, -7.9313e-01,  5.5139e-02, -5.0518e-03, -1.3580e-02,\n",
      "         1.4445e+00, -2.7540e-01, -9.7532e-04,  2.6185e+00,  2.1548e+00,\n",
      "        -1.3273e-03,  2.7660e-03, -5.9199e-02, -2.9659e-02,  3.2645e-01,\n",
      "        -3.3436e-01, -9.5921e-02,  4.1960e+00,  4.2505e+00,  9.3749e-01,\n",
      "         1.8490e+00,  3.0445e-04,  4.5149e-01, -4.6984e-02,  1.7726e-01,\n",
      "         1.1132e-02,  5.9014e-01, -1.4441e-02, -5.0097e-01,  7.8250e-01,\n",
      "         2.6715e+00,  9.5167e-01,  2.7783e-01,  5.7987e-02,  1.9873e+00,\n",
      "         1.1893e+00,  8.8009e-01,  1.9211e-01,  6.9451e-02,  2.8057e-01,\n",
      "         2.3206e-02,  1.0861e-02,  4.9461e+00,  2.4318e-01,  1.2453e+00,\n",
      "         3.3583e-01,  1.7951e+00, -2.3536e-01,  2.5779e+00,  2.2427e+00,\n",
      "         4.7208e-01], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.2.conv.2.weight\n",
      "Weights: tensor([[[[-0.1680]],\n",
      "\n",
      "         [[ 0.0610]],\n",
      "\n",
      "         [[ 0.1652]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0985]],\n",
      "\n",
      "         [[ 0.1989]],\n",
      "\n",
      "         [[-0.0177]]],\n",
      "\n",
      "\n",
      "        [[[-0.3762]],\n",
      "\n",
      "         [[ 0.0889]],\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0473]],\n",
      "\n",
      "         [[ 0.0692]],\n",
      "\n",
      "         [[-0.0124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0762]],\n",
      "\n",
      "         [[-0.5220]],\n",
      "\n",
      "         [[ 0.4601]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3724]],\n",
      "\n",
      "         [[-0.2044]],\n",
      "\n",
      "         [[-0.3410]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.7030]],\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[-0.1395]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0261]],\n",
      "\n",
      "         [[ 0.0780]],\n",
      "\n",
      "         [[-0.0275]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0539]],\n",
      "\n",
      "         [[-0.0503]],\n",
      "\n",
      "         [[ 0.1892]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1650]],\n",
      "\n",
      "         [[ 1.0237]],\n",
      "\n",
      "         [[-0.0188]]],\n",
      "\n",
      "\n",
      "        [[[-0.1638]],\n",
      "\n",
      "         [[-0.2871]],\n",
      "\n",
      "         [[ 0.0037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0950]],\n",
      "\n",
      "         [[ 0.1159]],\n",
      "\n",
      "         [[-0.1064]]]], device='cuda:0')\n",
      "Shape: torch.Size([24, 96, 1, 1])\n",
      "\n",
      "Layer: features.2.conv.3.weight\n",
      "Weights: tensor([5.2228, 5.2894, 5.4275, 3.9051, 3.2605, 5.6396, 6.7108, 7.2005, 6.5244,\n",
      "        5.9433, 7.1542, 6.2734, 5.2621, 5.5405, 5.0873, 6.6448, 3.3335, 5.3758,\n",
      "        4.6607, 5.6264, 4.3071, 7.7067, 6.9634, 5.4482], device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.2.conv.3.bias\n",
      "Weights: tensor([ 1.0881e-06,  3.0214e-06,  4.3825e-06,  1.5142e-06,  2.4640e-06,\n",
      "        -6.3383e-08,  5.0872e-06,  6.8371e-06,  2.7354e-06,  1.0333e-06,\n",
      "         1.7848e-07, -6.2331e-06,  3.8128e-07, -8.5036e-07,  6.6239e-06,\n",
      "        -1.0822e-06, -2.1203e-06,  1.5032e-06,  4.5900e-06,  1.1467e-05,\n",
      "         3.6715e-06,  1.4438e-05,  3.8392e-06, -2.5940e-06], device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.3.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.1575]],\n",
      "\n",
      "         [[ 0.0842]],\n",
      "\n",
      "         [[-0.1252]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1475]],\n",
      "\n",
      "         [[-0.0208]],\n",
      "\n",
      "         [[ 0.1073]]],\n",
      "\n",
      "\n",
      "        [[[-0.0812]],\n",
      "\n",
      "         [[ 0.3641]],\n",
      "\n",
      "         [[-0.0048]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3482]],\n",
      "\n",
      "         [[-0.2009]],\n",
      "\n",
      "         [[ 0.0918]]],\n",
      "\n",
      "\n",
      "        [[[-0.0345]],\n",
      "\n",
      "         [[-0.1274]],\n",
      "\n",
      "         [[ 0.0390]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3065]],\n",
      "\n",
      "         [[ 0.0241]],\n",
      "\n",
      "         [[-0.0779]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0490]],\n",
      "\n",
      "         [[ 0.0140]],\n",
      "\n",
      "         [[ 0.0162]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4867]],\n",
      "\n",
      "         [[-0.2367]],\n",
      "\n",
      "         [[-0.0338]]],\n",
      "\n",
      "\n",
      "        [[[-0.2036]],\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.0829]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1718]],\n",
      "\n",
      "         [[-0.1291]],\n",
      "\n",
      "         [[ 0.0009]]],\n",
      "\n",
      "\n",
      "        [[[-0.0956]],\n",
      "\n",
      "         [[ 0.0184]],\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1969]],\n",
      "\n",
      "         [[ 0.2275]],\n",
      "\n",
      "         [[ 0.0758]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 24, 1, 1])\n",
      "\n",
      "Layer: features.3.conv.0.1.weight\n",
      "Weights: tensor([ 1.4705,  3.9500,  1.4371,  2.9074,  0.5869,  1.8881,  1.1719,  1.5630,\n",
      "         1.0753,  1.1106,  0.8656,  1.6424,  0.5247,  2.8106,  0.7844,  1.8731,\n",
      "         1.3254,  1.2403,  3.3885,  1.4286,  1.3130,  2.0703,  0.4931,  2.1968,\n",
      "         1.2217,  1.2172,  2.1691,  1.0059,  0.4284,  1.8862,  1.0327,  1.1014,\n",
      "         1.8866,  1.1264,  2.1209,  0.8309,  1.9617,  0.8717,  1.8313,  1.9960,\n",
      "         1.6821,  2.8242,  1.2718,  0.9867,  2.7427,  1.5671,  2.5326,  1.7861,\n",
      "         1.1244,  0.8854,  1.9865,  0.7512,  0.6260,  1.4307,  0.8909,  1.5297,\n",
      "         1.6954,  0.8946,  2.0853,  0.6280,  0.9074,  1.7771,  0.6599,  1.9918,\n",
      "         3.6987,  1.3391,  1.0758,  0.8746,  0.7409,  1.5825,  1.1363,  1.3878,\n",
      "         1.6332,  0.8567,  1.4563,  2.0853,  0.9557,  3.1424,  1.3901,  0.8912,\n",
      "         1.9686,  2.0343, -0.1904,  1.0059,  1.1780,  1.9324,  0.7931,  0.8474,\n",
      "         2.1453,  2.0205,  0.9631,  1.3360,  0.9160,  1.1844,  1.4485,  0.8336,\n",
      "         1.7230,  3.1257,  1.0907,  1.6966,  1.2159,  0.3927,  0.4711,  0.9441,\n",
      "         0.9869,  2.4748,  0.3877,  0.8638,  1.1051,  0.8813,  2.0619,  0.7175,\n",
      "         0.7268,  1.1465,  0.6309,  1.7022,  0.8760,  2.5244,  1.3976,  1.4171,\n",
      "         0.8820,  1.0383,  1.9960,  1.7679,  1.5610,  0.7921,  1.0721,  2.4079,\n",
      "         1.9697,  1.7457,  1.0617,  2.6330,  2.1217,  0.6383,  0.4111,  2.2287,\n",
      "         1.0802,  1.0018,  0.7214,  3.8245,  1.6819,  0.8121,  1.0306,  1.5368],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.0.1.bias\n",
      "Weights: tensor([-0.5232, -3.1802,  1.5296, -1.2349,  1.8479, -0.9926,  1.8178,  1.6625,\n",
      "         0.8027,  1.4830,  2.4380, -1.1387,  1.7272,  1.6183,  1.5773, -0.9225,\n",
      "         0.5680,  1.4517, -3.3136, -0.3723,  1.0956, -0.0978,  2.1974, -1.2445,\n",
      "        -1.1887,  1.2709, -0.4919,  0.8362,  1.4255, -0.3078,  1.9176,  1.6258,\n",
      "        -0.8781,  1.2311, -1.0883,  1.1537, -0.2803,  1.6166, -0.2742, -0.5851,\n",
      "        -1.4594, -2.0855, -0.3799,  1.1365, -2.8877, -1.4197, -2.9356, -0.2443,\n",
      "         1.3150,  1.3154,  0.7153,  0.5749,  2.1254,  1.4043,  2.6706,  1.0689,\n",
      "        -0.4070,  1.0811, -0.9382,  2.1009,  1.5768, -0.3971,  2.4209, -0.4000,\n",
      "        -2.7176,  1.0587,  1.0363,  1.3204,  0.9793,  0.5368,  2.0689, -1.6877,\n",
      "         0.0446,  1.4897, -0.0239, -0.2206,  1.5489, -1.9373,  0.4771,  2.9947,\n",
      "        -0.5353, -0.0832, -1.8680,  1.0696,  1.5789,  1.8354,  0.2771,  2.4789,\n",
      "        -0.1117,  0.1722,  0.8008,  0.9835,  2.0963,  3.1257,  0.7726,  1.2979,\n",
      "        -0.7372,  3.0755,  1.1197, -0.7724,  2.3576,  3.3552,  5.5105,  1.5695,\n",
      "         2.8269,  3.6163,  3.6288,  1.8301,  1.8532,  1.2849, -0.2604,  2.5892,\n",
      "         1.7444,  0.3364,  1.9969,  1.5724,  1.2440,  1.4637,  0.4011,  1.2331,\n",
      "         1.4448,  0.1138, -0.6111,  0.1576, -0.4200,  1.2432,  2.7150,  2.7100,\n",
      "         0.4211, -0.4594,  0.5366,  1.0729,  1.6563,  1.2238,  2.0673, -2.0134,\n",
      "         1.4736,  0.2564,  1.3629,  4.9738,  1.3160,  1.4545,  1.3644, -0.3849],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0044, -0.1482, -0.0025],\n",
      "          [ 0.0576,  0.1330,  0.0086],\n",
      "          [ 0.1016,  0.2966,  0.0783]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0917,  0.1543,  0.1421],\n",
      "          [-0.0501, -0.7903, -0.1335],\n",
      "          [ 0.0780,  0.0840,  0.1025]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1437, -0.4141,  0.1264],\n",
      "          [ 0.0858, -0.2970,  0.1174],\n",
      "          [ 0.1316, -0.5710,  0.1309]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0784,  0.1673, -0.1362],\n",
      "          [ 0.3877,  0.1857, -0.4764],\n",
      "          [ 0.1749, -0.1880, -0.2622]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0067,  0.1376, -0.0119],\n",
      "          [-0.3247,  0.6082, -0.1075],\n",
      "          [-0.0718,  0.1341, -0.1093]]],\n",
      "\n",
      "\n",
      "        [[[-0.1851, -0.2015,  0.6039],\n",
      "          [-0.1613, -0.0538, -0.0851],\n",
      "          [ 0.5323, -0.0086, -0.3313]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 1, 3, 3])\n",
      "\n",
      "Layer: features.3.conv.1.1.weight\n",
      "Weights: tensor([1.0484, 0.5453, 1.7957, 0.8726, 3.1691, 0.8834, 0.9053, 1.1800, 1.4355,\n",
      "        1.2199, 1.3819, 0.5177, 1.3578, 0.8317, 1.0966, 0.5962, 0.5823, 1.0062,\n",
      "        0.4840, 0.5120, 0.9160, 1.2373, 1.8740, 0.5472, 0.3596, 1.5106, 0.7291,\n",
      "        0.9804, 2.5180, 0.6472, 0.9336, 0.8728, 0.8871, 1.5701, 0.7105, 1.3158,\n",
      "        1.0303, 1.2513, 0.7031, 0.9187, 0.5797, 0.9106, 0.6124, 1.0269, 0.6915,\n",
      "        0.5485, 1.1414, 0.7799, 0.9681, 0.9744, 1.1301, 1.1109, 1.1294, 1.7731,\n",
      "        1.3318, 1.1713, 0.7863, 1.0319, 0.5835, 1.2527, 1.2582, 0.9243, 0.8246,\n",
      "        0.9665, 0.6110, 0.9205, 1.2405, 1.2000, 1.4102, 0.8589, 0.8317, 0.3950,\n",
      "        1.0655, 1.1464, 0.5862, 1.1509, 1.2173, 0.8281, 1.1580, 4.3548, 0.9781,\n",
      "        1.1158, 0.5397, 1.3602, 1.3729, 0.7663, 1.8210, 1.4286, 1.1494, 0.7470,\n",
      "        1.3593, 0.7299, 1.1442, 0.8895, 0.6520, 1.3868, 0.6388, 1.0983, 1.0498,\n",
      "        0.7341, 1.4697, 2.1416, 1.2755, 1.1909, 0.7445, 1.5495, 4.8102, 1.2479,\n",
      "        0.9831, 1.0044, 0.8886, 1.4183, 1.0457, 1.2022, 1.3125, 1.2659, 1.2307,\n",
      "        1.2132, 0.9878, 0.7791, 1.1402, 1.1023, 0.8364, 0.7902, 0.8022, 1.2410,\n",
      "        1.2686, 1.2770, 1.0265, 0.7513, 1.1410, 1.1307, 1.1551, 1.0097, 2.3919,\n",
      "        0.8638, 0.8451, 0.9614, 1.1221, 1.5679, 1.2282, 1.1022, 1.3413, 0.6503],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.1.1.bias\n",
      "Weights: tensor([-1.3360e+00,  3.1414e+00, -1.0548e+00,  2.1674e-01, -3.1877e+00,\n",
      "         9.4011e-02,  2.6164e-03,  2.7771e-01, -5.2949e-01, -1.7107e-01,\n",
      "        -2.8380e-01,  2.5221e+00, -1.1125e-01,  7.4532e-01,  3.1851e-02,\n",
      "         2.3968e+00,  1.8716e+00, -5.8063e-02,  1.1389e+00,  2.3893e+00,\n",
      "         3.9203e-01,  2.5424e-02, -1.6268e+00,  1.8135e+00,  2.6642e+00,\n",
      "        -1.2059e+00,  2.8084e+00, -6.8557e-02, -6.3216e-01,  1.4009e+00,\n",
      "         2.1943e+00,  5.5944e-01,  7.2002e-03, -6.7995e-01,  6.2051e-01,\n",
      "        -5.1100e-03,  5.4799e-03, -5.1318e-01,  3.3272e+00,  5.9600e-02,\n",
      "         1.0165e+00,  3.8100e-01,  2.9263e+00, -1.0969e-01, -2.4174e-01,\n",
      "         3.8776e+00, -3.5973e+00,  4.7224e+00,  7.9077e-01,  5.4057e-02,\n",
      "         2.1317e-02, -2.3211e-01,  6.0020e-01,  6.8948e+00, -1.0372e-01,\n",
      "         7.2680e-03,  5.8811e-01,  1.1594e-02,  3.7885e+00, -1.5496e-02,\n",
      "         3.7930e-03, -1.8444e-01,  2.3845e+00, -2.9691e-02,  1.8386e+00,\n",
      "         7.5800e-01, -7.2158e-01, -1.3044e-02, -2.4782e-01,  3.5527e+00,\n",
      "         3.0909e+00,  3.5342e+00,  5.8332e-02, -2.7726e-01,  3.6157e+00,\n",
      "        -4.5028e-02, -4.3413e-01, -1.1491e-01,  1.7729e+00, -3.7289e-01,\n",
      "         7.5847e-03,  4.4589e-02, -6.3821e-01, -9.7726e-01, -2.6957e-01,\n",
      "         3.4671e-01, -1.1596e+00, -9.5065e-01, -6.5904e-03,  1.9222e+00,\n",
      "        -1.0770e-01,  2.3386e-01, -2.0107e-01,  1.1042e+00,  9.0699e-01,\n",
      "        -2.7845e-01,  2.6434e+00,  2.4803e-01, -3.3316e-01, -9.2999e-01,\n",
      "        -1.9949e-01,  4.8973e-01, -2.5600e-01,  3.3059e-02,  3.3313e+00,\n",
      "        -7.3918e-01, -2.5631e+00, -8.9273e-03,  1.5617e+00, -8.3449e-02,\n",
      "         1.8885e-01, -1.0513e+00, -4.5201e-02, -2.2191e-01, -4.7450e-02,\n",
      "        -3.9315e-01, -1.1857e-01, -5.3980e-02,  5.6569e-01, -2.3768e-02,\n",
      "        -1.1561e-01, -2.2656e-01, -7.1466e-02,  3.0843e-01,  2.7804e+00,\n",
      "        -1.4833e-01, -2.0032e-01, -9.8723e-02, -1.9379e-02,  7.1101e-01,\n",
      "        -1.5793e-01, -5.2176e-04, -3.7700e-01,  6.5474e-01, -2.9873e+00,\n",
      "        -8.3942e-01,  3.2947e+00,  5.9254e-01, -2.7000e-01, -1.2329e+00,\n",
      "        -2.5178e-02, -1.1659e-01, -1.4326e-01,  3.8965e+00], device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.3.conv.2.weight\n",
      "Weights: tensor([[[[ 0.1717]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[-0.0907]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1531]],\n",
      "\n",
      "         [[-0.1316]],\n",
      "\n",
      "         [[ 0.0274]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0616]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         [[ 0.1291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1601]],\n",
      "\n",
      "         [[ 0.0864]],\n",
      "\n",
      "         [[-0.0418]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0569]],\n",
      "\n",
      "         [[-0.1338]],\n",
      "\n",
      "         [[-0.0136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0808]],\n",
      "\n",
      "         [[-0.0587]],\n",
      "\n",
      "         [[-0.0410]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1046]],\n",
      "\n",
      "         [[-0.3163]],\n",
      "\n",
      "         [[-0.1079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0920]],\n",
      "\n",
      "         [[ 0.0929]],\n",
      "\n",
      "         [[-0.0221]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0259]],\n",
      "\n",
      "         [[ 0.3398]],\n",
      "\n",
      "         [[-0.0430]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0793]],\n",
      "\n",
      "         [[-0.3462]],\n",
      "\n",
      "         [[-0.1475]]],\n",
      "\n",
      "\n",
      "        [[[-0.0062]],\n",
      "\n",
      "         [[ 0.0785]],\n",
      "\n",
      "         [[-0.0539]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0616]],\n",
      "\n",
      "         [[-0.0482]],\n",
      "\n",
      "         [[ 0.0340]]]], device='cuda:0')\n",
      "Shape: torch.Size([24, 144, 1, 1])\n",
      "\n",
      "Layer: features.3.conv.3.weight\n",
      "Weights: tensor([ 5.1378,  4.7547,  2.2893,  6.0456, 10.0808,  5.4543,  3.4893,  4.6860,\n",
      "         2.0659,  6.4861,  4.4153,  4.6330,  2.4860,  3.1361,  7.1040,  2.9484,\n",
      "        10.2731,  4.7423,  4.0836,  6.4447,  6.0243,  2.7786,  5.7020,  2.1510],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.3.conv.3.bias\n",
      "Weights: tensor([ 6.3783e-07,  1.0743e-06,  1.3509e-06,  5.6569e-07,  2.5455e-06,\n",
      "        -1.2566e-06,  3.8278e-06,  3.7090e-06,  4.7356e-07,  2.6085e-06,\n",
      "        -8.7942e-06, -3.9438e-06, -9.0818e-07, -7.1828e-07, -1.3535e-08,\n",
      "        -3.9213e-06,  1.9390e-06,  4.8957e-06,  6.2979e-07,  3.7465e-06,\n",
      "         4.7056e-06,  1.0944e-05,  2.3808e-06, -4.6929e-06], device='cuda:0')\n",
      "Shape: torch.Size([24])\n",
      "\n",
      "Layer: features.4.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.2264]],\n",
      "\n",
      "         [[ 0.1353]],\n",
      "\n",
      "         [[ 0.0187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3013]],\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         [[-0.0167]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1615]],\n",
      "\n",
      "         [[ 0.0351]],\n",
      "\n",
      "         [[-0.0508]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1164]],\n",
      "\n",
      "         [[-0.0584]],\n",
      "\n",
      "         [[ 0.3263]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0732]],\n",
      "\n",
      "         [[ 0.0015]],\n",
      "\n",
      "         [[ 0.1558]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2342]],\n",
      "\n",
      "         [[ 0.0659]],\n",
      "\n",
      "         [[-0.1773]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0804]],\n",
      "\n",
      "         [[-0.0498]],\n",
      "\n",
      "         [[ 0.0212]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2225]],\n",
      "\n",
      "         [[-0.8159]],\n",
      "\n",
      "         [[-0.0336]]],\n",
      "\n",
      "\n",
      "        [[[-0.2520]],\n",
      "\n",
      "         [[ 0.1753]],\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.4517]],\n",
      "\n",
      "         [[-0.0596]],\n",
      "\n",
      "         [[-0.0750]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0122]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[-0.6465]],\n",
      "\n",
      "         [[ 0.0507]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 24, 1, 1])\n",
      "\n",
      "Layer: features.4.conv.0.1.weight\n",
      "Weights: tensor([2.2369, 1.4738, 3.6327, 1.4013, 1.3992, 1.2629, 1.4573, 4.0059, 2.0175,\n",
      "        2.8470, 2.1820, 1.8551, 2.6802, 1.6920, 1.0090, 2.4253, 1.5307, 1.6719,\n",
      "        0.9758, 2.2957, 2.3644, 0.9213, 1.2862, 1.2355, 1.2170, 2.1270, 0.9452,\n",
      "        2.5388, 1.7158, 2.5274, 2.6421, 0.8484, 1.7902, 2.1487, 2.5015, 0.7637,\n",
      "        0.4686, 2.2535, 1.6168, 2.1135, 0.8464, 0.9237, 1.6183, 3.2904, 1.4617,\n",
      "        1.3740, 1.3918, 1.4688, 1.5761, 1.2394, 0.9115, 0.7763, 1.2161, 1.2297,\n",
      "        1.1300, 1.7883, 2.2473, 4.1798, 2.7102, 3.8978, 2.0793, 1.9123, 1.1888,\n",
      "        0.6734, 1.2773, 1.0395, 0.7821, 3.1244, 1.4891, 0.4185, 3.6612, 2.0465,\n",
      "        1.5604, 3.1105, 1.1223, 1.2049, 2.3392, 1.2523, 1.9331, 0.5851, 1.1710,\n",
      "        1.7746, 1.3706, 1.6128, 1.1468, 1.3938, 1.0986, 1.6300, 2.0689, 2.2090,\n",
      "        4.3002, 1.0057, 1.0135, 1.5171, 1.7037, 0.7852, 2.4912, 2.2777, 0.9821,\n",
      "        1.3826, 2.3538, 2.3194, 2.0294, 3.0632, 3.0419, 1.1543, 1.8169, 3.0965,\n",
      "        2.2415, 3.3154, 3.3182, 1.5402, 2.6372, 2.0929, 3.2703, 1.2346, 1.6202,\n",
      "        1.0144, 2.1630, 0.9933, 0.4861, 0.5109, 2.0687, 1.6936, 2.5403, 1.3318,\n",
      "        1.0740, 1.0930, 2.3555, 1.1639, 2.3474, 2.7985, 1.3384, 1.8416, 2.4805,\n",
      "        1.9009, 2.0629, 3.0202, 4.0851, 3.0758, 2.3877, 2.4670, 3.6558, 1.7344],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.0.1.bias\n",
      "Weights: tensor([-1.0041, -2.2723,  0.1727,  0.5893,  0.8099, -0.0219, -0.3419,  1.6427,\n",
      "        -1.0926,  4.6672, -1.8937,  0.0323, -1.2680, -0.5612,  0.6553, -0.8568,\n",
      "        -0.4177, -0.5648,  1.8210, -0.4014, -1.0975,  0.1124, -1.2683,  0.0799,\n",
      "        -0.8365, -0.3541,  0.7097, -2.0862,  0.2308,  0.0260, -1.7066, -0.2801,\n",
      "        -0.9940, -0.4207,  0.5891,  0.5104,  1.7426, -0.3184, -0.3920,  2.7225,\n",
      "         0.9297,  0.2083, -0.5575, -0.4435, -0.9565,  0.3844, -0.7018,  0.1271,\n",
      "        -1.2774, -0.2287,  0.8559,  0.3299,  0.4216,  0.7357,  0.3025,  0.5548,\n",
      "        -0.1615,  0.6427,  0.9184, -0.8191, -0.7536,  2.3566, -0.1294,  1.3628,\n",
      "        -0.0297,  0.6189,  1.3305, -0.9879, -0.1336,  1.1663,  0.2930, -1.0249,\n",
      "        -1.2917,  0.9303,  0.0100,  0.3111,  5.5986, -1.6798, -0.8039,  1.4727,\n",
      "        -0.3513, -0.1628, -0.3404,  2.2219,  1.2453,  0.4051,  0.1982, -1.3802,\n",
      "         0.0320,  2.7404, -1.1067,  0.9235, -0.1420, -1.3834,  0.1664,  1.2832,\n",
      "        -0.4833,  1.1943,  0.9504, -1.8088, -0.7069,  0.7565,  5.3276, -0.4533,\n",
      "         0.2845, -0.7368, -0.2467, -1.1306, -2.0307, -2.6805, -0.2317, -2.7627,\n",
      "         2.2826, -0.2068, -3.6284,  1.7060,  3.1853,  1.7100, -0.5282, -1.2024,\n",
      "         1.7985,  2.0764, -0.4361, -0.4741,  0.5294, -0.9663,  1.8879,  0.0312,\n",
      "        -2.0869, -0.0642,  1.5564, -1.8572, -0.4360, -0.0155,  2.5979,  3.3513,\n",
      "        -2.0807, -4.2992,  0.9501, -0.7168,  1.1991,  1.4821,  2.0369, -1.4841],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0369, -0.1349, -0.0946],\n",
      "          [-0.1142, -0.2704, -0.1790],\n",
      "          [-0.0886, -0.1903, -0.1447]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1032,  0.1668,  0.1483],\n",
      "          [ 0.1662,  0.2045,  0.1770],\n",
      "          [ 0.1166,  0.1614,  0.1396]]],\n",
      "\n",
      "\n",
      "        [[[-0.0880, -0.1551, -0.1004],\n",
      "          [-0.1473, -0.2526, -0.1715],\n",
      "          [-0.0945, -0.1826, -0.1204]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0682, -0.1680, -0.1729],\n",
      "          [-0.1674, -0.2851, -0.2150],\n",
      "          [-0.1574, -0.2182, -0.1240]]],\n",
      "\n",
      "\n",
      "        [[[-0.0432, -0.1345, -0.0944],\n",
      "          [-0.1176, -0.2445, -0.2021],\n",
      "          [-0.0596, -0.1680, -0.1236]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1152,  0.1799,  0.0623],\n",
      "          [ 0.1592,  0.3269,  0.2542],\n",
      "          [ 0.0308,  0.2138,  0.2069]]]], device='cuda:0')\n",
      "Shape: torch.Size([144, 1, 3, 3])\n",
      "\n",
      "Layer: features.4.conv.1.1.weight\n",
      "Weights: tensor([0.7261, 0.3465, 2.5337, 0.8213, 0.9702, 0.9505, 0.9197, 2.2751, 0.8717,\n",
      "        0.8335, 0.8297, 1.1587, 0.8061, 0.8651, 0.8729, 0.8481, 0.8413, 0.8552,\n",
      "        1.1066, 1.7382, 0.9099, 0.8687, 0.6885, 1.1281, 0.7856, 1.0491, 1.0757,\n",
      "        0.6695, 0.9269, 1.4746, 0.7835, 0.7310, 0.9648, 1.7556, 2.3967, 1.0735,\n",
      "        0.9006, 1.5241, 0.7658, 2.3220, 0.9926, 1.2957, 0.8557, 1.0462, 0.7438,\n",
      "        0.7836, 0.9545, 0.8915, 0.6668, 0.9748, 0.9929, 1.0063, 0.9102, 1.4203,\n",
      "        0.8937, 1.1869, 1.6314, 1.9627, 1.7616, 1.9999, 0.9106, 1.0332, 0.9049,\n",
      "        1.2957, 0.7470, 0.8401, 1.6645, 2.0251, 0.9237, 1.9586, 3.6156, 0.8826,\n",
      "        0.6460, 2.3717, 0.8831, 1.1359, 0.9812, 0.7636, 1.0006, 1.7259, 0.7762,\n",
      "        0.8487, 0.7184, 1.2705, 1.1751, 0.9654, 0.8600, 0.5355, 1.4665, 1.9383,\n",
      "        1.7031, 1.0787, 1.0987, 0.7832, 0.8984, 0.8285, 1.2391, 1.3090, 1.2199,\n",
      "        0.5316, 1.9012, 1.8150, 1.0321, 1.3140, 1.8869, 0.6805, 0.9396, 1.3266,\n",
      "        0.7261, 0.8493, 1.6665, 0.4452, 2.4666, 1.1827, 0.5519, 1.2743, 1.4426,\n",
      "        1.0256, 1.7497, 0.8090, 1.4783, 1.8026, 1.1696, 0.9103, 1.1204, 0.7137,\n",
      "        1.1238, 0.8461, 0.6183, 0.8246, 1.8448, 0.8402, 1.0072, 0.9631, 1.0890,\n",
      "        1.3488, 0.7219, 1.0054, 2.6044, 1.5106, 1.6173, 2.8169, 2.8924, 0.8173],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.1.1.bias\n",
      "Weights: tensor([ 5.2370,  0.1270, -1.3967,  1.5023,  1.7834,  1.0116,  1.1932, -0.6150,\n",
      "         0.9475,  1.4066,  0.3781,  0.2520,  0.5593,  2.5467,  1.7511,  0.3656,\n",
      "         1.0340,  0.9629,  2.3361,  0.6535,  0.6885,  1.0785,  0.4266,  1.2879,\n",
      "         1.0967,  1.6065,  1.5466,  0.4464,  3.5142, -0.1750,  0.6386,  0.7801,\n",
      "         1.4182,  0.8451, -1.3534, -0.3171,  3.2001,  0.2491,  1.3243, -2.4091,\n",
      "        -0.1302, -0.4909,  0.8836,  1.5284,  0.8005,  1.3958,  0.6821,  4.5130,\n",
      "         0.2742,  1.3969, -0.2023, -0.2390,  0.8965, -0.4294,  1.4053,  1.4944,\n",
      "        -0.0201, -0.7961, -0.2522, -1.1536,  0.8202,  2.6362,  0.6780, -0.2099,\n",
      "         2.6013,  1.3559, -0.5828, -0.7797,  1.2649, -0.5460, -3.0757,  2.1770,\n",
      "         0.4486, -0.8580,  1.1001,  1.2822,  1.3086,  2.3402,  0.8884, -0.4220,\n",
      "         1.0344,  1.0497,  0.7848, -0.3230, -0.1687,  2.4975,  1.0518,  0.3715,\n",
      "         0.5728, -2.0167, -0.1627, -0.2605,  1.4521,  1.9300,  1.4268,  0.3423,\n",
      "         1.2723,  0.2245, -0.3154,  0.8325,  0.6607, -0.3248,  1.0065,  1.2415,\n",
      "        -0.3753,  0.6976,  1.5444,  1.0625,  0.4370,  1.4925,  0.3264,  0.1511,\n",
      "        -0.4226,  1.3229,  0.1938, -0.2064, -0.3165,  1.4591, -0.0300,  1.8116,\n",
      "        -0.4072, -0.7881,  0.5462,  1.5608,  0.3831,  0.5804,  2.1728,  0.8799,\n",
      "         0.2989,  0.6063,  0.0638,  0.6306,  1.9533,  1.2390,  0.5278,  0.1031,\n",
      "         3.3595, -0.1674, -1.1965,  1.2332,  0.0595, -0.8469, -1.7791,  1.1729],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([144])\n",
      "\n",
      "Layer: features.4.conv.2.weight\n",
      "Weights: tensor([[[[ 0.1212]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[-0.2634]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0487]],\n",
      "\n",
      "         [[ 0.1192]],\n",
      "\n",
      "         [[ 0.1421]]],\n",
      "\n",
      "\n",
      "        [[[-0.0111]],\n",
      "\n",
      "         [[ 0.0802]],\n",
      "\n",
      "         [[-0.0359]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.3386]],\n",
      "\n",
      "         [[-0.0748]],\n",
      "\n",
      "         [[-0.1906]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0735]],\n",
      "\n",
      "         [[ 0.3767]],\n",
      "\n",
      "         [[ 0.0118]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.3106]],\n",
      "\n",
      "         [[ 0.2452]],\n",
      "\n",
      "         [[-0.2738]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0141]],\n",
      "\n",
      "         [[-0.0820]],\n",
      "\n",
      "         [[ 0.5217]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0065]],\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         [[-0.0428]]],\n",
      "\n",
      "\n",
      "        [[[-0.3648]],\n",
      "\n",
      "         [[-0.1968]],\n",
      "\n",
      "         [[ 0.0329]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2351]],\n",
      "\n",
      "         [[ 0.0217]],\n",
      "\n",
      "         [[-0.3777]]],\n",
      "\n",
      "\n",
      "        [[[-0.1456]],\n",
      "\n",
      "         [[ 0.1378]],\n",
      "\n",
      "         [[-0.1040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0130]],\n",
      "\n",
      "         [[ 0.1997]],\n",
      "\n",
      "         [[ 0.1276]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 144, 1, 1])\n",
      "\n",
      "Layer: features.4.conv.3.weight\n",
      "Weights: tensor([4.9028, 6.2684, 4.9340, 6.2001, 4.3269, 5.8029, 5.0184, 4.4519, 5.9551,\n",
      "        6.0546, 5.6649, 4.5998, 6.5915, 3.2259, 5.5010, 6.6378, 4.3936, 4.7463,\n",
      "        3.4861, 5.3670, 6.8166, 3.7912, 5.0145, 5.6286, 5.6646, 5.8290, 5.6283,\n",
      "        5.7119, 4.2634, 5.6147, 5.4345, 7.4288], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.4.conv.3.bias\n",
      "Weights: tensor([-4.3353e-07,  1.7914e-06,  2.5913e-06,  2.6290e-06, -1.8708e-06,\n",
      "        -1.4881e-07, -3.3277e-07,  1.2786e-06, -2.1400e-06,  6.3715e-07,\n",
      "         1.6981e-07, -1.0889e-06, -8.8385e-07, -7.4630e-07,  2.8402e-07,\n",
      "         1.2994e-06, -1.3340e-06, -6.6812e-07, -1.0725e-06,  1.1744e-06,\n",
      "        -1.0800e-06,  2.4396e-06, -1.2818e-06,  2.9553e-06,  1.5508e-06,\n",
      "         4.9451e-07, -1.7859e-06, -2.2576e-06,  1.8819e-06,  7.1620e-08,\n",
      "         1.3129e-07,  1.2972e-06], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.5.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.1083]],\n",
      "\n",
      "         [[-0.1098]],\n",
      "\n",
      "         [[ 0.1325]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1126]],\n",
      "\n",
      "         [[-0.0357]],\n",
      "\n",
      "         [[ 0.0544]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0870]],\n",
      "\n",
      "         [[-0.0438]],\n",
      "\n",
      "         [[-0.0459]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0192]],\n",
      "\n",
      "         [[ 0.0544]],\n",
      "\n",
      "         [[ 0.2662]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1540]],\n",
      "\n",
      "         [[-0.1716]],\n",
      "\n",
      "         [[ 0.1190]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         [[-0.0770]],\n",
      "\n",
      "         [[-0.1777]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1003]],\n",
      "\n",
      "         [[ 0.1773]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0036]],\n",
      "\n",
      "         [[ 0.0084]],\n",
      "\n",
      "         [[-0.1530]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0401]],\n",
      "\n",
      "         [[ 0.0782]],\n",
      "\n",
      "         [[-0.0162]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[ 0.1727]],\n",
      "\n",
      "         [[ 0.2245]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0179]],\n",
      "\n",
      "         [[ 0.0639]],\n",
      "\n",
      "         [[-0.1889]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0028]],\n",
      "\n",
      "         [[ 0.0789]],\n",
      "\n",
      "         [[ 0.0984]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 32, 1, 1])\n",
      "\n",
      "Layer: features.5.conv.0.1.weight\n",
      "Weights: tensor([1.1080, 0.8199, 0.7798, 1.0138, 1.9251, 1.8279, 1.0542, 1.1945, 1.4307,\n",
      "        1.2311, 0.9359, 1.8228, 1.0253, 0.8480, 0.9317, 1.3302, 0.8085, 0.7431,\n",
      "        1.1524, 1.1843, 0.7515, 0.9013, 1.3220, 1.4406, 1.0030, 0.8915, 0.9438,\n",
      "        1.5107, 0.9146, 1.2934, 0.9666, 1.1265, 1.7415, 1.1471, 1.0861, 1.1046,\n",
      "        0.7756, 0.7765, 1.2916, 1.3263, 0.8056, 0.7406, 0.7331, 1.4359, 1.1534,\n",
      "        1.3664, 0.9369, 1.2411, 1.0602, 0.9496, 0.9233, 0.9996, 0.8872, 1.2786,\n",
      "        0.7198, 1.2096, 0.1720, 1.3983, 0.9113, 0.8634, 0.8133, 0.9947, 1.0365,\n",
      "        1.0349, 1.1003, 0.9561, 1.0338, 0.8518, 1.5006, 1.2092, 0.8852, 2.6781,\n",
      "        1.0947, 0.6527, 0.7703, 1.0564, 1.2133, 0.4999, 0.6207, 1.0265, 0.8756,\n",
      "        1.4968, 1.3028, 1.0696, 0.4973, 1.5661, 1.2293, 1.5227, 1.4677, 0.8851,\n",
      "        1.2656, 1.3382, 1.5687, 1.6905, 1.7996, 1.5857, 1.4342, 0.9115, 0.7465,\n",
      "        3.0256, 0.8414, 0.7096, 0.2533, 1.0365, 1.3154, 0.8064, 0.9716, 1.6955,\n",
      "        0.5585, 0.9089, 0.8014, 1.0437, 1.6837, 1.2087, 1.6723, 1.8250, 0.7967,\n",
      "        0.9474, 1.1700, 1.6067, 1.2041, 0.7718, 0.8579, 1.6724, 0.8662, 0.9816,\n",
      "        0.8369, 1.1159, 0.4524, 1.0016, 1.0178, 1.3851, 1.1137, 1.5984, 0.3596,\n",
      "        1.7484, 0.8290, 1.3969, 0.7956, 1.0636, 1.0604, 1.0861, 1.2685, 0.5797,\n",
      "        1.9814, 1.8503, 1.6001, 2.3665, 1.0080, 0.5198, 0.8858, 0.7869, 1.1424,\n",
      "        0.9184, 1.3033, 1.6423, 0.6892, 1.1091, 1.5440, 0.7942, 0.5346, 1.4680,\n",
      "        1.4861, 1.3289, 1.0240, 0.9188, 1.2690, 1.5794, 1.4328, 1.0004, 1.5113,\n",
      "        1.6207, 0.9171, 1.2657, 1.2052, 1.5501, 1.4821, 1.5640, 1.6189, 0.9061,\n",
      "        0.7574, 1.1972, 0.8526, 0.4889, 0.9939, 0.4885, 1.6071, 1.4995, 1.7677,\n",
      "        1.0520, 0.9439, 1.5952], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.0.1.bias\n",
      "Weights: tensor([-0.6321,  1.7301,  1.4955,  1.4657,  0.3186,  3.0372,  1.0514,  1.8080,\n",
      "         1.4596, -0.4394,  0.7613,  0.3089,  1.3106,  1.6003,  1.2276, -2.3040,\n",
      "         1.3358,  0.6621,  1.4977,  1.4328,  1.6855,  1.0089,  1.4696, -0.3902,\n",
      "         0.9553,  1.1692,  0.9312, -1.0802,  1.2085, -0.1462,  1.3503,  1.6300,\n",
      "        -1.2448,  1.4456,  2.0456,  2.2065,  1.2983,  1.4920, -1.5475, -0.4649,\n",
      "         1.6717,  1.5919,  1.2341,  0.8986,  0.2032, -0.5742,  1.5787,  1.4476,\n",
      "         0.9369,  1.0493,  1.6649,  1.3093,  1.4274,  1.4131,  1.4943, -1.8162,\n",
      "         3.5096,  1.1399,  1.4570,  2.2535,  3.0559,  1.4272,  1.3734,  1.7661,\n",
      "         3.3985,  1.4291,  2.0007,  1.6367, -0.6913,  0.7240,  1.5041,  2.8269,\n",
      "         1.5225,  1.6379,  0.7181,  1.7530,  1.3687,  2.1632,  2.0032,  1.5286,\n",
      "         1.1041, -0.9721,  0.0351,  2.2508,  2.0746, -0.7570, -0.1140, -1.8896,\n",
      "        -2.1774,  1.3546,  1.3085,  0.5257, -0.5924, -0.1340,  1.1243,  2.2176,\n",
      "         0.5400,  1.3139,  1.2544, -0.1220,  1.6864,  1.9011,  2.4554,  1.2370,\n",
      "        -0.5433,  0.8329,  1.9715,  0.5506,  2.4027,  1.5688,  1.5753,  1.3758,\n",
      "         0.1310, -0.1230,  0.3610, -0.7091,  0.7256,  2.6412,  1.1538, -1.3965,\n",
      "        -0.5833,  1.6821,  1.2527, -0.4237,  1.5691,  1.0308,  1.2852,  0.5719,\n",
      "         2.0166,  0.9368,  2.2125,  1.5620,  0.9070, -0.8415,  1.7637, -0.5970,\n",
      "         1.1645, -0.3983,  1.0789,  0.7530,  2.9759,  1.7000,  1.3792,  1.8193,\n",
      "         2.6336,  1.0009,  0.6380,  0.5727,  0.8914,  1.6514,  1.3985,  1.3996,\n",
      "         1.5399,  2.2648, -0.7523,  0.0628,  1.4306,  1.5470, -2.1429,  1.6102,\n",
      "         1.4361,  1.9000, -0.3307,  1.4363,  1.4541,  2.1810, -2.2566, -2.6672,\n",
      "        -1.8935,  0.5000, -0.2117,  0.6438,  3.4583, -0.3894,  1.0468, -0.4223,\n",
      "        -0.6591,  0.3914,  0.2017,  1.3934,  3.2001,  1.9090,  0.7471,  1.7090,\n",
      "         0.8918,  1.7600,  0.0865, -0.0602,  0.4964,  1.2025,  1.2939,  0.1246],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0027, -0.2112, -0.0109],\n",
      "          [-0.2004,  0.0576, -0.2278],\n",
      "          [-0.0028, -0.1982, -0.0051]]],\n",
      "\n",
      "\n",
      "        [[[-0.0782, -0.0171,  0.0842],\n",
      "          [-0.4048, -0.0473,  0.4577],\n",
      "          [-0.1088, -0.0307,  0.1269]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0721,  0.3964,  0.1021],\n",
      "          [-0.0110,  0.0090, -0.0435],\n",
      "          [-0.0770, -0.3844, -0.1098]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0701, -0.1196,  0.0399],\n",
      "          [-0.2441, -0.2079,  0.4240],\n",
      "          [-0.0545,  0.1230,  0.0602]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1009,  0.4717,  0.1150],\n",
      "          [ 0.0067, -0.0996,  0.0165],\n",
      "          [-0.1136, -0.3870, -0.1250]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0134, -0.1110,  0.0043],\n",
      "          [-0.0956, -0.1530, -0.1686],\n",
      "          [-0.0155, -0.1258, -0.0125]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 1, 3, 3])\n",
      "\n",
      "Layer: features.5.conv.1.1.weight\n",
      "Weights: tensor([3.6588, 0.9327, 0.8331, 0.8979, 0.8972, 0.9275, 1.3142, 0.8784, 0.9916,\n",
      "        0.4690, 0.8371, 0.5801, 0.8921, 0.9310, 1.1299, 3.1569, 0.7838, 1.3640,\n",
      "        0.6354, 2.0154, 0.9925, 0.8892, 2.4617, 0.5991, 0.8516, 1.0558, 1.5816,\n",
      "        0.5124, 0.7473, 0.5010, 0.9259, 0.9353, 0.8907, 0.5452, 0.9162, 1.0461,\n",
      "        0.8045, 0.9200, 0.4433, 0.5015, 1.0689, 0.8900, 0.8183, 2.2863, 0.7318,\n",
      "        0.8993, 0.9627, 1.2408, 1.1460, 1.0870, 1.0347, 1.6060, 0.8904, 0.9617,\n",
      "        0.7988, 0.5081, 1.0798, 1.7039, 1.0260, 0.7695, 0.8499, 0.8307, 1.5548,\n",
      "        0.9754, 5.6211, 0.9040, 0.9989, 0.8936, 0.5654, 0.6828, 1.0595, 0.8928,\n",
      "        0.9609, 1.1159, 1.5107, 1.0150, 3.0899, 1.6330, 1.9912, 0.9165, 0.9727,\n",
      "        0.6329, 1.1206, 1.1460, 1.5398, 1.0385, 0.4930, 2.2946, 0.5158, 1.4169,\n",
      "        1.2513, 1.4488, 0.4444, 0.4668, 2.8671, 1.2401, 2.0311, 0.9856, 2.0045,\n",
      "        1.8666, 2.0446, 1.1865, 1.1086, 0.7469, 0.4918, 1.8173, 1.7957, 1.1046,\n",
      "        2.0615, 1.0666, 1.2060, 0.8698, 0.6256, 0.5136, 0.9158, 0.3479, 1.6742,\n",
      "        1.0274, 0.9154, 0.5980, 0.7085, 1.1286, 0.7941, 0.6011, 0.8180, 0.9140,\n",
      "        1.0256, 1.4059, 1.3392, 1.5929, 1.0596, 0.9917, 0.6106, 0.5792, 1.7699,\n",
      "        0.3643, 0.8857, 0.4291, 0.9576, 1.0330, 0.9058, 1.5630, 1.1657, 2.3188,\n",
      "        1.4182, 2.7563, 2.6372, 2.2193, 1.3698, 1.0926, 0.9056, 1.2264, 0.7171,\n",
      "        1.1786, 0.6381, 0.8371, 1.4561, 0.9270, 0.6213, 0.9834, 0.9065, 2.3070,\n",
      "        0.5981, 1.3284, 0.9271, 1.1762, 0.5817, 0.7917, 0.6666, 1.0051, 0.7083,\n",
      "        0.5665, 0.7244, 0.4299, 0.8390, 1.3262, 0.5673, 0.9828, 0.6382, 0.8874,\n",
      "        2.6305, 0.9537, 1.4207, 1.4360, 1.1148, 1.6594, 0.5995, 0.8516, 0.5381,\n",
      "        0.8843, 0.8579, 1.4098], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.1.1.bias\n",
      "Weights: tensor([-1.3198e+00, -6.7988e-02, -9.4947e-02, -6.1492e-02, -1.4465e-02,\n",
      "         2.1085e-02, -8.0046e-01, -7.1468e-02, -5.4054e-02,  3.1265e+00,\n",
      "        -1.0668e-01,  2.0972e+00, -1.9811e-01, -6.5346e-02, -1.6393e-01,\n",
      "        -3.4134e+00,  8.4012e-02, -1.2860e+00,  2.4388e-01, -1.7810e+00,\n",
      "        -9.5745e-02, -1.0249e-01, -2.6471e+00,  8.2793e-02, -9.9117e-02,\n",
      "        -3.7137e-01, -1.3414e+00,  2.1890e+00, -4.7516e-02,  2.1221e+00,\n",
      "        -9.2361e-02, -5.7570e-02, -1.6861e+00,  2.7471e+00, -4.8315e-02,\n",
      "        -9.7194e-02, -5.8725e-02, -8.0010e-02,  3.6001e+00,  3.0061e+00,\n",
      "        -2.3374e-01, -6.9083e-02, -1.9120e-01, -1.5239e+00, -3.9726e-01,\n",
      "        -1.9561e+00,  1.1958e-03, -6.3034e-01, -3.0003e-01, -3.9785e-01,\n",
      "        -2.8566e-02, -1.3711e+00,  1.1149e-03, -1.3885e-01,  1.4926e+00,\n",
      "         4.2849e+00,  3.3116e-01, -1.3239e+00, -1.2592e-01,  2.9500e+00,\n",
      "         3.4330e-01, -7.3270e-02, -1.1489e+00, -5.5692e-02, -1.1893e+01,\n",
      "        -1.5726e-01, -6.9493e-02, -2.2731e-01,  2.0232e-01,  2.4773e+00,\n",
      "        -4.7782e-02, -2.5324e-01,  1.4262e-02, -1.7850e-01, -1.2664e+00,\n",
      "        -3.3157e-02, -2.7901e+00, -7.3685e-02, -1.6905e+00, -7.6723e-02,\n",
      "        -4.1989e-02, -7.7617e-02, -1.5365e+00, -1.6751e-01, -1.7647e+00,\n",
      "        -1.3244e+00,  2.4611e+00, -5.0226e-01,  5.3356e-01, -1.3031e+00,\n",
      "        -6.2405e-01, -1.9640e+00,  2.1309e+00,  2.4186e+00, -2.7187e+00,\n",
      "        -4.4776e-01, -4.2508e+00, -3.5425e-01, -2.3552e+00, -9.5259e-01,\n",
      "        -1.9200e+00, -2.8149e-01,  2.3627e+00, -1.2309e-01,  2.5919e+00,\n",
      "        -4.9296e+00, -1.3600e+00, -2.7057e-01, -3.4806e+00, -2.7429e-01,\n",
      "        -3.8040e-01, -2.0586e-01,  1.6229e-01,  3.5688e+00, -2.7773e-01,\n",
      "         1.4331e+00, -4.6078e+00, -2.1764e-01, -4.4950e-01,  4.1372e-01,\n",
      "        -8.8355e-01, -3.1431e-01, -1.0492e-01,  2.7134e+00, -1.1884e-02,\n",
      "        -4.3980e-02, -2.8911e-01, -2.4548e+00, -1.0777e+00, -1.1327e+00,\n",
      "         1.9487e-02, -2.2267e-02, -6.0721e-02,  4.0448e+00, -2.2496e+00,\n",
      "         1.2683e+00, -1.4564e-01,  2.2652e+00, -7.6952e-03, -1.7834e-01,\n",
      "         2.0252e+00, -1.1836e+00, -6.0749e-01, -2.7153e+00, -7.7461e-01,\n",
      "        -2.2756e+00, -1.9855e+00, -7.2187e-01, -1.0059e+00, -4.0434e-01,\n",
      "        -1.5177e-01, -4.5178e-01,  2.6970e+00, -8.0103e-02, -4.3912e-01,\n",
      "        -1.0765e+00, -8.0281e-01, -4.9205e-02,  3.4417e+00, -1.9168e-01,\n",
      "        -3.0450e-01, -2.8600e+00,  1.1666e+00, -7.3492e-01, -1.4572e-01,\n",
      "        -4.2563e-02, -2.0833e+00,  6.3244e-01, -1.8994e+00, -8.5769e-01,\n",
      "        -4.4696e-02,  1.7825e-01,  5.4371e-01,  2.2791e+00, -2.0680e-01,\n",
      "        -3.4206e-01,  4.4814e+00, -7.9222e-01,  2.5951e+00, -3.2195e-02,\n",
      "        -3.6064e+00, -8.3044e-02, -2.1782e+00, -1.2028e+00, -6.2642e-01,\n",
      "        -1.4455e+00,  2.5186e+00, -1.3062e-01,  3.0082e+00, -1.3192e-01,\n",
      "        -5.1006e-02, -2.6194e-01], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.5.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0171]],\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[-0.0515]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0997]],\n",
      "\n",
      "         [[-0.0883]],\n",
      "\n",
      "         [[-0.0484]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0021]],\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[ 0.0519]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0394]],\n",
      "\n",
      "         [[-0.0401]],\n",
      "\n",
      "         [[-0.0089]]],\n",
      "\n",
      "\n",
      "        [[[-0.0867]],\n",
      "\n",
      "         [[-0.0571]],\n",
      "\n",
      "         [[ 0.1442]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0228]],\n",
      "\n",
      "         [[ 0.0855]],\n",
      "\n",
      "         [[ 0.2315]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0042]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[-0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0399]],\n",
      "\n",
      "         [[ 0.1018]],\n",
      "\n",
      "         [[-0.0390]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0728]],\n",
      "\n",
      "         [[ 0.0577]],\n",
      "\n",
      "         [[ 0.0753]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0629]],\n",
      "\n",
      "         [[ 0.0764]],\n",
      "\n",
      "         [[ 0.0045]]],\n",
      "\n",
      "\n",
      "        [[[-0.0891]],\n",
      "\n",
      "         [[ 0.0402]],\n",
      "\n",
      "         [[ 0.0603]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0598]],\n",
      "\n",
      "         [[-0.0031]],\n",
      "\n",
      "         [[ 0.0934]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 192, 1, 1])\n",
      "\n",
      "Layer: features.5.conv.3.weight\n",
      "Weights: tensor([1.8504, 2.4106, 3.1048, 2.2347, 3.5254, 1.5071, 1.9146, 2.3095, 2.2912,\n",
      "        3.1115, 2.3757, 1.7182, 1.6727, 5.5134, 1.5428, 1.5395, 2.9440, 2.5768,\n",
      "        7.8259, 2.3754, 1.9300, 5.9415, 3.1814, 1.6341, 6.0258, 2.4171, 2.1446,\n",
      "        1.7618, 5.1358, 1.6920, 2.0558, 2.6001], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.5.conv.3.bias\n",
      "Weights: tensor([-1.3089e-07,  2.1377e-06,  2.2826e-06,  3.1088e-06, -4.8461e-07,\n",
      "        -1.2732e-06, -1.6444e-07,  7.6097e-08, -2.8071e-07, -1.1957e-07,\n",
      "        -9.9765e-07, -1.1833e-06,  5.2089e-07, -1.8745e-07,  1.5195e-06,\n",
      "         1.3220e-06, -7.1936e-07, -1.4845e-06, -1.1570e-06,  1.8697e-06,\n",
      "        -3.9736e-07,  9.1128e-07, -7.6910e-07, -4.5134e-07,  1.5619e-06,\n",
      "         1.0951e-07,  6.3376e-07, -1.4328e-06,  2.0770e-06, -1.1447e-06,\n",
      "         1.8749e-06,  1.7566e-06], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.6.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.1142]],\n",
      "\n",
      "         [[-0.0242]],\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2228]],\n",
      "\n",
      "         [[ 0.0761]],\n",
      "\n",
      "         [[-0.1166]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0545]],\n",
      "\n",
      "         [[-0.2082]],\n",
      "\n",
      "         [[ 0.0745]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0222]],\n",
      "\n",
      "         [[ 0.1749]],\n",
      "\n",
      "         [[-0.0736]]],\n",
      "\n",
      "\n",
      "        [[[-0.0086]],\n",
      "\n",
      "         [[ 0.0211]],\n",
      "\n",
      "         [[-0.0345]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0956]],\n",
      "\n",
      "         [[-0.0344]],\n",
      "\n",
      "         [[ 0.0832]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0888]],\n",
      "\n",
      "         [[-0.0618]],\n",
      "\n",
      "         [[ 0.0445]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0032]],\n",
      "\n",
      "         [[-0.0838]],\n",
      "\n",
      "         [[-0.0377]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0841]],\n",
      "\n",
      "         [[-0.1064]],\n",
      "\n",
      "         [[ 0.1025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0126]],\n",
      "\n",
      "         [[ 0.1327]],\n",
      "\n",
      "         [[-0.2382]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1094]],\n",
      "\n",
      "         [[ 0.1500]],\n",
      "\n",
      "         [[-0.0114]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.2036]],\n",
      "\n",
      "         [[ 0.1267]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 32, 1, 1])\n",
      "\n",
      "Layer: features.6.conv.0.1.weight\n",
      "Weights: tensor([1.2764, 1.6089, 0.6316, 1.2476, 0.9759, 0.8111, 1.5027, 1.1746, 1.3136,\n",
      "        1.3437, 1.0125, 1.4031, 0.9400, 1.6430, 0.6995, 1.7408, 0.7815, 1.0188,\n",
      "        1.4212, 1.2009, 1.3564, 1.8750, 0.2940, 2.2067, 0.8606, 1.9364, 1.1680,\n",
      "        0.6797, 1.3273, 1.3835, 2.2106, 1.9314, 0.8408, 1.8470, 1.2532, 0.7963,\n",
      "        0.5576, 1.4990, 1.3067, 2.0888, 1.3872, 1.1313, 1.3588, 1.5783, 1.6698,\n",
      "        0.7696, 0.8864, 0.8730, 1.1621, 0.7516, 0.8691, 1.4087, 1.2809, 2.1468,\n",
      "        1.5282, 1.0197, 1.4433, 2.1798, 1.2121, 1.4007, 1.2368, 1.4114, 1.5409,\n",
      "        1.4833, 0.9242, 1.3162, 1.6041, 2.0921, 0.8727, 0.9365, 1.2996, 2.6119,\n",
      "        2.0940, 1.0963, 1.7719, 1.6227, 1.2455, 0.8172, 1.6465, 1.4215, 1.2626,\n",
      "        0.8321, 1.6243, 1.5956, 0.6840, 1.4437, 0.7285, 1.7361, 1.4481, 1.8235,\n",
      "        0.8982, 1.3630, 0.6345, 0.8176, 0.9484, 0.5312, 1.3064, 0.5752, 0.9805,\n",
      "        1.2156, 1.4071, 0.6511, 1.4165, 0.9006, 1.0456, 0.7815, 1.0052, 0.8296,\n",
      "        1.4775, 0.9258, 1.4882, 1.4678, 1.9727, 0.6195, 1.0275, 0.7554, 2.0670,\n",
      "        0.6583, 1.2901, 1.4866, 0.8705, 2.3609, 0.9680, 0.8056, 0.7456, 1.4466,\n",
      "        1.8345, 1.3172, 1.0919, 1.5468, 1.1092, 1.1712, 0.8060, 0.7276, 1.0607,\n",
      "        1.0122, 0.6815, 1.3763, 1.0798, 0.7935, 1.3988, 2.1456, 0.9885, 1.3291,\n",
      "        1.7109, 0.8712, 1.1464, 1.5853, 1.2481, 1.6456, 0.9897, 1.4344, 0.6364,\n",
      "        0.8178, 1.0320, 0.9112, 1.2751, 0.5683, 0.7323, 1.4230, 0.9454, 1.2244,\n",
      "        1.2431, 0.8678, 1.2122, 1.3930, 1.9234, 0.5264, 1.5444, 1.6733, 1.2477,\n",
      "        1.3893, 1.2661, 1.4375, 0.5970, 1.3762, 0.8627, 0.7606, 1.1691, 1.5878,\n",
      "        1.8852, 1.2184, 0.9412, 0.8030, 1.3245, 1.3297, 1.3349, 1.3720, 1.3066,\n",
      "        1.5379, 1.2482, 0.5730], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.0.1.bias\n",
      "Weights: tensor([-1.0138, -0.2723,  1.5498,  1.1579,  1.8743, -0.5113, -0.3506,  1.6892,\n",
      "        -1.4452,  0.3010,  1.3006,  0.9635,  0.7547, -0.1281,  1.6000,  1.1199,\n",
      "         1.3270,  2.4239,  0.3288,  1.5117,  0.7132,  0.7507,  1.3733, -0.0445,\n",
      "         1.1348, -1.0610, -1.0289,  1.5714,  2.0002, -0.9603,  0.8445,  0.4076,\n",
      "         1.1261,  1.1766, -2.0157,  2.3385,  1.8849, -0.5780, -1.5987, -0.9709,\n",
      "        -1.3022,  1.2693, -0.5773, -0.9236,  0.7682,  1.4904,  1.6947,  2.2865,\n",
      "         0.6189,  1.3664,  2.0191, -0.6180,  0.8177, -1.2570, -1.4049,  0.8356,\n",
      "         0.6979,  0.0220, -0.4635,  0.1308,  0.4107, -0.9143, -0.0188, -1.5075,\n",
      "         1.0602,  0.1543, -1.1070, -1.5640,  1.3826,  1.1943,  1.5190, -1.2060,\n",
      "         2.0078,  2.2724, -0.7797,  0.0187,  1.6176,  1.2249,  1.2318, -1.0938,\n",
      "        -0.7763,  1.4549,  0.7480,  0.8782,  2.5354, -0.1219,  1.3539, -0.6149,\n",
      "        -0.1361, -0.9645,  1.4306, -0.1660,  1.3469,  1.2204,  1.3595,  1.8874,\n",
      "        -1.2280,  1.7156,  0.2510,  1.2557, -0.1181,  2.9917, -0.8341,  0.7431,\n",
      "         0.8263,  1.6481,  1.3891,  2.4107, -0.8533,  1.1455, -0.4185, -1.7651,\n",
      "        -0.1739,  1.2729,  1.9984,  1.4260, -0.2278,  3.3311,  0.2405, -0.2497,\n",
      "         1.0270,  0.2022,  1.7721,  1.4807,  1.4902,  0.5633, -0.5503,  0.8975,\n",
      "        -0.7029, -1.1576,  1.4341,  0.5620,  0.6353,  0.7546,  1.1692,  1.9971,\n",
      "         1.2476, -1.1519,  0.8654, -0.5412, -0.3377, -0.8481,  0.4749,  1.0399,\n",
      "         0.0869, -0.2530, -0.1837,  0.6106, -0.6184, -0.1149,  0.6630,  0.6969,\n",
      "         1.3424,  0.7441,  1.6705,  1.1518,  1.7462,  1.4103,  0.7381, -0.2206,\n",
      "        -0.0262, -0.2388,  0.8487,  1.5627,  1.0761, -0.7400, -0.8659,  1.4100,\n",
      "         1.9330,  1.6464,  1.2561,  0.7622,  0.2830, -0.9568,  1.9578,  0.0905,\n",
      "         1.3952,  1.0841,  0.1497,  0.3120, -3.2301, -1.4217,  1.3634,  1.2069,\n",
      "        -0.1666, -0.5466,  0.8250,  0.5436,  1.0045,  0.4103, -0.9055,  1.2999],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0394,  0.1204,  0.0495],\n",
      "          [ 0.1054, -0.6780,  0.1046],\n",
      "          [ 0.0418,  0.1541,  0.0485]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0125,  0.2270,  0.0834],\n",
      "          [-0.0803, -0.4119, -0.0882],\n",
      "          [ 0.0599,  0.1398,  0.0267]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0528, -0.1878,  0.0182],\n",
      "          [-0.1372, -0.4605,  0.2606],\n",
      "          [-0.0087,  0.2387,  0.2316]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0069, -0.0749,  0.0026],\n",
      "          [-0.1533, -0.0672, -0.1787],\n",
      "          [-0.0052, -0.0869, -0.0436]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0355,  0.1140,  0.0022],\n",
      "          [ 0.1349,  0.2346,  0.1782],\n",
      "          [ 0.0282,  0.1429,  0.0240]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1446,  0.3484,  0.1485],\n",
      "          [-0.0286, -0.1860, -0.0765],\n",
      "          [-0.0966, -0.1330, -0.0813]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 1, 3, 3])\n",
      "\n",
      "Layer: features.6.conv.1.1.weight\n",
      "Weights: tensor([0.8958, 0.8874, 1.2139, 1.4007, 1.1834, 2.0182, 0.9398, 1.3544, 0.7719,\n",
      "        1.4759, 1.1618, 1.2117, 1.4552, 0.6127, 1.4564, 2.6535, 1.7178, 1.6046,\n",
      "        0.6995, 1.4002, 1.4253, 1.2219, 1.5637, 0.7370, 1.5033, 2.6674, 0.4675,\n",
      "        1.3963, 1.9720, 0.5678, 7.7972, 1.6829, 1.2428, 2.5061, 0.3087, 2.4386,\n",
      "        1.1180, 0.5371, 0.2684, 1.0820, 0.6703, 2.3756, 0.7062, 1.0450, 2.4568,\n",
      "        1.0398, 0.9238, 1.5477, 1.1128, 1.2210, 0.9662, 0.8026, 0.6451, 7.4910,\n",
      "        0.3754, 1.5166, 1.6056, 0.7591, 1.0937, 0.7379, 1.4918, 0.9568, 1.3466,\n",
      "        0.3224, 1.1089, 1.0238, 0.6446, 8.7082, 1.0090, 0.9822, 3.3796, 1.2280,\n",
      "        2.4050, 1.1087, 1.1812, 0.6378, 1.5660, 1.7830, 2.0451, 0.6081, 0.5629,\n",
      "        1.1021, 2.0740, 0.5007, 0.7945, 1.2292, 1.1781, 1.0388, 0.6794, 1.1644,\n",
      "        1.2512, 0.6704, 0.8376, 1.6420, 1.5035, 1.1505, 0.4735, 1.0544, 1.2431,\n",
      "        1.1627, 0.7018, 1.3859, 0.8161, 0.9679, 0.9621, 1.1200, 0.8865, 1.7234,\n",
      "        1.2816, 1.0031, 0.8641, 0.4601, 2.1031, 1.1510, 1.5187, 1.0698, 4.2675,\n",
      "        3.5604, 0.8706, 1.3248, 0.8520, 2.0677, 0.9238, 1.0854, 0.9926, 0.4421,\n",
      "        0.4275, 0.9499, 0.9522, 1.4538, 0.8891, 1.1433, 1.0831, 0.9948, 0.9767,\n",
      "        1.5672, 0.9242, 0.3931, 0.9104, 1.6800, 1.2669, 1.2142, 1.1423, 0.8245,\n",
      "        0.9434, 2.4734, 1.3324, 1.0003, 1.8407, 0.6076, 1.9629, 1.9318, 0.8668,\n",
      "        1.0683, 2.3358, 1.2820, 2.9992, 1.1858, 1.0598, 0.6463, 1.6061, 0.6398,\n",
      "        1.6224, 1.3305, 1.1134, 1.2005, 1.0901, 1.2109, 2.2858, 2.1058, 1.2556,\n",
      "        1.5337, 1.5854, 0.6289, 1.0036, 1.0070, 1.1552, 1.2608, 0.5971, 1.2611,\n",
      "        1.3429, 0.9213, 1.1492, 1.0174, 0.7385, 1.7840, 0.9985, 1.3268, 1.0055,\n",
      "        1.8652, 1.0765, 1.2448], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.1.1.bias\n",
      "Weights: tensor([ 9.1343e-01, -7.5100e-02, -3.3606e-01, -7.8758e-01, -2.4197e-01,\n",
      "        -8.4443e-01, -7.5334e-01, -5.2277e-01, -3.1062e-03, -1.9916e+00,\n",
      "        -5.1679e-01, -1.7483e-01, -3.3072e+00,  2.0667e+00, -9.8595e-01,\n",
      "        -1.7365e+00, -2.9286e+00, -1.9570e+00,  2.0596e+00, -7.3158e-01,\n",
      "        -9.5676e-01, -3.9886e-01, -1.4231e+00,  3.0134e+00, -2.3952e+00,\n",
      "        -7.1580e+00, -2.5996e-02, -6.1191e-01, -2.2296e+00,  5.7431e-02,\n",
      "        -9.3650e+00, -7.8725e-01, -5.3861e-01, -1.5990e+00, -1.3228e-01,\n",
      "        -2.0393e+00, -4.4720e-01,  2.4389e+00,  2.2363e+00, -2.4743e-01,\n",
      "        -8.4914e-01, -2.3480e+00,  3.7385e-01, -3.1203e-01, -2.1504e+00,\n",
      "        -1.1582e-01,  2.6827e+00, -2.0522e+00, -4.7457e-01, -3.0105e-01,\n",
      "        -3.4454e-01, -1.1167e+00,  1.3349e+00, -6.2084e+00,  2.2624e+00,\n",
      "        -1.6713e+00, -1.2054e+00,  3.1458e+00, -1.8087e+00, -2.0947e-01,\n",
      "        -1.0035e+00, -1.6318e+00, -1.5265e+00,  7.9093e-01, -4.7939e-01,\n",
      "        -1.3615e+00,  1.6098e+00, -2.5502e+00, -3.3980e-01, -2.3600e-01,\n",
      "        -4.4359e+00, -3.8477e-01, -2.9576e+00, -3.2164e-01, -3.1942e-01,\n",
      "         2.9302e+00, -1.1233e+00, -3.0634e+00, -1.2873e+00,  3.3724e-01,\n",
      "         5.5638e-02, -3.1193e-01, -1.9069e+00,  1.4170e+00,  4.2119e-01,\n",
      "        -1.6041e+00, -3.2731e-01, -1.5676e+00,  2.3422e+00, -3.0526e-01,\n",
      "        -7.7621e-01,  3.2553e-01, -2.1459e-01, -2.7066e+00, -8.0422e-01,\n",
      "        -3.0993e-01, -2.8130e-02, -3.5278e-01, -2.9817e-01, -5.8043e-01,\n",
      "         1.3690e+00, -7.2632e-01, -7.8579e-01, -2.0418e-01, -5.4568e-02,\n",
      "        -4.9564e-01, -5.5753e-02, -7.6332e-01, -3.3999e-01, -3.4093e-01,\n",
      "        -6.6696e-01,  1.0974e-01, -1.6268e+00, -4.2143e-01, -9.3238e-01,\n",
      "        -1.6298e-01, -3.4838e+00, -4.8640e+00, -8.4231e-02, -1.5776e+00,\n",
      "        -1.5521e-02, -8.1711e-01, -3.4647e-01, -1.7954e-01, -1.1594e-01,\n",
      "         8.4441e-01,  2.3986e+00, -4.4166e-02, -1.7043e+00, -4.9945e+00,\n",
      "         1.6213e-02, -1.1082e+00, -2.1669e-01, -2.1185e-01, -3.1798e-01,\n",
      "        -1.5685e+00, -1.9480e-01,  2.1013e+00, -1.4240e-01,  4.0164e+00,\n",
      "        -1.0985e+00, -3.6301e-01, -3.5348e-01, -3.1727e-01, -4.0984e-01,\n",
      "        -2.6479e+00, -2.8448e+00, -3.8255e-01, -5.0275e+00,  3.1011e+00,\n",
      "        -4.6029e+00, -1.0923e+00, -1.6496e-01, -2.4081e-01, -2.8228e+00,\n",
      "        -1.6596e+00, -3.8198e+00, -2.5719e-01, -1.5458e-01,  2.1840e+00,\n",
      "        -6.4481e-01,  2.8528e-02, -1.5083e+00, -3.3184e-01, -2.8100e-01,\n",
      "        -2.1431e+00, -1.7658e-01, -3.3467e-01, -2.6022e+00, -1.3198e+00,\n",
      "        -6.6175e-01, -1.1021e+00, -2.2268e+00,  2.3786e-01, -1.6133e-01,\n",
      "        -1.5209e-01, -4.2308e-01, -9.7563e-01, -1.0561e-01, -3.2366e-01,\n",
      "        -3.5449e+00,  4.0140e+00, -3.5861e-01, -2.6811e-01, -2.6390e-01,\n",
      "        -3.1834e+00, -2.1754e-01, -7.7023e-01, -4.9779e-01, -1.0004e+00,\n",
      "        -8.7814e-01, -6.3863e-01], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.6.conv.2.weight\n",
      "Weights: tensor([[[[-0.1693]],\n",
      "\n",
      "         [[-0.0757]],\n",
      "\n",
      "         [[-0.1058]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0714]],\n",
      "\n",
      "         [[-0.0168]],\n",
      "\n",
      "         [[-0.1297]]],\n",
      "\n",
      "\n",
      "        [[[-0.0016]],\n",
      "\n",
      "         [[ 0.0380]],\n",
      "\n",
      "         [[-0.0300]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0011]],\n",
      "\n",
      "         [[-0.0194]],\n",
      "\n",
      "         [[-0.0576]]],\n",
      "\n",
      "\n",
      "        [[[-0.0292]],\n",
      "\n",
      "         [[-0.0771]],\n",
      "\n",
      "         [[-0.1455]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1384]],\n",
      "\n",
      "         [[ 0.0203]],\n",
      "\n",
      "         [[ 0.0357]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0874]],\n",
      "\n",
      "         [[-0.0296]],\n",
      "\n",
      "         [[ 0.0129]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0046]],\n",
      "\n",
      "         [[-0.1060]],\n",
      "\n",
      "         [[-0.0245]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0310]],\n",
      "\n",
      "         [[-0.0337]],\n",
      "\n",
      "         [[ 0.0818]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0906]],\n",
      "\n",
      "         [[ 0.1218]],\n",
      "\n",
      "         [[-0.1784]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0817]],\n",
      "\n",
      "         [[ 0.0213]],\n",
      "\n",
      "         [[-0.0050]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0561]],\n",
      "\n",
      "         [[-0.0162]],\n",
      "\n",
      "         [[-0.1362]]]], device='cuda:0')\n",
      "Shape: torch.Size([32, 192, 1, 1])\n",
      "\n",
      "Layer: features.6.conv.3.weight\n",
      "Weights: tensor([ 1.3031,  1.6153,  3.6860,  1.8646,  4.2714,  1.1679,  1.1188,  1.9756,\n",
      "         1.3828,  2.0659,  2.1791,  1.0369,  1.7859, 12.3622,  1.4574,  1.3365,\n",
      "         2.9994,  3.8325,  6.1924,  2.1878,  2.1189,  3.9293,  2.8397,  1.3792,\n",
      "         7.7294,  2.2338,  2.2770,  1.5190,  4.5124,  1.0372,  1.8825,  1.8724],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.6.conv.3.bias\n",
      "Weights: tensor([ 1.9880e-08,  9.6169e-07,  1.1876e-06,  2.2520e-06, -9.4791e-07,\n",
      "         1.0793e-06, -1.1531e-07, -7.7937e-07, -1.0639e-06, -9.4290e-08,\n",
      "        -3.1666e-07, -1.4618e-06, -1.0784e-06,  1.5291e-06,  7.5439e-07,\n",
      "         3.5494e-07,  8.3515e-07, -8.5871e-07, -1.1881e-06,  1.1209e-06,\n",
      "        -1.0833e-06,  1.1094e-06, -7.1011e-07, -2.0106e-06,  1.0150e-07,\n",
      "        -1.2871e-06, -1.0712e-06, -1.2361e-06,  6.2901e-07, -1.9035e-06,\n",
      "        -4.9620e-07,  1.0358e-06], device='cuda:0')\n",
      "Shape: torch.Size([32])\n",
      "\n",
      "Layer: features.7.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0837]],\n",
      "\n",
      "         [[-0.0673]],\n",
      "\n",
      "         [[-0.3664]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0243]],\n",
      "\n",
      "         [[-0.1280]],\n",
      "\n",
      "         [[ 0.1523]]],\n",
      "\n",
      "\n",
      "        [[[-0.0465]],\n",
      "\n",
      "         [[ 0.0630]],\n",
      "\n",
      "         [[ 0.0754]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.2346]],\n",
      "\n",
      "         [[-0.0108]],\n",
      "\n",
      "         [[ 0.0623]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3000]],\n",
      "\n",
      "         [[ 0.6404]],\n",
      "\n",
      "         [[ 0.0025]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0235]],\n",
      "\n",
      "         [[ 0.1098]],\n",
      "\n",
      "         [[ 0.4107]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0200]],\n",
      "\n",
      "         [[ 0.0671]],\n",
      "\n",
      "         [[ 0.3451]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         [[ 0.1897]],\n",
      "\n",
      "         [[-0.0291]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2250]],\n",
      "\n",
      "         [[-0.5676]],\n",
      "\n",
      "         [[-0.0434]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0284]],\n",
      "\n",
      "         [[-0.0896]],\n",
      "\n",
      "         [[ 0.6948]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3341]],\n",
      "\n",
      "         [[ 0.3176]],\n",
      "\n",
      "         [[ 0.1479]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0842]],\n",
      "\n",
      "         [[-0.1933]],\n",
      "\n",
      "         [[-0.2003]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 32, 1, 1])\n",
      "\n",
      "Layer: features.7.conv.0.1.weight\n",
      "Weights: tensor([1.4475, 0.7053, 1.2833, 1.2769, 1.2610, 0.9718, 1.9706, 1.4851, 0.7424,\n",
      "        2.1487, 1.7827, 0.9752, 2.1316, 1.2237, 0.9248, 1.3937, 1.7525, 1.9055,\n",
      "        1.1787, 1.4476, 2.3869, 1.8935, 1.1646, 0.7818, 1.5184, 2.8785, 2.4223,\n",
      "        1.4519, 2.6137, 1.5061, 1.4898, 1.6938, 1.3915, 1.5767, 2.7065, 0.6752,\n",
      "        1.5031, 2.1060, 1.4614, 0.6792, 1.4254, 1.8735, 1.3151, 1.9691, 1.4984,\n",
      "        1.7060, 1.3657, 1.3047, 1.1543, 1.0512, 1.4901, 0.7932, 1.5603, 1.2785,\n",
      "        1.4116, 1.7910, 1.6635, 1.2031, 1.1287, 1.4329, 1.8765, 2.0297, 0.9419,\n",
      "        1.4580, 1.8558, 1.3981, 1.6554, 0.5583, 2.1085, 0.9910, 1.4555, 1.2155,\n",
      "        1.9243, 1.9665, 1.4248, 1.1543, 1.1075, 1.1448, 1.6946, 1.7284, 1.5196,\n",
      "        0.8480, 1.2595, 1.9297, 1.5609, 0.9716, 1.0502, 1.0315, 0.9782, 2.1666,\n",
      "        1.9025, 1.7670, 1.2052, 1.9299, 1.5723, 0.5870, 2.1790, 1.2268, 1.7597,\n",
      "        1.3814, 2.6201, 1.0102, 1.2964, 1.6394, 1.5469, 1.6861, 1.3844, 1.3282,\n",
      "        1.5295, 1.3901, 1.0933, 0.7767, 1.5828, 1.2544, 1.7683, 1.3332, 1.6344,\n",
      "        1.4324, 1.7472, 1.4741, 1.2081, 1.7713, 1.4790, 1.2631, 1.5529, 1.3749,\n",
      "        1.1886, 1.5782, 1.4398, 1.7304, 1.2306, 2.2526, 1.0114, 1.8456, 1.0004,\n",
      "        2.2090, 1.8044, 1.2463, 1.4128, 1.3906, 1.4538, 1.1795, 0.5657, 1.6245,\n",
      "        1.0721, 1.3556, 1.5177, 1.2204, 1.7447, 1.4815, 1.6514, 1.1066, 1.2771,\n",
      "        1.1032, 1.2682, 1.3931, 1.9798, 1.1453, 1.1041, 1.7539, 1.2274, 1.2033,\n",
      "        1.4184, 1.5484, 1.3023, 2.0150, 0.9180, 1.4313, 1.6607, 2.3907, 0.6106,\n",
      "        2.0719, 1.1288, 1.1903, 1.4954, 1.4150, 1.5462, 1.8253, 0.8033, 1.5109,\n",
      "        1.1588, 1.2568, 1.3880, 1.2549, 1.3589, 1.2952, 2.0122, 1.2842, 1.0836,\n",
      "        1.2361, 1.2513, 1.2227], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.0.1.bias\n",
      "Weights: tensor([ 8.0111e-01,  3.0361e-01,  1.4105e-01, -1.2132e+00, -7.5173e-02,\n",
      "         2.3419e+00,  2.1147e-01, -1.5065e+00,  1.5972e-01,  1.0114e+00,\n",
      "        -3.1587e-01,  1.7879e+00,  4.3799e-01, -1.8763e+00, -5.8389e-01,\n",
      "        -7.5751e-02,  1.0926e+00, -7.8798e-01,  4.1252e-01, -4.3961e-01,\n",
      "         8.9231e-01, -1.8799e+00,  3.0205e-01,  6.9119e-01,  4.6871e-01,\n",
      "         1.1085e+00,  2.0741e-01, -6.5506e-01, -7.9232e-01,  1.9575e-01,\n",
      "        -1.7984e+00, -7.0940e-02, -4.9481e-01, -9.0466e-01,  1.1777e+00,\n",
      "         1.2433e-01,  9.8375e-01, -1.2868e+00, -1.6631e-01,  2.0235e+00,\n",
      "        -6.4421e-01,  1.7650e-01, -9.7631e-01,  5.3333e-01, -1.2582e+00,\n",
      "        -1.9675e+00, -1.6913e-01, -1.4387e+00, -3.9907e-02, -6.7926e-01,\n",
      "        -7.5377e-01,  5.1385e-01, -1.0166e+00, -7.2470e-01, -7.1369e-01,\n",
      "        -2.2953e+00, -2.0373e+00, -5.4904e-01,  1.9548e-01, -9.8337e-01,\n",
      "         1.7157e-01, -1.6871e-01,  1.9705e-01,  1.7849e-03, -1.6642e+00,\n",
      "        -2.2781e-01, -8.5328e-02,  1.3907e+00,  1.3069e+00, -7.5624e-02,\n",
      "        -1.2585e+00, -3.8903e-01, -1.2368e+00, -1.1226e+00, -2.7059e-01,\n",
      "        -3.2184e-01, -2.9145e-01,  1.0267e-01,  6.1851e-01, -3.5564e-01,\n",
      "         1.4928e+00,  8.9047e-01,  1.1415e-01,  1.9925e-01,  3.2021e-01,\n",
      "         1.8355e+00,  1.2115e-01,  8.5182e-01,  1.3610e+00, -8.6966e-02,\n",
      "         9.6677e-01, -1.2843e+00, -6.7260e-01, -5.7960e-01,  1.0412e+00,\n",
      "         3.9570e-01,  5.9277e-01, -5.1432e-01, -2.9324e-03, -1.1414e+00,\n",
      "         4.7527e-01,  6.9123e-01, -2.6116e-02,  1.6276e+00, -3.1591e-01,\n",
      "        -1.4855e+00, -1.2713e+00,  4.8559e-01, -8.6697e-01, -2.6159e-01,\n",
      "         8.6428e-01,  1.8266e+00, -1.2675e+00,  3.6323e-01, -7.4445e-01,\n",
      "        -7.9946e-01, -1.2892e+00,  8.5094e-02, -1.0354e+00, -1.7283e+00,\n",
      "        -2.5682e+00, -4.2259e+00, -1.8656e+00, -1.2296e+00, -3.9067e-01,\n",
      "        -1.4867e+00, -8.0471e-01, -1.3286e+00, -1.3721e+00, -1.5070e+00,\n",
      "         3.0556e-01,  1.9858e-01, -7.0610e-02, -1.4206e+00, -1.5420e+00,\n",
      "        -1.3234e+00, -1.1438e+00,  7.9510e-01, -4.3455e-01, -8.9592e-01,\n",
      "        -7.1319e-01,  9.2059e-01,  3.3891e-01, -1.1412e+00,  6.4110e-01,\n",
      "         6.5814e-01,  5.2832e-01, -8.4056e-01, -8.6229e-01, -3.0611e-01,\n",
      "         5.8471e-01,  1.2924e-01,  2.0356e-01,  6.5843e-01, -1.9903e-01,\n",
      "        -1.0718e+00, -2.2806e+00, -3.6958e-01, -1.2210e-02, -1.6844e+00,\n",
      "        -6.2470e-01, -3.4114e-01, -8.0347e-01, -2.7153e+00, -5.3505e-01,\n",
      "        -2.6030e-01,  3.1264e-01, -8.8703e-02,  6.9225e-01,  8.9789e-01,\n",
      "         2.3728e-01, -1.6002e-01,  1.0537e-01, -1.3314e-01, -8.7320e-01,\n",
      "         5.3498e-01,  4.1497e-01,  1.6912e+00,  3.8446e-01, -7.1414e-01,\n",
      "        -2.3859e-01,  2.2595e-01, -1.9683e+00, -1.6616e-01, -1.8015e+00,\n",
      "        -3.0713e-01, -1.1204e+00,  5.8478e-01,  6.2189e-01, -3.8468e-01,\n",
      "        -2.6405e-01, -1.2117e+00], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0338, -0.0552, -0.0523],\n",
      "          [-0.1635, -0.3457, -0.2524],\n",
      "          [-0.1376, -0.2814, -0.2011]]],\n",
      "\n",
      "\n",
      "        [[[-0.0609, -0.1427, -0.1051],\n",
      "          [-0.0614, -0.1519, -0.1516],\n",
      "          [ 0.0976,  0.2657,  0.1850]]],\n",
      "\n",
      "\n",
      "        [[[-0.1057, -0.1830, -0.1228],\n",
      "          [-0.1706, -0.3587, -0.2427],\n",
      "          [-0.1167, -0.2310, -0.1604]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0486,  0.0925,  0.0669],\n",
      "          [ 0.1124,  0.2293,  0.1758],\n",
      "          [ 0.0721,  0.1716,  0.1341]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0307,  0.1269,  0.0999],\n",
      "          [ 0.1285,  0.4070,  0.3225],\n",
      "          [ 0.0905,  0.2852,  0.2349]]],\n",
      "\n",
      "\n",
      "        [[[-0.0544, -0.1203, -0.0938],\n",
      "          [-0.1144, -0.2201, -0.1834],\n",
      "          [-0.0866, -0.1772, -0.1320]]]], device='cuda:0')\n",
      "Shape: torch.Size([192, 1, 3, 3])\n",
      "\n",
      "Layer: features.7.conv.1.1.weight\n",
      "Weights: tensor([0.9948, 0.8585, 0.8769, 0.5647, 0.7958, 1.1984, 1.1168, 0.8039, 0.9363,\n",
      "        2.0749, 0.8343, 1.3263, 1.3119, 0.4866, 1.9176, 0.9108, 1.6624, 0.8331,\n",
      "        0.9826, 0.8091, 1.2873, 0.6844, 0.8569, 1.0736, 0.9161, 1.2236, 1.1061,\n",
      "        0.8425, 1.1015, 0.7894, 0.7545, 0.8492, 0.8087, 0.6974, 1.3740, 0.9868,\n",
      "        1.1035, 0.8783, 0.9250, 0.9638, 1.2711, 1.2234, 0.6574, 1.1724, 0.6528,\n",
      "        0.6992, 0.8424, 1.3203, 0.9352, 0.7049, 0.7876, 0.7462, 0.7691, 0.8331,\n",
      "        0.7319, 0.6624, 0.7027, 0.8050, 0.8429, 0.6615, 1.3248, 1.7202, 1.0117,\n",
      "        0.8813, 0.6248, 0.7959, 1.0029, 0.7908, 1.7528, 0.9652, 0.6302, 0.7626,\n",
      "        0.8073, 0.7599, 0.7784, 0.6869, 0.8718, 0.9391, 1.1764, 0.9581, 2.2524,\n",
      "        0.7716, 0.9620, 2.1410, 0.9837, 0.9743, 0.9396, 1.1253, 0.9049, 1.5117,\n",
      "        2.4770, 0.7964, 0.8829, 1.3801, 1.3758, 0.9294, 1.2250, 0.7612, 0.9037,\n",
      "        0.7564, 0.9080, 1.3064, 1.0086, 2.2132, 0.8186, 0.6403, 0.6843, 0.9349,\n",
      "        0.6607, 0.7404, 0.7806, 1.1330, 0.5965, 0.8364, 0.7820, 0.6662, 0.6599,\n",
      "        1.4800, 0.8013, 0.5987, 0.3722, 1.7486, 0.5556, 0.6276, 1.2338, 0.7140,\n",
      "        0.8614, 0.7278, 0.5524, 0.7862, 0.9253, 1.5307, 0.8634, 0.7100, 0.5622,\n",
      "        0.8738, 0.8006, 1.1315, 0.7833, 0.7474, 0.7514, 1.0314, 0.9281, 0.7717,\n",
      "        1.0704, 0.9982, 1.1702, 0.9374, 0.7134, 0.8672, 0.9207, 0.9899, 0.9260,\n",
      "        0.8334, 0.7665, 0.7509, 0.7510, 0.8265, 0.9013, 0.6744, 0.9487, 0.7812,\n",
      "        0.7263, 0.7390, 0.6846, 1.3638, 0.9258, 0.8397, 1.1948, 1.2978, 0.9253,\n",
      "        1.5623, 0.8349, 0.8038, 0.7226, 0.8648, 1.0852, 1.2092, 1.0651, 0.6697,\n",
      "        0.7317, 0.8314, 0.5907, 0.7993, 0.5398, 0.7829, 0.8058, 1.0239, 0.8502,\n",
      "        0.7211, 1.0515, 0.5923], device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.1.1.bias\n",
      "Weights: tensor([ 4.1648, -0.1677,  3.6543,  0.5011,  0.5249,  2.9729,  1.1251,  0.4414,\n",
      "        -0.3485, -0.3876,  1.1080,  0.0146,  0.7800,  0.1937,  2.6402,  3.8656,\n",
      "        -0.3601,  1.0537,  3.9126,  0.7867,  1.0059,  0.3995,  3.3653, -0.5866,\n",
      "         3.3281,  0.0971,  0.8238,  5.2025,  0.4825,  3.8238,  1.7012,  2.9460,\n",
      "         0.8865,  0.6567, -0.1055, -0.2141,  0.9663, -0.0430,  1.3874,  2.8610,\n",
      "         1.4608,  0.2599,  5.0922,  1.0286,  0.4462,  0.3608,  5.1173,  0.7632,\n",
      "         0.9693,  0.6353,  0.9756,  0.2216,  0.6392,  2.0888,  1.4641,  1.8997,\n",
      "         0.3632,  1.1398,  3.7406,  0.7412,  0.5415,  0.1610,  1.0230,  1.2398,\n",
      "         0.6083,  0.8803,  1.1712,  0.8442, -0.5795,  0.9204,  0.4791,  2.8089,\n",
      "         0.3560,  5.3275,  4.9954,  0.5994,  2.3430,  4.7305,  0.6548,  0.5985,\n",
      "        -0.1074,  2.9094,  0.0245, -0.7090,  0.4342,  3.0736,  0.9586, -0.1582,\n",
      "         2.9498,  0.1442, -1.0848,  0.6531,  4.8700,  0.4323,  0.0798, -0.1644,\n",
      "         0.4223,  0.6839,  1.9791,  0.3666,  1.5669,  4.1732,  1.3243, -0.0931,\n",
      "         4.4862,  0.6875,  0.4432,  3.7057,  0.4926,  1.8602,  2.5578,  0.0313,\n",
      "         0.8661,  2.9627,  2.6793,  5.1765,  0.4049,  0.8774,  0.8500,  0.3713,\n",
      "         0.0827,  0.3710,  0.7086,  0.3721,  1.1178,  0.3269,  0.4685,  4.5774,\n",
      "         0.2818,  1.9588,  0.6310,  0.5611,  0.8173,  1.1823,  0.1759, -0.0909,\n",
      "         1.2916,  0.3535,  5.1910,  0.6026,  0.7259,  3.3524,  0.9955,  0.4978,\n",
      "         4.3324,  4.0413,  0.6696,  0.4714,  0.8439,  1.8340,  1.2896,  0.9401,\n",
      "         3.5714,  3.0298,  0.9461,  0.4518,  0.4094,  0.6219,  3.2914,  0.3965,\n",
      "         0.6349,  4.9253,  1.4254, -0.0167,  0.6852,  0.2714,  1.2512,  0.9223,\n",
      "         0.1240,  1.0234, -0.3625,  0.2868,  2.4609,  3.7127,  0.8551,  1.3398,\n",
      "         4.5068,  0.2285, -0.2920,  0.7450,  1.6389,  2.0957,  0.4726,  4.5406,\n",
      "         0.1956,  4.9449,  0.6690,  0.2735,  3.1163,  0.6732,  0.8308,  5.3966],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([192])\n",
      "\n",
      "Layer: features.7.conv.2.weight\n",
      "Weights: tensor([[[[-0.0950]],\n",
      "\n",
      "         [[-0.0125]],\n",
      "\n",
      "         [[ 0.0167]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0499]],\n",
      "\n",
      "         [[ 0.0303]],\n",
      "\n",
      "         [[-0.0685]]],\n",
      "\n",
      "\n",
      "        [[[-0.2837]],\n",
      "\n",
      "         [[-0.0446]],\n",
      "\n",
      "         [[-0.3037]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0257]],\n",
      "\n",
      "         [[ 0.3578]],\n",
      "\n",
      "         [[-0.1221]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0783]],\n",
      "\n",
      "         [[ 0.0079]],\n",
      "\n",
      "         [[ 0.0564]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1061]],\n",
      "\n",
      "         [[ 0.2310]],\n",
      "\n",
      "         [[ 0.0674]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1834]],\n",
      "\n",
      "         [[-0.1250]],\n",
      "\n",
      "         [[ 0.1619]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2192]],\n",
      "\n",
      "         [[ 0.0911]],\n",
      "\n",
      "         [[-0.1507]]],\n",
      "\n",
      "\n",
      "        [[[-0.0120]],\n",
      "\n",
      "         [[-0.0262]],\n",
      "\n",
      "         [[-0.1125]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1478]],\n",
      "\n",
      "         [[-0.3139]],\n",
      "\n",
      "         [[-0.2116]]],\n",
      "\n",
      "\n",
      "        [[[-0.0606]],\n",
      "\n",
      "         [[ 0.0617]],\n",
      "\n",
      "         [[-0.4877]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1798]],\n",
      "\n",
      "         [[-0.1686]],\n",
      "\n",
      "         [[-0.0026]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 192, 1, 1])\n",
      "\n",
      "Layer: features.7.conv.3.weight\n",
      "Weights: tensor([3.4909, 5.0772, 3.4203, 4.9683, 2.5276, 4.0449, 5.0557, 5.4148, 3.1032,\n",
      "        3.5418, 4.2296, 3.8709, 5.4469, 3.8369, 3.1175, 3.5389, 2.6501, 5.6267,\n",
      "        3.8622, 4.0628, 4.9248, 2.7033, 6.4886, 4.1041, 4.7610, 3.1811, 3.7074,\n",
      "        4.1247, 5.5939, 5.7338, 3.9746, 4.0841, 5.5424, 3.1707, 5.2315, 4.1086,\n",
      "        4.0435, 4.3210, 2.2280, 5.1654, 4.6756, 4.8783, 5.9836, 5.5982, 2.8929,\n",
      "        3.0458, 4.9810, 2.6632, 6.0324, 4.2237, 3.7914, 5.6260, 5.2592, 5.0913,\n",
      "        4.3263, 4.2697, 4.3860, 2.6081, 5.6625, 3.5980, 5.1861, 4.9160, 3.9668,\n",
      "        6.1849], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.7.conv.3.bias\n",
      "Weights: tensor([ 7.0355e-07, -9.4960e-07,  8.0578e-07, -2.5877e-07,  1.6052e-06,\n",
      "         2.9280e-07,  2.2018e-06, -1.7202e-06, -4.2902e-07, -5.6242e-07,\n",
      "        -2.4155e-07,  1.5350e-06, -9.0778e-07,  1.4574e-06, -1.7577e-06,\n",
      "        -8.0902e-07,  4.8703e-08,  1.1551e-06, -4.6082e-07, -1.7447e-06,\n",
      "         1.5194e-06, -9.7728e-07, -1.5073e-06,  7.8497e-09, -1.0841e-06,\n",
      "        -3.8008e-07, -7.1193e-07,  2.5575e-06,  1.7590e-06,  2.6706e-06,\n",
      "         9.1619e-09,  1.5506e-06,  3.7418e-07, -6.4105e-07, -1.9798e-06,\n",
      "        -2.0963e-08,  6.4487e-07,  5.5833e-07,  4.1162e-08, -5.8162e-07,\n",
      "         2.3458e-06, -1.5582e-06, -9.5809e-07,  5.4557e-07, -2.3324e-06,\n",
      "        -7.6304e-07, -1.1273e-06, -6.7281e-07,  1.0622e-06, -2.1107e-06,\n",
      "        -6.8348e-07,  1.9201e-07,  5.9632e-07, -9.3814e-07, -1.5318e-07,\n",
      "         5.9577e-07, -2.6176e-07, -1.0978e-06, -1.4485e-06, -8.2112e-08,\n",
      "         8.5230e-07, -1.6214e-06,  4.2095e-07, -3.9995e-07], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.8.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0346]],\n",
      "\n",
      "         [[-0.0285]],\n",
      "\n",
      "         [[ 0.0848]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0257]],\n",
      "\n",
      "         [[ 0.0247]],\n",
      "\n",
      "         [[ 0.1087]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0617]],\n",
      "\n",
      "         [[-0.0513]],\n",
      "\n",
      "         [[ 0.1027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1441]],\n",
      "\n",
      "         [[ 0.0108]],\n",
      "\n",
      "         [[ 0.0508]]],\n",
      "\n",
      "\n",
      "        [[[-0.0580]],\n",
      "\n",
      "         [[-0.0125]],\n",
      "\n",
      "         [[ 0.0055]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0286]],\n",
      "\n",
      "         [[ 0.0700]],\n",
      "\n",
      "         [[ 0.0076]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.2637]],\n",
      "\n",
      "         [[ 0.0237]],\n",
      "\n",
      "         [[ 0.0532]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0462]],\n",
      "\n",
      "         [[-0.0344]],\n",
      "\n",
      "         [[-0.0079]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0080]],\n",
      "\n",
      "         [[ 0.0107]],\n",
      "\n",
      "         [[ 0.0209]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1256]],\n",
      "\n",
      "         [[ 0.0966]],\n",
      "\n",
      "         [[-0.0268]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0488]],\n",
      "\n",
      "         [[ 0.1133]],\n",
      "\n",
      "         [[ 0.0109]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0752]],\n",
      "\n",
      "         [[-0.0547]],\n",
      "\n",
      "         [[-0.0607]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.8.conv.0.1.weight\n",
      "Weights: tensor([0.8284, 1.1204, 0.9475, 1.1092, 1.1616, 1.4802, 0.9515, 0.8518, 1.4569,\n",
      "        1.2612, 1.0200, 1.3870, 1.0982, 1.0198, 0.8574, 0.7480, 0.8058, 2.0396,\n",
      "        1.3823, 0.8071, 0.7984, 1.7803, 1.3590, 1.1740, 1.4933, 0.9050, 1.0073,\n",
      "        1.7909, 1.0633, 1.1453, 1.1761, 0.7099, 1.1754, 0.7333, 0.6466, 0.5983,\n",
      "        0.8571, 1.4184, 1.3680, 1.5683, 1.1689, 1.2855, 1.2191, 0.8485, 0.8217,\n",
      "        0.7986, 2.4725, 1.1756, 1.2914, 0.8845, 0.9082, 1.6219, 0.7320, 1.2502,\n",
      "        1.3607, 1.0703, 1.2898, 0.7701, 1.1508, 0.9456, 1.2169, 0.8393, 1.7461,\n",
      "        0.9180, 0.9539, 1.1281, 0.8869, 1.1577, 0.9772, 0.5352, 0.6976, 1.3741,\n",
      "        1.0615, 1.1860, 0.4224, 0.6838, 1.2411, 1.3892, 0.9654, 1.2261, 0.7977,\n",
      "        0.9899, 1.2436, 1.1046, 1.2748, 1.1457, 1.0218, 1.3260, 1.0252, 0.8335,\n",
      "        0.7278, 1.0090, 1.2660, 0.5976, 0.7512, 0.8421, 1.1791, 0.4380, 1.1117,\n",
      "        0.6834, 0.9450, 0.8456, 0.9176, 1.6302, 1.2563, 0.9362, 0.9731, 0.9592,\n",
      "        1.1805, 0.6416, 1.0945, 0.9530, 0.9581, 1.0323, 1.5806, 0.7471, 1.2551,\n",
      "        0.7777, 0.6557, 1.2490, 1.0327, 0.9110, 1.0589, 1.1899, 1.0831, 0.6448,\n",
      "        0.9927, 1.4514, 1.0162, 0.9467, 1.3576, 0.7772, 1.1184, 1.4386, 1.3598,\n",
      "        1.1429, 1.5112, 0.8473, 1.4451, 0.7149, 1.1017, 0.4332, 1.5427, 0.9329,\n",
      "        0.8928, 0.7807, 1.5208, 1.5840, 0.5344, 1.2297, 0.8382, 1.0852, 0.8047,\n",
      "        0.7813, 0.5127, 1.2792, 1.4979, 0.4432, 1.0757, 0.9777, 0.9333, 0.9596,\n",
      "        0.8273, 1.5701, 1.0238, 1.3675, 0.8766, 1.1342, 1.1984, 0.6647, 1.5695,\n",
      "        0.6859, 1.1082, 1.0083, 1.1101, 0.3919, 0.9456, 1.0219, 1.0028, 1.0637,\n",
      "        1.5030, 0.7903, 0.8494, 0.8871, 0.7925, 1.1354, 1.2838, 1.5585, 1.7610,\n",
      "        0.9039, 0.4815, 1.2488, 1.5563, 1.1780, 0.6409, 0.6666, 0.7282, 0.8197,\n",
      "        1.0832, 1.6211, 1.3366, 0.7779, 1.2918, 0.6430, 1.1329, 1.1239, 0.3816,\n",
      "        0.9506, 0.5007, 0.8700, 1.1732, 0.5860, 1.4405, 0.9604, 0.8865, 0.8333,\n",
      "        0.5645, 1.2111, 1.4191, 1.2265, 0.6468, 1.2580, 1.0604, 1.3966, 1.2944,\n",
      "        1.2095, 0.5962, 1.0575, 0.9384, 1.0353, 1.4902, 1.4330, 0.8097, 1.3723,\n",
      "        1.2101, 0.8387, 0.7621, 0.7528, 1.4239, 1.0120, 0.8598, 1.0055, 1.0721,\n",
      "        0.6402, 1.1105, 0.6751, 0.5352, 1.4766, 0.7936, 1.1736, 0.7923, 1.4277,\n",
      "        1.4406, 0.8198, 0.3704, 1.1576, 1.0302, 0.8499, 0.8596, 0.3358, 0.7827,\n",
      "        0.8056, 1.3512, 1.2342, 1.0618, 0.7730, 1.1888, 0.9532, 0.5952, 0.9462,\n",
      "        0.8761, 0.6574, 1.3030, 1.4818, 1.2338, 0.9907, 0.9350, 0.8367, 1.2840,\n",
      "        1.0310, 1.1483, 1.1006, 1.4312, 1.4883, 0.9556, 1.4052, 1.0226, 0.8139,\n",
      "        1.1075, 1.3623, 1.4351, 0.8628, 1.0371, 0.8568, 1.0349, 1.1157, 1.5574,\n",
      "        1.0136, 1.6235, 0.6489, 1.0558, 1.1865, 1.0181, 1.7590, 0.8035, 1.2843,\n",
      "        1.6887, 0.6964, 0.7736, 0.8231, 0.7292, 0.9584, 1.2590, 1.2665, 1.1206,\n",
      "        0.7950, 0.6815, 1.0586, 1.4787, 1.4134, 0.9430, 0.8500, 0.8348, 1.2532,\n",
      "        0.7398, 0.8055, 0.9681, 0.9184, 0.8713, 0.8152, 1.3714, 0.8441, 1.4310,\n",
      "        0.6104, 0.8090, 1.0887, 1.0186, 1.1828, 1.2849, 0.9849, 0.7614, 0.8050,\n",
      "        0.7324, 0.8292, 1.3121, 0.9376, 0.7941, 1.4366, 1.2445, 0.6326, 0.8972,\n",
      "        0.6945, 1.0635, 1.1059, 1.2511, 0.8916, 1.0204, 0.7389, 0.9079, 0.2858,\n",
      "        1.2982, 0.6289, 0.8780, 0.9911, 0.9252, 0.7219, 0.9194, 0.9517, 0.6093,\n",
      "        1.5321, 0.8655, 0.6389, 0.5657, 1.4675, 1.9323, 1.0231, 0.3759, 1.5259,\n",
      "        0.8208, 0.8775, 1.5185, 0.8946, 0.4485, 0.8958], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.0.1.bias\n",
      "Weights: tensor([ 1.1080e+00,  5.0562e-01,  1.0183e+00,  1.4906e+00,  1.1653e+00,\n",
      "        -4.4482e-01,  1.2343e+00,  1.1669e+00,  2.0300e-01,  1.0827e+00,\n",
      "         9.6976e-01, -1.1398e+00,  1.3755e-01,  1.2921e+00,  1.2268e+00,\n",
      "         1.1074e+00,  1.1944e+00, -3.4355e+00,  4.2203e-01,  9.8519e-01,\n",
      "         1.3263e+00, -7.6559e-01, -3.3385e-01, -4.5704e-01, -1.0657e+00,\n",
      "         9.9664e-01,  1.0283e+00,  1.0203e+00, -1.6502e+00, -8.7633e-01,\n",
      "         7.9810e-01,  1.3196e+00, -2.9677e-01,  1.3487e+00,  2.6285e+00,\n",
      "         1.8504e+00,  1.3218e+00, -1.1370e+00, -7.4434e-01,  2.7937e-02,\n",
      "         3.5456e-01, -2.1654e-01, -2.5624e-01,  9.6426e-01,  1.0186e+00,\n",
      "         1.4466e+00,  1.6163e+00,  1.0301e+00, -1.2582e+00,  1.3435e+00,\n",
      "         1.2950e+00, -1.2106e+00,  1.5334e+00, -9.7030e-01, -3.6214e-01,\n",
      "         1.1444e+00, -1.2012e+00,  1.0362e+00,  4.0590e-01,  1.2516e+00,\n",
      "        -7.7962e-01,  1.2714e+00, -7.5580e-02,  1.2809e+00,  1.3888e+00,\n",
      "         7.1695e-01,  1.3051e+00, -1.3105e+00,  9.2374e-01,  1.2624e+00,\n",
      "         1.2294e+00,  1.8591e+00,  1.2963e+00,  2.1821e-01,  2.7794e+00,\n",
      "         9.1757e-01,  8.0828e-01, -5.9700e-01,  1.1069e+00, -2.7309e-01,\n",
      "         1.4762e+00,  6.2831e-01, -1.5206e-01, -7.3576e-01,  1.4088e+00,\n",
      "         1.3819e+00,  1.0244e+00,  1.4181e+00, -3.9286e+00,  1.4835e+00,\n",
      "         1.4562e+00,  9.4657e-01, -8.3221e-02,  1.9655e+00,  1.1507e+00,\n",
      "         1.1379e+00,  4.6532e-01, -2.4626e+00,  1.3578e+00,  1.2360e+00,\n",
      "         1.6467e+00,  1.0516e+00,  1.2932e+00, -1.5040e-01, -8.2870e-01,\n",
      "         1.0495e+00, -1.3663e+00,  1.3687e+00, -9.2209e-01,  1.8452e+00,\n",
      "         8.0645e-01,  9.3561e-01, -8.7899e-01,  1.1996e+00, -2.6015e+00,\n",
      "         1.4684e+00,  1.6750e+00,  1.1137e+00,  2.0312e+00, -1.1742e+00,\n",
      "         1.2688e+00,  1.3324e+00, -1.5944e-01,  1.5873e+00,  1.6796e+00,\n",
      "         1.1694e+00,  1.0895e+00,  3.1536e-02, -2.5737e-03,  1.3041e+00,\n",
      "         1.9014e-01,  1.4119e+00,  1.3713e+00,  1.4026e-01,  3.6310e-02,\n",
      "        -6.5684e-01,  6.8303e-01,  9.6861e-01, -4.7678e-02,  1.3454e+00,\n",
      "        -9.2591e-01,  1.6636e+00,  2.0623e-02,  8.5316e-01,  9.6819e-01,\n",
      "         1.1853e+00, -2.7520e+00, -2.3305e-03,  1.7146e+00, -3.1654e-01,\n",
      "         1.2491e+00, -7.7049e-01,  1.2586e+00,  1.1153e+00,  1.6932e+00,\n",
      "         4.6474e-01, -7.8455e-01,  2.4370e+00,  1.2054e+00,  8.9117e-01,\n",
      "         9.5678e-01,  1.1546e+00,  1.5096e+00,  1.8448e+00,  1.2954e+00,\n",
      "        -4.2678e-01, -1.3636e+00,  4.8038e-01,  6.9695e-01,  1.2360e+00,\n",
      "         1.3973e-01,  1.5028e+00, -1.5365e+00, -5.3808e-01,  4.5377e-01,\n",
      "         1.4934e+00,  1.0644e+00,  1.0409e+00,  9.5230e-01, -9.3394e-01,\n",
      "         1.3379e+00,  1.0816e+00,  1.1710e+00,  1.6282e+00,  1.1453e+00,\n",
      "         1.1464e+00, -5.1774e-01,  3.4406e-01, -8.5693e-01,  1.2420e+00,\n",
      "         1.1879e+00, -3.6180e-01, -9.4694e-01, -8.1218e-01,  1.3685e+00,\n",
      "         1.5185e+00,  2.8449e+00,  1.5240e+00,  1.3958e+00, -8.7492e-01,\n",
      "        -1.3478e+00,  1.1101e+00,  2.4428e+00,  1.2718e+00,  1.0506e+00,\n",
      "        -7.0619e-02,  3.0173e+00,  1.4499e+00,  1.4692e+00,  1.3329e+00,\n",
      "         4.7165e-01,  3.4379e+00, -1.9067e+00,  8.5566e-01,  1.2185e+00,\n",
      "         1.4656e+00,  1.4998e+00, -1.4734e+00,  4.2771e-01,  1.1819e+00,\n",
      "         1.2401e+00,  4.5974e-01, -8.9125e-01, -1.5907e+00,  1.4822e-01,\n",
      "         6.9739e-01,  1.1184e+00,  1.1884e+00,  1.1403e+00,  1.3088e-01,\n",
      "        -8.1635e-01, -3.0778e-01,  8.6722e-01,  5.4695e-01,  6.8414e-01,\n",
      "         1.5621e+00,  1.6749e+00,  1.5232e+00, -5.0810e-01,  1.4368e+00,\n",
      "         1.2813e+00,  1.2203e+00,  6.7916e-01,  1.0375e+00,  1.2828e+00,\n",
      "         1.5895e+00,  1.5852e+00,  5.8038e-01,  1.0083e+00, -8.2948e-01,\n",
      "         1.1652e+00,  1.6023e+00,  7.4950e-01,  1.0436e+00,  1.6583e+00,\n",
      "         1.0942e+00,  1.5901e+00,  1.0655e+00,  1.6368e+00,  1.2619e+00,\n",
      "         1.2817e+00,  1.7335e+00, -7.3325e-02,  3.1109e-01,  5.8219e-01,\n",
      "         2.4599e+00,  4.2329e-01,  1.0522e+00,  1.0710e+00,  1.6198e+00,\n",
      "         1.2235e+00,  9.0721e-01,  5.9254e-02, -7.5689e-01, -9.0611e-01,\n",
      "         1.7575e+00,  1.4247e+00,  1.3443e+00,  9.4425e-01,  4.9349e-01,\n",
      "         6.1611e-01, -7.4518e-01, -6.1105e-01, -1.5826e-01,  1.1952e+00,\n",
      "        -9.9673e-01,  1.2867e+00,  1.2254e+00,  3.3601e-02, -4.6906e-01,\n",
      "        -1.7318e+00,  8.7018e-01,  1.0890e+00,  1.1819e+00,  1.0342e+00,\n",
      "        -3.5816e-01, -8.3410e-01,  8.1382e-01,  6.6531e-01,  1.5319e+00,\n",
      "        -9.2415e-01,  1.6495e+00,  1.2403e+00, -8.0503e-01,  7.8153e-01,\n",
      "        -3.0415e-01,  1.6089e+00,  1.3075e+00,  1.0594e+00,  1.4029e+00,\n",
      "         1.3443e+00,  1.1273e+00, -1.0265e+00,  2.4229e-01, -5.6223e-01,\n",
      "         1.6125e+00,  1.1479e+00,  1.1338e+00, -2.6935e-01,  7.7036e-01,\n",
      "         1.1932e+00,  1.0723e+00,  1.3945e+00, -3.8067e-01,  1.2487e+00,\n",
      "         1.3421e+00,  1.1702e+00,  1.5083e+00,  8.2712e-01,  1.2670e+00,\n",
      "        -2.1505e-01,  1.0874e+00, -6.0648e-01,  2.0291e+00,  1.2374e+00,\n",
      "         1.5560e+00,  8.4237e-01, -1.2254e-01, -4.4108e-01,  1.2449e+00,\n",
      "         1.2757e+00,  1.1005e+00,  1.5063e+00,  9.5069e-01, -3.2607e-01,\n",
      "         1.2332e+00,  1.4244e+00,  1.3049e-01,  3.9028e-01,  1.6806e+00,\n",
      "         8.2451e-01,  1.7497e+00,  1.2481e+00,  1.3697e+00, -9.2058e-02,\n",
      "         1.1929e+00,  4.9009e-01,  1.6120e+00,  1.2492e+00,  2.9322e+00,\n",
      "        -4.7594e-02,  1.7051e+00,  1.0426e+00, -1.1951e+00,  6.1147e-01,\n",
      "         1.5296e+00,  9.7097e-01,  7.4113e-01,  1.3715e+00,  1.6972e-01,\n",
      "         7.7703e-01,  1.1677e+00,  1.6069e+00,  1.7604e+00, -6.5044e-01,\n",
      "         9.4531e-01,  2.7876e+00, -1.4466e+00,  1.3482e+00,  9.8740e-01,\n",
      "        -8.6544e-01,  1.0822e+00,  1.7059e+00,  1.2179e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0114,  0.0153, -0.0350],\n",
      "          [ 0.2751, -0.2081, -0.1776],\n",
      "          [ 0.0358,  0.0149, -0.0543]]],\n",
      "\n",
      "\n",
      "        [[[-0.0878, -0.1321, -0.1117],\n",
      "          [-0.1370,  0.3901, -0.1423],\n",
      "          [-0.0522, -0.1384, -0.0691]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0748,  0.3992,  0.0834],\n",
      "          [-0.0008, -0.1331,  0.0140],\n",
      "          [-0.0565, -0.3057, -0.0629]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0537, -0.0571, -0.0310],\n",
      "          [ 0.3341, -0.3015, -0.0377],\n",
      "          [ 0.0594, -0.0597, -0.0306]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0174, -0.0831,  0.0290],\n",
      "          [-0.0836, -0.2823, -0.0803],\n",
      "          [ 0.0316, -0.0671,  0.0330]]],\n",
      "\n",
      "\n",
      "        [[[-0.0490, -0.0813, -0.0361],\n",
      "          [-0.0680,  0.3082, -0.0133],\n",
      "          [-0.0527, -0.0271, -0.0696]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.8.conv.1.1.weight\n",
      "Weights: tensor([2.2056, 0.5348, 1.0448, 1.0461, 1.3236, 0.8818, 0.9702, 0.9639, 2.5181,\n",
      "        0.6802, 1.7958, 0.4458, 1.3204, 1.1280, 0.9913, 0.9994, 0.9210, 1.0034,\n",
      "        1.3272, 1.1273, 1.0678, 8.1944, 0.9502, 0.9111, 0.5075, 1.7521, 1.0799,\n",
      "        2.9968, 2.6702, 0.4609, 0.8589, 1.3415, 1.4582, 1.1861, 0.9654, 1.4726,\n",
      "        1.0283, 0.4420, 1.3046, 1.2491, 0.9834, 0.4354, 0.5898, 1.2345, 0.8672,\n",
      "        1.0886, 1.7560, 1.9951, 0.3984, 0.9603, 1.0780, 0.9656, 1.7989, 0.4050,\n",
      "        1.6103, 1.2088, 1.0949, 1.0111, 1.3924, 0.9701, 0.5817, 0.8560, 1.5565,\n",
      "        1.1173, 1.0013, 1.2465, 1.0924, 0.3230, 1.6207, 0.8210, 1.3923, 2.9803,\n",
      "        1.0532, 1.2067, 3.2694, 1.4073, 1.6223, 0.9725, 1.0388, 0.5011, 1.0723,\n",
      "        0.7993, 0.8055, 0.7658, 0.9822, 2.0198, 1.3053, 0.9120, 2.0328, 1.1219,\n",
      "        1.1166, 0.9330, 1.2456, 2.4578, 1.9136, 0.8659, 0.5197, 4.3416, 1.1744,\n",
      "        1.0547, 1.0186, 0.9506, 1.0659, 1.1395, 0.6680, 1.1936, 0.9082, 1.0010,\n",
      "        0.7964, 1.3160, 0.9172, 0.8756, 0.5787, 1.0597, 1.1162, 1.2815, 1.1519,\n",
      "        1.4730, 2.7108, 0.7557, 0.9938, 1.6249, 0.8043, 1.1466, 1.1877, 1.3009,\n",
      "        1.1977, 0.8690, 0.9024, 1.0731, 0.9449, 1.3167, 1.1092, 1.1883, 2.1687,\n",
      "        0.6003, 1.1818, 0.9749, 2.0615, 1.1139, 0.6226, 1.3787, 2.0828, 1.1354,\n",
      "        1.0363, 0.9214, 1.8205, 0.5272, 1.2786, 1.0126, 1.0057, 0.6876, 1.0908,\n",
      "        1.0381, 1.7412, 0.9365, 0.7021, 1.5340, 2.6393, 1.4852, 0.9214, 1.0045,\n",
      "        1.4832, 1.3174, 1.0387, 1.0681, 0.8090, 1.3103, 1.5254, 1.6061, 2.2567,\n",
      "        1.7024, 0.4378, 0.8105, 1.0396, 2.0641, 0.8919, 2.1444, 2.1790, 0.7846,\n",
      "        0.8767, 0.9506, 1.5672, 1.2481, 2.2654, 0.9097, 0.5492, 0.5759, 7.1716,\n",
      "        1.0709, 0.6702, 0.8305, 1.6848, 0.7773, 1.9153, 1.1567, 3.1382, 1.1598,\n",
      "        1.1031, 1.6002, 0.4192, 1.0507, 5.5110, 1.3161, 0.7905, 0.5657, 1.8134,\n",
      "        1.2044, 1.1940, 1.1129, 0.6201, 2.5777, 0.4047, 0.9654, 1.2328, 2.5275,\n",
      "        1.7188, 0.7167, 1.0440, 1.3632, 1.2220, 1.1120, 0.8448, 0.5351, 1.2521,\n",
      "        2.0321, 0.9657, 0.8605, 0.9406, 0.8333, 1.6608, 0.6330, 1.1966, 1.2487,\n",
      "        1.3240, 1.0026, 1.2792, 2.1557, 1.5535, 1.1390, 0.8896, 1.0585, 1.6802,\n",
      "        0.4738, 1.1811, 1.4117, 1.8129, 1.4291, 1.2739, 0.6342, 0.8765, 1.0701,\n",
      "        2.7961, 1.1032, 1.3169, 0.9552, 1.1157, 0.9682, 1.1478, 1.9132, 1.0196,\n",
      "        1.1418, 0.8309, 0.5541, 4.6048, 0.9446, 0.8023, 1.0916, 1.2646, 1.1118,\n",
      "        0.9599, 0.8714, 0.6944, 0.4782, 0.5619, 1.9174, 1.8018, 0.8714, 1.8047,\n",
      "        0.9798, 0.6048, 0.4999, 0.7641, 0.7122, 2.8098, 0.5741, 0.9961, 1.3045,\n",
      "        1.0290, 1.2705, 0.6602, 1.0380, 0.9660, 1.2145, 0.9610, 0.7637, 1.6382,\n",
      "        0.7855, 2.7030, 1.7156, 0.7232, 2.6970, 1.0432, 2.0588, 1.0347, 1.1773,\n",
      "        0.6750, 1.5590, 1.4403, 1.0526, 1.3752, 1.0473, 0.5793, 0.6361, 0.8748,\n",
      "        1.5924, 1.2096, 0.9493, 1.8145, 1.0386, 1.9946, 0.9617, 1.3005, 1.1581,\n",
      "        1.0206, 0.9206, 0.9388, 1.1464, 1.2204, 0.9464, 1.8168, 1.3643, 1.1772,\n",
      "        2.5307, 1.1163, 1.1957, 1.6632, 0.6051, 0.6378, 0.9920, 1.6187, 1.7163,\n",
      "        1.3907, 1.3645, 0.4756, 1.0143, 1.0437, 1.4477, 0.8146, 2.4328, 0.9719,\n",
      "        2.6244, 0.9618, 1.0988, 0.7343, 0.9977, 0.7777, 2.2296, 1.3463, 3.1860,\n",
      "        1.0105, 0.9760, 0.8999, 0.2862, 1.0686, 2.2185, 1.5826, 0.9887, 1.3527,\n",
      "        1.3569, 1.1242, 1.0464, 1.5298, 0.9699, 2.4838, 1.1136, 1.7729, 0.8392,\n",
      "        1.0505, 1.2000, 1.6058, 1.2118, 1.6971, 1.4762], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.1.1.bias\n",
      "Weights: tensor([-2.2880e+00,  1.1662e+00, -1.8449e-01, -1.5887e-01, -1.5456e+00,\n",
      "         1.5474e-01, -1.3016e-01, -2.0207e-01, -1.5889e+00,  2.5408e+00,\n",
      "        -2.1592e+00,  2.6129e+00, -2.0648e+00, -1.1270e-01, -1.8089e-01,\n",
      "        -2.3930e-01, -1.0245e-01, -2.7740e+00, -5.7584e-01, -2.7595e-01,\n",
      "        -1.9493e-01, -5.6517e+00, -6.9978e-01, -6.5886e-01,  1.0392e+00,\n",
      "        -1.0611e+00, -1.2996e-02, -1.8956e+00, -5.4760e-01,  2.3935e+00,\n",
      "        -1.3456e-01, -1.9535e-01, -1.6882e+00, -2.1413e-01,  6.5721e-01,\n",
      "        -1.4263e+00, -1.3546e-01,  3.0586e+00,  1.1739e-01, -4.3801e-01,\n",
      "        -8.5371e-01,  1.8159e+00, -2.5354e-01, -9.3614e-01,  2.8002e-01,\n",
      "        -1.6873e-01, -1.1246e+00, -1.6429e+00,  1.0317e-01, -1.4303e-01,\n",
      "        -1.4691e-01,  5.0491e-01, -7.9472e-01,  1.0118e+00, -3.3278e-01,\n",
      "        -3.4448e-01, -2.8202e+00, -1.3103e-01, -1.5915e+00, -5.3766e-02,\n",
      "         2.1535e-01,  2.5898e-01, -3.3072e+00, -2.8096e-01, -1.4154e-02,\n",
      "        -8.7402e-01, -7.9811e-02,  1.7786e+00, -1.1642e+00, -1.5078e-01,\n",
      "        -4.4531e-01, -3.3804e+00, -1.6540e-01, -1.2375e+00, -2.1894e+00,\n",
      "        -9.4609e-01, -6.7523e-01, -1.8606e+00, -2.4980e-01,  1.3277e+00,\n",
      "        -1.5061e-01,  5.0641e-01, -2.0220e-01, -8.2776e-01, -1.1232e-01,\n",
      "        -1.9844e+00, -7.8735e-01, -1.9660e-01, -7.0284e-01, -4.1420e-02,\n",
      "        -1.8974e-01, -2.7378e-01, -1.3226e+00, -3.3656e+00, -2.5139e+00,\n",
      "        -1.1407e-01,  2.5735e+00, -8.9287e-01, -1.9160e-01, -1.5853e-01,\n",
      "        -1.0590e-01, -1.4623e-01, -2.3391e-01, -2.3157e-01, -5.9041e-02,\n",
      "        -5.3487e-01, -3.8668e-01, -1.9367e-01, -1.5986e+00,  2.8254e-01,\n",
      "        -1.7459e-02,  2.9249e-01, -7.9914e-02, -1.2027e-01,  1.8672e+00,\n",
      "        -5.0854e-01, -3.6931e-01, -6.1376e-01, -3.7012e+00, -9.2239e-01,\n",
      "        -1.2255e-01, -1.5379e+00, -8.3593e-01, -5.6772e-02, -1.1562e-01,\n",
      "        -7.4481e-01, -4.4826e-01,  1.2312e-01,  2.5009e+00, -8.1079e-02,\n",
      "         1.1156e-01, -1.2632e-01, -7.7714e-02, -3.5745e-02, -1.2258e+00,\n",
      "        -5.2018e-01, -2.5546e-01,  2.4113e-01, -1.1178e+00,  1.9980e-02,\n",
      "        -6.6314e-01,  1.5619e-01, -1.0516e+00, -3.3419e-01, -3.2856e-01,\n",
      "        -1.6314e-01, -2.4973e+00,  2.4497e+00,  3.6238e-01, -2.2081e+00,\n",
      "        -1.4156e-01, -3.6120e-01, -1.8063e-01, -7.7170e-02, -1.4898e+00,\n",
      "         2.1298e-02, -7.4237e-01,  4.9642e-02, -2.5020e+00, -1.0401e+00,\n",
      "        -1.2313e-01, -1.6171e-01, -7.5706e-01, -9.6268e-01, -6.5296e-02,\n",
      "        -1.3818e+00, -3.3109e+00, -5.2676e-01, -8.4386e-01, -1.5238e+00,\n",
      "        -1.1653e+00, -6.2380e-01,  2.2994e+00, -1.2417e+00, -3.4926e-01,\n",
      "        -1.8247e+00, -1.6187e-01, -1.3900e+00, -1.4349e+00, -1.2270e+00,\n",
      "         3.1454e-01, -2.1081e-01, -6.7784e-01,  1.6767e-02, -3.0886e+00,\n",
      "        -1.8952e-01,  2.6897e+00,  1.5748e+00, -4.2525e+00, -1.0194e-01,\n",
      "         1.8971e+00, -5.1647e-01, -5.2635e-01, -3.9951e-01, -2.5932e+00,\n",
      "        -7.1740e-02, -4.9863e+00, -8.3583e-02, -2.0192e-01, -8.8036e-02,\n",
      "         1.2658e+00, -2.4254e-01, -8.4222e+00, -5.4129e-01,  3.5836e-01,\n",
      "         1.7701e-01, -5.1058e-01, -2.7325e-01,  1.8076e-01, -2.1652e-01,\n",
      "         2.0516e+00, -5.1125e-01,  9.1529e-02, -3.0498e-01, -4.1111e-01,\n",
      "        -2.0800e+00, -1.4302e+00, -1.4638e+00, -6.0455e-01, -6.0855e-01,\n",
      "        -2.9916e-01, -8.3353e-01, -1.2250e+00,  1.9912e+00, -1.6663e+00,\n",
      "        -1.2360e+00, -3.7833e-02, -6.5865e-02, -1.6246e-01, -1.9448e-01,\n",
      "        -5.0714e-01,  2.6733e+00, -5.8749e-01, -4.9030e-01, -1.1274e+00,\n",
      "        -9.8689e-02,  7.3401e-01, -1.7703e+00, -2.3017e-01, -1.2463e-01,\n",
      "        -1.3837e-01, -1.1648e-01, -1.0305e+00,  1.0885e+00, -2.9856e-01,\n",
      "         4.1140e-01, -2.7728e+00, -1.0470e-01, -2.7720e-01,  2.3048e+00,\n",
      "        -1.2202e-01, -2.7429e-01, -1.8144e+00, -2.7435e-01, -1.0694e+00,\n",
      "        -2.3683e-01, -9.0983e-02, -1.5407e-01, -5.7553e-02, -1.1508e+00,\n",
      "        -2.3061e-01,  6.1433e-02,  1.3914e-01,  1.8034e+00, -4.8391e+00,\n",
      "         3.5702e-01,  3.9118e-01, -1.5145e-01, -3.8461e-01, -1.0340e-01,\n",
      "        -1.7378e-01, -2.8085e-01,  2.7413e+00,  6.8859e-01,  4.6162e-01,\n",
      "        -1.9619e+00, -1.5784e+00,  6.6865e-01, -1.0793e+00,  2.3698e-03,\n",
      "         2.0845e+00,  7.7262e-01,  3.7148e-01,  3.8132e-01, -2.8006e+00,\n",
      "         1.6508e-01, -1.3651e-01, -5.4360e-01, -1.0459e+00, -1.0474e-01,\n",
      "         9.2405e-01, -7.8172e-01, -1.3193e-01, -3.5455e-01, -1.6735e-01,\n",
      "        -8.2591e-01, -5.2584e-01,  4.1587e-01, -1.7864e+00, -1.5373e+00,\n",
      "        -1.4316e+00, -2.8390e+00, -1.8756e-01, -5.0244e-01, -6.2711e-01,\n",
      "        -5.0864e-01,  1.3805e+00, -6.7854e-01, -1.2733e+00, -1.5499e-01,\n",
      "        -4.9401e-01, -1.6704e-01,  5.5896e-01,  2.2323e+00, -8.9735e-01,\n",
      "        -9.8596e-01, -4.6223e-01, -2.1796e-01, -5.7308e-01, -2.5387e-01,\n",
      "        -1.1511e+00, -2.1810e-01, -2.8645e-02, -2.9318e-01, -1.0809e-01,\n",
      "         2.3630e-01, -1.7926e-01, -1.5979e-01, -8.3438e-01, -1.5599e-01,\n",
      "        -1.7885e-01, -7.9877e-01,  9.1309e-02, -4.5110e+00, -2.6579e-01,\n",
      "        -1.0908e-01, -9.8625e-01,  8.8400e-01,  6.6456e-01, -2.9203e-01,\n",
      "        -1.7430e+00, -1.1392e+00, -8.9908e-01, -8.4892e-01,  1.3939e+00,\n",
      "        -2.5099e-01, -6.0728e-03,  3.3052e-02,  1.6374e-01, -3.2597e+00,\n",
      "        -1.1394e-01, -2.8892e+00, -1.7021e-01,  7.4032e-02,  7.7582e-01,\n",
      "        -2.3341e-01, -3.3132e-02, -1.9573e+00, -6.3186e-01, -4.7945e+00,\n",
      "        -4.3385e-01, -7.2496e-02, -1.6405e-01,  2.7470e+00, -7.8944e-01,\n",
      "        -2.0351e+00, -1.4804e+00, -3.7836e-01, -2.9204e-01, -1.9908e+00,\n",
      "        -3.4169e-01, -2.5531e-01, -4.7015e-01, -1.8226e-01, -8.0380e+00,\n",
      "        -3.1750e-01, -5.0041e-01, -2.8405e-01, -2.1286e-01, -9.4528e-01,\n",
      "        -5.0160e-01, -4.5813e-01, -1.7940e+00, -2.2183e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.8.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0391]],\n",
      "\n",
      "         [[ 0.1005]],\n",
      "\n",
      "         [[-0.3028]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0325]],\n",
      "\n",
      "         [[-0.0300]],\n",
      "\n",
      "         [[ 0.0328]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0082]],\n",
      "\n",
      "         [[ 0.0277]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0364]],\n",
      "\n",
      "         [[ 0.0687]],\n",
      "\n",
      "         [[ 0.1747]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0557]],\n",
      "\n",
      "         [[-0.2247]],\n",
      "\n",
      "         [[-0.0555]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1919]],\n",
      "\n",
      "         [[ 0.0095]],\n",
      "\n",
      "         [[-0.0044]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0416]],\n",
      "\n",
      "         [[ 0.1816]],\n",
      "\n",
      "         [[ 0.0418]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0651]],\n",
      "\n",
      "         [[-0.0065]],\n",
      "\n",
      "         [[-0.0220]]],\n",
      "\n",
      "\n",
      "        [[[-0.0669]],\n",
      "\n",
      "         [[ 0.0156]],\n",
      "\n",
      "         [[-0.0310]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0056]],\n",
      "\n",
      "         [[ 0.1093]],\n",
      "\n",
      "         [[ 0.0129]]],\n",
      "\n",
      "\n",
      "        [[[-0.0259]],\n",
      "\n",
      "         [[ 0.0074]],\n",
      "\n",
      "         [[-0.0378]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1508]],\n",
      "\n",
      "         [[ 0.1671]],\n",
      "\n",
      "         [[-0.0322]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 384, 1, 1])\n",
      "\n",
      "Layer: features.8.conv.3.weight\n",
      "Weights: tensor([7.8360, 1.0584, 3.5380, 1.3484, 3.8707, 2.0086, 1.1544, 1.2525, 3.5590,\n",
      "        2.9910, 2.1427, 2.9652, 1.6902, 2.1715, 5.0603, 3.3359, 4.4349, 1.0763,\n",
      "        2.4037, 2.0562, 1.9034, 3.3303, 0.7753, 2.5673, 1.5712, 3.4064, 2.7877,\n",
      "        4.6141, 1.4077, 0.7443, 2.6933, 1.6813, 1.3904, 3.0798, 2.1638, 1.7055,\n",
      "        1.5508, 1.5130, 8.2281, 1.1929, 1.5605, 1.3594, 0.8352, 1.2160, 4.2037,\n",
      "        2.9349, 1.0145, 3.0941, 1.1828, 1.5339, 2.1415, 1.1163, 0.9817, 1.4607,\n",
      "        1.9959, 2.3850, 1.9434, 4.9441, 1.5986, 3.3613, 1.4026, 1.4228, 1.7048,\n",
      "        0.7788], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.8.conv.3.bias\n",
      "Weights: tensor([ 9.5386e-07, -2.1270e-06,  3.1705e-07, -1.2848e-06,  1.6270e-06,\n",
      "         1.1604e-06,  1.4727e-06, -1.7946e-06, -7.6655e-07,  5.6483e-07,\n",
      "         6.4463e-07,  9.4201e-07, -9.1535e-07,  1.0354e-06, -1.9462e-06,\n",
      "        -1.0773e-06, -1.9959e-07,  8.5836e-07,  3.6076e-07, -1.5350e-06,\n",
      "         2.4976e-06, -8.4938e-07, -6.9491e-07, -1.9235e-07, -3.9416e-07,\n",
      "        -7.0716e-07, -3.2572e-07,  2.0955e-06,  2.7134e-06,  1.3194e-06,\n",
      "         1.2889e-08,  9.0924e-07,  5.3636e-07, -1.6711e-08, -8.9832e-07,\n",
      "        -6.7974e-07,  1.0358e-06,  8.8916e-08,  5.0032e-07, -4.1835e-07,\n",
      "         1.7055e-06, -1.2290e-06, -2.4564e-06,  4.0875e-07, -1.3184e-06,\n",
      "        -4.9341e-07, -1.1799e-06, -6.8926e-07,  9.4612e-07, -2.7302e-06,\n",
      "        -9.3285e-07, -3.3220e-07,  3.7139e-07, -1.5727e-06, -9.6127e-07,\n",
      "         1.2016e-07, -1.6230e-07, -9.1434e-07, -3.0399e-07,  5.2820e-07,\n",
      "         8.2581e-07, -8.0286e-07,  9.3195e-07,  7.8068e-07], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.9.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.1028]],\n",
      "\n",
      "         [[ 0.1069]],\n",
      "\n",
      "         [[ 0.0267]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         [[ 0.2539]]],\n",
      "\n",
      "\n",
      "        [[[-0.1232]],\n",
      "\n",
      "         [[ 0.0303]],\n",
      "\n",
      "         [[-0.1224]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0274]],\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[ 0.0862]]],\n",
      "\n",
      "\n",
      "        [[[-0.0809]],\n",
      "\n",
      "         [[-0.0221]],\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0646]],\n",
      "\n",
      "         [[ 0.0508]],\n",
      "\n",
      "         [[-0.0372]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0393]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[ 0.0191]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0762]],\n",
      "\n",
      "         [[-0.1868]],\n",
      "\n",
      "         [[ 0.0809]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0132]],\n",
      "\n",
      "         [[-0.0494]],\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0094]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         [[-0.0616]]],\n",
      "\n",
      "\n",
      "        [[[-0.0570]],\n",
      "\n",
      "         [[ 0.1543]],\n",
      "\n",
      "         [[ 0.1038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0067]],\n",
      "\n",
      "         [[-0.0581]],\n",
      "\n",
      "         [[ 0.0676]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.9.conv.0.1.weight\n",
      "Weights: tensor([1.2247, 1.1375, 1.5587, 1.2605, 1.7905, 1.3319, 0.9271, 0.7306, 1.1570,\n",
      "        1.1270, 1.2706, 0.9174, 1.2075, 0.9994, 1.1334, 1.2735, 1.2341, 1.1240,\n",
      "        0.6217, 1.0682, 1.3678, 0.9267, 0.7160, 1.3272, 0.5850, 1.0568, 1.1308,\n",
      "        1.1699, 1.1467, 1.1139, 1.1899, 0.9553, 1.4446, 0.9257, 1.1200, 1.1544,\n",
      "        1.2099, 1.3622, 1.0605, 1.2864, 1.4646, 1.2600, 1.0775, 1.3196, 1.0544,\n",
      "        1.4159, 1.0296, 1.7860, 0.8223, 0.8773, 1.1370, 1.3795, 1.0294, 0.9859,\n",
      "        0.6218, 1.4418, 1.1956, 1.3195, 0.7942, 1.2628, 0.8311, 0.5926, 1.3720,\n",
      "        1.3514, 1.2451, 1.2751, 0.5950, 0.9713, 0.5686, 0.9298, 0.6719, 1.4048,\n",
      "        1.3249, 0.9544, 1.1625, 1.3505, 1.1257, 1.2884, 0.3721, 0.6023, 1.2198,\n",
      "        0.7009, 0.6254, 0.6601, 1.2044, 1.1272, 0.4512, 1.1454, 1.2123, 1.2149,\n",
      "        1.6064, 1.3374, 0.5999, 0.6180, 1.1897, 0.7004, 1.1596, 1.0527, 0.7141,\n",
      "        0.6673, 1.3365, 0.5321, 1.2933, 1.4120, 1.1460, 0.6605, 1.0941, 1.5137,\n",
      "        1.0643, 1.0473, 1.2784, 0.9210, 0.5798, 1.0701, 0.5918, 1.2109, 1.1027,\n",
      "        0.9317, 1.1368, 0.9343, 1.3213, 0.9702, 0.5929, 1.4052, 1.1654, 0.6157,\n",
      "        1.4288, 0.6099, 1.1879, 1.3866, 1.1631, 1.2171, 1.3828, 0.9685, 1.0189,\n",
      "        0.7135, 1.2614, 0.9958, 0.5219, 0.8380, 1.0442, 1.4127, 0.7038, 0.5785,\n",
      "        1.1623, 0.8370, 1.0238, 1.3738, 1.4752, 0.7426, 1.4060, 1.1875, 0.9354,\n",
      "        1.0247, 1.5004, 1.2205, 0.9207, 1.1096, 1.2854, 1.2910, 1.0682, 0.6870,\n",
      "        0.4800, 1.0331, 0.7883, 1.0602, 0.5652, 1.3000, 1.3198, 0.6695, 0.6855,\n",
      "        1.1397, 0.4620, 1.1411, 1.0324, 1.1645, 1.2394, 0.7520, 1.3329, 1.3988,\n",
      "        1.2085, 1.0467, 0.9672, 0.8114, 1.1462, 1.2935, 0.9463, 1.2793, 0.9609,\n",
      "        1.2150, 1.2541, 1.0114, 1.1022, 0.9757, 1.1047, 1.0835, 0.4400, 1.1525,\n",
      "        1.3645, 1.2801, 0.9070, 1.2803, 1.0506, 1.0975, 0.6680, 1.2554, 1.0576,\n",
      "        1.0020, 0.5412, 1.6024, 1.2508, 1.3417, 0.5715, 0.7739, 1.2930, 1.0637,\n",
      "        1.2778, 0.5556, 1.6170, 1.1505, 1.2391, 1.5787, 0.7590, 0.6874, 0.4593,\n",
      "        1.4690, 1.0302, 0.9585, 0.6635, 1.3803, 1.4930, 1.0763, 0.6895, 1.6858,\n",
      "        0.7701, 1.3450, 0.8564, 1.3328, 0.9498, 0.8946, 1.2266, 1.6966, 1.2953,\n",
      "        1.1048, 1.2038, 0.8577, 1.1502, 1.2335, 1.0836, 0.5851, 0.9193, 1.7771,\n",
      "        1.1180, 0.3746, 1.1419, 0.8631, 0.5371, 0.5888, 0.4927, 0.9812, 0.7242,\n",
      "        1.0284, 1.0119, 1.2319, 1.5432, 1.3668, 1.1239, 1.3172, 1.5897, 0.4537,\n",
      "        1.0931, 0.5889, 0.6831, 0.6870, 1.4803, 0.8453, 0.9494, 1.2484, 0.5748,\n",
      "        1.3145, 1.2412, 1.1966, 0.5682, 1.1510, 1.2905, 1.5041, 1.3102, 0.6730,\n",
      "        1.1696, 0.5652, 1.2835, 1.1091, 0.9145, 1.2322, 1.1157, 1.3320, 1.3608,\n",
      "        1.0650, 1.0816, 1.2727, 0.8668, 0.4862, 1.0629, 1.0235, 0.6801, 1.1817,\n",
      "        1.0384, 1.1515, 0.8617, 1.2278, 0.6188, 1.2520, 0.9429, 1.5417, 1.5592,\n",
      "        0.8589, 1.1344, 0.6190, 1.1346, 1.1565, 1.0179, 1.0926, 0.6457, 0.9641,\n",
      "        0.6314, 1.3112, 1.2587, 1.2944, 0.3347, 1.2255, 1.4568, 1.3431, 0.8822,\n",
      "        1.2660, 1.3949, 1.2419, 1.2546, 1.7418, 0.9883, 0.5059, 1.1343, 1.0440,\n",
      "        0.7269, 1.2580, 1.2497, 0.8218, 1.4405, 0.5258, 1.0814, 1.4908, 1.3569,\n",
      "        0.6677, 0.7482, 1.1102, 1.4171, 1.3310, 0.9778, 0.7552, 1.1442, 1.3026,\n",
      "        0.6240, 1.2633, 0.6307, 0.6129, 1.3931, 1.2825, 1.5428, 1.6562, 1.2040,\n",
      "        1.1929, 1.3232, 1.6134, 1.3370, 1.0972, 1.5372, 1.1384, 1.4837, 1.0083,\n",
      "        1.1821, 1.1027, 1.0670, 1.2188, 2.8051, 1.2074], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.0.1.bias\n",
      "Weights: tensor([-3.2372e-01, -1.8765e+00,  1.4882e+00, -3.0089e-01,  1.1437e+00,\n",
      "        -1.1333e+00,  8.1730e-01,  1.0791e+00,  3.9402e-02, -6.4035e-01,\n",
      "         1.7595e+00,  7.3942e-01,  7.1933e-01,  1.1604e+00, -6.6969e-01,\n",
      "        -9.4501e-01,  2.9424e-01, -9.0298e-02,  1.0008e+00, -9.0757e-02,\n",
      "         4.8240e-01, -1.2557e+00,  1.2607e+00, -3.6026e-01,  1.3371e+00,\n",
      "         7.0015e-01,  5.5856e-01, -1.1235e+00, -5.6212e-01,  4.9198e-01,\n",
      "        -6.0216e-01,  9.8026e-01, -8.5122e-01,  1.0291e+00,  8.3081e-01,\n",
      "         7.3905e-01,  5.9484e-01,  4.3449e-02,  6.0487e-01, -2.0276e-01,\n",
      "        -8.9012e-01,  2.0483e-01, -1.1112e+00, -1.1006e-01, -7.2662e-01,\n",
      "        -5.7325e-01,  9.8976e-01, -1.4405e+00,  1.2537e+00, -1.0667e+00,\n",
      "        -1.0065e-01, -9.0243e-01,  9.3452e-01, -1.0358e+00,  1.2787e+00,\n",
      "         1.8021e+00,  3.0598e-01,  9.7220e-02,  9.1296e-01,  7.5202e-01,\n",
      "         9.3218e-01,  1.0692e+00, -4.8578e-01, -2.1600e-01, -6.3231e-02,\n",
      "         1.0696e-01,  1.3584e+00, -1.4057e+00,  1.1853e+00,  1.5787e+00,\n",
      "         1.2912e+00, -8.2016e-01,  1.5396e-01, -9.8854e-01,  4.2354e-01,\n",
      "        -5.3753e-01, -8.2151e-01, -7.9073e-01,  1.3882e+00,  1.1481e+00,\n",
      "         1.3999e-01,  1.2147e+00,  1.7614e+00,  9.4833e-01, -3.4347e-01,\n",
      "        -6.6727e-01,  1.2369e+00,  9.8356e-01,  1.4226e-01,  1.2118e+00,\n",
      "        -9.9549e-01,  1.7688e-01,  1.9047e+00,  1.1853e+00,  7.2337e-01,\n",
      "         1.1084e+00, -1.3660e-01,  3.8580e-01,  1.3991e+00,  1.0050e+00,\n",
      "         2.1241e-01,  1.2422e+00, -7.3368e-01, -1.1834e-01, -1.1421e+00,\n",
      "         1.1962e+00,  7.8071e-01, -9.8592e-01,  4.1459e-01,  7.2877e-01,\n",
      "        -9.8509e-01,  7.9047e-01,  1.8030e+00,  5.8128e-01,  1.3498e+00,\n",
      "        -3.5446e-01,  1.0782e-01,  6.8958e-01,  3.7628e-01, -9.9576e-01,\n",
      "         8.0870e-01,  8.9852e-01,  1.3857e+00, -4.3562e-01,  1.2856e+00,\n",
      "         1.1700e+00, -1.1244e+00,  1.1997e+00, -4.5031e-01, -3.3478e-01,\n",
      "        -9.1685e-01, -1.2817e-01,  9.0440e-02, -1.8404e+00, -8.3392e-01,\n",
      "         9.7533e-01, -1.9185e-01,  3.7612e-01,  1.4056e+00,  1.2719e+00,\n",
      "         5.9657e-01, -1.8727e-01,  1.0884e+00,  1.2094e+00,  6.3172e-01,\n",
      "         2.0508e+00,  6.8588e-01,  3.1477e-01,  7.7176e-01,  1.3779e+00,\n",
      "        -1.6982e-01, -7.3240e-01,  8.3516e-01,  1.1421e+00,  1.8792e-01,\n",
      "        -1.1964e-01,  1.0223e+00,  1.6759e-03, -5.2079e-01,  1.8675e-01,\n",
      "         1.2255e+00,  1.5084e+00,  2.1510e+00, -1.3598e+00,  1.0145e+00,\n",
      "        -5.0576e-01,  1.1472e+00, -1.3530e+00,  1.0190e-01,  1.5358e+00,\n",
      "         1.3085e+00,  5.4804e-01,  1.4734e+00,  9.2088e-01, -9.8157e-01,\n",
      "         1.1946e-02,  8.4432e-01,  1.0628e+00, -1.6476e-02, -3.2200e-01,\n",
      "         1.5064e-03, -3.5100e-01, -1.0025e+00,  4.8554e-01,  2.0533e+00,\n",
      "        -3.0114e-02,  7.1926e-01, -7.7459e-01,  7.2858e-01, -1.1830e+00,\n",
      "        -2.9894e-01, -8.0097e-01,  3.2070e-01,  9.9228e-01,  5.4093e-01,\n",
      "        -7.4802e-01,  1.3746e+00, -5.8820e-01, -2.9297e-01, -5.0861e-01,\n",
      "         7.3956e-01, -8.6296e-01,  8.6694e-01,  3.9240e-01,  1.2625e+00,\n",
      "         1.3972e-01,  7.5223e-01, -8.0534e-01,  1.3934e+00, -2.8851e-01,\n",
      "        -8.0099e-01, -5.0818e-02,  1.2869e+00,  1.1616e+00,  6.6944e-01,\n",
      "        -4.1568e-01, -2.2770e-01,  1.2645e+00, -1.2789e+00,  2.0523e-01,\n",
      "         1.5668e-01, -3.5524e-01,  1.8497e+00,  9.3451e-01,  1.2829e+00,\n",
      "         9.8627e-01, -9.4876e-01,  7.5155e-01,  1.2395e+00,  1.5923e-02,\n",
      "        -1.7489e-01, -5.3632e-01,  8.6865e-01, -8.0808e-01,  8.4111e-01,\n",
      "        -2.4051e-02,  8.7339e-01, -5.7973e-01,  5.8347e-01,  1.2832e+00,\n",
      "        -7.7010e-01, -9.3090e-01, -2.6166e-01, -8.0142e-01, -1.7003e-01,\n",
      "         1.0464e+00, -8.3371e-01,  5.3250e-02,  7.1268e-01,  1.1815e+00,\n",
      "         1.0128e+00, -2.2324e-01, -6.4767e-01,  1.4832e+00,  4.6491e-01,\n",
      "         9.6979e-01,  1.4739e+00,  1.4113e+00,  1.2262e+00,  9.9623e-01,\n",
      "         1.4615e+00,  5.4483e-01, -4.0937e-01, -4.3403e-01,  1.8275e+00,\n",
      "        -3.1348e-01,  5.4469e-01, -2.5643e-01, -1.6659e+00,  1.7619e+00,\n",
      "         1.0875e+00,  1.2256e+00,  1.3126e+00,  9.4571e-01, -4.0425e-01,\n",
      "         9.7487e-01,  5.2372e-01, -2.4667e-01,  1.4636e+00,  1.9808e-01,\n",
      "         3.6560e-01, -1.2618e-01,  1.2091e+00,  1.6888e-01, -3.3194e-01,\n",
      "        -3.1604e-01, -8.8200e-01,  1.4826e+00, -9.7396e-01,  1.4890e+00,\n",
      "         1.6974e+00, -8.1492e-01,  9.3601e-01, -1.4010e+00,  5.5445e-01,\n",
      "        -8.7787e-01, -3.9964e-01,  3.2829e-01,  6.5151e-01, -2.4316e-01,\n",
      "         9.6468e-01,  1.1005e+00, -4.5817e-01,  7.3000e-01,  1.2843e+00,\n",
      "         9.9958e-02,  1.0509e+00,  2.7769e-01,  1.2468e+00, -8.4509e-02,\n",
      "         1.1832e+00,  3.9825e-02, -6.2028e-01, -1.1149e+00,  1.0095e+00,\n",
      "         1.2789e+00,  7.1910e-01,  1.2329e+00, -5.4907e-01, -9.2781e-01,\n",
      "         7.0935e-01, -7.9145e-01,  1.2964e+00,  1.1865e+00,  1.7870e+00,\n",
      "        -4.4338e-01,  5.7930e-01,  1.8001e-01, -1.4640e+00,  4.0916e-01,\n",
      "        -9.8748e-01, -8.6795e-02,  1.5707e+00, -3.1613e-01, -3.6647e-01,\n",
      "         1.1661e+00,  2.6075e-01,  1.5539e+00, -9.8121e-01,  1.4665e+00,\n",
      "        -2.1876e-01,  8.1020e-01,  1.8546e+00, -1.4988e-01,  1.1734e-01,\n",
      "         9.2945e-01,  2.9455e-01,  1.0983e+00, -7.5200e-01, -8.2301e-01,\n",
      "         6.9018e-01, -1.1504e+00,  1.1765e+00, -9.6073e-01, -1.2053e+00,\n",
      "        -8.8442e-01, -5.6788e-01,  1.1335e+00, -3.2093e-01, -7.1361e-01,\n",
      "         1.1220e+00, -4.2796e-01,  1.6160e+00,  1.4159e+00,  3.2731e-01,\n",
      "         9.9334e-02,  7.4840e-01, -4.3162e-01, -5.9208e-01, -4.8068e-01,\n",
      "        -1.1396e-01, -3.0549e-01, -9.0022e-01,  3.7152e-01, -3.1887e-01,\n",
      "        -1.2246e+00, -7.6393e-01,  4.7923e-01, -9.1393e-01, -6.7876e-01,\n",
      "        -5.7567e-01, -1.2653e+00,  5.3300e-01, -8.7161e-02], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0228, -0.0108,  0.0094],\n",
      "          [ 0.0190,  0.1936,  0.0175],\n",
      "          [ 0.0886,  0.1106,  0.0539]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0280,  0.0889, -0.0113],\n",
      "          [ 0.0748,  0.3087,  0.0727],\n",
      "          [-0.0015,  0.0464,  0.0678]]],\n",
      "\n",
      "\n",
      "        [[[-0.1253, -0.0791, -0.0947],\n",
      "          [-0.0870,  0.0066, -0.0835],\n",
      "          [-0.0961, -0.0759, -0.0604]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0391,  0.0313,  0.0313],\n",
      "          [ 0.0187,  0.3106,  0.0299],\n",
      "          [ 0.0344,  0.0398,  0.0255]]],\n",
      "\n",
      "\n",
      "        [[[-0.0829, -0.2055, -0.0470],\n",
      "          [-0.1397,  0.2251, -0.0395],\n",
      "          [-0.0540, -0.0011, -0.0072]]],\n",
      "\n",
      "\n",
      "        [[[-0.1174, -0.0458, -0.1329],\n",
      "          [-0.0478,  0.7905, -0.0814],\n",
      "          [-0.1381, -0.0553, -0.1214]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.9.conv.1.1.weight\n",
      "Weights: tensor([0.5250, 1.7151, 3.2216, 0.5674, 4.3309, 0.5055, 1.8063, 1.0272, 1.0621,\n",
      "        0.6975, 2.7806, 0.7727, 0.9472, 0.6514, 0.5760, 1.1489, 0.5135, 0.8056,\n",
      "        0.9966, 1.1238, 1.2854, 0.3494, 2.4143, 0.9230, 1.3578, 1.0195, 0.6271,\n",
      "        0.4953, 0.8441, 0.5718, 0.8020, 1.0234, 1.4853, 1.8625, 1.0375, 0.5596,\n",
      "        1.9328, 0.6923, 1.1891, 0.6960, 1.5010, 1.6797, 0.3971, 0.6800, 0.6809,\n",
      "        1.2867, 0.9515, 8.4395, 1.7885, 0.3232, 0.7655, 0.5712, 1.0026, 0.5237,\n",
      "        0.8089, 3.0344, 0.7394, 0.6424, 0.6825, 0.8533, 0.8906, 1.7530, 1.1866,\n",
      "        0.5582, 1.2391, 0.6638, 1.4737, 0.3957, 1.2195, 1.7494, 1.0701, 1.4387,\n",
      "        0.5325, 0.9158, 1.1889, 0.7995, 0.8170, 0.7805, 2.0655, 1.4929, 1.5388,\n",
      "        1.2552, 2.1766, 1.2576, 0.9573, 0.8131, 1.0943, 0.9496, 0.7426, 2.0734,\n",
      "        0.6910, 1.2389, 1.5607, 1.2827, 1.7584, 1.3459, 0.7398, 0.9569, 1.6798,\n",
      "        1.1476, 0.8811, 1.2608, 1.0766, 0.9917, 4.0969, 1.1590, 0.8488, 0.6353,\n",
      "        1.4974, 1.2611, 0.4454, 1.4890, 1.7309, 0.9885, 1.2747, 0.9531, 0.7768,\n",
      "        1.0172, 0.6285, 0.4626, 1.0363, 0.9837, 1.2626, 1.1193, 1.8655, 1.7304,\n",
      "        1.0056, 1.3073, 0.4204, 0.4604, 0.4863, 0.4441, 2.1229, 0.4076, 0.4887,\n",
      "        1.4396, 0.4762, 1.6909, 1.5860, 1.5380, 0.4820, 1.0675, 1.2138, 1.0445,\n",
      "        1.0641, 3.0025, 0.5554, 0.5240, 1.0550, 1.5556, 0.5586, 0.5777, 1.3192,\n",
      "        1.4976, 0.9033, 1.2041, 1.4747, 0.7504, 0.5227, 0.5389, 1.3042, 2.2231,\n",
      "        2.1372, 0.5230, 1.4147, 0.9392, 1.7440, 0.4671, 1.8456, 1.8573, 1.3550,\n",
      "        1.4423, 1.6955, 1.1662, 0.6212, 0.7896, 1.3490, 1.5940, 0.6285, 0.6281,\n",
      "        1.0369, 0.9740, 0.7555, 1.1835, 2.6697, 0.7729, 0.8725, 0.4744, 1.4037,\n",
      "        1.0649, 0.6038, 0.6316, 0.9634, 1.6472, 0.5770, 0.4242, 1.3836, 0.7175,\n",
      "        0.8767, 0.8166, 1.6490, 1.2102, 1.6702, 1.0320, 1.6088, 0.5287, 0.9783,\n",
      "        0.5096, 1.7424, 0.8664, 1.1594, 0.5787, 1.3340, 1.0098, 0.9782, 1.0640,\n",
      "        0.5847, 1.2206, 0.6660, 0.7545, 1.0870, 1.7881, 1.1706, 0.5670, 1.1876,\n",
      "        3.0093, 0.6785, 2.1137, 1.6654, 0.6100, 0.5079, 0.3850, 2.0281, 1.6395,\n",
      "        1.2067, 1.1961, 1.2009, 0.9631, 1.0606, 1.8718, 0.5062, 0.6887, 0.5091,\n",
      "        0.4049, 0.6541, 1.5026, 0.4508, 0.7197, 1.1099, 1.1601, 1.0472, 2.1934,\n",
      "        0.5028, 1.1402, 1.1743, 1.1967, 1.0975, 1.2024, 2.4396, 0.7191, 1.0968,\n",
      "        1.2785, 0.7483, 0.5162, 2.6821, 0.9195, 1.0889, 1.3723, 1.4052, 1.6314,\n",
      "        1.3695, 2.0667, 1.5056, 1.2573, 0.9509, 0.9825, 0.6892, 0.6290, 0.8388,\n",
      "        0.5815, 0.9973, 0.9889, 1.5381, 0.6784, 0.4449, 1.0903, 1.0661, 1.2361,\n",
      "        0.4753, 1.8047, 2.6610, 1.1997, 1.3166, 0.5583, 0.6332, 1.9280, 0.7534,\n",
      "        1.0215, 1.3988, 0.6149, 1.5088, 1.4614, 1.0157, 1.4578, 1.5047, 0.5565,\n",
      "        1.0940, 0.8774, 1.8352, 0.5443, 2.3571, 0.4837, 1.0862, 0.6299, 2.2598,\n",
      "        1.0042, 0.6761, 1.4077, 0.7926, 0.5275, 0.7669, 0.5049, 1.6025, 1.8200,\n",
      "        2.3097, 0.9298, 1.1379, 0.5101, 0.6460, 0.9042, 0.5731, 1.5992, 1.6405,\n",
      "        0.6240, 0.9097, 2.3338, 0.5235, 2.9395, 0.4093, 1.4009, 0.5956, 0.7553,\n",
      "        1.0905, 0.5095, 1.2821, 1.3804, 1.0181, 0.8931, 0.4012, 1.5412, 1.1034,\n",
      "        2.3177, 1.5337, 0.4228, 0.5548, 0.5022, 0.5225, 1.6676, 0.5847, 1.0184,\n",
      "        1.4110, 0.9656, 1.9720, 1.0745, 0.8857, 0.7918, 3.6490, 0.8842, 0.4553,\n",
      "        0.6473, 1.1950, 1.9238, 0.3574, 0.6459, 0.5209, 0.3875, 0.6921, 1.2324,\n",
      "        1.1098, 0.4079, 0.7759, 1.2701, 1.2571, 0.5313], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.1.1.bias\n",
      "Weights: tensor([-1.8232e-01, -3.5230e+00, -3.4527e+00,  1.3376e+00, -4.9679e+00,\n",
      "         1.8277e+00, -2.7361e+00, -1.7246e-01, -1.4002e+00, -8.5535e-01,\n",
      "        -3.1674e+00, -1.9495e-01, -1.4121e-01,  1.7991e+00,  1.2190e+00,\n",
      "        -1.1625e+00,  1.6339e+00, -4.5809e-01, -1.7331e-01, -1.3993e+00,\n",
      "        -5.5476e-01,  4.0669e+00, -2.2389e+00, -1.3050e+00,  3.1525e-01,\n",
      "        -3.1410e-01,  3.7858e-01,  5.0899e-02, -1.5023e+00,  6.1377e-01,\n",
      "        -1.4918e+00, -4.3500e-01, -4.7019e-01, -2.3914e+00, -2.6103e-01,\n",
      "         1.6652e+00, -1.1773e+00,  3.6893e-01, -5.5615e-01,  1.5619e-01,\n",
      "        -4.8105e-01, -3.2978e+00,  7.3339e-02,  1.3489e-01, -1.5201e-01,\n",
      "        -3.1965e+00, -2.0774e-01, -4.0275e+00, -1.8106e+00,  7.1763e-01,\n",
      "        -1.4286e-01,  3.7352e-01, -7.2528e-02, -2.9680e-01,  3.1689e-01,\n",
      "        -3.5497e+00,  5.6167e-03,  5.2743e-02,  2.6852e+00,  1.1892e-02,\n",
      "        -8.6113e-02, -1.4669e+00, -2.3282e+00,  1.7919e+00, -2.1374e+00,\n",
      "         9.9770e-02, -2.1418e+00,  2.4123e-01, -5.8749e-01, -1.9647e+00,\n",
      "        -3.9463e-01, -4.5058e-01,  1.7948e+00, -9.7429e-01, -6.5483e-01,\n",
      "         1.7837e-01, -6.9834e-01, -1.2827e+00, -2.3446e+00, -1.3156e+00,\n",
      "        -2.4653e+00, -1.1085e+00, -2.8875e+00, -1.4639e+00, -1.5902e+00,\n",
      "         1.0764e+00, -1.9262e-01, -1.7722e-01,  1.5278e-01, -1.9297e+00,\n",
      "        -1.4211e-01, -2.4701e+00, -1.4170e+00, -1.7266e-01, -1.0425e+00,\n",
      "        -7.9772e-01, -3.3385e-01, -8.4322e-01, -7.3235e-01, -4.8604e-01,\n",
      "         3.4075e-02, -6.9328e-01, -9.6762e-01, -2.9107e-01, -1.6932e+00,\n",
      "        -4.1696e-01,  3.2968e-01, -4.5411e-01, -2.6586e+00, -9.8221e-01,\n",
      "         1.1800e-01, -1.5409e+00, -1.8840e+00, -3.0280e-01,  3.8522e-02,\n",
      "        -1.0117e+00, -4.2868e-01, -5.9629e-01,  4.0847e-01,  4.3905e-01,\n",
      "        -1.3268e-01, -3.7926e-01,  3.4895e-01, -1.3188e+00, -1.9316e+00,\n",
      "        -1.5840e+00, -4.4183e-01, -2.6085e-01,  2.0353e+00,  2.2017e+00,\n",
      "         1.3488e-01,  3.8959e-01, -1.1856e+00,  4.0021e-01,  1.6693e+00,\n",
      "        -1.1693e+00,  2.5059e+00, -3.9257e+00, -1.2287e+00, -1.2377e+00,\n",
      "         1.0965e+00, -1.0254e+00, -7.6103e-01, -3.1492e-02, -4.2883e-01,\n",
      "        -4.0493e+00,  1.5768e+00,  2.5867e+00, -2.8798e-01, -5.0214e-01,\n",
      "         5.4002e-01,  6.7227e-01, -9.7163e-01, -8.3220e-01, -5.8125e-01,\n",
      "        -2.6138e+00, -8.4142e-01, -3.5902e-01,  8.1660e-01,  1.1970e+00,\n",
      "        -4.9647e-01, -2.6900e+00, -3.4175e+00,  1.1478e+00, -9.3168e-01,\n",
      "        -2.4779e+00, -1.1218e+00,  2.2233e-01, -3.6104e+00, -1.8560e+00,\n",
      "        -1.1155e+00, -1.3427e+00, -1.2132e+00, -5.0707e-01, -2.6819e-01,\n",
      "        -7.1653e-01, -3.5859e-01, -1.5966e+00,  2.8434e-01,  2.7399e-01,\n",
      "        -1.0379e+00, -4.2322e-01, -4.0357e-01, -9.3672e-01, -3.7877e+00,\n",
      "        -3.0166e-01, -8.3538e-02,  2.9280e-01, -9.6712e-01, -3.1921e+00,\n",
      "         1.5991e+00, -1.6884e-01,  3.3759e-01, -1.0033e+00,  3.8241e-01,\n",
      "         2.7753e+00, -5.0461e-01, -3.4836e-01, -1.2009e-01, -9.3318e-01,\n",
      "        -2.8873e+00, -1.6793e+00, -1.2261e+00, -4.8646e-01, -1.9311e+00,\n",
      "         5.6711e-01, -2.8732e-01,  2.2662e+00, -1.3902e+00,  7.4449e-01,\n",
      "        -1.2861e+00,  1.6783e+00, -4.0211e-01, -2.5468e-01, -2.8798e-01,\n",
      "        -1.5633e+00,  1.5310e+00, -4.8541e-01,  3.4600e-01,  1.1429e-01,\n",
      "        -1.2303e+00, -4.5774e+00,  4.4684e-01,  4.4062e-01, -2.3319e-01,\n",
      "        -3.1478e+00, -1.1458e+00, -4.0469e+00, -1.2259e+00,  8.6267e-01,\n",
      "         6.5120e-01,  1.4736e+00, -4.2855e+00, -4.8857e+00, -9.3563e-01,\n",
      "        -1.5110e+00, -7.6495e-01, -1.4133e+00, -1.0504e+00, -1.7936e+00,\n",
      "         2.0565e+00, -3.4389e-01,  2.1341e+00,  2.0642e+00,  3.5084e-01,\n",
      "        -9.6963e-01,  7.1680e-01, -5.5866e-01, -6.2489e-01,  3.0970e-01,\n",
      "        -2.8006e-01, -5.8275e+00,  2.5934e+00,  1.3509e-01, -1.0744e+00,\n",
      "        -4.2471e-01, -2.5211e-01,  3.7750e-01, -2.6480e+00,  1.2402e+00,\n",
      "         1.5800e-01, -1.4470e+00, -4.7699e-01,  1.7420e+00, -2.4828e+00,\n",
      "         1.3865e-01, -3.2556e-01, -2.5367e+00, -1.0890e+00, -1.7630e+00,\n",
      "        -6.3041e-01, -1.6931e+00, -1.1403e+00, -7.4301e-01, -9.0488e-01,\n",
      "        -1.9815e-01, -1.3956e-01,  6.0863e-01,  2.3374e-01,  2.0154e+00,\n",
      "        -1.6331e-02, -1.1832e+00, -1.3919e+00, -5.3566e-02,  6.1461e-01,\n",
      "        -1.1214e+00, -2.5208e+00,  2.5998e-01,  2.3767e+00, -1.3270e+00,\n",
      "        -2.8912e+00, -1.4201e+00, -6.9705e-01,  1.3652e+00,  1.6491e+00,\n",
      "        -4.7187e-01,  3.9201e-01, -1.0859e+00, -8.0448e-01,  4.5124e-01,\n",
      "        -8.9680e-01, -7.2596e-01, -7.5460e-01, -1.4828e+00, -8.5318e-01,\n",
      "         1.3679e+00, -2.9146e-01, -3.9049e-01, -1.4426e+00,  2.5848e-01,\n",
      "        -4.8758e+00,  1.8169e+00, -1.1325e+00,  3.4561e-01, -1.7861e+00,\n",
      "        -3.8364e-01,  1.6693e+00, -6.0267e-01, -8.7105e-01,  2.5471e-01,\n",
      "         1.3181e-02,  4.1059e-01, -2.1264e+00, -1.9110e+00, -2.9541e+00,\n",
      "        -1.1355e+00, -4.1122e-01,  1.8335e+00, -1.5078e+00, -2.0221e-01,\n",
      "         1.9257e+00, -3.7638e+00, -1.0537e+00,  2.3011e-01,  2.1461e-02,\n",
      "        -2.0711e+00,  1.1290e+00, -2.0932e+00,  2.8662e-01, -4.8219e-01,\n",
      "         1.3440e+00,  1.9015e+00,  6.2811e-01,  2.5538e+00, -5.8639e-01,\n",
      "        -1.2281e+00, -1.1724e+00,  4.4286e-01,  3.5739e-01, -5.2951e-01,\n",
      "        -6.1469e-01, -1.7704e+00, -8.9433e-01,  1.7648e-01,  2.8165e-01,\n",
      "         2.7764e+00,  1.4646e-01, -1.2034e+00, -4.7363e-01, -8.9330e-01,\n",
      "        -1.3469e+00, -1.4399e+00, -1.7488e+00, -1.9003e-01,  2.8347e-01,\n",
      "        -2.6900e-01, -3.5838e+00,  6.8681e-01,  2.3002e-01,  2.6737e-02,\n",
      "        -4.1083e-01, -4.5345e+00,  1.4432e+00,  3.2285e-02,  5.8610e-01,\n",
      "         1.0390e+00, -5.4471e-01, -2.1708e+00, -8.1303e-01,  2.7784e+00,\n",
      "        -1.0696e+00, -2.7113e+00, -7.2411e-01,  1.5415e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.9.conv.2.weight\n",
      "Weights: tensor([[[[-0.0983]],\n",
      "\n",
      "         [[ 0.1338]],\n",
      "\n",
      "         [[ 0.0957]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         [[ 0.0304]],\n",
      "\n",
      "         [[ 0.0458]]],\n",
      "\n",
      "\n",
      "        [[[-0.1257]],\n",
      "\n",
      "         [[-0.0734]],\n",
      "\n",
      "         [[ 0.0144]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0697]],\n",
      "\n",
      "         [[ 0.0113]],\n",
      "\n",
      "         [[ 0.0631]]],\n",
      "\n",
      "\n",
      "        [[[-0.0872]],\n",
      "\n",
      "         [[-0.0151]],\n",
      "\n",
      "         [[ 0.0985]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0075]],\n",
      "\n",
      "         [[ 0.0266]],\n",
      "\n",
      "         [[ 0.0409]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0464]],\n",
      "\n",
      "         [[-0.0671]],\n",
      "\n",
      "         [[-0.0978]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0663]],\n",
      "\n",
      "         [[-0.0609]],\n",
      "\n",
      "         [[ 0.0414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1015]],\n",
      "\n",
      "         [[ 0.0631]],\n",
      "\n",
      "         [[ 0.0344]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1766]],\n",
      "\n",
      "         [[ 0.0023]],\n",
      "\n",
      "         [[-0.0054]]],\n",
      "\n",
      "\n",
      "        [[[-0.0338]],\n",
      "\n",
      "         [[ 0.2749]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1361]],\n",
      "\n",
      "         [[-0.0468]],\n",
      "\n",
      "         [[ 0.0297]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 384, 1, 1])\n",
      "\n",
      "Layer: features.9.conv.3.weight\n",
      "Weights: tensor([4.0139, 1.0381, 4.9999, 1.5891, 5.1128, 1.8994, 1.6986, 1.5771, 4.7695,\n",
      "        2.9778, 2.6517, 3.1057, 1.3664, 3.1281, 3.5239, 3.9334, 4.1106, 2.2833,\n",
      "        3.6815, 1.7932, 1.6130, 4.5159, 1.2931, 3.0917, 1.9548, 4.0787, 3.0074,\n",
      "        4.0454, 1.2622, 1.3055, 3.3019, 1.2488, 1.6542, 3.7581, 1.0676, 2.9645,\n",
      "        2.0916, 1.7270, 4.1136, 1.4224, 1.9086, 1.3162, 1.2018, 1.1067, 3.1520,\n",
      "        5.1115, 1.7988, 3.9100, 1.5210, 1.8581, 2.7534, 1.2647, 1.1804, 1.1914,\n",
      "        1.9094, 2.6008, 2.0109, 3.4761, 1.4089, 4.6844, 2.0796, 1.5178, 2.1971,\n",
      "        1.4005], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.9.conv.3.bias\n",
      "Weights: tensor([-8.4964e-07, -2.2777e-06,  3.0347e-07, -1.2773e-06,  6.7043e-07,\n",
      "         7.8253e-08,  1.1301e-06, -2.2724e-06,  1.5217e-07,  2.7333e-07,\n",
      "         4.4017e-08, -8.5987e-08, -2.9115e-07,  1.6596e-06, -5.8144e-07,\n",
      "        -7.3607e-07,  3.2431e-07,  1.2212e-06, -2.1649e-07, -5.2412e-07,\n",
      "         1.3040e-06, -3.8831e-07, -1.3338e-06,  4.6735e-08, -4.5250e-07,\n",
      "        -4.4467e-07, -4.5450e-07,  1.4347e-06,  1.4358e-06,  1.6739e-06,\n",
      "        -3.2338e-07,  1.6206e-06,  5.3682e-07,  5.4699e-07, -1.3205e-06,\n",
      "        -3.5321e-07,  6.7596e-07,  5.4651e-08,  1.0551e-06, -3.8971e-07,\n",
      "         7.2752e-07, -1.5838e-06, -1.6754e-06,  4.6236e-07, -1.0805e-06,\n",
      "        -6.5832e-07,  2.0918e-07,  8.0463e-08, -4.4652e-08, -1.9199e-06,\n",
      "        -3.8964e-07, -1.9357e-07, -4.9755e-07, -1.5784e-06,  3.1265e-07,\n",
      "         7.1842e-07, -1.0249e-06, -4.8917e-07, -3.6831e-07,  6.5335e-07,\n",
      "         6.6431e-07, -1.1618e-06,  6.8385e-07, -1.7435e-08], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.10.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0062]],\n",
      "\n",
      "         [[ 0.0600]],\n",
      "\n",
      "         [[-0.0239]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1140]],\n",
      "\n",
      "         [[-0.1440]],\n",
      "\n",
      "         [[ 0.0252]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2051]],\n",
      "\n",
      "         [[ 0.0558]],\n",
      "\n",
      "         [[ 0.2291]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0085]],\n",
      "\n",
      "         [[-0.0322]],\n",
      "\n",
      "         [[ 0.0350]]],\n",
      "\n",
      "\n",
      "        [[[-0.0122]],\n",
      "\n",
      "         [[-0.0990]],\n",
      "\n",
      "         [[ 0.0169]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1174]],\n",
      "\n",
      "         [[ 0.0070]],\n",
      "\n",
      "         [[ 0.0183]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0288]],\n",
      "\n",
      "         [[-0.0034]],\n",
      "\n",
      "         [[-0.1387]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0013]],\n",
      "\n",
      "         [[-0.0163]],\n",
      "\n",
      "         [[ 0.0273]]],\n",
      "\n",
      "\n",
      "        [[[-0.0841]],\n",
      "\n",
      "         [[-0.1137]],\n",
      "\n",
      "         [[-0.1486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[ 0.0771]],\n",
      "\n",
      "         [[ 0.0347]]],\n",
      "\n",
      "\n",
      "        [[[-0.0393]],\n",
      "\n",
      "         [[-0.1354]],\n",
      "\n",
      "         [[-0.0777]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0078]],\n",
      "\n",
      "         [[-0.0206]],\n",
      "\n",
      "         [[ 0.0124]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.10.conv.0.1.weight\n",
      "Weights: tensor([0.8384, 0.9399, 0.5547, 1.1175, 1.3795, 1.5326, 0.9934, 0.9072, 0.9317,\n",
      "        1.0473, 0.9409, 1.0078, 0.6418, 0.8856, 1.1907, 1.1189, 1.0533, 1.5419,\n",
      "        1.1749, 0.9897, 1.5076, 1.3177, 0.4890, 1.1002, 1.1330, 0.9449, 1.2394,\n",
      "        0.4413, 0.3597, 1.2642, 1.0619, 1.1887, 1.0832, 0.6682, 0.7698, 1.4585,\n",
      "        0.7542, 1.1843, 0.9538, 1.2725, 1.3898, 1.2297, 1.1023, 1.1041, 0.7631,\n",
      "        0.7608, 1.3335, 1.3548, 1.2222, 1.2096, 1.0968, 1.1671, 1.1259, 1.3498,\n",
      "        0.8837, 1.2118, 1.1696, 0.7441, 0.9355, 0.9170, 1.5154, 1.6156, 1.0900,\n",
      "        1.2188, 0.6000, 1.0866, 1.1620, 1.5096, 1.3313, 0.6033, 1.2619, 1.2819,\n",
      "        1.3805, 0.7039, 0.5105, 1.2047, 1.1455, 1.8528, 0.6513, 1.1302, 0.7940,\n",
      "        1.0581, 0.5113, 1.3989, 1.0269, 0.7269, 1.1020, 1.4804, 0.6600, 1.2555,\n",
      "        1.7417, 1.0856, 0.9829, 0.9811, 1.1449, 1.1379, 1.0570, 1.0783, 1.2326,\n",
      "        1.2378, 1.2558, 0.8216, 1.1531, 0.9549, 1.2290, 1.1715, 1.0043, 1.2913,\n",
      "        1.4780, 0.7191, 1.0960, 1.1234, 1.0809, 1.4230, 1.2894, 0.4606, 1.1341,\n",
      "        1.4085, 1.0552, 1.1025, 1.3915, 1.4144, 1.0604, 0.8302, 0.8846, 1.1015,\n",
      "        1.5155, 0.8433, 1.0699, 1.1959, 1.0386, 1.0981, 1.1764, 0.5950, 1.3334,\n",
      "        0.5970, 1.1373, 0.8371, 1.1744, 1.2204, 1.0524, 1.2177, 1.2127, 1.2188,\n",
      "        1.3542, 0.4120, 1.2541, 1.1766, 1.1333, 0.7530, 1.0914, 1.1368, 1.0235,\n",
      "        1.1399, 1.1696, 1.0876, 1.1291, 0.4810, 1.0469, 0.6525, 0.6734, 1.1238,\n",
      "        1.1117, 1.1517, 0.5864, 1.1348, 1.2990, 0.8471, 0.6965, 1.1984, 1.3771,\n",
      "        0.8853, 1.2780, 1.0487, 1.2856, 1.3035, 0.9933, 0.7980, 1.3828, 0.9243,\n",
      "        1.2252, 1.1731, 0.8978, 1.1817, 1.2306, 1.2852, 1.0191, 1.0565, 1.1033,\n",
      "        1.0912, 0.6048, 1.1122, 1.0465, 1.0660, 1.0823, 0.9592, 1.1019, 1.2957,\n",
      "        1.5923, 1.2002, 1.5722, 1.1155, 0.6631, 0.6337, 0.4827, 1.1310, 0.6711,\n",
      "        1.1487, 0.4797, 0.4482, 0.9806, 1.1786, 0.7987, 1.3117, 1.0882, 1.0680,\n",
      "        1.0968, 0.6804, 0.9365, 0.8631, 0.7153, 1.0675, 0.6184, 1.0284, 0.9462,\n",
      "        1.2846, 0.9748, 0.9797, 1.1769, 1.0453, 0.9985, 1.7365, 1.2432, 1.3276,\n",
      "        1.1839, 0.6818, 1.2092, 1.2642, 1.3371, 1.2011, 1.6665, 0.9690, 1.1857,\n",
      "        1.1576, 1.2386, 0.6297, 0.8453, 0.6006, 0.9092, 0.8416, 0.9960, 1.2798,\n",
      "        1.0550, 1.2346, 0.6056, 1.2746, 1.2245, 1.3714, 0.5629, 1.1983, 0.9385,\n",
      "        1.5302, 1.0740, 0.7351, 1.1718, 1.1694, 1.1967, 1.0154, 0.9992, 1.0614,\n",
      "        1.2135, 1.2285, 0.5267, 1.1548, 0.5553, 1.1178, 1.3473, 1.1415, 0.8713,\n",
      "        0.7438, 1.2333, 0.8234, 1.5388, 1.0992, 1.2565, 1.0869, 1.2526, 0.7076,\n",
      "        0.8800, 0.8345, 1.4145, 1.1505, 1.2325, 1.3512, 1.1314, 1.3317, 1.2423,\n",
      "        1.0524, 0.9157, 1.1870, 0.4813, 0.9691, 1.1488, 1.2995, 1.6443, 1.1962,\n",
      "        1.0267, 0.9792, 1.0511, 0.9022, 1.1920, 1.0522, 1.3035, 0.8738, 1.0344,\n",
      "        1.0051, 0.8244, 1.0912, 1.0923, 1.0979, 0.9333, 0.8380, 1.1813, 1.0978,\n",
      "        0.7890, 0.4129, 1.1087, 0.9218, 0.9741, 0.8633, 1.0583, 0.7335, 1.1026,\n",
      "        1.0656, 0.9542, 1.0512, 1.1115, 0.4301, 1.1184, 0.4976, 1.0783, 1.1294,\n",
      "        1.1074, 0.9617, 1.0073, 1.4481, 1.0598, 1.0917, 1.1016, 0.9082, 0.9092,\n",
      "        0.5274, 0.3821, 1.2110, 1.2183, 1.0480, 1.0611, 1.1408, 1.1081, 0.5238,\n",
      "        1.6584, 1.1637, 1.2739, 1.1152, 1.1818, 0.7285, 1.1121, 0.8760, 1.0032,\n",
      "        0.9138, 1.1871, 1.2944, 1.1747, 1.7334, 1.1465, 1.3166, 0.6650, 0.4866,\n",
      "        1.0419, 0.8960, 1.1853, 0.9377, 1.1187, 0.7011], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.0.1.bias\n",
      "Weights: tensor([ 1.0480e+00,  9.1100e-01,  1.0231e+00, -4.3094e-01, -3.1793e-01,\n",
      "        -2.4482e-01, -6.3643e-01,  7.1579e-01,  7.5852e-01, -1.1583e+00,\n",
      "        -1.0918e+00, -1.0775e+00,  1.1366e+00, -1.5093e+00, -4.3303e-01,\n",
      "         4.7133e-01, -5.4242e-01, -5.1453e-01, -7.5186e-01, -9.5022e-01,\n",
      "        -1.2393e+00, -4.9089e-01,  1.8141e+00, -4.1869e-01, -5.0568e-01,\n",
      "        -8.1444e-01, -4.0511e-01,  1.2887e+00,  1.6205e+00, -2.4891e-01,\n",
      "        -7.5603e-01,  1.8523e-01, -1.6006e-01,  9.7984e-01,  9.9763e-01,\n",
      "        -5.7607e-01,  8.7795e-01, -5.8504e-01,  5.7509e-01, -2.9419e-01,\n",
      "        -1.6286e-01, -1.2389e+00, -3.6012e-01,  2.6708e-01,  9.0266e-01,\n",
      "         1.3664e+00, -9.7553e-01, -4.3327e-01, -4.6591e-01, -2.1081e-01,\n",
      "        -2.3300e-01,  6.9378e-01, -9.5021e-01, -3.6284e-01,  8.3826e-01,\n",
      "         5.7266e-02, -4.9500e-01,  1.6921e+00, -6.6958e-01,  1.0112e+00,\n",
      "        -1.0758e+00, -1.3546e+00, -6.3787e-01,  7.9305e-01,  1.3816e+00,\n",
      "        -6.4807e-01, -1.6884e-02, -7.7820e-01, -1.1608e-01,  1.2878e+00,\n",
      "        -6.6105e-01, -7.0807e-01, -2.2295e+00,  1.3137e+00,  1.5561e+00,\n",
      "         6.1171e-02, -4.9403e-01,  1.4905e+00,  1.5379e+00, -6.3293e-01,\n",
      "         1.2202e+00, -6.3352e-01,  1.1790e+00, -4.2638e-01,  1.1065e+00,\n",
      "         1.0695e+00, -2.7709e-01,  1.9769e-02,  9.2078e-01, -1.2144e+00,\n",
      "        -3.3144e+00, -1.6426e+00, -6.6347e-01, -9.8945e-01,  6.1236e-01,\n",
      "         1.0577e-01,  3.0318e-01, -8.9757e-01,  1.2113e-01,  2.1264e-01,\n",
      "         1.3534e-01,  9.1065e-01, -5.0761e-01,  1.3526e+00, -4.6380e-01,\n",
      "        -8.9371e-01, -1.3725e+00, -7.6697e-02, -3.1684e-01,  8.1234e-01,\n",
      "         3.0665e-01, -6.7090e-01,  3.0784e-02, -6.3646e-01,  3.0907e-01,\n",
      "         1.3234e+00,  1.3436e-01, -4.0942e-01,  2.7782e-01, -3.9590e-01,\n",
      "        -8.2225e-01, -1.8897e+00,  1.3781e+00,  1.8407e+00, -1.2201e-01,\n",
      "         3.0068e-01, -5.7808e-01,  1.4141e+00, -4.4749e-01, -4.5097e-01,\n",
      "         6.7319e-01,  7.1802e-01, -3.5413e-01,  1.4386e+00, -3.5395e-03,\n",
      "         2.0827e+00, -3.1263e-01,  1.3675e+00,  4.2472e-01,  3.3647e-01,\n",
      "         4.5722e-01, -1.1283e+00, -6.5970e-01, -6.8614e-01, -3.3853e-01,\n",
      "         1.1448e+00, -1.0623e+00, -2.4222e-01, -7.0199e-01,  1.3730e+00,\n",
      "        -2.3285e-02, -8.0778e-01,  5.0944e-01,  9.3612e-02, -2.6624e-01,\n",
      "        -2.5299e-01, -2.6870e-01,  1.5364e+00, -1.2573e-01,  1.1872e+00,\n",
      "         1.2733e+00,  4.2364e-01,  3.6562e-01, -4.2439e-01,  1.7830e+00,\n",
      "         1.0978e+00,  4.0575e-05,  1.1003e+00,  1.1190e+00,  4.9664e-01,\n",
      "        -1.1227e+00,  8.1517e-01,  4.5914e-01,  8.5543e-01, -4.3175e-01,\n",
      "        -5.6873e-01,  1.1051e+00,  7.9963e-01, -4.3868e-02, -9.0335e-01,\n",
      "        -6.4453e-01, -1.4727e-01, -1.2596e+00, -3.3933e-02,  3.7932e-01,\n",
      "        -1.0317e+00, -9.4346e-01, -5.0353e-01,  2.2811e-01, -1.6485e-01,\n",
      "         1.4105e+00,  6.5726e-01, -5.8306e-01,  3.9866e-01, -9.2203e-01,\n",
      "         8.6619e-01, -4.2111e-01,  1.0400e-01, -1.3025e+00, -2.6060e-01,\n",
      "        -9.0598e-01,  5.2402e-01,  9.6730e-01,  1.3415e+00,  1.8230e+00,\n",
      "         1.7132e-01,  1.1101e+00,  2.3795e-01,  1.6230e+00,  1.7251e+00,\n",
      "         5.0618e-01,  1.3632e-01,  9.3957e-01, -9.5370e-01, -5.0050e-01,\n",
      "         3.4146e-01, -4.5077e-01,  1.1261e+00, -7.6565e-01,  9.5185e-01,\n",
      "         9.5123e-01, -4.5007e-01,  1.0905e+00, -7.3592e-01,  1.8993e+00,\n",
      "        -4.4336e-01,  1.0768e+00, -6.0922e-01,  2.7937e-01,  8.6479e-01,\n",
      "        -1.0926e+00, -6.6051e-02, -7.3178e-01,  4.1825e-01, -1.2517e+00,\n",
      "         1.5891e+00, -5.4501e-01, -6.1561e-01, -7.3093e-01,  3.7760e-02,\n",
      "        -7.0638e-01,  1.5996e+00, -6.7713e-02, -8.0189e-01, -9.7556e-01,\n",
      "         1.1268e+00,  1.0635e+00,  1.3705e+00, -7.4154e-01,  1.0914e+00,\n",
      "         5.5618e-01,  1.1354e+00, -7.1124e-01, -4.5994e-01,  1.0999e+00,\n",
      "        -8.4040e-01,  8.8211e-01, -9.3559e-02,  1.3953e+00,  1.0457e-01,\n",
      "         8.0885e-01,  1.6294e+00, -2.6126e-01,  1.2471e+00, -8.3744e-01,\n",
      "        -2.2050e-01, -9.2337e-01, -9.0380e-01,  7.0204e-01, -6.6978e-01,\n",
      "        -5.5532e-01, -1.0569e+00,  1.4049e+00, -6.3144e-01,  1.1088e+00,\n",
      "        -2.8760e-02, -5.4089e-01, -8.7708e-01,  6.7200e-01,  1.2201e+00,\n",
      "         5.7736e-01, -4.7172e-01, -2.7782e-01, -2.6789e-01,  2.1465e-01,\n",
      "        -5.1630e-01,  1.1133e-01,  1.1517e+00,  8.5605e-01,  1.2005e+00,\n",
      "         1.1810e-01, -2.7912e-01, -4.3232e-01, -4.4129e-01, -5.8305e-01,\n",
      "        -6.1311e-01, -3.7357e-01,  3.3112e-01, -7.0520e-01, -7.8810e-01,\n",
      "         1.4800e+00, -6.3095e-01,  1.1133e-01, -3.1126e-01, -1.3207e+00,\n",
      "        -1.1588e-02,  4.3230e-01,  6.7008e-01, -1.3277e-01,  1.9187e+00,\n",
      "        -1.4521e-01,  7.1978e-01, -8.8925e-01,  1.1790e+00, -8.2598e-01,\n",
      "        -2.2596e+00,  5.1619e-01, -1.1306e+00, -8.5202e-02,  4.3400e-01,\n",
      "         1.3742e+00,  8.6796e-01,  6.9598e-02, -3.1875e-01,  1.1972e+00,\n",
      "         1.2787e+00, -2.0617e-01, -6.7190e-01, -1.0664e+00,  9.1266e-01,\n",
      "        -4.0725e-01,  9.0178e-01, -2.5362e-01, -1.0544e+00,  8.9853e-01,\n",
      "        -7.1402e-01,  6.9600e-02,  1.4364e+00, -1.5772e-01,  1.2248e+00,\n",
      "        -7.2673e-01, -1.1300e+00, -1.4456e+00, -5.9768e-01, -8.6821e-01,\n",
      "        -1.3768e+00,  1.1972e+00,  3.5325e-01,  7.1293e-02, -7.0335e-01,\n",
      "         9.6290e-01,  9.5984e-01,  1.3268e+00, -2.7872e-01,  1.4399e-01,\n",
      "         8.6268e-02, -4.1552e-01,  8.2340e-02,  3.7282e-01,  1.6087e+00,\n",
      "        -1.1896e+00,  3.0887e-03, -3.9219e-01,  9.6691e-01,  5.3129e-02,\n",
      "         8.7245e-01, -1.2251e+00, -8.0874e-01, -7.8129e-01,  7.3335e-01,\n",
      "        -6.8510e-01, -5.0933e-01,  5.2032e-02, -1.4730e+00,  7.0952e-01,\n",
      "         2.0388e-01,  8.9897e-01,  1.4309e+00,  5.1228e-01,  7.6007e-01,\n",
      "        -3.9373e-01, -1.2797e+00, -7.2417e-01,  1.0586e+00], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.1.0.weight\n",
      "Weights: tensor([[[[-5.0462e-02, -8.0521e-02, -4.4498e-02],\n",
      "          [-7.8831e-02, -1.0647e-01, -9.5035e-02],\n",
      "          [-2.3903e-02, -1.1521e-01, -2.8724e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3492e-01,  9.2133e-02,  1.3120e-01],\n",
      "          [ 1.2560e-01, -3.2119e-01,  1.0872e-01],\n",
      "          [ 9.1903e-02,  5.9489e-02,  8.6197e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3387e-02,  1.0068e-02, -8.0975e-02],\n",
      "          [-1.8131e-01, -1.0268e-02,  2.4308e-01],\n",
      "          [ 8.4934e-02,  3.9660e-02, -1.1195e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.7331e-02, -6.3483e-02,  4.3272e-02],\n",
      "          [-2.8044e-01, -1.4931e-01,  1.7585e-01],\n",
      "          [-5.8480e-03,  8.0385e-02,  2.4625e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.5204e-02, -1.6924e-01, -2.0029e-01],\n",
      "          [ 2.3787e-04,  7.2921e-03, -3.2232e-02],\n",
      "          [ 2.1134e-01,  1.8388e-01,  3.6585e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.5433e-02, -3.3323e-02,  6.6884e-02],\n",
      "          [ 2.4483e-02, -2.1936e-01,  2.8432e-01],\n",
      "          [-2.7703e-02, -3.3312e-02,  8.4945e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.10.conv.1.1.weight\n",
      "Weights: tensor([1.7614, 1.6871, 1.1576, 0.4178, 0.3668, 0.6751, 0.5607, 0.8781, 0.5108,\n",
      "        0.5102, 0.4349, 0.3057, 1.2037, 0.7762, 0.8918, 1.5237, 0.3631, 1.4866,\n",
      "        0.5743, 0.4291, 0.4249, 0.4924, 2.3656, 0.8607, 0.7765, 0.3943, 0.4464,\n",
      "        1.2093, 1.8385, 0.6160, 0.3606, 1.1642, 0.5425, 0.8887, 2.1860, 1.3354,\n",
      "        0.6677, 0.8909, 0.8414, 0.7061, 0.5730, 0.5126, 0.7654, 1.2494, 1.5467,\n",
      "        2.2573, 0.3069, 1.3278, 0.9817, 0.6854, 0.9751, 2.5580, 0.8472, 0.5439,\n",
      "        0.9930, 0.5059, 1.1905, 1.8208, 0.5213, 1.3834, 0.4591, 0.3631, 0.9015,\n",
      "        1.8618, 0.9453, 0.6491, 0.5251, 0.5246, 0.4967, 1.0607, 0.6128, 0.5595,\n",
      "        0.4276, 1.3858, 1.9333, 1.2296, 0.4177, 3.5417, 2.2067, 0.5838, 1.3065,\n",
      "        0.7236, 0.8670, 0.7349, 1.4403, 1.2818, 0.6165, 0.5712, 1.0169, 0.5080,\n",
      "        1.6019, 0.3966, 0.5661, 0.4357, 1.7129, 0.6774, 1.0401, 0.5489, 0.8569,\n",
      "        0.6075, 1.0026, 2.3664, 0.4662, 1.2174, 0.4573, 0.9819, 0.2240, 1.7046,\n",
      "        0.5624, 1.0747, 0.8531, 0.7428, 0.7443, 0.3447, 1.6445, 1.8935, 0.4500,\n",
      "        0.4442, 0.6693, 0.7167, 0.3469, 0.3812, 1.3417, 0.6511, 1.0356, 1.4150,\n",
      "        0.6482, 2.4499, 0.4540, 0.4395, 0.9187, 2.2150, 1.0337, 1.4784, 1.7377,\n",
      "        3.2860, 4.0820, 2.0404, 1.0147, 1.5940, 0.9528, 0.8673, 0.6145, 0.4177,\n",
      "        0.6106, 0.9277, 0.7096, 0.6651, 0.4406, 1.3287, 0.8397, 0.5755, 0.7921,\n",
      "        0.5817, 0.8323, 0.4578, 0.8028, 2.2233, 1.4028, 0.4592, 1.2169, 1.1915,\n",
      "        0.7067, 0.6845, 2.5505, 2.3601, 1.2598, 2.7937, 0.8400, 0.5815, 0.8559,\n",
      "        2.2343, 1.4837, 1.4562, 0.9501, 0.5136, 1.6370, 1.0740, 0.6846, 0.3389,\n",
      "        0.5704, 0.9707, 0.8493, 0.4765, 0.5150, 0.2990, 0.4007, 0.4331, 0.9604,\n",
      "        0.4945, 1.4331, 0.9433, 0.5505, 0.8302, 0.4058, 1.1412, 0.5068, 0.5946,\n",
      "        0.4317, 0.5418, 1.4065, 1.0523, 1.3346, 1.2406, 2.4884, 0.7088, 0.7158,\n",
      "        0.5470, 1.4518, 2.3038, 0.9102, 1.2784, 1.0223, 0.9356, 0.8287, 0.9568,\n",
      "        0.4726, 1.2251, 0.3936, 1.5607, 1.2539, 0.5232, 1.2281, 1.4891, 1.8972,\n",
      "        0.6147, 1.4989, 0.6862, 0.5139, 1.5037, 0.5017, 1.1765, 0.4935, 1.6346,\n",
      "        1.8916, 2.0998, 0.5462, 0.5679, 0.8774, 0.9058, 5.8928, 2.2332, 1.3655,\n",
      "        0.4084, 0.3697, 0.8527, 0.8767, 0.7666, 0.4644, 1.4847, 0.8334, 1.5123,\n",
      "        0.6198, 0.7915, 1.1592, 0.8427, 1.0924, 1.6457, 1.1716, 1.1529, 1.3337,\n",
      "        1.7588, 0.4166, 0.8679, 0.7547, 0.5159, 0.4478, 0.3791, 1.0316, 0.3782,\n",
      "        0.7044, 0.4730, 1.0922, 0.6267, 0.7726, 0.8741, 0.4771, 0.3772, 0.9587,\n",
      "        1.6150, 0.4477, 1.3165, 0.6400, 0.6630, 1.2495, 0.4525, 1.5891, 0.7609,\n",
      "        1.6170, 1.2426, 1.0182, 0.7587, 0.5192, 0.8857, 0.7185, 0.4775, 1.1074,\n",
      "        0.7799, 1.0701, 0.4471, 1.4327, 0.3702, 1.3999, 1.1818, 0.3679, 0.7785,\n",
      "        0.7361, 1.4514, 0.8860, 0.7037, 1.1287, 1.6277, 0.4362, 1.1576, 0.7804,\n",
      "        1.1923, 0.9519, 0.4216, 1.5048, 0.5090, 1.2164, 1.4044, 0.5780, 0.5660,\n",
      "        1.3160, 1.5327, 0.6888, 0.7063, 0.4934, 0.9712, 1.1012, 1.1052, 0.5099,\n",
      "        0.3681, 1.1572, 1.4916, 0.8299, 1.7649, 0.5282, 1.5708, 0.5164, 0.4149,\n",
      "        1.2241, 0.3932, 0.3951, 1.1179, 1.7539, 0.4608, 0.7356, 0.4380, 0.8522,\n",
      "        1.7900, 1.5523, 0.5549, 1.8362, 0.9211, 0.7782, 0.6179, 1.2762, 0.7728,\n",
      "        0.4722, 0.8785, 0.9086, 0.5489, 0.3975, 1.2287, 0.2735, 0.3865, 0.5136,\n",
      "        1.5447, 0.4289, 0.7720, 0.5232, 0.4507, 0.6515, 1.9110, 1.4198, 1.3732,\n",
      "        0.8834, 1.2761, 0.7271, 0.9455, 0.4022, 1.0764], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.1.1.bias\n",
      "Weights: tensor([-1.6860e+00, -1.9292e+00, -1.0530e+00,  2.1579e+00,  1.4332e+00,\n",
      "         8.8952e-02, -2.9376e-01, -6.7400e-01,  2.6178e-01,  2.2084e+00,\n",
      "         1.2912e+00,  1.5315e-01, -7.1289e-01, -5.4374e-01, -1.1077e+00,\n",
      "        -2.7512e+00,  3.5208e-01, -2.8462e+00, -5.1227e-01, -5.6360e-02,\n",
      "         1.8069e-01,  1.7270e-01, -7.2766e+00, -5.5100e-01, -9.9924e-01,\n",
      "         3.2930e-01,  1.9525e+00, -1.4202e+00, -3.2279e+00, -5.2274e-01,\n",
      "         1.8478e+00, -1.4266e+00, -1.1236e-01, -2.9600e-01, -2.3237e+00,\n",
      "        -3.7263e+00, -7.4676e-02, -6.7619e-01, -3.9197e-01, -2.1707e-01,\n",
      "         3.2730e+00, -1.7002e-01, -7.1433e-01, -1.6306e+00, -2.5696e+00,\n",
      "        -2.6193e+00,  8.7605e-01, -2.7480e+00, -1.8760e+00, -6.7134e-01,\n",
      "        -2.7471e+00, -5.4059e+00, -1.1645e+00,  1.3393e-02, -4.8009e-01,\n",
      "         2.8741e-01, -3.1684e+00, -2.3256e+00, -3.4360e-01, -1.2753e+00,\n",
      "         1.7439e-01,  5.0337e-01, -2.3370e+00, -1.6023e+00,  3.9177e-01,\n",
      "        -5.1098e-01,  1.7367e-01, -1.0810e-02,  9.6965e-01, -2.6689e-01,\n",
      "        -3.8232e-01,  2.2772e+00,  2.9117e+00, -1.2467e+00, -1.7391e+00,\n",
      "        -2.0135e+00,  1.1108e+00, -4.9742e+00, -1.9800e+00,  7.9088e-01,\n",
      "        -7.0062e-01, -3.8670e-01,  3.4695e-01, -3.5263e-01, -3.7685e-01,\n",
      "        -1.2722e+00, -1.6680e-03,  2.9553e-01, -3.7260e-01,  6.9386e-01,\n",
      "         2.7590e+00,  2.3266e+00, -3.4060e-01,  1.2175e-01, -3.1099e+00,\n",
      "        -2.1094e-01, -1.8176e+00, -8.7392e-01,  1.1185e-02,  3.0278e-02,\n",
      "        -2.0797e-01, -4.7940e+00,  2.0609e+00, -1.1177e+00,  9.0728e-01,\n",
      "        -9.3532e-01,  1.7453e+00, -3.5532e+00,  2.1270e+00, -8.1266e-01,\n",
      "        -4.1798e-01, -8.6945e-01, -6.8777e-01,  1.9473e+00, -1.1103e+00,\n",
      "        -1.5715e+00,  1.4915e+00,  1.2196e+00, -4.8230e-01, -9.1285e-01,\n",
      "         2.0954e-01,  1.9008e+00, -9.7766e-01,  1.4780e+00, -2.9057e+00,\n",
      "        -2.5121e+00, -3.9597e-01, -2.9617e+00,  1.5809e+00,  1.7344e+00,\n",
      "        -1.7792e-01, -5.2561e+00, -1.2538e+00, -1.6112e+00, -8.4341e-01,\n",
      "        -6.2242e+00, -1.7343e+00, -2.0180e+00, -2.4363e-01, -9.5824e-01,\n",
      "        -1.1717e+00, -6.4918e-02,  4.2947e-01,  2.4513e+00, -7.5598e-02,\n",
      "        -3.5480e-01, -1.3951e+00, -6.3412e-01,  1.8883e+00, -5.8158e-01,\n",
      "        -4.9390e-01, -6.0666e-01, -2.6852e-01,  5.7815e-02, -1.1450e+00,\n",
      "         9.9047e-02, -9.1434e-01, -2.7120e+00, -4.7730e+00,  6.1176e-01,\n",
      "        -3.4479e-01, -3.8060e-01, -2.4672e-01, -7.2907e-01, -2.7684e+00,\n",
      "        -2.5547e+00, -2.7793e+00, -5.6594e+00, -6.7149e-02,  1.1152e-01,\n",
      "        -1.6020e+00, -4.8618e+00, -6.3957e-01, -1.1704e+00, -1.3541e+00,\n",
      "         1.3908e-01, -1.1428e+00, -6.9268e-01,  2.3471e-01,  1.6234e+00,\n",
      "        -4.9405e-01, -9.7055e-01, -1.8001e+00,  1.1149e+00,  1.7137e+00,\n",
      "         1.9021e-01, -1.1008e-01,  1.3116e+00, -1.4179e+00,  7.8332e-02,\n",
      "        -1.2675e+00, -2.2253e-01, -6.6251e-01, -3.0017e-01,  5.1885e-02,\n",
      "        -8.8720e-01, -3.0543e-01,  2.0092e-01,  1.4921e-01,  5.3450e-01,\n",
      "        -3.6300e+00, -4.6544e-01, -1.5042e+00, -6.1189e-01, -4.0025e+00,\n",
      "        -5.8980e-01, -4.3559e-02,  2.7312e-01, -1.3228e+00, -3.2918e+00,\n",
      "        -6.2026e-01, -2.7267e+00, -6.5863e-01, -2.0089e+00, -1.4555e-01,\n",
      "        -1.0292e+00, -1.6427e-02, -1.4022e+00,  2.9716e-02, -1.0968e+00,\n",
      "        -1.2026e+00, -2.4008e-01, -7.6010e-01, -4.6562e-01, -2.7589e+00,\n",
      "         1.4444e-01, -4.2325e-01, -1.0442e+00,  1.9011e+00, -1.5382e+00,\n",
      "        -2.0001e-01, -2.2186e+00,  1.1160e+00, -5.9425e-01, -1.1197e+00,\n",
      "        -2.9211e+00, -7.3471e-02, -2.4868e-01, -1.9925e+00, -6.8507e-01,\n",
      "        -2.8308e+00, -2.2321e+00, -2.7519e+00,  2.6564e+00,  2.1406e-01,\n",
      "        -2.1709e-01,  2.0272e-01,  9.6139e-01, -2.2131e-01, -1.5494e+00,\n",
      "        -2.0824e-01, -1.0663e+00,  1.3765e-02, -6.6245e-01, -9.4454e-01,\n",
      "        -2.6533e-01, -1.2016e+00, -6.5767e-01, -5.5014e-01, -2.3487e-01,\n",
      "        -9.5682e-01, -1.8761e+00,  1.2738e-01,  3.0688e-02,  4.5622e-02,\n",
      "         8.0198e-01,  1.2725e-01,  4.2344e-01, -5.8125e-01,  1.1130e+00,\n",
      "        -7.1504e-01,  4.1446e-03, -5.9068e-01, -6.2118e-01,  3.8273e-01,\n",
      "        -1.0234e+00,  2.0015e+00,  1.7736e+00, -5.6943e-01, -1.8014e+00,\n",
      "         4.5359e-01, -1.8691e-01, -3.9602e-01, -4.7924e-01, -5.1838e-01,\n",
      "         1.8732e+00, -2.5176e+00,  4.6852e-01, -3.3864e+00, -8.6585e-01,\n",
      "        -2.1781e-01, -7.5760e-01,  1.0813e-01, -1.0849e+00, -3.4090e-01,\n",
      "         1.8533e+00, -2.4369e+00, -1.4579e-01, -1.3168e+00,  2.0141e-01,\n",
      "        -2.0152e+00,  2.7416e-01, -2.7210e+00, -1.4297e-01,  6.1430e-01,\n",
      "        -1.3741e+00, -1.9152e-01, -2.0366e+00, -1.2505e+00,  9.1348e-01,\n",
      "        -1.4997e+00, -2.5609e+00,  2.2006e-01, -1.2702e+00, -1.0339e+00,\n",
      "        -3.6549e+00, -1.8179e+00,  2.0999e+00, -4.7236e+00,  2.1428e+00,\n",
      "        -1.2482e+00, -1.7201e+00, -2.0599e-01, -1.9456e-01, -6.1703e-01,\n",
      "        -3.2048e-01, -1.1398e-01, -9.5324e-01, -4.1460e-01, -5.3052e-01,\n",
      "        -2.0352e+00, -1.7795e+00, -9.2434e-02,  1.3669e-01, -7.7642e-01,\n",
      "        -3.0362e+00, -1.4375e-01, -1.8707e+00,  1.3503e-01, -1.3054e+00,\n",
      "        -2.1628e-01,  9.8951e-02, -3.0878e-01,  5.4288e-01,  3.2816e+00,\n",
      "         9.1935e-01, -1.7921e+00,  1.1480e+00, -4.7884e-01,  3.4175e-01,\n",
      "         2.2155e-01, -2.1436e+00, -1.7722e+00,  4.9098e-01, -4.7889e+00,\n",
      "        -1.3480e+00, -1.0723e+00, -8.3306e-02, -2.4353e+00,  3.5074e-02,\n",
      "         1.3334e-01, -3.8055e-01, -1.3414e+00,  4.3070e-01,  1.0843e+00,\n",
      "        -8.9623e-01,  2.2447e+00, -4.4980e-02, -3.7996e-01, -3.4153e+00,\n",
      "         1.9043e+00, -9.5483e-01,  8.3323e-01,  8.1806e-01,  2.6549e-01,\n",
      "        -4.6761e+00, -1.9026e+00, -6.5945e-01, -4.1188e-01, -1.4196e+00,\n",
      "        -4.4763e-01, -1.9713e-01,  1.6761e+00, -8.1595e-01], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.10.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0671]],\n",
      "\n",
      "         [[ 0.0348]],\n",
      "\n",
      "         [[ 0.0255]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0687]],\n",
      "\n",
      "         [[ 0.0121]],\n",
      "\n",
      "         [[-0.0123]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0075]],\n",
      "\n",
      "         [[-0.0455]],\n",
      "\n",
      "         [[-0.0464]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0032]],\n",
      "\n",
      "         [[-0.0068]],\n",
      "\n",
      "         [[ 0.1225]]],\n",
      "\n",
      "\n",
      "        [[[-0.0723]],\n",
      "\n",
      "         [[ 0.1953]],\n",
      "\n",
      "         [[-0.0502]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1621]],\n",
      "\n",
      "         [[-0.0066]],\n",
      "\n",
      "         [[ 0.1163]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0191]],\n",
      "\n",
      "         [[ 0.0096]],\n",
      "\n",
      "         [[ 0.0523]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0475]],\n",
      "\n",
      "         [[-0.0201]],\n",
      "\n",
      "         [[ 0.0311]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1116]],\n",
      "\n",
      "         [[ 0.0091]],\n",
      "\n",
      "         [[ 0.0529]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0231]],\n",
      "\n",
      "         [[ 0.1721]],\n",
      "\n",
      "         [[-0.0607]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0196]],\n",
      "\n",
      "         [[ 0.0374]],\n",
      "\n",
      "         [[-0.0121]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0311]],\n",
      "\n",
      "         [[ 0.0032]],\n",
      "\n",
      "         [[-0.0154]]]], device='cuda:0')\n",
      "Shape: torch.Size([64, 384, 1, 1])\n",
      "\n",
      "Layer: features.10.conv.3.weight\n",
      "Weights: tensor([1.9378, 0.9872, 6.9928, 1.5813, 5.1038, 2.0274, 1.2569, 1.1775, 4.2219,\n",
      "        3.5326, 2.3307, 3.0572, 1.0382, 2.7175, 4.3027, 4.7480, 4.6148, 1.2230,\n",
      "        3.2733, 1.5476, 1.5013, 4.7089, 1.1100, 2.4626, 1.8728, 3.7182, 2.6695,\n",
      "        4.8734, 1.0934, 0.9412, 3.7655, 1.3054, 1.1903, 3.9655, 1.2690, 2.2902,\n",
      "        1.6020, 1.5254, 1.6357, 1.1028, 1.5539, 1.2705, 1.1657, 1.2440, 4.4574,\n",
      "        6.2776, 1.1568, 4.3910, 1.1096, 1.4099, 3.3740, 1.4511, 1.1916, 1.3195,\n",
      "        1.2786, 2.4235, 1.5877, 7.0662, 1.4588, 5.1415, 1.4237, 1.3148, 1.8732,\n",
      "        0.9873], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.10.conv.3.bias\n",
      "Weights: tensor([-6.4385e-07, -2.7339e-06,  8.0729e-07, -1.1939e-08,  1.1810e-06,\n",
      "        -3.2340e-09,  9.4471e-07, -7.1138e-07,  1.3689e-07, -4.7650e-08,\n",
      "         2.3305e-07,  1.6059e-07,  8.2482e-09,  8.3813e-07, -3.8147e-07,\n",
      "        -2.1289e-07,  6.6519e-07,  7.1511e-07,  7.1958e-07, -1.2390e-06,\n",
      "         1.0269e-06,  1.9098e-07, -1.0201e-06, -1.1513e-07, -8.3142e-07,\n",
      "        -3.3052e-07, -9.6507e-08,  1.4103e-06,  9.5611e-07,  1.3663e-06,\n",
      "         1.1550e-07,  1.3260e-06,  1.3175e-06,  2.1705e-07, -1.0543e-06,\n",
      "         4.5691e-07,  1.9202e-07, -1.0362e-07,  7.8162e-07, -2.4831e-07,\n",
      "         4.3724e-07, -7.5882e-07, -1.7948e-06,  3.8779e-07, -6.9935e-07,\n",
      "        -6.6828e-07,  8.8063e-07,  6.6335e-07, -1.0470e-07, -1.2610e-06,\n",
      "        -7.6499e-09, -1.4330e-07, -1.3259e-07, -1.1523e-06,  3.2641e-07,\n",
      "         1.8865e-07, -1.3416e-06, -6.0434e-07,  4.7090e-07,  4.2432e-07,\n",
      "         5.8093e-07, -1.0854e-06, -2.8033e-07,  5.9377e-07], device='cuda:0')\n",
      "Shape: torch.Size([64])\n",
      "\n",
      "Layer: features.11.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.0209]],\n",
      "\n",
      "         [[-0.2387]],\n",
      "\n",
      "         [[ 0.0540]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0413]],\n",
      "\n",
      "         [[-0.0739]],\n",
      "\n",
      "         [[ 0.0554]]],\n",
      "\n",
      "\n",
      "        [[[-0.0199]],\n",
      "\n",
      "         [[ 0.2173]],\n",
      "\n",
      "         [[-0.0966]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1849]],\n",
      "\n",
      "         [[-0.0354]],\n",
      "\n",
      "         [[-0.0875]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0248]],\n",
      "\n",
      "         [[-0.2514]],\n",
      "\n",
      "         [[-0.0258]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0130]],\n",
      "\n",
      "         [[-0.1779]],\n",
      "\n",
      "         [[ 0.1439]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0886]],\n",
      "\n",
      "         [[-0.0573]],\n",
      "\n",
      "         [[-0.2098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[ 0.0863]],\n",
      "\n",
      "         [[ 0.0534]]],\n",
      "\n",
      "\n",
      "        [[[-0.0657]],\n",
      "\n",
      "         [[ 0.2107]],\n",
      "\n",
      "         [[ 0.0688]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0914]],\n",
      "\n",
      "         [[-0.2014]],\n",
      "\n",
      "         [[ 0.0119]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0277]],\n",
      "\n",
      "         [[-0.1450]],\n",
      "\n",
      "         [[ 0.0520]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0390]],\n",
      "\n",
      "         [[ 0.0338]],\n",
      "\n",
      "         [[ 0.0547]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 64, 1, 1])\n",
      "\n",
      "Layer: features.11.conv.0.1.weight\n",
      "Weights: tensor([1.0653, 1.1748, 0.6834, 1.3344, 1.2329, 1.3266, 1.3392, 1.3528, 1.5336,\n",
      "        1.4694, 1.1259, 1.5070, 1.3940, 1.1592, 1.1809, 1.2428, 1.3787, 1.0781,\n",
      "        1.0042, 0.3570, 1.3401, 0.9163, 1.4291, 1.4720, 1.3933, 1.3051, 1.8400,\n",
      "        1.3953, 1.3010, 1.1175, 0.9711, 0.7644, 1.1909, 1.5157, 1.4897, 1.7730,\n",
      "        1.3950, 1.3379, 0.5332, 0.7859, 0.4322, 1.1519, 1.0429, 1.1295, 1.2696,\n",
      "        1.4281, 1.2681, 1.2734, 1.6332, 1.4555, 1.4633, 1.0856, 1.5455, 1.1250,\n",
      "        1.3335, 1.1245, 1.2785, 1.2026, 1.3196, 1.2784, 1.6063, 1.1249, 1.4101,\n",
      "        1.5803, 0.7828, 1.4252, 1.5660, 1.1769, 0.5878, 1.5242, 1.5586, 1.2284,\n",
      "        1.2755, 1.3069, 1.3107, 0.9983, 1.2548, 1.2906, 1.3038, 1.3206, 1.2590,\n",
      "        1.3318, 1.2827, 0.9802, 1.1993, 1.5205, 1.4092, 1.1615, 1.6462, 1.2719,\n",
      "        1.3224, 1.1879, 1.1718, 1.3275, 1.1662, 1.2930, 1.0354, 1.0467, 1.3297,\n",
      "        1.5094, 0.5880, 1.2629, 0.6660, 1.6909, 1.2714, 1.2858, 1.3503, 1.2753,\n",
      "        1.2575, 1.3846, 1.6170, 1.1866, 1.1869, 1.3428, 1.3171, 0.9672, 1.3274,\n",
      "        1.5827, 1.4505, 0.6065, 1.4596, 1.5251, 1.1615, 1.3687, 1.5792, 1.5114,\n",
      "        1.4104, 1.4863, 0.5567, 1.2976, 1.1959, 0.9906, 0.9250, 1.5068, 1.1655,\n",
      "        1.4619, 1.2172, 1.4645, 1.3888, 1.2417, 1.1011, 1.2537, 1.4516, 1.1796,\n",
      "        1.3328, 1.0910, 1.2547, 1.2958, 0.8166, 1.2871, 1.5372, 1.2963, 1.2995,\n",
      "        1.3933, 1.3516, 1.0032, 1.2639, 1.4672, 1.0977, 2.3011, 1.4447, 1.6099,\n",
      "        1.2847, 0.8300, 1.3673, 1.1200, 1.1778, 1.1896, 1.4364, 1.4700, 0.8645,\n",
      "        1.0268, 1.3171, 1.2423, 1.2146, 1.3246, 1.3057, 1.4855, 0.5458, 1.0774,\n",
      "        1.5748, 1.2179, 1.0712, 1.0311, 1.2291, 1.4528, 1.1169, 1.1913, 1.4442,\n",
      "        0.7808, 1.2505, 1.2939, 1.3017, 1.2540, 1.4373, 1.0656, 1.1767, 1.3250,\n",
      "        1.1716, 0.6949, 1.4213, 1.3973, 1.8008, 1.1915, 1.4125, 0.8987, 1.0506,\n",
      "        1.2754, 1.2896, 1.2257, 1.4095, 1.0099, 1.5551, 1.0938, 1.1848, 1.1833,\n",
      "        1.4799, 1.4782, 0.8993, 1.2132, 1.5666, 0.8360, 1.2055, 1.3040, 1.3258,\n",
      "        1.5043, 1.2579, 1.1979, 1.3589, 1.2941, 1.5201, 1.1491, 1.1241, 1.4784,\n",
      "        1.6316, 1.3290, 1.3502, 1.2455, 1.5282, 1.4477, 1.0303, 0.9400, 0.9492,\n",
      "        1.0750, 1.1495, 1.3824, 2.0096, 1.2162, 1.2270, 1.2503, 1.5286, 1.3138,\n",
      "        0.4112, 1.1664, 1.2967, 1.1272, 1.0982, 1.3710, 1.1970, 1.2451, 1.1396,\n",
      "        0.6001, 1.2598, 1.9278, 1.3641, 1.3146, 1.5506, 1.6435, 1.4488, 1.2609,\n",
      "        1.3667, 0.5885, 1.5727, 1.4283, 0.8309, 1.3717, 1.2026, 1.2312, 1.3904,\n",
      "        1.2973, 1.2075, 1.3014, 0.8991, 1.1865, 1.3941, 1.3610, 1.0903, 1.4510,\n",
      "        1.5555, 0.4803, 1.4450, 1.4490, 1.2605, 1.4272, 1.2989, 1.1175, 1.5200,\n",
      "        1.4705, 1.6879, 1.1078, 1.0853, 1.3081, 1.3863, 1.4368, 1.2188, 1.3774,\n",
      "        1.1651, 1.2563, 1.3376, 1.1862, 1.1606, 1.5641, 1.2495, 1.6775, 1.0013,\n",
      "        1.3107, 1.2325, 1.4235, 1.4602, 1.7501, 1.1995, 1.0234, 1.3206, 1.3106,\n",
      "        1.2779, 1.2842, 1.3172, 1.4999, 1.5539, 1.5722, 0.9856, 1.4934, 1.2686,\n",
      "        1.4157, 1.4387, 1.1998, 1.2959, 1.2124, 1.0351, 1.4116, 1.2256, 1.3218,\n",
      "        1.3513, 1.2958, 1.2179, 1.3943, 1.5164, 1.3539, 1.3482, 1.3986, 1.2798,\n",
      "        1.1134, 0.5530, 1.5435, 1.4823, 0.5287, 1.2689, 1.2932, 1.3030, 1.1652,\n",
      "        0.8793, 1.0312, 1.3030, 1.0858, 0.9611, 1.6050, 1.2484, 1.2993, 0.6648,\n",
      "        1.0238, 1.1197, 1.2147, 1.4730, 1.5315, 0.9052, 0.5683, 1.1487, 0.9084,\n",
      "        1.3849, 1.2824, 1.2613, 1.2633, 1.0070, 0.6274], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.0.1.bias\n",
      "Weights: tensor([-0.1576,  0.7837,  1.9044, -0.7876,  0.6068, -0.4094, -0.2696,  0.0169,\n",
      "         0.2671, -0.9222,  1.6837, -0.2191, -0.3021,  0.2019,  0.0385,  0.4504,\n",
      "         0.0240,  0.3857,  0.0653,  1.6351,  0.2038,  1.4827,  0.7771, -0.4229,\n",
      "         0.0974, -0.3766, -0.1431, -0.1358, -0.7717,  0.4155,  1.5652,  1.7263,\n",
      "        -0.7153, -1.5665, -0.1382,  0.5840, -0.0218, -0.5747,  3.6936,  0.4572,\n",
      "        -0.0256, -0.0573,  0.5809,  1.0647,  1.7891,  0.4680,  0.4109, -0.7749,\n",
      "        -0.7168,  0.5410, -0.5127,  0.9732, -0.0426,  1.3883, -0.6187, -0.1847,\n",
      "         0.1976, -0.1430, -0.9572, -0.0463, -0.8450, -0.1530, -0.4282, -0.6077,\n",
      "         1.8759,  0.0115, -0.2511,  0.2060,  1.5379,  0.3458,  0.6756,  0.6087,\n",
      "        -0.9053, -0.7929,  0.1056,  0.8723,  1.0099, -0.0854, -0.1670, -0.0699,\n",
      "        -0.4687, -0.5225,  0.2523, -0.5401, -0.2328, -0.5532,  0.6112, -0.2164,\n",
      "        -0.2260,  1.0657, -0.5041, -0.1931, -0.1866, -0.7709, -0.4205,  0.7702,\n",
      "         0.9870,  0.1684, -0.0194,  0.4252,  1.4484, -0.9562,  1.6919, -0.6445,\n",
      "        -0.6649,  0.2337,  2.1018, -0.6360, -0.2496,  0.3810,  0.2271, -0.2972,\n",
      "        -0.2192, -0.2027,  0.1062,  0.9095,  1.2418, -0.1854,  0.4183,  0.3957,\n",
      "         0.1559, -0.7482,  0.7325, -0.5466,  2.2542, -0.6612, -1.0543, -0.1536,\n",
      "         1.8853, -0.3178, -0.4590,  0.5390,  1.6451, -0.0764,  0.1395,  0.0831,\n",
      "        -0.7590, -0.1262, -1.2446, -0.6383, -0.3961, -1.0283, -0.2948,  0.1845,\n",
      "         0.3687,  1.1496, -0.6338,  0.7759,  1.7510, -0.3031, -0.1241,  0.1892,\n",
      "        -0.2775, -0.4049,  0.5285, -0.4048, -0.0289, -0.8509,  0.9910,  0.3513,\n",
      "         0.5165, -0.6024, -0.4299,  1.9614,  0.5025, -0.2912,  0.4907, -0.2899,\n",
      "        -0.3464,  0.2936, -0.3204,  0.9759, -0.3318, -0.2051, -0.5438,  0.0089,\n",
      "         0.1403,  0.0565,  1.9054,  1.5053,  0.5446,  0.8330,  0.7623,  0.9168,\n",
      "         0.1791, -0.0675, -0.2818,  0.0809, -0.4231,  2.0986,  0.5917,  1.2191,\n",
      "         0.4102, -0.3079,  0.0624,  1.3518,  0.8209,  0.8241, -0.7147,  1.7941,\n",
      "         0.1053, -0.2634,  0.0978, -1.3734,  0.4173,  1.5533,  1.1427, -0.6136,\n",
      "         0.2145,  0.0289,  0.2943,  0.4769, -1.8222,  0.0227,  0.8840, -0.2986,\n",
      "         0.7518, -0.2828,  1.7271,  1.0617, -0.5995,  2.1815,  1.3297,  0.0309,\n",
      "        -0.6224, -0.2793, -1.0855,  1.5901, -0.2017, -0.5170, -0.4518,  0.8666,\n",
      "         1.2799, -0.4048,  0.5648, -0.6741, -0.1975, -0.3762,  0.2341, -0.2773,\n",
      "         0.9097, -0.2928, -0.1931,  0.7897, -0.6239,  0.1095,  0.1258, -0.7722,\n",
      "        -0.3525,  1.5550,  0.0208,  0.2256,  0.7450,  1.0465, -0.5804, -0.8582,\n",
      "        -0.3019,  1.0391,  0.1066, -0.5947,  0.0183,  1.5648, -0.5590,  0.5523,\n",
      "         0.3831,  2.1059, -0.4827, -0.6148,  0.2435, -0.6077,  1.9654,  1.5422,\n",
      "        -0.7434,  0.3624,  0.3651,  0.1939, -0.2947, -0.1325,  2.2594, -0.2039,\n",
      "        -2.1780, -0.4043,  0.4584,  0.1604, -0.1053, -0.5958, -0.1488, -0.4878,\n",
      "        -0.1155, -0.1295,  0.4589, -0.5169,  0.1595, -0.1277, -0.4722,  1.3653,\n",
      "        -0.6715,  1.6744,  0.8912,  0.0527,  1.4696,  0.2187,  0.2924,  0.8012,\n",
      "        -0.5733, -0.4287,  0.1368, -0.5821,  0.9838,  0.4676, -0.1598,  0.5534,\n",
      "         0.4470, -0.2059,  1.1840,  0.1323,  0.3970, -0.1575, -0.0933, -0.6444,\n",
      "         1.7797,  1.2909, -0.8902, -0.3012,  0.7909, -0.3415,  0.7637, -0.7677,\n",
      "         0.5083, -0.3626,  0.0924,  0.6773,  0.9406,  0.1850,  0.3540,  0.7464,\n",
      "         1.0366,  1.2839,  1.3520,  0.7960,  0.2923, -0.7434, -0.1224, -0.3727,\n",
      "        -0.6526, -0.5136, -0.1758, -0.3901, -0.2980, -0.9460, -0.8022,  1.1045,\n",
      "         1.6277, -0.5406,  0.0481, -0.3989, -0.6038, -0.4311, -0.7374, -0.3581,\n",
      "         2.1029,  1.8823, -0.2276, -0.0834,  0.3363,  0.7860, -0.1152, -0.1198,\n",
      "         1.6242,  1.0393,  0.3620, -0.2943,  0.3746,  1.1881,  0.1785,  1.5429,\n",
      "         0.0345, -0.1553, -0.5829, -0.5274,  1.2515,  1.0312,  1.8793,  1.3705],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.1.0.weight\n",
      "Weights: tensor([[[[-1.1589e-01, -6.6866e-02, -1.2909e-01],\n",
      "          [-5.1430e-02, -5.6317e-03, -4.9895e-02],\n",
      "          [-1.3824e-01, -7.3430e-02, -1.3444e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.7623e-03, -4.8888e-02, -3.6841e-03],\n",
      "          [-8.3434e-02, -3.4875e-01, -9.3236e-02],\n",
      "          [-4.3724e-02, -5.9930e-02, -3.7883e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.7786e-04, -7.1330e-02,  1.7061e-03],\n",
      "          [-6.8612e-02, -3.4188e-01, -8.6674e-02],\n",
      "          [-2.4407e-02, -8.4478e-02, -1.6576e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.9653e-02,  2.0546e-01,  4.0452e-02],\n",
      "          [-9.0566e-02, -7.1098e-02, -7.7015e-02],\n",
      "          [-1.3687e-01, -3.3485e-01, -1.4459e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3074e-02,  1.7918e-01,  3.4782e-02],\n",
      "          [ 1.5058e-01, -9.1790e-01,  8.9586e-02],\n",
      "          [ 5.1830e-02,  4.7739e-02,  5.4556e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6702e-02, -2.0779e-01,  1.0262e-02],\n",
      "          [-1.3448e-01,  5.3438e-01, -1.0691e-01],\n",
      "          [ 3.6431e-02, -2.4226e-01,  1.4608e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([384, 1, 3, 3])\n",
      "\n",
      "Layer: features.11.conv.1.1.weight\n",
      "Weights: tensor([0.7270, 0.7479, 1.1373, 0.5958, 0.8306, 0.6505, 0.6371, 1.2207, 0.8265,\n",
      "        0.7315, 2.0185, 0.7965, 0.7867, 1.8377, 1.1576, 0.7019, 0.6082, 0.8035,\n",
      "        1.2279, 1.9053, 0.8237, 1.0353, 1.7569, 0.7661, 1.2023, 0.6416, 0.5145,\n",
      "        0.7261, 0.8418, 0.8416, 0.9299, 1.2667, 0.6132, 0.4586, 0.8898, 2.2488,\n",
      "        0.9692, 0.5341, 3.3451, 1.0796, 1.9557, 0.6791, 0.7075, 0.9297, 1.6600,\n",
      "        0.7631, 0.7147, 0.6056, 0.4528, 0.6160, 0.4950, 0.7959, 0.5548, 0.9853,\n",
      "        0.7914, 0.6622, 0.7386, 0.7900, 0.5453, 0.8785, 0.4771, 0.8693, 0.6546,\n",
      "        0.5385, 0.9758, 0.8971, 0.9619, 0.7522, 0.7927, 1.6277, 0.8276, 0.8854,\n",
      "        0.5703, 0.5371, 1.2829, 0.8865, 0.7457, 0.7138, 0.5961, 0.6749, 0.7415,\n",
      "        0.5293, 0.6896, 0.9605, 0.9791, 0.6505, 0.8116, 0.7440, 0.7888, 1.6663,\n",
      "        0.7843, 0.8548, 0.9571, 0.4725, 0.5398, 0.7171, 0.8996, 0.8165, 0.8495,\n",
      "        0.8072, 0.8331, 0.6450, 1.0667, 0.8345, 0.7268, 0.6255, 1.0175, 0.4950,\n",
      "        0.7097, 0.8315, 0.9642, 0.6736, 0.6048, 0.8322, 0.7003, 0.8069, 1.4822,\n",
      "        0.8345, 0.7724, 0.9485, 0.7073, 0.7543, 0.7478, 0.5449, 3.4346, 0.6551,\n",
      "        1.0346, 0.8637, 1.0328, 0.7548, 0.6749, 1.1997, 1.3149, 0.6782, 0.9485,\n",
      "        1.3427, 0.5906, 0.6536, 0.6193, 0.5883, 0.6696, 0.5858, 0.6769, 1.0203,\n",
      "        0.8515, 1.2669, 0.6042, 0.6664, 0.8512, 0.5554, 0.8028, 0.7480, 0.6027,\n",
      "        0.8031, 1.1505, 0.6251, 0.7121, 1.0819, 0.8353, 0.6777, 0.8722, 0.8208,\n",
      "        0.7020, 0.9163, 1.5501, 0.5826, 0.7021, 0.6662, 0.5233, 0.9753, 1.3113,\n",
      "        0.7583, 0.6093, 0.8055, 0.8098, 0.6307, 0.8559, 0.6912, 1.2572, 1.0509,\n",
      "        1.2084, 1.5229, 0.9761, 0.8460, 0.7293, 0.7312, 0.8771, 1.2177, 0.7529,\n",
      "        1.3131, 0.6798, 2.0793, 0.8025, 0.8259, 0.7215, 0.9370, 0.7272, 0.9950,\n",
      "        0.7930, 0.9912, 0.7391, 0.6816, 0.7962, 0.5858, 1.3346, 0.8408, 0.7772,\n",
      "        0.6631, 0.8775, 0.6703, 1.4361, 0.9882, 0.7134, 0.6764, 0.8705, 0.9107,\n",
      "        1.0788, 0.6841, 0.7532, 0.8218, 0.6473, 1.4338, 0.6951, 0.6745, 0.6619,\n",
      "        0.6254, 0.7131, 0.9320, 0.6440, 0.6385, 0.6025, 1.0990, 0.7886, 0.8952,\n",
      "        0.9314, 0.5493, 0.8787, 0.6425, 0.6635, 0.7359, 0.9046, 0.6840, 0.7978,\n",
      "        0.8032, 0.5566, 0.7548, 1.0174, 0.7525, 0.7087, 1.2543, 0.7133, 0.6744,\n",
      "        1.5243, 0.9268, 0.6449, 0.5402, 0.8720, 1.7201, 1.1387, 0.6762, 0.7131,\n",
      "        0.9676, 0.6892, 0.7078, 0.6438, 1.7138, 0.8746, 0.8389, 0.7103, 0.5969,\n",
      "        1.1124, 0.9600, 0.5753, 1.0062, 1.1421, 0.8193, 0.6274, 0.8513, 1.9196,\n",
      "        0.7631, 1.3097, 0.4109, 1.3187, 0.8176, 0.5891, 0.7980, 0.7067, 0.6694,\n",
      "        0.8316, 3.4203, 0.7932, 0.6500, 0.7696, 0.5747, 0.6649, 0.8984, 0.4764,\n",
      "        1.4736, 0.7643, 0.7376, 0.9177, 0.6678, 1.0372, 1.1685, 0.7178, 0.5562,\n",
      "        0.8355, 0.6710, 1.4381, 1.3558, 0.8504, 0.8362, 1.1143, 0.5807, 0.8834,\n",
      "        0.6623, 0.9477, 0.7242, 0.8142, 0.8237, 1.0392, 0.9581, 0.6093, 0.8760,\n",
      "        0.8382, 0.8999, 1.6040, 0.5367, 0.7212, 0.7547, 1.4964, 0.8707, 0.8443,\n",
      "        0.7465, 1.6708, 1.0172, 1.3960, 0.9208, 0.8899, 1.7391, 0.8549, 0.7335,\n",
      "        0.7038, 0.6826, 0.5785, 0.7276, 0.5382, 0.5855, 0.8016, 0.7059, 0.4428,\n",
      "        0.6978, 0.9461, 0.4958, 0.7659, 1.5768, 0.8209, 0.8476, 0.7134, 0.7769,\n",
      "        2.3742, 0.9350, 0.7732, 0.7299, 1.2093, 1.4640, 0.7840, 0.6077, 0.9116,\n",
      "        0.9228, 1.2770, 0.8830, 0.8032, 0.6061, 0.6567, 1.1066, 1.0420, 0.6708,\n",
      "        0.6988, 0.7185, 0.7085, 0.7977, 0.9331, 1.0114], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.1.1.bias\n",
      "Weights: tensor([ 7.3851e-01,  7.3549e-01, -4.4571e-01,  1.5337e-02,  1.3252e+00,\n",
      "         3.1545e-01,  3.2549e-01, -1.0135e-01,  4.2000e+00,  6.7198e-01,\n",
      "        -1.3562e+00,  4.5963e-01,  5.4034e-01, -2.2089e+00, -1.6174e+00,\n",
      "         4.7691e-01,  2.2349e+00,  2.0955e-01, -7.3506e-01, -2.3936e+00,\n",
      "        -1.0213e-01,  2.6030e+00, -1.0869e+00,  8.1308e-02, -8.8340e-01,\n",
      "         3.1841e-01,  6.5252e-01,  3.8198e-01, -1.3247e+00,  1.8835e-01,\n",
      "         3.4111e+00, -1.7249e-01, -4.0365e-01,  3.2976e+00,  8.7287e-02,\n",
      "        -1.1388e+00, -4.9168e-01,  1.0686e+00, -3.3419e+00, -6.4303e-01,\n",
      "        -3.7007e-01,  3.0134e+00,  5.8837e-01,  4.3376e+00, -5.3020e-01,\n",
      "         3.7002e-01,  2.8680e+00,  3.8818e-02,  1.9981e+00,  1.8261e+00,\n",
      "         2.2149e+00,  1.8790e+00,  2.1520e+00,  3.8436e+00, -4.9147e-01,\n",
      "         2.3394e-01,  2.1055e-01, -1.2290e-01,  2.6487e-01, -1.2890e-01,\n",
      "         3.3885e-01,  7.2316e-02,  5.1825e-01,  1.6557e+00,  2.8751e+00,\n",
      "         5.6288e-01,  2.2747e-01,  4.4823e-02,  2.2619e-01, -8.4554e-01,\n",
      "         2.8067e+00,  1.1969e+00,  1.1362e+00,  2.0176e+00, -1.4145e+00,\n",
      "         2.8155e-01,  4.3017e-01,  2.7309e-01,  4.0158e+00,  4.4956e-01,\n",
      "        -3.9287e-01,  1.5840e+00,  4.1709e-01, -9.9363e-01, -9.1442e-01,\n",
      "         2.6534e+00,  1.6490e+00, -7.0156e-02,  7.1433e-02, -7.7910e-01,\n",
      "        -4.0313e-01, -7.8682e-01, -1.2442e+00,  1.5552e+00,  7.4173e-02,\n",
      "         1.1959e+00,  1.1995e-01,  8.8195e-02,  2.2225e-01,  2.2265e+00,\n",
      "         3.1682e-01, -6.4946e-01,  9.7244e-02,  3.0827e+00, -9.1679e-01,\n",
      "         3.1239e+00,  5.7486e-02,  3.0691e-01,  3.9116e-01,  1.2096e+00,\n",
      "         6.7613e-01,  2.0232e-01,  1.7679e-01,  1.9411e-02,  3.6331e+00,\n",
      "         2.8731e+00, -5.5937e-01,  6.0676e-01,  6.9554e-01,  1.6689e+00,\n",
      "         5.4996e-01, -1.0961e-01,  2.2259e+00,  3.1971e+00, -3.3467e+00,\n",
      "         5.2047e-01,  7.3346e-01,  6.2727e-01,  8.8583e-02,  3.4419e-01,\n",
      "         1.7316e-02, -5.8806e-01, -2.8673e-01,  9.7336e-01, -1.9140e-01,\n",
      "        -2.7065e-01, -1.4633e-01,  1.1563e+00, -1.7330e-01, -1.2259e-03,\n",
      "        -1.5208e-01, -2.8551e-01,  6.9069e-01, -3.0556e-01,  1.0800e+00,\n",
      "        -1.3643e-01, -1.6767e-01,  2.3058e+00,  3.9010e+00,  3.2470e+00,\n",
      "         4.7368e-01,  4.7232e-01,  3.2868e+00, -1.2775e-01, -2.8666e-01,\n",
      "        -2.3898e-01,  2.3393e-01,  3.3489e-01,  1.2214e+00,  9.3957e-01,\n",
      "         1.7790e+00,  2.6644e+00, -2.4961e-01,  4.6497e-01, -7.2387e-01,\n",
      "         2.3885e-01,  9.4110e-02, -8.0530e-02,  3.4392e+00, -3.9067e-01,\n",
      "        -7.7182e-01,  1.7792e+00,  4.2342e-01, -3.3165e-01, -1.1893e-01,\n",
      "         3.8718e+00,  4.3652e-01,  2.6460e+00, -4.7476e-01, -3.4953e-02,\n",
      "        -1.2668e-01, -8.6223e-01,  5.7717e-01,  1.1318e+00,  4.2533e-01,\n",
      "         3.8108e-01, -5.2585e-01, -1.2048e+00,  2.5537e-01, -9.1395e-02,\n",
      "         7.1151e-01, -1.3963e+00,  3.6598e-01, -5.3852e-01,  2.8181e-01,\n",
      "         1.3814e+00,  2.5139e+00,  1.2285e+00, -8.2660e-01,  2.7550e-01,\n",
      "         4.9912e-01,  2.0420e+00,  1.6861e+00,  1.6091e-01, -2.5898e-01,\n",
      "         5.4164e-01,  7.4250e-01, -3.7358e-01,  8.7416e-02,  1.2915e+00,\n",
      "        -4.9335e-01, -1.9283e-01,  1.2425e+00,  2.8761e+00,  3.9685e-01,\n",
      "        -8.1801e-01,  9.6430e-02,  5.6361e-01,  7.5770e-01,  1.6491e+00,\n",
      "         1.9638e-01, -2.5259e-01,  6.6849e-01,  4.0595e-01,  1.1426e+00,\n",
      "         5.6511e-01, -2.2427e-01,  5.0051e-01,  4.3231e-01,  2.0512e-01,\n",
      "         4.6073e-01, -3.0768e-01,  2.7112e+00, -7.9873e-02,  1.4219e+00,\n",
      "         3.1466e-01, -1.0306e-02,  6.6097e-01,  3.2097e+00,  6.6619e-01,\n",
      "         8.3433e-02,  2.4626e+00, -7.4078e-01,  1.6184e+00, -2.5986e-03,\n",
      "         1.5049e+00,  7.4849e-03, -1.6659e-01, -3.2683e-01, -3.5083e-01,\n",
      "         1.8460e+00,  4.4711e-01, -1.2574e+00,  8.7386e-01, -3.3008e-02,\n",
      "        -1.9937e-01, -4.7572e-01, -8.6988e-01, -6.5205e-01,  3.1576e-02,\n",
      "         9.8169e-01,  2.3211e-01, -5.3487e-02,  8.8117e-01,  1.4322e+00,\n",
      "        -5.3620e-01,  2.5385e-01,  2.8238e+00,  1.3947e+00,  2.3077e-01,\n",
      "         3.4623e+00,  9.4043e-01,  3.9674e+00, -4.0259e-01, -1.0833e+00,\n",
      "         5.1012e-01,  2.2164e-01,  2.3634e-01, -1.2147e+00,  2.2369e-01,\n",
      "         2.4050e+00,  3.5888e-01, -9.9776e-01,  2.3825e-01,  7.6572e-01,\n",
      "        -7.0855e-01,  4.7220e-02,  1.3056e+00,  2.8891e+00, -8.2598e-01,\n",
      "         3.5338e-01,  2.5313e+00,  5.2007e-01,  2.8876e-01,  2.3199e+00,\n",
      "         1.0083e+00,  3.3694e-01, -4.0320e-01,  1.6390e+00,  2.1507e-01,\n",
      "         1.5326e+00,  3.2514e-01, -1.6963e-01, -2.4290e-01, -1.0427e-01,\n",
      "         6.7288e-02,  3.3325e-01, -3.2756e-01, -7.7695e-01, -1.1303e+00,\n",
      "        -3.5389e-01,  3.5189e+00, -2.3770e-01,  9.1936e-01,  3.7517e+00,\n",
      "         4.6934e-01,  3.1354e-01,  3.6663e-01,  2.7689e+00,  2.8366e+00,\n",
      "         3.7699e-01,  2.1191e+00, -2.2876e-01, -8.0470e-02,  1.7080e+00,\n",
      "        -1.2786e-01, -2.9619e+00,  3.6572e-01,  1.0359e+00,  1.9434e+00,\n",
      "        -5.8175e-01,  1.5777e+00,  5.2208e-01,  1.7799e+00, -5.7440e-01,\n",
      "         1.4760e-01, -7.7315e-01,  4.7193e+00,  2.1117e+00, -7.4468e-01,\n",
      "         3.8568e-01, -4.8341e-01, -1.9333e-01,  3.1464e-01,  4.4727e-01,\n",
      "        -1.0360e-01,  6.6191e-01,  3.1211e-01,  2.8075e-02, -7.5305e-03,\n",
      "         2.7576e+00,  5.3324e-01,  4.2957e-01,  1.4722e+00,  4.0007e+00,\n",
      "         4.7229e+00, -9.4386e-01, -3.3874e-01, -7.1062e-01, -6.2849e-01,\n",
      "        -2.6164e+00,  3.8077e+00,  2.3474e-01, -1.8497e-01, -8.9474e-01,\n",
      "        -9.2402e-01,  1.2277e-01,  2.3629e-01,  3.5288e+00,  1.0353e+00,\n",
      "        -1.1109e+00, -5.4483e-01,  1.2381e+00,  5.9471e-01,  1.8784e+00,\n",
      "        -5.8136e-02, -1.0474e+00,  2.3388e-02,  7.2995e-02, -3.8702e-01,\n",
      "         1.1071e+00,  1.2868e+00,  3.6389e+00,  3.5779e-01], device='cuda:0')\n",
      "Shape: torch.Size([384])\n",
      "\n",
      "Layer: features.11.conv.2.weight\n",
      "Weights: tensor([[[[-0.0610]],\n",
      "\n",
      "         [[-0.0040]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1468]],\n",
      "\n",
      "         [[ 0.1996]],\n",
      "\n",
      "         [[ 0.0240]]],\n",
      "\n",
      "\n",
      "        [[[-0.0143]],\n",
      "\n",
      "         [[ 0.1642]],\n",
      "\n",
      "         [[ 0.1100]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0551]],\n",
      "\n",
      "         [[-0.1201]],\n",
      "\n",
      "         [[ 0.0318]]],\n",
      "\n",
      "\n",
      "        [[[-0.1181]],\n",
      "\n",
      "         [[ 0.0395]],\n",
      "\n",
      "         [[-0.1187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0378]],\n",
      "\n",
      "         [[ 0.0656]],\n",
      "\n",
      "         [[-0.1202]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0440]],\n",
      "\n",
      "         [[ 0.0336]],\n",
      "\n",
      "         [[ 0.0202]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0955]],\n",
      "\n",
      "         [[-0.1132]],\n",
      "\n",
      "         [[ 0.0011]]],\n",
      "\n",
      "\n",
      "        [[[-0.0852]],\n",
      "\n",
      "         [[-0.0574]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0634]],\n",
      "\n",
      "         [[-0.2565]],\n",
      "\n",
      "         [[-0.0611]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0048]],\n",
      "\n",
      "         [[-0.1114]],\n",
      "\n",
      "         [[ 0.0891]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0147]],\n",
      "\n",
      "         [[-0.0103]],\n",
      "\n",
      "         [[-0.0059]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 384, 1, 1])\n",
      "\n",
      "Layer: features.11.conv.3.weight\n",
      "Weights: tensor([2.9741, 5.5332, 3.2604, 4.0375, 2.8986, 3.1309, 2.7739, 3.1628, 3.3457,\n",
      "        2.9168, 4.2698, 3.1080, 3.9861, 5.2623, 3.5785, 3.1324, 3.9318, 2.6281,\n",
      "        3.8744, 4.6508, 4.8861, 3.2463, 2.8417, 4.5962, 4.2495, 2.6260, 2.9381,\n",
      "        4.0735, 4.0897, 4.1590, 3.2609, 4.9767, 2.8378, 4.4331, 4.9978, 2.6178,\n",
      "        2.8788, 4.0455, 2.9217, 2.3867, 2.9513, 2.9133, 4.4409, 2.4029, 3.1889,\n",
      "        4.4372, 3.5394, 4.1361, 3.6185, 3.7651, 5.3719, 2.8776, 3.1763, 4.3046,\n",
      "        2.8378, 4.8691, 2.9758, 4.4852, 3.6803, 2.6420, 3.1134, 3.6995, 2.9466,\n",
      "        4.2564, 2.7176, 3.6013, 3.4084, 3.0422, 4.1733, 2.6794, 4.1583, 3.3241,\n",
      "        3.2797, 2.6427, 3.3332, 3.1261, 2.8712, 2.9212, 3.3155, 2.4594, 3.3921,\n",
      "        3.4952, 5.2719, 2.8673, 3.7296, 2.9474, 2.6561, 2.7415, 2.8212, 2.6919,\n",
      "        4.0853, 3.1541, 3.7723, 3.0184, 3.4575, 4.1154], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.11.conv.3.bias\n",
      "Weights: tensor([-2.0243e-07, -4.8820e-07, -6.9870e-08,  1.5077e-06, -9.5832e-07,\n",
      "        -2.9177e-07, -1.5487e-06,  1.7722e-07, -2.0332e-07,  1.6077e-06,\n",
      "        -1.5140e-07,  4.6030e-09, -7.2116e-07, -1.8416e-06, -4.1749e-07,\n",
      "        -6.6610e-07, -2.7996e-07, -9.5907e-07, -9.9642e-09, -1.0053e-06,\n",
      "        -8.1612e-07,  6.7731e-07,  1.0918e-07, -1.1630e-06,  1.2033e-06,\n",
      "        -7.6328e-07,  1.0589e-06, -1.2107e-06, -1.5177e-07, -2.2695e-07,\n",
      "         7.2759e-07, -4.1832e-07, -3.5047e-07, -1.1325e-07,  1.3356e-06,\n",
      "        -1.5299e-06,  4.4778e-07,  1.2048e-06, -1.2090e-06,  1.0251e-06,\n",
      "         3.1870e-07, -3.0226e-07, -5.8349e-07,  2.2791e-06, -5.4127e-07,\n",
      "         4.0925e-07,  5.3115e-07, -1.3387e-07, -1.1326e-07, -2.2188e-06,\n",
      "         1.5248e-06, -2.3296e-07,  1.4183e-06,  2.6719e-07, -4.2346e-07,\n",
      "         3.4140e-07,  7.9001e-08,  4.8099e-07, -1.0306e-06, -1.7724e-06,\n",
      "         1.4905e-07, -2.4811e-07, -1.2946e-06,  1.1764e-06, -8.5550e-07,\n",
      "         3.5046e-08, -3.0477e-07, -1.0621e-06,  1.7086e-06,  7.2543e-07,\n",
      "         1.5367e-06, -8.7346e-08, -1.6616e-06, -2.0005e-07,  4.9133e-07,\n",
      "         4.1884e-07,  7.8050e-07, -7.7125e-07,  1.8921e-07, -1.8378e-07,\n",
      "         1.8187e-07,  2.6906e-07, -6.9544e-07,  5.7481e-07, -1.5392e-07,\n",
      "         2.4390e-07, -1.1330e-06, -1.2455e-08, -1.6742e-06,  1.5721e-06,\n",
      "         1.6854e-07, -3.2157e-07,  8.3526e-07,  8.2384e-07, -3.2154e-07,\n",
      "         1.2549e-06], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.12.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0024]],\n",
      "\n",
      "         [[ 0.0629]],\n",
      "\n",
      "         [[ 0.0657]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0781]],\n",
      "\n",
      "         [[ 0.0231]],\n",
      "\n",
      "         [[-0.0295]]],\n",
      "\n",
      "\n",
      "        [[[-0.0194]],\n",
      "\n",
      "         [[ 0.0415]],\n",
      "\n",
      "         [[-0.0348]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0156]],\n",
      "\n",
      "         [[ 0.0013]],\n",
      "\n",
      "         [[-0.0823]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1166]],\n",
      "\n",
      "         [[-0.0282]],\n",
      "\n",
      "         [[-0.0094]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.2079]],\n",
      "\n",
      "         [[-0.1185]],\n",
      "\n",
      "         [[ 0.0392]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0750]],\n",
      "\n",
      "         [[ 0.0958]],\n",
      "\n",
      "         [[-0.0510]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1194]],\n",
      "\n",
      "         [[ 0.0462]],\n",
      "\n",
      "         [[ 0.0426]]],\n",
      "\n",
      "\n",
      "        [[[-0.0072]],\n",
      "\n",
      "         [[ 0.0940]],\n",
      "\n",
      "         [[-0.0440]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0179]],\n",
      "\n",
      "         [[-0.0217]],\n",
      "\n",
      "         [[-0.0549]]],\n",
      "\n",
      "\n",
      "        [[[-0.0050]],\n",
      "\n",
      "         [[ 0.1478]],\n",
      "\n",
      "         [[ 0.0473]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0630]],\n",
      "\n",
      "         [[-0.0064]],\n",
      "\n",
      "         [[-0.0173]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 96, 1, 1])\n",
      "\n",
      "Layer: features.12.conv.0.1.weight\n",
      "Weights: tensor([0.7594, 1.1064, 1.1134, 1.1040, 1.0824, 1.2655, 0.5072, 1.2841, 1.3580,\n",
      "        0.9926, 1.0181, 0.8181, 1.3877, 1.4232, 1.1767, 1.2266, 1.1949, 1.0320,\n",
      "        1.2356, 0.9549, 1.0766, 0.9764, 0.8662, 1.0245, 1.1646, 1.2725, 1.1435,\n",
      "        1.0536, 0.7598, 1.3088, 1.3005, 1.1798, 1.2387, 0.7272, 1.2152, 1.3525,\n",
      "        0.7503, 0.7965, 1.1013, 1.3179, 1.2801, 1.0357, 1.1546, 1.1366, 1.3002,\n",
      "        0.6004, 1.3330, 0.9353, 1.2064, 1.3403, 1.3019, 1.3529, 1.1263, 1.0709,\n",
      "        1.3626, 1.0189, 0.4106, 1.2049, 1.0061, 1.1658, 1.1716, 1.2699, 1.0206,\n",
      "        1.1483, 0.8508, 1.0712, 1.2537, 1.2533, 1.0386, 1.0715, 1.0928, 1.2500,\n",
      "        0.8601, 0.7399, 1.0890, 1.1374, 1.0216, 1.3330, 1.2934, 1.3617, 1.2659,\n",
      "        0.9717, 1.2401, 1.1664, 1.2791, 1.2996, 1.3638, 1.1917, 1.0590, 0.5950,\n",
      "        0.7919, 0.5684, 0.9987, 2.1275, 1.1426, 1.2353, 1.1251, 1.5497, 0.7368,\n",
      "        1.2045, 0.9341, 0.9501, 1.2485, 1.2099, 0.9014, 0.9312, 1.1487, 1.1847,\n",
      "        0.6648, 0.9201, 1.2186, 1.5022, 1.1115, 1.0537, 1.1492, 1.1466, 1.0609,\n",
      "        1.3012, 1.2213, 1.2418, 1.1595, 0.7429, 1.0704, 0.8080, 1.0181, 1.1132,\n",
      "        1.0508, 1.0581, 1.1127, 0.9418, 1.1973, 1.0076, 1.3314, 1.1090, 1.1521,\n",
      "        0.8179, 1.4207, 1.2080, 1.2884, 0.9751, 1.1951, 1.1980, 1.2184, 1.2027,\n",
      "        1.1604, 1.2604, 1.0840, 0.8806, 0.9959, 3.5900, 1.0088, 1.0545, 1.1393,\n",
      "        1.4067, 1.0152, 1.3979, 0.5362, 0.9811, 1.1631, 1.2612, 0.4815, 1.3638,\n",
      "        1.1203, 1.1804, 1.3027, 1.1182, 0.8836, 1.1096, 0.8778, 1.1804, 1.2946,\n",
      "        1.1795, 1.1624, 1.0817, 1.2229, 0.9853, 1.1210, 1.0527, 1.1382, 1.0302,\n",
      "        1.1663, 1.3470, 1.2351, 1.3298, 1.1916, 0.8817, 1.3211, 1.1219, 1.0470,\n",
      "        1.2064, 0.7759, 1.0010, 1.0756, 1.3333, 1.0700, 1.3184, 1.1978, 0.7726,\n",
      "        1.1102, 1.3539, 1.3467, 0.8705, 1.1323, 0.8064, 0.9680, 1.1137, 1.1817,\n",
      "        0.9932, 1.2301, 1.0522, 1.0327, 1.1880, 1.1647, 1.3468, 1.2920, 0.8675,\n",
      "        1.1650, 1.0893, 1.1524, 1.1468, 1.0817, 0.8214, 1.2529, 0.8981, 1.0887,\n",
      "        1.1049, 1.2498, 0.6590, 1.0183, 1.1166, 1.1526, 1.3800, 1.3553, 1.0348,\n",
      "        1.3621, 1.2765, 1.3541, 1.0487, 0.9527, 1.2360, 1.2018, 0.7915, 1.1238,\n",
      "        1.3006, 0.3665, 1.3565, 1.2798, 1.1887, 1.0869, 1.2386, 1.2056, 1.0624,\n",
      "        1.3634, 1.3102, 0.8440, 0.8190, 1.2233, 0.7065, 0.6642, 1.4104, 0.6924,\n",
      "        1.0342, 1.5235, 1.1452, 1.1956, 1.1999, 0.8511, 1.3930, 0.5254, 0.6328,\n",
      "        1.1367, 1.2651, 0.9815, 1.1093, 0.8287, 0.8107, 0.7770, 1.1429, 1.1958,\n",
      "        1.2634, 1.0049, 1.0931, 1.1487, 1.1811, 0.8517, 0.6480, 1.1450, 1.1402,\n",
      "        1.2028, 1.4769, 0.9994, 1.0214, 0.9869, 1.0554, 1.1372, 1.4214, 1.3911,\n",
      "        1.2301, 1.2093, 1.0439, 1.3263, 0.4175, 1.1690, 1.0576, 1.2168, 1.1388,\n",
      "        1.2452, 1.0525, 1.4911, 1.4570, 0.3893, 1.1783, 1.0511, 1.3735, 0.7776,\n",
      "        1.1013, 0.7344, 1.2958, 1.1121, 0.4722, 0.7511, 1.2411, 1.1639, 1.1671,\n",
      "        1.3035, 0.9470, 1.2139, 1.1585, 1.1924, 1.7824, 1.0011, 1.0021, 1.5084,\n",
      "        1.2822, 0.8105, 1.0653, 1.0867, 1.5717, 1.2011, 2.4077, 1.0112, 1.3135,\n",
      "        1.0240, 1.3082, 1.2119, 1.0426, 0.9859, 1.1096, 1.0509, 1.3342, 0.9093,\n",
      "        1.3384, 1.2047, 0.8537, 1.0012, 1.2759, 0.6288, 1.2908, 1.1721, 1.2363,\n",
      "        0.8440, 1.2120, 1.0431, 1.2122, 0.8342, 0.7803, 1.1043, 1.1553, 1.1310,\n",
      "        1.2127, 1.0870, 0.9738, 1.1847, 1.1181, 0.9195, 1.4009, 1.0893, 0.9074,\n",
      "        0.4990, 1.0929, 0.9645, 1.0095, 1.4290, 0.9787, 0.7954, 1.2488, 1.1382,\n",
      "        1.0756, 0.7223, 0.8321, 0.9225, 1.7372, 1.2359, 1.3951, 1.3569, 0.9617,\n",
      "        0.9043, 1.1223, 1.0691, 1.2812, 1.2498, 0.8007, 1.1504, 1.1175, 0.8172,\n",
      "        1.1084, 1.0665, 1.2629, 0.9825, 0.8650, 1.1250, 0.5073, 1.3942, 0.8534,\n",
      "        1.1759, 1.2897, 0.9592, 1.4290, 1.0974, 1.1608, 1.3180, 0.9064, 1.2914,\n",
      "        1.2028, 1.5255, 1.2608, 1.3337, 2.8321, 0.9823, 0.7875, 1.0029, 1.1246,\n",
      "        1.1279, 1.4547, 1.3344, 1.3611, 1.0541, 1.3993, 1.3057, 1.2199, 1.2780,\n",
      "        1.1590, 1.5576, 1.2044, 0.9628, 1.2474, 1.0255, 1.1953, 1.1854, 0.6371,\n",
      "        0.9924, 1.2883, 1.3162, 1.0738, 0.5925, 1.3987, 1.1331, 1.0662, 1.2911,\n",
      "        0.8244, 0.4484, 1.2890, 0.6921, 1.1634, 1.2448, 1.2487, 0.8683, 1.3288,\n",
      "        1.1543, 1.2579, 1.2266, 0.9958, 1.2095, 1.0910, 1.1160, 0.7133, 0.9379,\n",
      "        1.1857, 1.0273, 1.2023, 1.0572, 0.7486, 0.4913, 1.0360, 1.0928, 1.1841,\n",
      "        0.9025, 1.1203, 1.3334, 0.9276, 1.1947, 1.1863, 1.0256, 1.0752, 1.1428,\n",
      "        0.9104, 1.2557, 1.2460, 1.0736, 1.0096, 1.2858, 0.8826, 1.1557, 0.9107,\n",
      "        1.1561, 1.3161, 0.8715, 1.0842, 1.1062, 0.6495, 0.9292, 1.3803, 1.0906,\n",
      "        1.6002, 1.3953, 0.9303, 1.2051, 1.3240, 1.4497, 1.3563, 1.1684, 1.0023,\n",
      "        1.2438, 0.8602, 0.6066, 1.3455, 0.9111, 0.6813, 0.6507, 0.6316, 1.2209,\n",
      "        1.2586, 0.4542, 0.7673, 1.1349, 1.2082, 1.1843, 1.2011, 2.1799, 1.3677,\n",
      "        1.2789, 1.2324, 1.2958, 1.0403, 1.2362, 0.4359, 0.7223, 0.8642, 1.1085,\n",
      "        1.2551, 1.3478, 1.1803, 0.5649, 1.0757, 1.0277, 1.1622, 0.9007, 1.2547,\n",
      "        1.1263, 1.0676, 0.9878, 1.1433, 1.3520, 0.6851, 1.3245, 0.9984, 0.9998,\n",
      "        1.0053, 1.0668, 0.6820, 1.0333, 1.0217, 1.1859, 1.0046, 1.0133, 0.7727],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.0.1.bias\n",
      "Weights: tensor([-0.0203,  0.1077, -0.4481,  0.3536, -0.7823, -1.1826,  1.1160, -0.9622,\n",
      "        -0.1455, -0.5723, -1.3229,  0.1494, -0.3831,  0.5368, -0.0607,  0.2174,\n",
      "         0.3153, -0.2389, -1.7505, -1.3642,  0.3722,  0.6254, -0.8842,  1.4759,\n",
      "        -0.9487, -0.6390,  0.5313, -0.7817,  0.1341, -0.3555, -0.6292,  0.2146,\n",
      "        -1.1371,  1.2961, -1.1607, -1.1768,  0.9630,  0.9533, -0.9130, -0.5646,\n",
      "        -0.6221,  0.7541, -0.0058, -0.4986, -1.5709,  1.2741, -0.9130, -1.2433,\n",
      "        -0.3180, -1.3259, -0.4626, -1.1289,  1.7128,  0.4996,  0.2715, -0.6211,\n",
      "         1.2948, -0.6960, -1.2618, -0.2493, -0.3225, -0.2762, -0.7404, -0.8966,\n",
      "         0.8287, -0.9149, -1.1568, -0.6368,  1.8644,  0.5022, -0.5686, -0.7332,\n",
      "         0.9036,  1.1223,  0.5909, -0.5223,  0.4831, -0.6630, -0.9076, -0.6310,\n",
      "        -0.3758,  0.8322, -0.5036, -0.5983,  0.0941, -0.5983,  1.4446, -0.7842,\n",
      "         1.8090,  1.1291,  1.0660,  1.2092, -1.1585,  1.6444, -0.5230, -1.4019,\n",
      "        -0.4904, -0.5640,  1.0493, -1.1509, -1.0883, -0.9309, -0.1463, -0.5138,\n",
      "         1.0362, -0.9644,  0.6918,  0.2130,  1.0201,  0.7875, -1.1006, -1.1872,\n",
      "        -0.6590, -1.0851,  0.8419,  0.2083, -0.9872, -0.3242, -0.3951, -0.2952,\n",
      "        -1.4502,  0.9878, -1.0613,  0.9004,  0.4940, -2.0278, -0.8066, -0.5686,\n",
      "         0.4857,  0.7671,  0.1912,  0.4118, -0.6217,  1.0116, -0.5918,  0.8278,\n",
      "         0.0268, -0.4636, -0.7921,  0.6986, -0.4066, -0.3636, -2.1904, -0.4583,\n",
      "        -0.4938, -0.1352, -1.1813,  0.9209, -0.2497,  0.9673, -0.5545,  1.1211,\n",
      "         0.4321, -0.3027, -0.4893, -0.4295,  1.3061, -1.3529, -0.4158, -0.3760,\n",
      "         1.2575, -1.3498, -1.1114,  0.3520, -0.7047, -0.7068, -0.1985, -0.3442,\n",
      "         1.0806, -0.9606, -1.4305, -1.0362, -1.8104, -0.1445, -0.5125,  0.4875,\n",
      "         0.6840, -0.0372, -0.3344,  0.3660, -1.7536,  0.1931, -0.2430, -0.8781,\n",
      "        -0.3588,  1.1301, -0.3476, -1.0047,  0.6586, -0.7074,  0.9200, -1.2560,\n",
      "         0.1114,  0.0341,  0.2145,  0.0469,  0.1058,  0.8834, -0.3051, -0.4733,\n",
      "        -0.3888,  0.6855, -0.1786,  0.9710,  0.6930, -1.6657, -0.7414, -0.6999,\n",
      "         0.3444, -0.5981, -1.2141, -0.3307, -0.5679,  0.2207, -1.5616,  0.7742,\n",
      "        -0.7898, -0.2977,  0.5579, -0.4155, -0.9036,  0.8905, -0.5863,  0.8620,\n",
      "         0.1208,  0.0799,  0.2416,  1.0630, -0.5931, -0.3087, -0.8004, -0.2263,\n",
      "        -0.2625,  0.7086, -0.4142, -0.4338, -0.3942, -0.5089, -1.8433, -0.2722,\n",
      "        -1.2949,  1.5783, -0.5178, -1.1342,  1.4929, -0.2673, -0.8445, -0.4742,\n",
      "        -0.7723, -0.2038, -0.3284, -0.7931, -0.8864, -0.8143,  1.7137,  0.7791,\n",
      "        -0.9282,  0.5892,  0.9324, -0.3290,  1.0478,  0.6328, -0.8427, -0.2438,\n",
      "        -0.9944, -0.1634,  1.0415,  0.1271,  1.5426,  1.1661, -0.6123, -0.5170,\n",
      "        -1.3553, -1.2130,  0.6016,  0.8296,  1.0180, -1.5339,  0.1849, -0.7673,\n",
      "         0.7016, -0.8372,  0.2788, -0.9649,  1.0099,  1.1213, -0.7317, -0.2986,\n",
      "        -0.4299, -0.0905, -0.9613,  0.3332, -1.0449,  1.1246, -0.5923,  0.3384,\n",
      "        -0.7794,  0.1605, -0.4377, -0.9393, -0.8918,  1.2392,  0.2499, -1.0494,\n",
      "         0.9426, -1.1892, -0.1211,  0.7823, -0.8405, -0.3173,  1.6458,  0.1837,\n",
      "        -0.7861, -1.3125,  1.0233, -0.3617,  0.0294, -0.9505,  1.7220,  1.3329,\n",
      "         1.1693,  0.1442, -0.1146, -0.3431, -0.7092,  0.7841,  0.1143, -0.3184,\n",
      "        -0.8742, -0.2077, -0.5182, -0.8943, -1.4850,  0.0772,  0.9799, -1.1324,\n",
      "         0.4059, -0.6786, -0.5606, -0.3850,  0.4889, -1.2650,  0.6659, -0.9783,\n",
      "        -1.1068, -0.8386,  0.5612,  1.8278,  0.6380, -0.8829,  0.7750, -0.4572,\n",
      "         0.2229,  0.9251,  0.7157, -0.0487,  1.0651,  0.7988, -1.1671, -0.6217,\n",
      "         1.5175, -0.6479,  0.0353, -0.0257, -0.2374,  1.0639, -0.1375,  0.4640,\n",
      "        -0.8372, -0.5072,  0.9480, -1.5917, -1.0715,  0.3461, -0.9014, -0.9888,\n",
      "         0.0819,  0.7485,  1.4193,  0.4095,  0.6989,  0.8840,  0.3299, -0.9597,\n",
      "         0.9292, -1.1574, -0.3039, -1.3465,  1.1911,  0.8198,  0.9575,  0.2285,\n",
      "         0.2822, -0.6630, -1.0965, -0.8857,  0.7217, -0.9302,  0.6366,  0.2143,\n",
      "        -0.9629,  1.6650,  0.1615, -1.1545,  0.7701, -0.4936, -1.1289, -0.3316,\n",
      "        -0.6327,  0.9757, -1.3797,  0.9910, -0.9189,  0.9264, -1.0752, -0.0165,\n",
      "        -1.4630, -0.0193,  0.6926, -0.3484,  1.4911,  0.9454, -0.3153,  0.2820,\n",
      "         0.2633, -0.5402,  0.3417, -0.1181,  0.7823,  0.7177, -1.3429,  0.7656,\n",
      "        -0.4643,  0.1040, -0.3013, -1.1809, -0.7690,  0.0654, -1.1184, -0.3854,\n",
      "         0.5948, -0.4908,  1.0384, -0.8512,  0.8340,  0.0572, -0.8085, -0.5127,\n",
      "        -0.3778,  1.0267,  0.5011, -0.4411,  0.9047, -0.9646,  1.2831, -0.4127,\n",
      "         0.3210, -1.0962,  0.2295,  1.0944,  2.6226, -0.4814,  1.1250, -1.7387,\n",
      "         0.2137, -0.5122,  1.1955, -1.1227,  0.0431,  1.1662, -0.1080,  0.6472,\n",
      "        -0.7664, -0.7673,  0.9757,  0.4058, -1.3428, -0.5402,  0.7513, -0.7807,\n",
      "         0.7389, -0.0667,  0.6506, -1.3059,  0.2488, -0.8279,  0.9846,  0.4271,\n",
      "        -0.5092, -0.7782, -0.7228, -1.3777, -0.8181, -1.8669, -1.2679, -0.5725,\n",
      "        -0.1658, -0.7562,  0.9933,  0.9941, -0.2937,  1.4059, -1.4131,  0.8992,\n",
      "        -0.6052,  0.2530,  0.7580, -0.4844, -0.8323,  1.0647,  1.0082, -1.1124,\n",
      "        -0.6654,  1.9502, -1.0146, -1.1617,  0.3896, -0.1734, -0.6697, -0.3674,\n",
      "        -1.2886,  0.5226, -0.8277,  1.0143,  1.1877,  0.4029, -1.1714,  1.1450,\n",
      "         1.3128,  1.0496, -0.3495, -1.0058,  1.3469,  1.1624,  0.4734, -1.0472,\n",
      "        -0.7109, -0.8036, -1.1092, -0.4677, -0.5408, -0.1024, -0.8977, -0.7765,\n",
      "        -0.4485,  1.3851, -0.4757,  0.9442, -0.9680, -0.6108, -0.2888,  0.0328,\n",
      "         1.1300, -1.2357, -0.8466, -0.6994,  1.2976, -0.7381, -0.7913, -0.6992,\n",
      "        -0.6170, -0.6642, -0.7666,  1.3576, -0.9497,  0.8184, -1.6133, -0.6632,\n",
      "        -0.9331,  1.6116,  0.5895, -1.2166,  0.0251,  0.8025,  0.7678,  0.9914],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.2502, -0.0149,  0.0554],\n",
      "          [-0.3507,  0.1649,  0.1285],\n",
      "          [-0.2285, -0.0123,  0.0564]]],\n",
      "\n",
      "\n",
      "        [[[-0.1470, -0.2473, -0.1583],\n",
      "          [-0.0834,  0.1901, -0.0796],\n",
      "          [-0.0119,  0.0910, -0.0122]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0049, -0.0562, -0.0005],\n",
      "          [ 0.0460,  0.2950,  0.0577],\n",
      "          [ 0.0323, -0.0030,  0.0328]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0243, -0.0846, -0.0318],\n",
      "          [-0.1095, -0.0290, -0.1062],\n",
      "          [-0.0410, -0.0573, -0.0303]]],\n",
      "\n",
      "\n",
      "        [[[-0.0592,  0.0077,  0.0743],\n",
      "          [-0.1790, -0.1261,  0.3115],\n",
      "          [-0.0312, -0.0368,  0.0653]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0618,  0.0549, -0.0630],\n",
      "          [ 0.2736, -0.2357, -0.0828],\n",
      "          [ 0.0710,  0.0122, -0.0806]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 1, 3, 3])\n",
      "\n",
      "Layer: features.12.conv.1.1.weight\n",
      "Weights: tensor([2.4282, 1.7792, 0.9545, 0.7237, 0.4956, 0.6601, 1.4097, 0.7290, 1.5516,\n",
      "        0.6433, 0.4899, 1.9683, 1.0465, 2.0732, 0.9317, 1.0753, 0.8108, 1.0408,\n",
      "        0.3029, 0.3020, 0.9358, 1.1935, 0.4798, 1.6786, 0.8206, 1.0803, 1.0839,\n",
      "        0.5407, 2.5465, 1.6927, 0.4276, 1.5744, 0.7190, 1.8281, 0.2702, 0.8418,\n",
      "        1.0459, 1.4696, 0.6636, 1.0264, 0.4562, 1.1605, 0.7001, 0.6450, 0.4866,\n",
      "        0.9881, 0.4005, 0.5278, 7.5271, 1.6746, 1.1837, 0.9033, 1.2240, 0.8668,\n",
      "        1.2476, 1.3858, 1.9979, 0.5478, 0.3100, 0.9661, 0.8033, 0.6894, 0.5171,\n",
      "        0.6359, 1.3790, 0.8069, 0.9061, 0.5301, 1.6342, 1.0581, 0.8618, 0.8894,\n",
      "        1.7244, 1.5724, 1.3776, 0.6281, 1.2243, 1.1148, 0.9390, 1.2784, 0.5945,\n",
      "        1.9044, 1.8594, 0.5541, 1.8656, 0.5042, 1.1007, 0.8104, 2.0613, 1.9487,\n",
      "        1.5225, 1.7498, 0.3431, 0.8633, 0.7034, 0.3085, 0.5810, 0.6203, 1.3033,\n",
      "        0.3151, 0.6704, 0.4847, 0.6230, 0.4874, 1.8478, 0.4280, 0.9097, 0.8560,\n",
      "        1.6406, 1.4412, 0.5498, 0.9938, 0.9620, 0.4487, 1.3928, 0.8611, 0.8861,\n",
      "        0.5855, 0.5384, 1.0326, 0.4295, 1.0708, 0.6205, 1.6281, 0.5928, 0.3322,\n",
      "        0.6798, 0.5186, 1.4557, 1.6072, 0.7009, 0.9365, 1.0126, 0.7692, 0.8327,\n",
      "        1.2755, 1.2228, 0.9752, 0.9543, 0.8477, 1.1637, 0.7316, 0.5000, 1.3177,\n",
      "        0.5585, 1.1303, 0.5879, 1.8551, 1.4565, 1.2055, 0.8417, 2.4325, 1.6096,\n",
      "        0.5631, 0.9960, 0.5949, 1.2056, 0.7598, 0.9797, 0.9061, 1.5141, 0.3620,\n",
      "        0.6733, 1.5526, 0.5402, 0.7995, 1.0534, 1.2963, 1.0212, 0.9885, 0.4081,\n",
      "        0.7082, 0.4406, 1.0698, 1.1345, 1.5832, 1.0460, 1.0396, 0.5652, 0.9170,\n",
      "        0.4225, 0.6598, 1.2473, 1.1809, 0.9978, 1.3969, 0.5749, 0.7135, 1.6792,\n",
      "        0.5514, 1.1435, 0.5067, 1.1200, 1.1333, 1.0347, 1.4585, 1.1274, 1.7757,\n",
      "        1.0351, 1.0162, 1.1708, 1.1482, 1.4847, 1.5436, 1.6094, 0.5328, 0.8140,\n",
      "        0.6854, 1.7336, 0.6948, 0.6532, 0.9570, 0.5447, 1.3354, 0.4538, 1.1129,\n",
      "        0.7849, 1.0626, 1.2522, 0.6139, 0.7744, 1.1714, 0.8191, 1.0027, 0.9042,\n",
      "        0.6994, 1.7639, 1.7226, 0.7047, 0.9111, 0.4231, 0.6671, 0.5889, 0.9673,\n",
      "        0.5877, 0.7120, 0.6730, 0.7607, 0.3774, 0.8247, 0.4231, 0.9208, 0.7302,\n",
      "        0.8481, 1.8412, 0.6144, 0.8018, 0.5506, 0.3834, 1.5172, 0.9001, 0.8764,\n",
      "        0.8549, 0.7173, 1.1625, 1.2704, 0.6502, 1.0013, 1.2931, 1.4877, 1.3594,\n",
      "        0.7463, 0.5541, 0.5378, 0.8572, 0.9438, 0.8813, 1.1251, 1.9092, 1.2250,\n",
      "        0.8782, 1.4410, 0.3309, 0.2765, 1.5123, 1.4486, 1.6100, 0.5663, 1.2009,\n",
      "        0.5181, 1.0698, 0.3973, 1.5553, 0.9966, 1.3423, 1.6820, 0.5036, 0.8306,\n",
      "        0.9670, 1.1639, 0.4025, 1.5109, 0.4377, 1.2634, 0.9471, 1.4311, 1.1933,\n",
      "        0.6294, 0.6906, 0.8194, 0.3749, 1.6931, 1.1419, 0.5539, 1.3203, 0.4005,\n",
      "        0.6440, 2.6093, 1.0933, 0.6581, 1.9210, 1.1822, 0.7502, 0.3798, 1.2758,\n",
      "        1.0324, 1.4132, 0.4606, 2.1505, 1.6695, 0.8137, 1.8482, 0.7726, 0.8756,\n",
      "        1.1325, 1.3158, 1.1004, 1.0764, 0.7385, 1.2131, 0.7776, 0.4854, 0.8295,\n",
      "        0.6620, 1.0742, 0.5973, 1.2576, 0.7367, 0.6976, 1.6050, 1.1303, 0.8329,\n",
      "        2.2187, 0.5795, 0.4293, 0.4829, 0.9357, 1.5880, 0.6528, 0.9164, 0.9548,\n",
      "        1.3613, 1.9138, 0.6641, 0.8794, 0.9962, 1.4904, 0.7050, 1.0202, 0.6555,\n",
      "        2.9536, 0.7746, 1.0508, 0.9899, 1.9621, 1.4174, 0.9231, 2.1111, 0.4008,\n",
      "        0.7586, 0.9798, 0.3967, 0.5105, 1.4165, 0.6848, 0.4340, 1.1194, 1.4320,\n",
      "        1.3109, 0.8696, 1.8418, 1.9441, 1.7986, 0.4511, 1.1697, 0.4013, 0.9422,\n",
      "        0.3168, 0.9064, 0.8928, 1.6796, 2.2639, 1.8203, 1.0864, 0.7563, 0.7701,\n",
      "        0.9609, 0.8371, 1.2652, 2.2131, 0.6831, 1.7815, 1.6986, 0.7000, 1.1821,\n",
      "        1.0649, 0.5072, 1.1072, 1.3887, 1.1888, 0.5642, 1.0549, 0.5675, 1.9479,\n",
      "        0.6194, 1.2150, 0.5298, 1.7399, 1.6386, 0.8850, 1.1135, 1.3646, 1.7816,\n",
      "        1.3823, 2.8954, 0.5073, 1.7709, 1.4656, 1.0218, 1.0435, 0.4192, 1.1486,\n",
      "        0.6225, 1.7116, 0.6083, 0.3603, 0.5394, 1.3908, 0.5414, 0.5266, 1.7806,\n",
      "        0.9830, 2.2684, 0.7403, 1.3120, 0.8443, 0.4905, 0.9295, 0.9759, 1.6651,\n",
      "        1.4429, 0.7804, 1.3081, 0.3029, 1.3485, 0.5983, 1.5297, 0.6535, 0.9130,\n",
      "        1.3221, 2.1250, 0.9917, 1.2564, 0.5834, 1.4722, 0.4681, 1.6137, 0.3534,\n",
      "        0.7826, 2.3663, 0.9900, 1.8368, 0.7923, 0.5480, 1.3865, 1.4019, 0.4751,\n",
      "        1.0142, 2.0851, 0.9391, 1.5687, 2.7335, 1.6415, 0.6970, 1.8528, 0.4689,\n",
      "        1.7362, 0.6705, 0.8370, 0.8393, 0.4461, 0.4136, 0.4806, 0.3729, 0.2611,\n",
      "        1.0660, 1.3203, 0.7912, 1.7196, 1.6106, 0.5866, 1.3910, 0.7002, 1.7569,\n",
      "        0.6894, 1.1606, 1.2004, 1.6287, 0.6509, 1.1571, 1.4449, 0.5703, 0.9335,\n",
      "        0.9646, 0.4537, 0.4907, 0.6232, 1.5001, 1.0357, 1.4053, 0.3391, 1.1164,\n",
      "        0.4976, 0.9597, 1.6667, 1.3301, 0.9194, 1.6795, 1.1876, 1.2066, 0.8515,\n",
      "        0.9895, 1.7147, 1.4887, 1.2370, 0.5663, 0.8051, 0.7490, 4.4756, 0.7742,\n",
      "        0.8968, 1.0642, 0.6190, 0.6906, 0.5314, 1.5982, 2.1105, 1.7066, 0.3101,\n",
      "        0.8730, 1.4124, 0.9954, 1.2737, 0.4275, 0.5834, 0.7479, 2.1442, 0.7786,\n",
      "        0.7148, 0.7906, 0.8145, 1.0509, 0.9281, 2.1020, 1.0963, 1.2267, 0.4821,\n",
      "        0.5009, 0.4489, 2.2948, 1.6155, 0.3683, 1.8694, 2.2825, 1.3395, 1.2933],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.1.1.bias\n",
      "Weights: tensor([-8.0932e-01, -1.1458e+00, -2.1539e+00, -3.4944e-02,  6.0243e-01,\n",
      "        -9.5184e-01, -7.9764e-01, -4.4790e-01, -6.9726e-01, -4.8719e-01,\n",
      "        -5.8514e-01, -6.5039e-01, -1.1677e+00, -1.7226e+00, -3.0042e-01,\n",
      "        -9.0455e-01,  5.6477e-02, -2.0846e+00,  1.9696e+00,  2.0774e+00,\n",
      "        -6.0894e-01, -7.7356e-01,  1.6199e+00, -1.0844e+00, -2.6562e+00,\n",
      "        -2.2114e+00, -3.0650e-01,  1.1861e-01, -1.1113e+00, -2.1015e-01,\n",
      "         1.3017e+00, -8.8813e-01, -1.6117e+00, -2.0199e+00,  1.1959e+00,\n",
      "        -1.4172e+00, -1.9256e-01, -9.8474e-01, -5.2656e-01, -1.9984e+00,\n",
      "         6.9846e-01, -1.3315e+00, -7.4338e-02, -1.2009e-01, -4.5935e-01,\n",
      "         7.0889e-01,  7.3756e-01, -2.3757e-01, -3.6741e+00, -1.5698e+00,\n",
      "        -6.3920e-01, -1.7679e+00, -1.3115e+00,  1.2234e-02, -1.1894e+00,\n",
      "        -8.5446e-01, -2.6181e+00,  1.8864e+00,  1.9623e+00, -1.2197e+00,\n",
      "        -8.0108e-01, -5.3564e-01,  1.0920e-01, -1.5352e+00, -8.6823e-01,\n",
      "        -8.0846e-01, -1.7295e+00,  2.8383e+00, -7.2257e-01, -5.0934e-01,\n",
      "        -1.4077e+00, -1.0466e-01, -2.1656e+00, -1.3624e+00, -2.1838e+00,\n",
      "        -1.7546e-01, -1.2668e+00, -2.1400e+00, -1.7061e+00, -3.5751e+00,\n",
      "         8.9188e-01, -1.5900e+00, -7.3144e-01,  1.1616e+00, -1.2185e+00,\n",
      "         1.5260e+00, -4.8037e-01, -6.7007e-01, -2.6440e+00, -1.6013e+00,\n",
      "        -1.3425e+00, -1.1741e+00,  1.9283e+00, -2.0142e-01, -6.7792e-01,\n",
      "         1.8184e+00,  2.3860e+00, -3.9743e-01, -7.2694e-01,  1.4844e+00,\n",
      "        -1.1631e+00,  1.7579e+00,  2.4693e+00,  1.0985e+00, -1.1610e+00,\n",
      "        -8.7563e-03,  2.8343e-02, -1.8461e-02, -1.2353e+00, -1.1708e+00,\n",
      "         4.8391e-01, -2.9740e+00, -1.7134e+00, -1.4473e-01, -8.7900e-01,\n",
      "        -3.1476e-01, -1.5151e+00,  1.7042e+00,  2.2119e+00, -2.0712e+00,\n",
      "         2.5272e+00, -3.4521e-01, -1.0592e+00, -1.8490e+00,  6.3638e-01,\n",
      "        -2.5325e-02, -7.0050e-01, -1.1579e-02, -1.7567e+00, -1.0711e+00,\n",
      "         6.2337e-01, -2.9964e-01, -3.3705e-02,  8.4212e-01, -1.3612e+00,\n",
      "        -6.7699e-01, -8.4403e-01, -1.4092e+00, -1.4416e+00,  8.2640e-02,\n",
      "        -2.3956e-01,  1.4113e-01, -1.0092e+00, -3.5427e-01,  1.5644e+00,\n",
      "        -1.7942e+00, -1.2709e+00, -2.3010e+00, -3.6317e+00, -6.6137e-01,\n",
      "        -8.2339e-01, -2.3166e+00, -1.0785e+00,  6.0278e-01, -1.9012e+00,\n",
      "         1.4498e+00,  2.9083e-01, -1.9238e+00, -1.6451e+00, -9.6885e-01,\n",
      "        -1.5886e+00,  1.8849e+00, -9.0964e-01, -6.6321e-01,  1.5028e+00,\n",
      "         2.1141e-01, -2.3031e+00, -1.8189e+00, -5.6305e-02, -2.5828e+00,\n",
      "         1.4718e-01, -1.6234e+00, -5.1860e-01, -4.3839e-01, -1.8736e-01,\n",
      "        -1.6116e+00, -8.4465e-01, -1.5694e+00,  3.5765e-02, -3.5417e-01,\n",
      "         6.2846e-02,  1.8221e+00, -3.4415e-01, -3.3022e+00, -1.3070e-01,\n",
      "        -8.0286e-01,  1.6555e+00, -1.2576e+00, -1.2671e+00,  1.9582e+00,\n",
      "        -3.5472e-01, -2.5413e-01, -1.7540e+00, -1.3509e-01, -4.8881e-01,\n",
      "        -3.4612e-01, -1.2411e+00, -2.6800e+00, -1.3325e+00, -1.6855e+00,\n",
      "        -7.6053e-01, -6.0988e-01, -3.2133e+00, -8.9766e-01, -7.8407e-01,\n",
      "        -2.7126e+00, -1.2474e+00, -4.8281e-01, -1.1053e+00, -7.5748e-01,\n",
      "        -1.2171e+00,  3.5231e-02,  4.1453e-01, -1.3754e+00, -3.2979e-01,\n",
      "        -1.0288e+00, -1.7185e+00, -1.8607e+00, -1.3763e+00, -3.3111e-02,\n",
      "        -1.0448e+00, -6.7579e-01, -2.5608e-01, -2.4268e-01, -5.1690e-01,\n",
      "         5.7827e-02, -1.1857e+00, -1.8234e+00, -5.1304e-01, -8.8112e-01,\n",
      "         5.8419e-01, -1.5307e-01,  1.1777e+00, -2.1331e-01,  2.2192e+00,\n",
      "         2.9095e-01,  3.4487e-01, -3.7711e-01, -8.3142e-01, -6.4945e-01,\n",
      "         4.6079e-01, -2.5142e-01, -9.9721e-01, -2.3965e+00, -2.4828e+00,\n",
      "         1.1946e+00, -1.0406e+00,  4.2025e-01,  1.9842e+00, -3.6943e-01,\n",
      "        -1.2033e+00, -1.4625e+00, -1.8663e-03, -4.9404e-01,  5.4307e-01,\n",
      "        -6.9208e-01, -1.0511e+00, -9.1252e-01, -8.8746e-01, -6.6773e-01,\n",
      "        -9.0099e-01,  8.2044e-02,  2.1735e+00,  1.2882e-01, -1.5929e+00,\n",
      "        -6.3665e-01,  1.8061e-01, -1.4088e+00, -2.8788e+00, -4.3982e-01,\n",
      "         7.1730e-02, -5.2930e-01,  1.9640e+00,  1.4204e+00, -8.8340e-01,\n",
      "        -1.0821e+00, -1.3394e+00,  2.0239e-01, -2.0605e+00,  2.4701e+00,\n",
      "        -5.6264e-01,  1.9846e-01, -7.8620e-01, -1.4892e+00, -7.3350e-01,\n",
      "        -1.2640e+00,  1.6613e+00, -7.7084e-01,  3.3435e-02, -4.3058e-01,\n",
      "         1.0310e-01, -8.9603e-01,  1.1180e+00, -1.0972e+00, -1.8616e+00,\n",
      "        -6.8486e-01, -4.0330e+00,  9.8712e-01,  1.9643e-01, -1.8555e+00,\n",
      "         2.1691e+00, -1.5229e+00, -3.1399e-01, -5.3322e-01, -1.0043e+00,\n",
      "         1.6265e-01,  3.2754e-02, -2.5389e+00, -2.2078e+00,  1.4984e+00,\n",
      "        -2.5931e+00, -1.2881e+00, -1.4852e+00,  1.7641e+00, -8.3404e-01,\n",
      "        -2.0654e+00, -9.6257e-01,  1.1866e+00, -3.3557e+00, -1.6826e+00,\n",
      "         9.0249e-01, -9.3782e-01, -1.6744e-01, -1.5061e+00, -2.4672e+00,\n",
      "        -9.4117e-01, -9.9211e-01,  6.5697e-03, -1.8668e+00, -2.5769e+00,\n",
      "        -6.8563e-01,  1.4269e+00, -1.1487e+00,  8.2680e-01, -3.7793e-01,\n",
      "        -5.1438e-02, -8.0703e-01, -2.9866e-01,  8.5095e-01, -1.2344e-01,\n",
      "        -5.6101e-01, -1.1179e+00, -2.0259e+00,  1.0193e+00,  2.4634e-01,\n",
      "         2.3468e+00, -2.4160e-01, -7.2360e-01,  1.3661e+00, -1.3824e+00,\n",
      "        -2.0245e-01, -4.7602e-01, -6.9351e-01,  2.0528e+00,  9.8393e-02,\n",
      "        -8.4243e-01, -9.5411e-01,  1.0924e+00, -6.4743e-02, -5.3829e-01,\n",
      "        -3.2556e+00, -8.4056e-01, -1.2633e+00, -1.5120e-01, -1.3198e+00,\n",
      "        -1.2598e+00, -1.2047e+00, -1.6793e+00,  1.6157e+00, -5.3402e-01,\n",
      "        -3.8228e-01, -9.3500e-01,  8.2166e-01, -9.2249e-01, -8.5994e-01,\n",
      "         7.2473e-01, -1.3332e+00, -1.1662e+00,  6.3529e-02,  9.3258e-02,\n",
      "        -1.1359e+00, -1.6749e+00, -1.1370e+00,  1.1249e+00, -5.9948e-01,\n",
      "         2.4422e+00, -1.6797e+00,  2.2411e+00,  7.6514e-01, -1.7138e-01,\n",
      "        -1.3131e+00, -1.3288e+00, -1.3166e+00, -2.5516e+00, -2.0522e+00,\n",
      "        -9.2726e-01, -4.2768e-01, -1.8044e+00, -5.7382e-01, -1.5339e+00,\n",
      "        -7.9911e-01, -1.5493e+00, -8.1879e-01, -5.8963e-01, -6.0646e-01,\n",
      "        -5.1935e-01,  1.5311e+00, -1.2098e+00,  4.4674e+00, -5.7971e-01,\n",
      "        -3.1972e-01,  1.3471e-01,  1.8633e+00, -2.0369e+00, -1.2472e+00,\n",
      "        -2.1405e+00,  1.3699e+00, -7.9686e-01, -7.6680e-01, -1.2145e+00,\n",
      "        -3.3094e-01, -5.5803e-01, -7.0034e-01, -7.0254e-01, -1.4267e+00,\n",
      "         6.0199e-01, -1.1868e+00, -8.9215e-01, -3.9965e-01, -4.0879e-01,\n",
      "         5.4792e-02, -5.0704e-01, -1.7241e-01, -7.4222e-01,  2.0295e+00,\n",
      "         1.7037e+00, -3.8423e-01, -1.9980e+00,  1.7339e+00,  1.1139e+00,\n",
      "        -1.1971e+00, -1.6718e+00, -1.7710e+00, -1.2929e+00, -6.6464e-01,\n",
      "        -1.9437e-01,  5.4585e-01, -1.1522e+00, -1.5923e+00, -1.2858e+00,\n",
      "        -1.7372e+00, -2.4557e-01, -1.5580e+00,  1.2403e+00, -5.2539e-01,\n",
      "         2.4710e+00, -2.7286e+00, -1.2378e+00, -1.0141e-01, -4.7786e-01,\n",
      "        -3.8797e+00, -1.2020e+00, -5.0355e-01, -1.0291e+00, -7.4620e-01,\n",
      "         6.8660e-01, -1.3118e+00,  1.6219e+00,  4.3774e-02, -2.4227e+00,\n",
      "        -8.3605e-01, -1.6229e+00, -1.2333e+00, -2.7576e-01, -1.0605e+00,\n",
      "        -1.6703e+00,  2.7291e-01,  1.3722e-01, -1.2323e+00, -2.2285e+00,\n",
      "        -7.7863e-01, -9.6576e-01, -1.1675e+00, -2.1090e+00, -9.9341e-01,\n",
      "         2.3987e+00, -1.2857e+00,  1.5576e+00,  3.4685e-01, -1.3108e+00,\n",
      "         9.5441e-01,  9.1367e-01, -8.9250e-02, -9.3014e-01,  1.7949e+00,\n",
      "         1.6024e+00, -2.4577e+00, -6.5314e-01, -1.5003e+00, -1.3231e+00,\n",
      "         2.3494e+00, -8.2764e-01, -1.1047e+00, -1.2504e+00, -5.3919e-01,\n",
      "        -1.0350e+00, -8.7080e-01, -2.6022e+00, -6.8815e-01, -4.4726e-01,\n",
      "        -1.0419e+00,  7.5637e-01, -9.2546e-01,  2.7675e-01,  2.7273e+00,\n",
      "        -1.3876e+00,  6.9717e-01, -6.8049e-01, -1.9647e+00, -4.0191e-01,\n",
      "         1.5084e+00, -6.6711e-01,  2.0306e+00, -7.1832e-02, -1.1747e+00,\n",
      "        -6.7612e-01,  1.2594e+00, -9.4040e-01, -7.5183e-01, -1.1178e+00,\n",
      "        -8.0807e-01, -1.6969e+00, -1.3043e+00, -9.3966e-01, -3.7421e-01,\n",
      "         1.0133e+00, -1.1398e+00, -6.4484e-01, -2.5970e+00,  2.3351e-01,\n",
      "        -4.6400e-01, -1.3271e+00,  3.8755e-01, -1.2803e+00,  2.3033e+00,\n",
      "        -1.4908e+00,  1.8435e+00, -1.3741e+00,  1.0245e+00, -1.3083e+00,\n",
      "        -5.2057e-01, -1.2770e+00, -1.2733e-01,  3.3303e-02, -5.5523e-02,\n",
      "        -1.3380e+00, -2.3420e+00, -1.3307e+00, -8.5217e-01, -1.1927e+00,\n",
      "        -8.5589e-01, -2.3694e+00, -1.1539e+00, -2.0729e+00,  4.0806e-01,\n",
      "        -1.2590e+00, -1.2139e+00,  4.3243e-01,  2.3257e+00, -2.1106e+00,\n",
      "        -1.0345e+00,  2.5232e+00, -1.2316e+00, -1.7285e+00, -8.1632e-01,\n",
      "        -8.2319e-01], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.12.conv.2.weight\n",
      "Weights: tensor([[[[-0.0192]],\n",
      "\n",
      "         [[ 0.0299]],\n",
      "\n",
      "         [[ 0.0083]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0366]],\n",
      "\n",
      "         [[-0.0156]],\n",
      "\n",
      "         [[-0.0027]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0433]],\n",
      "\n",
      "         [[-0.0250]],\n",
      "\n",
      "         [[-0.0830]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1334]],\n",
      "\n",
      "         [[ 0.0183]],\n",
      "\n",
      "         [[-0.1385]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0186]],\n",
      "\n",
      "         [[ 0.0570]],\n",
      "\n",
      "         [[ 0.0142]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0062]],\n",
      "\n",
      "         [[ 0.0623]],\n",
      "\n",
      "         [[-0.0046]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0250]],\n",
      "\n",
      "         [[-0.0187]],\n",
      "\n",
      "         [[ 0.1177]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0618]],\n",
      "\n",
      "         [[ 0.1063]],\n",
      "\n",
      "         [[-0.0730]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0555]],\n",
      "\n",
      "         [[ 0.0230]],\n",
      "\n",
      "         [[ 0.0612]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0556]],\n",
      "\n",
      "         [[-0.0019]],\n",
      "\n",
      "         [[ 0.0068]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0401]],\n",
      "\n",
      "         [[-0.0652]],\n",
      "\n",
      "         [[ 0.0639]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1122]],\n",
      "\n",
      "         [[ 0.0915]],\n",
      "\n",
      "         [[-0.0669]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 576, 1, 1])\n",
      "\n",
      "Layer: features.12.conv.3.weight\n",
      "Weights: tensor([2.5566, 0.8799, 2.5256, 1.0240, 2.3386, 2.8116, 3.5005, 2.4960, 2.2585,\n",
      "        2.4022, 1.0821, 2.1034, 1.1050, 0.9187, 1.4641, 1.8530, 1.6998, 2.8533,\n",
      "        1.1295, 0.8574, 3.2371, 1.6772, 2.0554, 0.9517, 1.6768, 2.7320, 3.2117,\n",
      "        1.3508, 1.5073, 2.5650, 2.2337, 0.6147, 3.0230, 0.8017, 0.8199, 2.5508,\n",
      "        2.6607, 1.1814, 2.6815, 2.8206, 2.3871, 2.3340, 1.0578, 3.1964, 2.0758,\n",
      "        1.2527, 1.7326, 1.3768, 1.2452, 1.1427, 0.9360, 2.8195, 2.7087, 0.9215,\n",
      "        3.1640, 0.9920, 2.2958, 0.9024, 2.6961, 3.7496, 1.8943, 1.4735, 3.4808,\n",
      "        0.9716, 2.2611, 1.6436, 2.2246, 2.2479, 1.3220, 2.8476, 1.0036, 2.6411,\n",
      "        2.0302, 2.9014, 2.2884, 2.0796, 2.5196, 2.4327, 1.6998, 2.7087, 1.8828,\n",
      "        2.7406, 0.8264, 2.2532, 2.5534, 2.0674, 2.6120, 2.5335, 2.4617, 2.4381,\n",
      "        1.3527, 3.0385, 1.4872, 2.7635, 2.2262, 1.4745], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.12.conv.3.bias\n",
      "Weights: tensor([ 6.0900e-08, -1.7132e-07, -4.4346e-07,  1.5697e-06,  5.6462e-07,\n",
      "        -5.9357e-07, -1.3538e-06,  1.4029e-07, -4.2060e-07,  2.5664e-06,\n",
      "        -8.9918e-07, -7.0696e-07, -4.4270e-07, -7.3537e-07, -8.0812e-07,\n",
      "        -1.1608e-06, -3.1466e-07, -9.2736e-07,  1.2319e-06, -9.7317e-07,\n",
      "        -2.9163e-07,  6.8122e-07,  1.9007e-07, -9.5589e-07,  1.1879e-06,\n",
      "         3.3525e-08,  5.9936e-07, -4.4263e-07, -9.2492e-08,  4.0659e-07,\n",
      "         6.2321e-07,  1.2343e-06, -1.6967e-07, -8.6141e-08,  1.0967e-06,\n",
      "        -1.2139e-06, -2.4498e-08,  2.5625e-07, -1.3401e-06, -1.3326e-07,\n",
      "         7.5974e-08,  3.0751e-07,  2.3745e-07,  2.7966e-06,  1.1673e-07,\n",
      "        -3.7220e-07,  1.7071e-07,  7.2120e-07, -1.8418e-07, -1.2193e-06,\n",
      "         1.3361e-06,  2.3924e-07,  2.1791e-06,  1.7179e-07,  1.9085e-07,\n",
      "         8.6696e-07,  5.0692e-07,  1.5688e-06, -2.5235e-07, -6.9693e-07,\n",
      "         3.9662e-07, -6.2366e-07, -1.2281e-06,  6.6132e-07, -6.8678e-07,\n",
      "         5.5917e-09, -7.0969e-07, -9.2249e-07,  1.3493e-06,  4.5264e-07,\n",
      "         1.1563e-06,  7.7708e-08, -1.3121e-06,  1.1066e-07, -2.1409e-07,\n",
      "         2.9934e-07,  1.9704e-07, -2.8354e-07, -4.0097e-07, -6.5712e-09,\n",
      "         8.4551e-07, -1.9412e-07,  1.1275e-06,  2.4918e-07, -2.0902e-07,\n",
      "         1.1418e-06, -5.6945e-07, -4.1021e-07, -1.3950e-06,  8.4881e-07,\n",
      "        -2.4792e-07, -2.3087e-07,  9.8330e-07,  1.1036e-06, -3.8849e-07,\n",
      "         1.2057e-07], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.13.conv.0.0.weight\n",
      "Weights: tensor([[[[ 6.9506e-02]],\n",
      "\n",
      "         [[-3.0436e-01]],\n",
      "\n",
      "         [[-1.8298e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.3036e-02]],\n",
      "\n",
      "         [[-5.8360e-02]],\n",
      "\n",
      "         [[ 1.7919e-05]]],\n",
      "\n",
      "\n",
      "        [[[-7.1825e-02]],\n",
      "\n",
      "         [[ 7.4089e-02]],\n",
      "\n",
      "         [[-9.2468e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7030e-02]],\n",
      "\n",
      "         [[-6.3917e-02]],\n",
      "\n",
      "         [[ 1.0711e-01]]],\n",
      "\n",
      "\n",
      "        [[[-3.3651e-02]],\n",
      "\n",
      "         [[ 6.6046e-02]],\n",
      "\n",
      "         [[-7.9683e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.5008e-02]],\n",
      "\n",
      "         [[-4.0352e-02]],\n",
      "\n",
      "         [[ 1.4514e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0869e-01]],\n",
      "\n",
      "         [[ 5.4524e-02]],\n",
      "\n",
      "         [[-1.2877e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2411e-02]],\n",
      "\n",
      "         [[ 2.8880e-02]],\n",
      "\n",
      "         [[-1.1429e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3083e-01]],\n",
      "\n",
      "         [[ 8.4584e-02]],\n",
      "\n",
      "         [[ 1.0164e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3755e-02]],\n",
      "\n",
      "         [[ 2.8529e-02]],\n",
      "\n",
      "         [[-1.4559e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0942e-01]],\n",
      "\n",
      "         [[ 2.4684e-02]],\n",
      "\n",
      "         [[-1.3093e-01]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1508e-02]],\n",
      "\n",
      "         [[-7.3107e-03]],\n",
      "\n",
      "         [[-4.8259e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 96, 1, 1])\n",
      "\n",
      "Layer: features.13.conv.0.1.weight\n",
      "Weights: tensor([1.3129, 1.0618, 0.7200, 1.2027, 1.2718, 1.0866, 1.0842, 0.9471, 1.1074,\n",
      "        0.9508, 1.4767, 1.0490, 1.0604, 0.9947, 1.2521, 0.9903, 1.0383, 1.2287,\n",
      "        1.3168, 1.1587, 1.1425, 1.0854, 1.3487, 1.3563, 1.0245, 1.0061, 1.2161,\n",
      "        1.2119, 0.7751, 0.9133, 1.1162, 1.1046, 0.8038, 1.1261, 1.3268, 1.1021,\n",
      "        1.0180, 1.2447, 0.7256, 0.8709, 0.4411, 1.5799, 1.0443, 1.2683, 0.7446,\n",
      "        1.2719, 1.1950, 1.5865, 1.0757, 0.7835, 1.2679, 1.1946, 1.0675, 1.2318,\n",
      "        0.6320, 1.0234, 1.0827, 1.1088, 1.4074, 1.3521, 0.8974, 1.0228, 0.8644,\n",
      "        0.9510, 0.8855, 1.0914, 1.0687, 1.1979, 0.7114, 1.1609, 1.3959, 0.9946,\n",
      "        1.1130, 0.9168, 1.3126, 1.2539, 1.1357, 1.4045, 1.5096, 1.0838, 1.1538,\n",
      "        0.6779, 1.1156, 1.1276, 1.1828, 0.9958, 1.2208, 1.1785, 1.2781, 1.2800,\n",
      "        0.4491, 1.2448, 1.0671, 1.3866, 1.1853, 1.1681, 1.2599, 1.0552, 0.9769,\n",
      "        1.1391, 0.9111, 1.1001, 0.8669, 1.0563, 0.9955, 1.1489, 0.9614, 0.9816,\n",
      "        0.9896, 1.1416, 1.1443, 1.3810, 1.2908, 0.4846, 1.1871, 0.4989, 1.4014,\n",
      "        1.0956, 1.0591, 0.8586, 1.0703, 1.0453, 0.9787, 0.9072, 1.1783, 0.4811,\n",
      "        1.3998, 1.1922, 1.3140, 1.2020, 0.9656, 1.0911, 0.6768, 0.9981, 1.1826,\n",
      "        1.1181, 1.2746, 1.0999, 1.1846, 0.6863, 0.8138, 1.4665, 0.9795, 0.4337,\n",
      "        1.1977, 0.6705, 1.1631, 1.2865, 0.8715, 1.1423, 1.1292, 0.5405, 1.1027,\n",
      "        1.0993, 1.1784, 1.0654, 1.1474, 1.2254, 1.1429, 1.1735, 1.0598, 1.0654,\n",
      "        1.0796, 1.2650, 1.1115, 1.2671, 1.1915, 1.0346, 0.9940, 1.2043, 0.8977,\n",
      "        1.0947, 0.7239, 1.4571, 1.0712, 1.2287, 1.1926, 1.0028, 0.9783, 1.2926,\n",
      "        0.9655, 1.1899, 1.1259, 0.8602, 1.1860, 0.7926, 1.1168, 2.5590, 1.0953,\n",
      "        1.2097, 0.7910, 1.3285, 1.0092, 1.1975, 1.1952, 0.9178, 0.7386, 1.0510,\n",
      "        0.7376, 1.1714, 1.0528, 1.1573, 1.3372, 1.1365, 1.3110, 1.2517, 1.1887,\n",
      "        1.0085, 0.9935, 0.9156, 1.1824, 0.9357, 1.2701, 1.0550, 1.1813, 1.4455,\n",
      "        1.1943, 0.9530, 0.6520, 1.5878, 0.9144, 1.0554, 1.3685, 0.9797, 1.0870,\n",
      "        0.6975, 1.0098, 1.2240, 1.0463, 1.1554, 1.0632, 1.0978, 1.3450, 1.2912,\n",
      "        1.0816, 0.9215, 1.6081, 0.4660, 1.1378, 1.6015, 0.8906, 1.0390, 0.9744,\n",
      "        0.8568, 1.1076, 0.6379, 1.1993, 1.3284, 1.3123, 1.0091, 1.3354, 1.1221,\n",
      "        1.1206, 0.6315, 0.9109, 1.1393, 1.1778, 1.5572, 1.5241, 0.9288, 1.1048,\n",
      "        0.9926, 1.0524, 0.3631, 1.3050, 0.8990, 0.4773, 1.0395, 1.0278, 1.1300,\n",
      "        1.3414, 1.2611, 1.1289, 1.3272, 0.4039, 0.8373, 1.2432, 1.2143, 1.0308,\n",
      "        1.2759, 1.2228, 1.1821, 1.0093, 1.3454, 0.8026, 0.5041, 1.4054, 1.1766,\n",
      "        0.8456, 0.9704, 0.6301, 1.2475, 1.1624, 0.4767, 1.2807, 1.4405, 0.8213,\n",
      "        0.6578, 1.1539, 1.0873, 0.8319, 1.1546, 0.8593, 1.1199, 1.2137, 0.9010,\n",
      "        0.7823, 1.3559, 0.7087, 1.1617, 1.0567, 1.1287, 0.7434, 1.0020, 1.1926,\n",
      "        0.6755, 1.1587, 1.0516, 1.1138, 1.1823, 0.7727, 1.1625, 0.9154, 1.1492,\n",
      "        1.2106, 1.1802, 1.2727, 1.3185, 1.1623, 1.0592, 1.1130, 1.4003, 1.2998,\n",
      "        1.2054, 1.1044, 1.0144, 1.1061, 1.2095, 0.5116, 0.8698, 1.1739, 0.7052,\n",
      "        1.0875, 1.5356, 1.3684, 0.7980, 1.0604, 0.9175, 1.3008, 1.0075, 1.2371,\n",
      "        1.2768, 1.3003, 0.8126, 1.0749, 1.1761, 1.2453, 0.7871, 1.2353, 0.9494,\n",
      "        0.9589, 1.1302, 0.3915, 1.0358, 1.1361, 1.1976, 1.2470, 1.0555, 0.8121,\n",
      "        1.0846, 1.1591, 1.2149, 0.9765, 1.2567, 1.1599, 1.2371, 1.1225, 1.1103,\n",
      "        1.0066, 0.3822, 1.2120, 1.3083, 1.3634, 1.1283, 0.7825, 1.2514, 1.1331,\n",
      "        1.4325, 1.1645, 1.0921, 1.2001, 1.1854, 1.2786, 0.4991, 0.1092, 1.2047,\n",
      "        1.1430, 0.8163, 1.2333, 1.1564, 1.1607, 1.4303, 1.1883, 1.2928, 1.1048,\n",
      "        1.3014, 0.6405, 1.0837, 1.1507, 1.1334, 1.3134, 1.1526, 1.0000, 1.1264,\n",
      "        1.1192, 0.7816, 1.0529, 1.1445, 1.1844, 1.2384, 0.9860, 1.0113, 1.1329,\n",
      "        1.0594, 1.0936, 1.2185, 1.3098, 1.1937, 1.1694, 0.9203, 1.0866, 1.0402,\n",
      "        1.5230, 1.3623, 1.2044, 1.1555, 1.1827, 1.2313, 1.3152, 1.1065, 1.2472,\n",
      "        1.0599, 1.0144, 1.2290, 1.2482, 0.9341, 1.1471, 1.1330, 1.2763, 1.1171,\n",
      "        1.2160, 1.0820, 1.2000, 1.2348, 1.2416, 1.2248, 1.1638, 1.1699, 1.3080,\n",
      "        0.9134, 1.3910, 0.5787, 1.0071, 1.1055, 1.0031, 0.4281, 1.0586, 0.9351,\n",
      "        1.2837, 0.8398, 1.4458, 0.7638, 1.1583, 1.3845, 0.7143, 1.0907, 1.1861,\n",
      "        1.0604, 0.7736, 1.0600, 0.5647, 1.3120, 0.8468, 1.2982, 1.1004, 0.4552,\n",
      "        0.3966, 1.1247, 1.3536, 1.0594, 1.2834, 0.8949, 1.1303, 1.3833, 1.2030,\n",
      "        1.1001, 1.1248, 0.7706, 1.3213, 1.3188, 1.2185, 1.0171, 1.1595, 0.8498,\n",
      "        0.8135, 1.0636, 1.2781, 1.0573, 1.2851, 1.0572, 0.8405, 1.0464, 1.1964,\n",
      "        1.1595, 1.1180, 0.3153, 1.2285, 1.1744, 1.2124, 0.4499, 1.0722, 1.0078,\n",
      "        0.7574, 1.2718, 0.7463, 1.0804, 1.2841, 1.3574, 1.2397, 1.2981, 1.0001,\n",
      "        1.0549, 1.2852, 1.1400, 1.2315, 0.9560, 1.3933, 1.3862, 1.2243, 1.1172,\n",
      "        0.8518, 1.6866, 1.0177, 1.4783, 1.2111, 1.0782, 1.0844, 0.7494, 1.4446,\n",
      "        0.9478, 0.9406, 0.9123, 0.9244, 1.0944, 1.3772, 1.3219, 0.9654, 1.1807,\n",
      "        1.1376, 1.0847, 0.6479, 1.0004, 0.9220, 1.1314, 1.1506, 1.2477, 1.1392,\n",
      "        1.3576, 1.2479, 1.2160, 1.2844, 1.1520, 1.2053, 1.1021, 1.0072, 1.2178],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.0.1.bias\n",
      "Weights: tensor([-6.8811e-01,  4.7913e-01,  1.1079e+00, -1.5386e+00, -3.3712e-01,\n",
      "        -3.3432e-01,  1.1198e-01, -9.6005e-01, -1.2178e-01, -3.3857e-01,\n",
      "        -9.6505e-01,  2.0917e-02, -1.2905e+00,  9.8114e-01, -3.7444e-01,\n",
      "         1.0458e+00, -8.3714e-01,  1.7721e-01, -3.7903e-01, -9.6778e-01,\n",
      "         3.6742e-01, -1.2915e+00, -8.6810e-01, -6.7122e-01,  1.1709e-01,\n",
      "        -1.5585e+00, -2.3666e-01, -3.3470e-02, -5.0240e-01,  9.7308e-01,\n",
      "        -1.1258e+00,  2.9846e-01,  8.0102e-01,  4.3190e-01, -3.7795e-01,\n",
      "         1.3957e-01,  7.0685e-01,  8.6988e-02,  9.9130e-01,  1.1391e+00,\n",
      "         1.3015e+00, -2.3592e-01, -1.2630e+00, -3.8053e-01, -2.0794e-01,\n",
      "        -1.2066e+00, -3.7021e-01, -2.6874e-01, -1.4786e+00,  1.2954e+00,\n",
      "        -7.3766e-01, -1.1347e+00, -1.0459e+00, -1.0765e+00,  4.1002e-01,\n",
      "        -4.7630e-01, -1.1437e+00, -1.0135e+00, -3.3105e-01, -1.3008e-01,\n",
      "         1.0321e+00,  6.0022e-01,  7.1423e-01,  1.3245e+00,  8.8041e-01,\n",
      "         3.9893e-03, -1.1800e+00, -9.4973e-01,  9.8083e-01, -1.2763e+00,\n",
      "        -2.8505e-01, -1.2129e+00, -1.0078e+00, -1.3064e+00, -9.2836e-01,\n",
      "         1.0634e-01, -3.3524e-01, -7.1373e-01, -6.1145e-01, -2.1395e+00,\n",
      "        -5.8007e-01,  1.0424e+00, -1.0915e+00, -1.4955e+00,  8.1055e-02,\n",
      "        -5.4649e-01, -4.4101e-01, -1.1548e+00, -1.0447e+00, -5.7247e-01,\n",
      "         1.4646e+00, -1.0000e+00, -5.2786e-01,  1.2312e-01, -2.3551e-01,\n",
      "        -3.7765e-01, -9.5845e-01, -5.5925e-01, -2.2674e-01, -6.4493e-01,\n",
      "         2.2089e-01, -2.0381e-01,  1.9824e-01,  1.6436e-01,  4.1245e-01,\n",
      "         3.6336e-01, -9.2542e-01, -1.4808e+00, -1.0004e+00, -7.2124e-01,\n",
      "        -5.2629e-01, -5.9631e-01, -6.0975e-01,  1.6713e+00, -1.4983e+00,\n",
      "         1.2359e+00, -1.1848e-01, -4.1374e-01,  5.8443e-01,  9.2996e-01,\n",
      "        -1.9587e+00, -7.2126e-01,  3.2906e-01,  7.7608e-01, -1.2488e+00,\n",
      "         1.3893e+00, -7.1596e-01,  1.7292e-01, -4.8440e-01, -7.7319e-01,\n",
      "         6.5261e-01,  3.3377e-01,  5.0164e-01, -1.3081e+00, -1.1951e+00,\n",
      "        -1.1866e+00, -1.3635e+00, -4.6994e-01, -1.9838e-01,  1.0253e+00,\n",
      "         3.0006e-01, -3.9146e-01,  7.5420e-01,  1.1961e+00, -4.0022e-01,\n",
      "         9.5723e-01, -3.4582e-02, -1.4123e+00, -9.4611e-01, -2.8092e-01,\n",
      "        -8.9272e-01,  1.5090e+00, -9.2382e-01, -5.8281e-01, -9.4727e-01,\n",
      "        -9.0169e-01, -6.2933e-01, -1.9065e-02, -1.3587e+00, -1.2531e+00,\n",
      "         5.8388e-01, -8.9698e-01, -1.1871e+00, -8.1592e-01, -6.1953e-02,\n",
      "        -6.0799e-01, -5.9092e-01,  2.6572e-01,  9.3998e-01, -1.2063e+00,\n",
      "         9.2446e-01, -5.6148e-01,  1.1168e+00, -1.6046e+00, -7.5882e-01,\n",
      "         2.8871e-01, -3.8043e-01, -6.3221e-01, -6.2630e-01, -1.1393e+00,\n",
      "         7.3519e-01, -5.7907e-05,  1.3907e-01,  9.2260e-01, -4.3175e-01,\n",
      "         8.2566e-01, -8.1725e-01,  4.3053e-01, -3.5781e-01, -4.9579e-01,\n",
      "         9.1872e-01, -7.6001e-01, -1.4079e+00, -7.4629e-01, -1.4359e+00,\n",
      "        -6.4128e-01,  1.0760e+00,  4.1309e-02,  8.8303e-01, -1.0802e+00,\n",
      "        -8.2488e-01, -2.9546e-01, -1.3557e+00,  3.5004e-01, -3.4917e-01,\n",
      "        -4.0860e-01, -8.6188e-01,  1.5499e-01, -8.5266e-01, -5.2598e-01,\n",
      "         2.9822e-01,  8.8359e-01, -6.2227e-01, -2.8850e-01, -1.3739e+00,\n",
      "        -7.1734e-01,  2.9727e-01, -8.8323e-01,  1.1017e+00, -8.7006e-01,\n",
      "         8.2990e-01,  5.4909e-01, -1.2312e+00,  9.6382e-01, -4.1626e-01,\n",
      "         1.0832e+00, -1.7312e-01, -4.4168e-01, -1.0571e+00, -1.2408e+00,\n",
      "        -5.7665e-01, -7.2343e-01, -4.6456e-01,  1.8070e-01, -1.8594e+00,\n",
      "         9.3349e-01, -9.7387e-01,  1.3690e+00, -6.6027e-01, -1.1095e+00,\n",
      "        -1.0843e+00, -1.6173e+00, -7.7452e-01, -1.1391e+00, -1.1436e+00,\n",
      "         9.5985e-01,  1.7104e-01, -6.6921e-01, -8.2506e-01, -1.5003e-01,\n",
      "        -4.3306e-01, -3.2797e-01, -1.2281e+00,  1.1674e+00,  3.3813e-02,\n",
      "         2.2117e-01, -1.5616e-01, -8.6755e-01, -4.8643e-01,  5.6468e-01,\n",
      "        -1.5575e+00, -9.4775e-01, -2.4991e-01,  1.2922e+00, -5.1031e-01,\n",
      "        -4.5778e-02,  1.2165e+00,  5.6155e-01, -1.3149e+00, -8.8139e-02,\n",
      "        -1.2262e+00, -1.8139e-01, -1.2673e-01,  1.3819e-01,  1.3010e+00,\n",
      "         7.7496e-01,  1.5929e-01, -2.4601e+00, -5.9181e-02, -1.3599e+00,\n",
      "        -4.8886e-01, -2.5196e-01, -3.2622e-01, -7.4337e-01, -9.7540e-01,\n",
      "         1.6310e+00, -7.9353e-01, -1.1043e+00,  1.0994e+00, -9.7217e-01,\n",
      "         1.2527e+00, -1.7357e-01, -9.2336e-01,  1.4350e+00, -5.0141e-01,\n",
      "        -8.5410e-01,  1.1727e+00,  2.2073e-03, -7.1508e-01, -1.1510e+00,\n",
      "         6.1895e-01, -5.3328e-01, -1.0294e+00, -1.3023e-01, -1.3099e+00,\n",
      "        -1.2879e+00,  7.3467e-01, -5.0037e-01,  1.1563e+00, -6.3177e-01,\n",
      "        -1.1921e+00, -8.8047e-01,  9.0663e-01, -1.0688e+00, -7.0480e-01,\n",
      "         5.3734e-01, -6.1768e-01, -9.4505e-01, -1.0317e+00, -7.4995e-01,\n",
      "         1.0996e+00, -9.3386e-01, -1.4508e+00, -2.5155e-01, -1.1361e+00,\n",
      "        -1.5010e+00, -8.8903e-01, -8.0993e-01, -2.6516e-01, -8.1616e-01,\n",
      "        -1.0803e+00, -7.1512e-01, -2.2552e-01, -1.0081e+00, -5.4820e-02,\n",
      "         8.1218e-01, -1.1384e+00, -1.4414e+00,  1.4408e+00,  1.3913e+00,\n",
      "        -1.3690e+00,  6.2588e-01, -1.4573e+00, -1.0478e-02, -8.0563e-01,\n",
      "         1.5226e+00, -6.4413e-02,  5.3563e-01, -2.4780e-01, -1.8554e+00,\n",
      "        -5.6485e-01, -7.3927e-01, -1.2035e+00, -1.9004e+00, -6.3124e-01,\n",
      "         3.5529e-02, -6.4947e-01,  9.0935e-01, -3.6786e-01, -1.1038e+00,\n",
      "         3.0476e-01, -7.1104e-01,  1.2762e+00, -1.1388e+00,  8.3226e-01,\n",
      "        -1.1475e+00, -2.7829e-01, -9.9342e-02,  8.6783e-01, -1.1633e+00,\n",
      "        -3.5360e-01, -5.2435e-01, -5.3720e-01, -4.4764e-01, -8.3198e-01,\n",
      "        -6.6338e-01, -2.7613e-01,  3.9978e-02, -8.1012e-01,  1.4866e+00,\n",
      "        -1.0298e+00, -1.0614e-01, -7.5412e-01,  1.7650e-01,  2.8941e-01,\n",
      "        -7.4246e-01,  2.8279e-01, -3.5246e-01, -7.2937e-01, -3.6815e-01,\n",
      "        -5.7382e-01, -3.3350e-01, -1.1494e+00,  1.4667e+00, -1.0169e+00,\n",
      "         2.3352e-03, -1.0213e+00,  1.0004e+00, -9.1362e-02, -7.8765e-04,\n",
      "         6.7218e-01, -1.0454e+00, -1.2284e+00, -1.1417e+00, -1.7623e-01,\n",
      "        -8.6464e-01,  9.6737e-01,  1.0748e+00, -1.4189e+00, -5.9515e-01,\n",
      "        -9.6750e-01,  2.0307e-01, -1.4076e+00, -1.8204e-01, -7.8783e-01,\n",
      "        -5.5158e-01, -1.7000e+00, -4.9384e-01,  1.0658e-01, -4.9747e-01,\n",
      "        -1.1124e+00,  4.3037e-01, -1.3490e+00, -5.3769e-02,  7.3888e-01,\n",
      "        -7.5527e-01, -7.4699e-01,  1.6683e-01, -1.0143e+00,  8.5848e-01,\n",
      "        -6.9204e-01, -1.1693e+00, -5.1996e-01, -4.5217e-01, -3.3391e-01,\n",
      "        -2.3448e+00,  2.3619e-01, -6.8091e-01, -5.2703e-01,  2.5172e-01,\n",
      "         1.2546e-02, -8.8666e-01, -2.8037e-01, -8.3549e-01, -2.6185e-01,\n",
      "         8.6467e-01, -9.1154e-01, -1.0279e+00, -1.4084e+00, -6.2560e-01,\n",
      "        -7.4796e-02, -1.2225e+00, -1.0556e+00, -7.0154e-01, -1.0965e+00,\n",
      "        -5.3120e-02, -4.5576e-01, -1.1689e-01,  3.5786e-02,  8.4795e-01,\n",
      "        -5.4869e-01,  1.2234e+00,  7.6836e-01, -9.5040e-01,  1.5080e+00,\n",
      "         1.3493e+00,  4.1541e-01, -2.0930e+00, -1.4377e+00,  7.7598e-01,\n",
      "        -5.0522e-01,  1.6559e+00, -6.4284e-01, -1.0723e+00,  9.9723e-01,\n",
      "        -1.5704e-01, -1.6182e+00, -1.3123e+00, -1.3101e+00,  4.6346e-01,\n",
      "         1.0637e+00, -1.0700e+00,  8.5977e-01, -1.5115e-01, -7.1168e-01,\n",
      "         1.4870e+00,  1.3400e+00, -1.0443e+00, -1.0916e+00, -1.4113e+00,\n",
      "        -1.2940e-01,  1.3535e+00, -4.0737e-01, -2.0135e+00,  1.2143e-03,\n",
      "        -9.0605e-01, -4.2568e-01,  7.9707e-01, -7.9771e-01, -9.4280e-01,\n",
      "        -6.6161e-01, -1.0112e+00, -1.0027e+00, -9.6510e-01, -4.8189e-01,\n",
      "        -5.5534e-01, -4.7186e-01, -1.2540e+00, -1.4519e-01,  6.6955e-01,\n",
      "        -1.2048e+00, -4.3794e-01, -7.7246e-01, -9.2391e-01, -1.6297e-01,\n",
      "         1.3282e+00, -1.2578e+00, -6.4316e-01, -3.5181e-01,  2.3430e+00,\n",
      "        -1.1837e-01, -6.4861e-01,  8.0102e-01, -3.9638e-01,  8.8515e-01,\n",
      "        -3.0303e-01, -4.3899e-01, -7.6576e-01, -1.2331e-01, -1.4134e+00,\n",
      "         1.5847e+00, -5.6081e-01,  5.5368e-02, -9.8267e-01, -1.7459e+00,\n",
      "         7.2791e-01, -4.7001e-02, -1.1403e+00, -4.2678e-01,  6.5281e-01,\n",
      "        -8.1074e-01, -6.2384e-01, -9.0407e-01, -5.5762e-01, -6.6652e-01,\n",
      "        -1.0603e+00, -1.4441e+00, -1.1099e+00, -4.1918e-01, -6.3135e-01,\n",
      "         1.0103e+00, -6.5763e-01, -4.2753e-01, -8.3710e-01, -1.3244e-01,\n",
      "        -8.5653e-01, -7.8823e-01, -3.6590e-01, -8.9155e-01,  1.1571e+00,\n",
      "        -3.9095e-01, -1.3377e-01,  1.2301e+00, -9.5366e-01, -1.0548e-02,\n",
      "        -1.7546e-01, -9.3848e-01, -4.7648e-02, -2.0849e+00, -1.2997e+00,\n",
      "        -5.8113e-01,  2.4847e-01, -9.2764e-01,  4.5360e-01,  7.2318e-01,\n",
      "         2.7406e-01], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0169,  0.0376,  0.0119],\n",
      "          [ 0.0538,  0.3031,  0.0482],\n",
      "          [ 0.0159,  0.0492,  0.0129]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0405,  0.0552,  0.0358],\n",
      "          [ 0.0473,  0.3744,  0.0368],\n",
      "          [ 0.0427,  0.0413,  0.0399]]],\n",
      "\n",
      "\n",
      "        [[[-0.0100, -0.1215,  0.1981],\n",
      "          [-0.1155,  0.0303,  0.2032],\n",
      "          [ 0.0209,  0.0310, -0.1001]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0500, -0.0695, -0.0643],\n",
      "          [-0.0550, -0.0147, -0.0546],\n",
      "          [-0.0719, -0.0649, -0.0813]]],\n",
      "\n",
      "\n",
      "        [[[-0.0476, -0.0802, -0.0451],\n",
      "          [-0.0914, -0.0432, -0.0800],\n",
      "          [-0.0552, -0.0922, -0.0671]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0402,  0.0270,  0.0447],\n",
      "          [ 0.0286,  0.3983,  0.0303],\n",
      "          [ 0.0283,  0.0225,  0.0242]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 1, 3, 3])\n",
      "\n",
      "Layer: features.13.conv.1.1.weight\n",
      "Weights: tensor([0.8197, 1.1350, 1.2490, 0.3336, 0.8391, 0.6771, 0.7417, 0.5780, 1.2267,\n",
      "        0.8866, 0.4761, 1.0175, 0.2600, 0.7095, 0.8188, 0.6553, 0.3894, 1.2913,\n",
      "        0.8359, 0.3799, 1.3840, 0.4259, 0.8764, 0.4539, 1.1850, 0.2973, 0.9425,\n",
      "        1.0412, 0.9344, 1.1527, 0.4970, 1.0488, 2.0357, 1.4550, 0.8071, 0.7514,\n",
      "        1.0405, 1.5629, 1.2118, 1.8157, 1.0384, 6.1510, 0.2719, 0.9146, 1.2670,\n",
      "        0.6601, 0.8698, 0.6331, 0.3212, 1.5318, 0.4678, 0.2725, 0.5139, 0.3896,\n",
      "        1.3475, 0.7024, 0.5132, 0.2788, 1.0743, 1.3945, 1.3692, 1.4564, 0.5129,\n",
      "        2.0098, 1.0741, 0.6468, 0.2611, 0.3851, 1.7982, 0.7113, 0.7107, 0.4949,\n",
      "        0.5736, 0.4674, 0.7469, 1.4850, 1.1471, 1.3546, 0.4912, 0.2971, 0.6554,\n",
      "        1.1456, 0.6343, 0.2769, 1.3898, 0.7645, 1.2735, 0.4332, 0.8307, 0.3873,\n",
      "        1.2922, 0.3100, 0.7449, 0.5798, 0.4520, 0.5499, 0.6584, 0.7137, 0.6571,\n",
      "        0.4959, 0.9824, 0.6167, 0.9701, 0.9784, 0.8749, 0.9773, 0.7728, 0.2743,\n",
      "        0.6751, 0.4312, 0.6628, 0.4398, 1.1899, 1.5685, 0.5049, 1.4961, 0.5267,\n",
      "        0.7121, 1.4904, 0.8937, 0.3380, 0.4779, 1.2350, 1.3473, 0.6581, 1.7795,\n",
      "        1.3347, 0.4870, 0.5308, 0.6798, 0.7455, 0.8670, 0.8149, 0.2352, 0.3889,\n",
      "        0.2747, 0.5982, 1.0033, 0.7103, 1.1714, 6.5431, 2.2172, 1.6803, 1.2661,\n",
      "        0.7196, 0.8730, 0.4228, 0.5346, 0.4789, 0.4935, 0.3922, 1.6830, 0.2700,\n",
      "        0.5591, 0.8403, 0.5951, 0.4402, 0.6302, 0.6434, 0.2470, 1.7537, 0.3652,\n",
      "        0.2528, 0.8519, 0.6461, 0.6051, 1.0873, 1.2696, 1.5064, 0.2802, 1.2265,\n",
      "        0.4693, 1.1953, 0.7200, 0.4290, 1.1472, 1.0251, 0.3808, 0.4610, 0.8683,\n",
      "        1.1734, 0.4841, 0.6633, 1.2792, 0.4507, 1.1266, 0.7215, 2.5914, 0.7257,\n",
      "        0.8392, 1.0832, 0.4277, 0.2519, 0.8509, 0.2920, 0.4552, 1.3485, 0.9599,\n",
      "        1.0913, 0.8559, 0.5563, 0.3614, 0.2897, 1.4371, 1.0257, 0.4700, 0.2495,\n",
      "        1.0314, 0.5130, 0.6894, 0.9086, 1.2851, 1.2522, 0.8364, 0.4705, 1.2447,\n",
      "        1.2158, 0.4386, 1.3586, 1.5628, 0.8240, 1.8103, 1.1469, 0.9862, 0.8179,\n",
      "        1.4937, 1.5843, 0.7255, 0.3010, 0.3903, 0.8143, 0.5099, 1.2299, 0.4728,\n",
      "        0.3265, 1.0185, 0.7472, 1.5836, 0.7451, 0.4804, 0.4683, 0.3197, 0.4478,\n",
      "        0.6888, 0.5502, 1.4275, 0.5076, 0.8857, 0.5542, 0.9734, 0.7011, 0.9452,\n",
      "        0.2600, 1.7120, 0.8720, 0.5039, 1.0143, 0.4927, 0.4431, 1.1080, 0.6294,\n",
      "        0.4985, 1.1953, 1.0966, 0.8073, 0.7386, 1.4792, 1.6128, 0.6020, 0.3343,\n",
      "        0.7443, 1.1555, 1.0404, 0.9049, 1.3085, 1.0542, 1.8962, 0.3605, 1.2025,\n",
      "        0.4950, 0.3856, 1.2546, 0.7724, 0.3167, 0.4548, 2.2421, 1.0216, 0.4123,\n",
      "        1.1912, 0.4975, 1.6594, 0.7530, 0.4141, 1.4811, 0.4584, 0.4643, 1.3237,\n",
      "        1.8780, 0.6532, 0.8338, 1.0323, 0.9170, 0.5071, 0.6964, 0.5087, 0.3836,\n",
      "        1.0217, 1.5524, 1.4304, 1.1062, 0.3851, 0.3273, 1.2435, 0.3105, 0.9905,\n",
      "        1.1862, 0.8549, 0.3177, 0.8539, 0.9527, 1.4536, 0.8503, 0.4091, 0.8122,\n",
      "        0.8330, 0.7510, 0.8779, 0.9459, 0.6614, 0.4986, 0.6076, 0.8850, 1.1895,\n",
      "        0.7202, 1.0709, 0.6897, 0.3592, 0.2659, 1.2212, 1.7146, 0.5418, 1.8539,\n",
      "        0.4881, 1.1948, 1.4012, 1.6258, 1.2099, 0.9575, 0.8734, 0.3229, 0.8336,\n",
      "        0.6418, 0.2898, 0.3373, 0.9593, 0.5624, 0.5109, 0.9003, 1.5971, 0.7640,\n",
      "        0.8881, 0.8720, 1.3220, 0.5331, 1.8486, 0.6084, 1.0022, 0.8709, 1.6427,\n",
      "        0.2672, 0.6366, 0.7681, 0.3884, 1.1501, 0.6261, 0.6547, 0.9429, 0.7420,\n",
      "        0.6868, 1.7373, 0.7749, 1.4907, 0.8288, 0.8307, 1.6512, 1.0157, 0.5183,\n",
      "        0.4867, 0.2933, 0.6406, 0.5572, 0.5765, 0.7095, 1.2603, 0.5021, 0.8183,\n",
      "        0.4000, 1.3237, 1.1516, 1.3211, 0.5829, 1.0148, 0.3162, 0.9439, 0.4904,\n",
      "        0.6242, 1.5037, 0.7650, 0.7689, 0.8051, 0.6595, 1.3425, 0.2696, 0.6443,\n",
      "        0.6250, 3.5614, 0.3216, 0.7091, 0.4666, 1.2757, 0.3572, 1.9015, 0.6103,\n",
      "        0.7664, 1.0103, 0.2944, 0.7685, 0.7022, 0.5464, 0.8472, 0.5333, 0.2534,\n",
      "        0.4712, 0.5650, 0.7558, 0.2771, 0.9492, 0.4936, 0.4409, 0.9550, 1.6230,\n",
      "        0.4000, 0.5534, 0.8079, 1.1597, 0.9556, 0.2703, 0.2825, 0.5042, 0.5169,\n",
      "        1.2320, 0.7678, 0.6362, 0.7191, 0.9013, 1.0006, 0.6817, 1.4233, 1.1194,\n",
      "        1.2294, 1.0668, 1.6979, 0.6928, 0.5611, 2.0683, 1.3422, 1.1350, 0.2258,\n",
      "        0.5670, 0.8304, 0.5185, 2.2265, 0.4404, 0.9535, 1.2813, 0.6538, 0.3248,\n",
      "        0.4491, 0.4716, 0.7848, 1.4129, 0.3042, 1.1320, 0.9305, 0.4290, 1.0839,\n",
      "        0.9387, 0.5509, 0.8728, 0.5486, 0.7599, 1.7322, 0.5838, 0.5698, 0.4886,\n",
      "        0.3923, 0.9116, 1.1425, 0.8699, 1.0134, 0.9477, 0.4397, 0.6098, 0.4094,\n",
      "        0.9481, 0.7325, 1.3822, 0.3533, 0.7966, 1.7197, 0.4987, 0.4861, 0.4436,\n",
      "        0.3967, 1.0345, 1.3649, 0.5676, 1.0324, 0.6533, 1.7330, 0.9446, 0.6043,\n",
      "        0.9193, 0.4853, 1.3805, 0.7453, 1.1119, 0.2996, 0.6176, 0.4964, 1.5898,\n",
      "        0.6931, 0.5046, 0.4553, 0.5708, 0.9148, 1.2428, 0.2642, 1.4667, 1.0731,\n",
      "        0.7070, 0.5556, 0.5954, 0.7210, 0.9235, 0.2529, 0.4587, 0.4477, 0.7193,\n",
      "        0.8399, 1.0771, 0.5788, 1.0854, 0.8920, 1.2259, 0.4472, 0.3885, 0.4331,\n",
      "        0.5909, 0.8513, 0.7101, 0.9177, 1.4364, 0.5957, 0.6729, 0.5562, 0.6483,\n",
      "        1.0610, 0.3633, 0.5853, 0.7657, 1.0523, 0.9870, 1.6699, 1.6477, 1.0297],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.1.1.bias\n",
      "Weights: tensor([-1.8662e+00, -5.0893e-01, -1.2291e+00,  1.3708e-01, -1.1880e+00,\n",
      "        -8.4866e-01, -4.9873e-01, -1.3334e+00, -1.7012e+00, -1.5864e+00,\n",
      "         3.1676e+00, -2.0877e+00,  2.5298e+00,  3.1197e-01, -7.3821e-01,\n",
      "         1.1342e-01, -1.2678e-01, -6.5159e-01,  5.2607e-02,  2.4018e+00,\n",
      "        -8.9787e-01, -6.5955e-01, -1.6292e+00,  1.1768e+00, -2.1735e+00,\n",
      "         2.7300e-01, -1.1102e+00, -3.8603e-01,  2.9605e+00, -8.1187e-01,\n",
      "        -5.7333e-01, -9.5638e-01, -2.7051e+00, -8.8464e-01, -9.1615e-01,\n",
      "        -4.3798e-01, -5.4449e-01, -1.0839e+00, -9.4657e-01, -1.4845e+00,\n",
      "        -7.0570e-01, -3.5828e+00,  2.5886e+00, -8.0324e-01,  9.2598e-01,\n",
      "        -2.2462e+00, -9.7747e-01,  1.3990e+00,  2.6427e+00, -1.8537e+00,\n",
      "         1.4562e+00,  1.3942e+00, -5.2146e-01,  2.0811e+00, -1.0063e+00,\n",
      "        -1.1949e+00, -1.0470e+00,  1.5662e+00, -2.2311e+00, -1.6141e+00,\n",
      "        -1.0933e+00, -1.0787e+00,  4.5392e-01, -1.9909e+00, -8.0261e-01,\n",
      "        -3.8507e-01,  2.0772e+00,  2.1546e+00, -2.5386e+00, -1.7881e+00,\n",
      "        -7.0121e-01, -6.3063e-01, -1.7895e+00, -7.9999e-01, -2.4755e+00,\n",
      "        -1.5531e+00, -2.5320e+00, -3.5359e+00,  1.9559e+00,  3.5688e+00,\n",
      "        -9.1577e-01, -1.0543e+00, -2.0618e+00,  1.7791e-01, -7.5585e-01,\n",
      "        -1.3222e+00, -2.3612e+00, -7.3523e-02,  4.8713e+00,  1.8111e+00,\n",
      "        -9.3094e-01,  2.5833e+00, -2.0141e+00,  2.3060e+00,  1.6297e+00,\n",
      "         1.1720e-01, -1.1747e+00, -1.0932e+00, -6.9838e-01, -4.2694e-01,\n",
      "        -1.5297e+00, -2.1055e-01, -1.9285e+00, -1.0200e+00, -5.1811e-01,\n",
      "        -4.9671e-01, -2.1412e+00,  2.6941e+00, -1.8558e+00, -6.1947e-02,\n",
      "        -9.3897e-01,  1.8478e+00, -2.4368e+00, -1.7043e+00, -2.2085e+00,\n",
      "        -1.4581e+00,  2.2500e+00, -6.8781e-01, -9.7333e-01, -2.1753e-02,\n",
      "        -3.7182e-01, -1.4650e-01, -2.6040e+00, -1.1321e+00, -4.6405e-01,\n",
      "        -2.0326e+00, -3.3468e+00,  1.0456e+00, -3.8891e-01, -1.4686e+00,\n",
      "        -4.1191e-01, -9.7934e-01, -5.1943e-01,  2.2175e+00,  2.5798e+00,\n",
      "         2.0299e+00, -1.4257e+00, -2.0314e+00, -8.3694e-02, -1.1718e+00,\n",
      "        -4.6317e+00, -1.2364e+00, -1.5828e+00, -8.0719e-01,  1.6564e-01,\n",
      "        -1.6733e-01,  1.0737e+00, -8.3422e-01, -7.5275e-01,  1.0645e+00,\n",
      "         1.5095e+00, -1.9354e+00,  1.9545e+00, -5.5444e-01, -2.0242e+00,\n",
      "        -5.9676e-01,  2.1772e+00, -5.6454e-01, -2.3799e+00,  2.0820e+00,\n",
      "        -1.9133e+00, -2.3716e-02,  1.4451e+00, -1.7836e+00, -9.0882e-02,\n",
      "        -5.6233e-01, -2.9056e+00, -2.1647e+00, -1.0677e+00,  2.0973e+00,\n",
      "        -7.0668e-01,  3.4939e-01, -8.5120e-01, -2.5434e+00, -3.9889e-02,\n",
      "        -3.7732e-01, -2.2744e+00,  4.3743e-01, -7.6406e-02, -3.4921e+00,\n",
      "        -7.6683e-01,  1.8361e+00, -7.8444e-02, -1.3302e+00,  3.4612e-01,\n",
      "        -7.5527e-01, -1.3268e+00, -1.3353e+00, -9.0547e-01, -1.4222e+00,\n",
      "        -6.6171e-01,  2.2746e+00,  2.5421e+00, -1.9096e+00,  3.0510e+00,\n",
      "        -2.7824e-01, -1.3571e+00, -1.5308e+00, -8.2528e-01, -2.2501e+00,\n",
      "        -4.2292e-01,  4.0419e-01,  2.4761e+00, -8.4979e-01, -1.1310e+00,\n",
      "         7.1650e-03,  1.5749e+00, -1.5334e+00, -4.8752e-01, -8.0462e-01,\n",
      "        -7.8947e-01, -1.0317e+00, -3.0489e+00, -7.2215e-01, -9.0800e-01,\n",
      "        -3.9628e+00, -7.3156e-01, -2.6577e-01, -1.0332e+00, -4.0011e+00,\n",
      "        -3.4986e-01, -1.4726e+00, -2.6091e+00, -6.6158e-01, -6.0923e-01,\n",
      "        -1.3892e+00, -7.8451e-01, -8.7641e-01,  1.9069e+00,  1.1709e+00,\n",
      "        -9.5295e-01, -3.0938e-01, -3.8393e+00,  1.8703e+00,  2.7964e-01,\n",
      "        -5.0640e-01, -9.5450e-01, -1.8422e+00, -1.2902e+00,  9.6745e-01,\n",
      "        -8.8984e-01,  6.5605e-01, -2.6739e-01, -1.9192e+00, -8.9494e-01,\n",
      "        -9.9580e-01,  1.9947e+00, -1.6094e+00,  1.5229e+00, -1.7291e+00,\n",
      "        -4.1894e-01, -2.4523e+00,  2.1694e+00, -1.7991e+00, -1.2669e+00,\n",
      "         9.4039e-01, -2.6676e-01,  2.6294e+00,  2.2125e+00, -1.2649e+00,\n",
      "        -1.7924e+00, -1.6550e-01, -2.6384e+00, -8.4774e-01, -1.3442e+00,\n",
      "        -4.4932e-01, -1.3912e+00, -2.9637e+00, -2.4933e+00,  1.0333e+00,\n",
      "        -1.8180e+00, -2.3552e+00, -1.7840e+00, -9.9210e-01, -8.1094e-01,\n",
      "        -6.6695e-01, -2.7468e+00,  1.1345e+00, -2.1592e+00, -1.3791e+00,\n",
      "         1.8430e+00, -2.9918e+00, -1.2772e+00,  1.7859e+00, -3.6326e-01,\n",
      "        -4.3477e+00, -2.0654e+00,  9.8350e-01, -9.7478e-01, -1.9561e-01,\n",
      "        -2.1853e+00, -3.6678e-01,  1.9233e+00, -9.3653e-01,  1.6782e+00,\n",
      "         1.8106e+00, -9.4103e-01, -4.6398e+00,  7.5250e-02, -5.8307e-01,\n",
      "        -1.2273e+00, -2.0893e+00, -9.8659e-01, -6.5044e-01, -1.2412e-01,\n",
      "        -2.5234e-02, -7.2079e-01, -2.8790e+00, -9.8019e-01, -2.4758e+00,\n",
      "         1.3246e-01,  1.7147e+00, -8.2939e-01,  2.1882e+00, -2.9776e+00,\n",
      "        -2.1056e+00, -1.3892e+00,  1.0546e-01, -3.0730e+00, -1.4806e+00,\n",
      "        -1.6423e+00, -2.3788e+00, -1.6419e+00, -1.0564e+00, -2.4633e+00,\n",
      "        -2.8360e+00, -1.7405e+00, -1.6979e+00, -6.0627e-01, -3.6597e-01,\n",
      "        -9.1737e-01, -1.3702e+00, -3.6543e-01, -2.1964e+00, -3.3647e-01,\n",
      "        -2.8720e-01,  3.4876e-01,  1.3514e+00, -8.1380e-01, -1.7549e+00,\n",
      "        -2.3322e+00, -1.8778e+00, -1.7442e+00, -2.5536e+00, -4.7147e+00,\n",
      "        -1.0222e+00, -1.5628e+00, -8.1371e-01,  2.8799e-02,  6.0131e-02,\n",
      "        -1.5198e+00, -8.0292e-01,  2.7120e+00,  2.1820e-01, -1.0177e+00,\n",
      "         7.7227e-02,  2.1803e+00, -3.9907e-01, -1.1428e+00, -2.4347e+00,\n",
      "        -1.1615e+00, -1.3680e+00, -1.1695e+00,  3.6558e+00, -1.7257e+00,\n",
      "        -8.1347e-01, -1.3277e+00, -1.2834e+00, -1.6096e+00,  2.2480e+00,\n",
      "         2.0505e-02, -7.7338e-01,  8.2871e-02, -1.9131e+00, -1.1963e+00,\n",
      "        -7.1921e-01, -1.7774e+00, -5.5974e-01, -1.3586e+00, -1.6587e+00,\n",
      "        -1.9502e+00, -3.7858e+00, -1.7139e+00, -5.8564e-01, -1.4449e+00,\n",
      "        -1.4842e+00,  6.1636e-01,  2.4858e+00,  6.2416e-01, -4.0966e-01,\n",
      "        -1.6447e-01, -2.6867e-01, -1.2415e+00, -6.7792e-01, -6.4402e-01,\n",
      "        -3.2285e-02,  1.5506e+00, -1.0372e+00, -1.4474e+00, -6.4825e-01,\n",
      "         1.6978e+00, -2.7682e+00,  2.3478e+00, -2.7220e+00, -9.2085e-03,\n",
      "        -6.0858e-01, -1.9489e+00, -1.3581e-01, -2.6350e+00, -9.8619e-01,\n",
      "        -6.2931e-01, -2.4097e+00,  2.7786e+00, -1.2535e-01, -1.3435e+00,\n",
      "        -7.8129e-01, -1.0587e+00, -8.0187e-01,  1.4845e+00, -3.3232e-01,\n",
      "        -1.4269e-01, -6.0279e+00, -2.1636e+00, -6.0266e-01, -5.6934e-01,\n",
      "         1.1740e+00, -1.8604e+00,  2.3776e-02, -5.1033e-01, -1.7396e-01,\n",
      "         7.3405e-04,  1.7442e+00,  2.5188e+00, -1.1463e-01, -9.2406e-01,\n",
      "         9.5320e-01, -3.7432e-01,  1.9136e+00,  2.1090e+00, -7.7489e-01,\n",
      "        -8.8727e-01,  1.8718e+00, -1.1487e-01, -1.4352e+00, -3.6170e-01,\n",
      "        -4.4840e-01,  1.8504e+00,  1.6592e+00,  3.5015e+00,  8.4229e-01,\n",
      "        -5.0276e-01, -7.9944e-01, -1.3134e+00, -1.4819e+00, -2.3352e+00,\n",
      "        -4.0677e-01,  1.7565e-01, -7.4646e-01, -1.9879e+00, -6.5045e-01,\n",
      "        -2.3354e+00, -1.5810e+00, -2.6062e-02, -1.2607e+00, -2.1334e+00,\n",
      "        -1.0510e+00, -9.8456e-01,  2.2657e+00, -4.4037e-01, -4.8848e-01,\n",
      "        -2.4181e-02, -3.0123e+00, -5.1532e-02, -2.5967e+00, -1.1201e+00,\n",
      "        -1.3590e-01,  2.7707e+00, -1.0549e+00,  3.2210e-02, -2.7611e-01,\n",
      "        -1.0909e+00,  2.3628e+00, -6.1731e-01, -1.7914e-01,  2.0007e+00,\n",
      "        -6.8510e-01, -8.0366e-01, -5.1634e-01, -2.1848e+00, -1.6484e+00,\n",
      "        -5.6261e-01, -2.0620e+00, -7.8226e-04, -5.5762e-01,  2.1883e+00,\n",
      "         1.5876e+00, -1.6651e+00, -8.8492e-01, -1.5517e+00, -3.4368e+00,\n",
      "        -1.8897e+00, -3.2633e-01, -9.9199e-01, -3.3061e-01, -2.0679e+00,\n",
      "        -1.4595e+00, -4.4090e+00,  8.6700e-01, -8.8314e-02, -1.4327e+00,\n",
      "        -9.7306e-01, -1.2786e-01,  2.6243e+00,  1.5275e+00, -1.7725e+00,\n",
      "        -1.2593e+00, -1.1836e+00, -1.8093e+00, -6.8100e-01, -4.0375e-01,\n",
      "        -9.0430e-01, -1.2880e+00, -5.3567e-01,  2.6773e+00, -1.8066e+00,\n",
      "        -3.2544e-01, -2.2974e+00,  1.7244e+00,  1.2369e-01, -4.9307e-01,\n",
      "        -1.4013e+00, -2.6082e+00,  1.8549e+00, -4.7148e-01, -1.9720e+00,\n",
      "        -4.0636e-01, -5.6968e-01,  1.9545e+00, -3.9294e+00, -4.3409e-01,\n",
      "        -1.7786e+00,  8.9080e-01,  3.1457e+00, -7.2781e-01, -2.1432e+00,\n",
      "         2.1978e+00, -1.0728e+00, -8.3238e-01, -5.1832e-01, -1.4932e+00,\n",
      "        -6.1896e-01, -5.9648e-01, -3.6674e+00, -2.6160e+00, -1.3117e+00,\n",
      "         2.3638e+00,  1.6984e-01,  3.8134e-01, -9.5627e-01, -1.6982e-01,\n",
      "         2.4175e+00, -1.9158e+00, -1.2303e+00, -7.9999e-01,  4.2352e-01,\n",
      "        -1.8268e-01, -1.1998e+00, -1.0833e-01,  8.0989e-01, -2.6777e-01,\n",
      "        -7.2336e-01, -5.1332e-01, -3.1458e+00, -1.2689e+00, -1.5822e+00,\n",
      "        -7.5257e-01], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.13.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0541]],\n",
      "\n",
      "         [[ 0.1219]],\n",
      "\n",
      "         [[ 0.0604]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[ 0.0679]],\n",
      "\n",
      "         [[ 0.0424]]],\n",
      "\n",
      "\n",
      "        [[[-0.0634]],\n",
      "\n",
      "         [[-0.0324]],\n",
      "\n",
      "         [[-0.0010]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0358]],\n",
      "\n",
      "         [[-0.0007]],\n",
      "\n",
      "         [[-0.0597]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1161]],\n",
      "\n",
      "         [[-0.0601]],\n",
      "\n",
      "         [[ 0.0080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0730]],\n",
      "\n",
      "         [[ 0.1312]],\n",
      "\n",
      "         [[-0.1583]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0099]],\n",
      "\n",
      "         [[-0.1532]],\n",
      "\n",
      "         [[-0.0336]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1117]],\n",
      "\n",
      "         [[ 0.0427]],\n",
      "\n",
      "         [[-0.0993]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0466]],\n",
      "\n",
      "         [[-0.0770]],\n",
      "\n",
      "         [[-0.0356]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0422]],\n",
      "\n",
      "         [[ 0.1340]],\n",
      "\n",
      "         [[-0.0039]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0319]],\n",
      "\n",
      "         [[-0.0836]],\n",
      "\n",
      "         [[ 0.0020]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0052]],\n",
      "\n",
      "         [[ 0.0786]],\n",
      "\n",
      "         [[ 0.0979]]]], device='cuda:0')\n",
      "Shape: torch.Size([96, 576, 1, 1])\n",
      "\n",
      "Layer: features.13.conv.3.weight\n",
      "Weights: tensor([2.3462, 1.1076, 2.4558, 1.1446, 2.7596, 3.4581, 3.4509, 2.4032, 2.4825,\n",
      "        2.9053, 1.0885, 2.1729, 1.5070, 1.1521, 1.6025, 1.9701, 1.8116, 3.4066,\n",
      "        1.2077, 0.8244, 2.5042, 1.8505, 2.4262, 1.0967, 2.0292, 3.0289, 4.0606,\n",
      "        1.7235, 1.8096, 2.5487, 2.2635, 0.8900, 3.2766, 1.0540, 1.0154, 3.1115,\n",
      "        3.6768, 1.2845, 2.5682, 2.9025, 2.3743, 2.5410, 1.1457, 3.5237, 2.5571,\n",
      "        1.3600, 1.5969, 1.6582, 1.2767, 1.2771, 0.9937, 3.1546, 2.6688, 1.0845,\n",
      "        2.8863, 1.1163, 2.4055, 0.9251, 3.3920, 3.5508, 2.0892, 1.4950, 4.3684,\n",
      "        1.2598, 2.7995, 1.8211, 2.1045, 2.3494, 1.4068, 3.2438, 1.1187, 2.9958,\n",
      "        1.7708, 2.6674, 2.0745, 2.1259, 4.0351, 2.3139, 1.6170, 3.1082, 1.7424,\n",
      "        3.4872, 1.0737, 2.8217, 2.7398, 2.1692, 2.7343, 3.6734, 3.4890, 2.8258,\n",
      "        1.1770, 3.1165, 1.5946, 2.7876, 1.9006, 1.5863], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.13.conv.3.bias\n",
      "Weights: tensor([-2.8477e-07,  2.4400e-07, -7.1327e-07,  7.1594e-07,  1.0720e-07,\n",
      "        -8.2925e-07, -1.0257e-06,  2.6274e-07, -4.2308e-07,  2.0229e-06,\n",
      "        -1.4904e-07, -3.1578e-07, -1.0084e-06, -1.4149e-06, -7.6040e-07,\n",
      "        -1.2408e-06, -1.7556e-07, -3.0746e-07,  5.9444e-07, -1.1849e-06,\n",
      "        -7.9539e-08,  6.5606e-07,  5.9720e-08, -1.2160e-06,  7.6969e-07,\n",
      "        -3.4021e-08,  1.3479e-06, -2.5036e-07,  4.5764e-07,  4.0439e-07,\n",
      "         8.4799e-07, -1.1779e-07, -2.7320e-07,  4.5151e-08,  1.4502e-06,\n",
      "        -4.9933e-07,  2.7697e-07,  1.4250e-06, -1.1621e-06,  4.6229e-08,\n",
      "         3.7765e-07,  1.9208e-07,  1.5204e-08,  1.1692e-06,  3.6242e-08,\n",
      "         6.8967e-08,  1.8790e-07,  8.3298e-07,  2.3598e-07, -7.6212e-07,\n",
      "         2.6862e-07,  5.1627e-08,  1.0294e-06, -2.1595e-07,  2.6765e-07,\n",
      "         3.0125e-07,  5.9335e-07,  8.2671e-07, -2.1458e-07, -4.9420e-07,\n",
      "         6.1114e-07, -2.5923e-07, -6.0342e-07,  1.3453e-07, -7.1573e-07,\n",
      "        -2.6431e-07, -2.2532e-07, -7.6041e-08,  9.7670e-07,  2.3076e-07,\n",
      "         6.5309e-07, -9.7937e-07, -1.1313e-06, -2.4312e-07,  5.6558e-07,\n",
      "         2.4265e-07, -2.0282e-07, -1.1125e-06,  3.7599e-07, -1.1835e-07,\n",
      "         8.3440e-07, -5.4145e-07, -3.7260e-07,  4.9687e-07, -3.6257e-08,\n",
      "         5.3101e-07, -6.3533e-07,  3.3939e-07, -1.0574e-06,  3.5952e-07,\n",
      "         9.1234e-08, -6.9317e-07,  5.7544e-07,  3.4277e-07, -5.2252e-07,\n",
      "         1.4133e-07], device='cuda:0')\n",
      "Shape: torch.Size([96])\n",
      "\n",
      "Layer: features.14.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.0420]],\n",
      "\n",
      "         [[ 0.0087]],\n",
      "\n",
      "         [[ 0.1079]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1354]],\n",
      "\n",
      "         [[ 0.0197]],\n",
      "\n",
      "         [[-0.0812]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0451]],\n",
      "\n",
      "         [[ 0.0258]],\n",
      "\n",
      "         [[-0.1136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0341]],\n",
      "\n",
      "         [[ 0.0764]],\n",
      "\n",
      "         [[ 0.0496]]],\n",
      "\n",
      "\n",
      "        [[[-0.0148]],\n",
      "\n",
      "         [[ 0.1136]],\n",
      "\n",
      "         [[-0.0937]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0805]],\n",
      "\n",
      "         [[ 0.1227]],\n",
      "\n",
      "         [[ 0.1125]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1093]],\n",
      "\n",
      "         [[-0.2128]],\n",
      "\n",
      "         [[ 0.1439]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1404]],\n",
      "\n",
      "         [[-0.1311]],\n",
      "\n",
      "         [[-0.0320]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0632]],\n",
      "\n",
      "         [[ 0.0876]],\n",
      "\n",
      "         [[ 0.0468]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1252]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[-0.0605]]],\n",
      "\n",
      "\n",
      "        [[[-0.0240]],\n",
      "\n",
      "         [[-0.1722]],\n",
      "\n",
      "         [[-0.1315]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0463]],\n",
      "\n",
      "         [[ 0.1351]],\n",
      "\n",
      "         [[-0.1088]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 96, 1, 1])\n",
      "\n",
      "Layer: features.14.conv.0.1.weight\n",
      "Weights: tensor([2.3564, 1.4216, 1.0730, 1.4022, 1.3710, 1.4293, 1.4185, 1.3027, 1.4130,\n",
      "        1.3311, 1.3191, 1.4113, 1.2747, 1.0053, 1.4259, 1.2154, 1.1302, 1.2267,\n",
      "        1.3232, 1.3284, 1.4337, 1.3051, 1.3990, 1.4093, 1.3401, 1.3844, 1.9727,\n",
      "        1.3013, 1.3551, 1.1941, 1.5024, 0.5222, 1.2384, 1.4325, 1.2058, 1.4279,\n",
      "        1.3983, 1.3026, 1.0540, 1.4732, 1.3778, 1.3901, 1.4568, 1.5218, 1.4718,\n",
      "        1.0022, 1.3717, 1.3377, 1.3713, 1.4852, 1.4249, 1.3064, 1.5656, 1.1684,\n",
      "        1.3656, 1.3477, 0.6932, 1.1874, 1.4241, 1.4892, 1.2960, 1.1630, 1.2862,\n",
      "        1.5485, 1.1312, 1.4476, 1.3067, 1.2690, 1.3403, 1.2310, 1.1948, 1.2423,\n",
      "        1.5635, 1.3756, 0.4785, 1.2122, 0.5295, 1.4623, 0.8721, 1.4561, 0.4390,\n",
      "        1.2483, 1.4136, 1.1361, 1.3081, 1.1800, 1.2295, 1.2424, 1.3688, 1.4074,\n",
      "        1.1948, 1.3129, 1.3603, 1.4925, 1.4193, 1.0988, 1.3899, 1.4507, 1.0844,\n",
      "        1.2817, 1.4150, 1.1058, 1.4426, 1.4253, 1.4132, 1.4159, 1.6060, 1.3100,\n",
      "        1.3476, 1.2674, 1.3672, 1.5110, 1.2883, 1.5067, 1.2841, 1.4899, 1.4334,\n",
      "        1.3855, 1.6114, 0.8302, 1.5419, 1.4114, 1.4523, 1.3651, 1.3601, 1.4237,\n",
      "        1.3363, 1.3261, 1.3882, 1.3285, 1.0259, 1.3320, 1.3653, 1.3355, 1.3479,\n",
      "        1.3401, 1.2767, 1.3933, 1.2188, 1.4936, 1.2552, 0.6871, 1.3590, 1.2860,\n",
      "        1.2496, 1.6373, 1.1882, 1.3599, 1.2927, 1.4607, 1.3265, 1.1265, 1.2643,\n",
      "        1.1878, 1.3715, 1.4342, 1.2323, 1.4502, 1.4564, 1.1215, 1.3104, 1.6134,\n",
      "        1.3446, 1.1151, 1.4064, 0.9598, 1.3266, 1.2202, 1.2144, 1.3854, 1.3979,\n",
      "        1.3392, 1.1440, 1.2470, 1.1975, 1.2051, 1.0848, 1.2490, 1.4455, 1.2341,\n",
      "        1.4706, 1.2437, 0.5199, 1.2636, 1.2707, 1.3501, 1.4520, 1.3951, 1.2270,\n",
      "        1.2033, 1.2506, 1.4054, 1.4800, 1.2849, 1.5049, 1.4475, 0.3038, 1.1964,\n",
      "        1.4659, 1.1929, 1.2374, 1.2768, 1.2003, 1.3752, 1.1471, 1.3622, 1.3266,\n",
      "        1.4330, 1.2888, 1.3993, 1.3772, 1.5267, 1.3910, 1.2903, 1.3029, 1.5058,\n",
      "        1.3757, 1.3818, 1.3361, 1.1896, 1.2991, 1.0523, 1.3204, 1.3894, 1.4457,\n",
      "        1.3217, 0.6394, 1.4972, 1.0556, 1.4418, 1.2779, 1.5012, 1.2154, 1.2132,\n",
      "        1.4342, 1.4043, 1.3906, 1.2259, 1.3852, 1.3120, 1.3462, 1.3420, 1.4428,\n",
      "        1.3740, 1.2764, 1.3271, 1.2265, 1.2731, 1.2410, 1.4500, 1.2849, 1.5326,\n",
      "        1.3222, 1.1772, 1.2962, 1.3841, 1.3519, 1.1618, 1.3807, 1.4657, 1.1396,\n",
      "        1.3782, 0.9145, 1.1072, 1.3771, 1.3772, 1.3308, 1.7655, 1.3672, 1.3081,\n",
      "        1.3098, 1.3553, 1.2528, 1.4568, 1.3583, 1.4124, 1.2515, 1.5640, 1.4663,\n",
      "        1.5605, 1.1288, 0.7277, 1.4291, 1.3485, 1.3815, 1.3451, 1.1760, 1.4667,\n",
      "        1.2254, 1.3559, 1.2814, 1.5720, 1.2544, 1.4385, 1.4132, 1.4345, 1.5702,\n",
      "        1.3332, 1.3924, 1.3793, 1.3607, 1.5877, 1.4202, 1.5201, 1.3696, 1.6242,\n",
      "        1.3854, 1.4302, 1.2323, 1.3300, 1.3511, 1.2625, 1.3803, 1.3015, 1.4689,\n",
      "        1.4747, 1.3021, 1.3806, 1.4127, 1.2383, 0.9783, 1.5705, 1.4674, 1.5295,\n",
      "        1.4553, 0.9005, 0.9594, 1.2859, 1.3520, 1.6811, 1.2870, 1.3256, 1.5175,\n",
      "        2.0189, 1.0479, 1.3470, 1.5070, 0.9112, 1.4808, 1.3419, 1.3066, 1.2576,\n",
      "        1.3504, 1.3048, 1.1900, 1.2782, 1.3606, 1.3238, 1.5535, 0.4894, 1.1846,\n",
      "        1.2435, 1.3480, 1.3401, 1.4668, 1.3572, 1.3068, 1.2117, 1.1357, 1.4794,\n",
      "        1.3654, 0.5265, 1.4739, 1.4440, 1.3169, 1.1131, 1.3206, 1.3978, 1.6959,\n",
      "        1.2976, 1.6524, 1.3884, 1.3297, 1.3072, 1.4793, 1.3783, 1.2113, 1.5819,\n",
      "        1.3528, 1.5422, 1.3378, 1.1855, 1.5036, 1.4622, 1.5910, 1.1941, 1.3845,\n",
      "        1.3648, 1.1353, 1.2849, 1.4462, 1.3367, 1.4897, 1.2578, 1.5065, 1.3540,\n",
      "        1.3600, 1.4022, 1.1574, 0.6093, 1.3333, 1.5123, 1.3359, 1.2570, 1.1534,\n",
      "        1.5420, 1.4986, 1.4389, 1.3378, 1.3426, 1.4373, 1.3376, 1.5204, 1.4918,\n",
      "        0.9839, 1.3268, 1.7428, 1.3781, 0.1206, 1.6226, 1.4761, 1.2004, 1.2442,\n",
      "        1.3682, 1.4086, 1.4955, 1.0334, 1.2674, 1.3791, 1.1966, 1.4596, 1.5586,\n",
      "        1.2744, 1.3062, 1.2959, 1.4277, 1.5926, 1.4060, 1.3111, 1.6124, 1.2870,\n",
      "        1.4870, 1.2614, 1.1520, 1.4978, 0.7258, 1.2868, 1.4157, 0.8648, 1.4752,\n",
      "        1.4396, 1.2722, 1.4040, 1.5826, 1.1605, 1.3389, 1.2400, 1.5271, 1.3068,\n",
      "        1.2494, 1.2471, 1.2810, 0.8182, 1.3549, 1.5657, 1.4624, 1.4233, 1.4425,\n",
      "        1.4573, 1.2161, 1.4169, 1.4052, 1.3872, 1.3332, 1.4121, 1.1796, 1.3096,\n",
      "        1.3122, 1.3705, 1.2153, 1.3476, 1.4871, 1.4318, 1.2830, 1.2328, 1.2596,\n",
      "        1.2728, 1.2763, 1.2829, 0.6421, 1.5856, 1.2611, 1.4546, 1.4451, 1.4394,\n",
      "        1.2572, 1.2453, 1.3898, 1.2413, 1.4246, 1.3169, 1.6353, 1.1059, 1.4122,\n",
      "        1.4290, 1.3489, 1.3574, 1.2449, 1.2075, 1.3509, 1.3469, 1.5916, 1.3645,\n",
      "        1.2387, 1.5605, 1.5013, 1.3942, 1.2417, 1.1489, 1.3536, 1.3334, 1.4491,\n",
      "        1.5045, 1.2843, 1.0921, 1.4106, 0.9561, 1.1331, 1.3108, 1.3351, 1.2667,\n",
      "        1.4005, 1.4798, 1.2770, 1.0619, 1.1484, 1.4279, 1.6502, 1.3340, 1.5491,\n",
      "        1.0422, 1.2876, 1.4748, 1.5050, 1.2217, 1.4460, 1.2971, 1.3734, 1.3617,\n",
      "        1.4544, 1.1492, 1.3761, 1.2131, 1.3761, 1.5853, 1.4031, 1.0697, 1.4208,\n",
      "        1.3810, 1.2511, 1.3414, 1.3732, 1.4364, 1.3024, 1.4720, 1.6459, 1.4447,\n",
      "        1.1722, 1.4499, 1.3937, 1.2372, 1.2797, 1.4006, 1.3369, 1.2158, 1.3756],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.0.1.bias\n",
      "Weights: tensor([-3.1667, -1.1090,  0.7313, -1.2462, -1.0639, -0.4178, -1.1329, -1.1084,\n",
      "        -0.9609, -1.1443, -1.1076, -0.4417, -1.0455, -1.3613, -1.2978, -1.1138,\n",
      "        -1.8160, -0.5823, -1.8566, -1.3436, -1.4768, -0.9689, -1.3219, -1.2645,\n",
      "        -1.4269, -0.6804, -0.5877,  0.8673, -1.1518, -0.9923, -1.1916, -0.1131,\n",
      "        -1.3774, -1.8567,  1.1159, -0.7646, -1.6433, -0.7945, -1.5174, -0.7256,\n",
      "        -0.9475, -1.1487, -1.0939,  0.0289, -1.3178,  0.8545, -0.2715, -0.5574,\n",
      "        -0.7145, -0.8401, -1.3017, -1.4551, -0.9280, -0.9599, -1.2300, -1.8869,\n",
      "         1.2088, -0.5868, -1.2961, -1.4131, -0.8564, -1.0733, -1.4909, -1.4301,\n",
      "        -1.9328, -0.7686, -0.8887, -1.5181, -1.1642,  0.4866, -1.2942, -1.6594,\n",
      "        -1.2006,  0.4666,  1.8238, -0.5499, -0.2043,  0.3510,  1.5696, -1.3016,\n",
      "         1.7042, -1.6040, -0.9855, -1.1126, -1.5323, -1.6804, -1.4199, -1.4532,\n",
      "        -1.0089, -1.2694, -2.0194, -1.4371, -1.6170, -1.3002, -1.6117, -0.9242,\n",
      "        -0.2876,  0.0903,  0.8441, -1.4307, -1.3416, -0.3728, -1.1125, -2.4441,\n",
      "        -0.3616, -0.8687, -1.8897, -1.2868, -1.2125, -1.7862, -1.6396, -1.2642,\n",
      "        -1.4300,  0.1499, -0.3720, -1.0042, -0.8221,  0.4041, -0.7846,  1.2548,\n",
      "        -0.3712, -1.2656, -1.7190, -0.6805, -1.3841, -1.6996, -1.0967, -1.5444,\n",
      "        -0.9629, -1.7399, -1.2423, -1.4698, -1.7275, -1.8737, -1.3083, -1.7423,\n",
      "        -1.8565, -1.9044, -1.0050, -0.4843, -0.5660,  1.6788, -1.5358, -1.2960,\n",
      "        -1.2101, -1.8073, -2.0096, -0.8897, -2.4372, -0.7681, -0.9076, -2.0483,\n",
      "        -2.3113, -1.1362, -1.3170, -1.6869, -1.6668, -0.3226, -1.4634, -1.1351,\n",
      "        -0.7044, -1.2994, -1.3541, -1.3001, -1.3372,  1.2186, -0.5827, -0.8823,\n",
      "        -0.8317, -1.7779, -0.7237,  0.6886,  0.0496, -0.6887, -1.2588, -1.4540,\n",
      "         1.4637, -2.0997, -1.3250, -1.6699, -1.2297, -1.4034,  1.1551, -1.3735,\n",
      "        -1.5353, -1.6374, -0.9993, -2.1690, -1.7022, -1.5738,  0.8541, -0.6833,\n",
      "        -0.7646, -0.6280, -1.3090, -0.6542,  1.3408, -1.3380, -1.5115, -1.3482,\n",
      "        -2.1626, -1.4316, -1.3444, -1.1075, -1.8234, -0.4628, -0.0087, -0.7009,\n",
      "        -0.9384, -1.0279, -1.3963, -1.5443, -1.5226, -0.7685, -1.4181, -1.3029,\n",
      "        -1.3066, -1.7270, -0.9460, -1.5698, -0.8247, -1.0925, -1.0823, -1.6031,\n",
      "        -0.6464, -0.8502,  0.0043, -1.2547, -1.7468, -2.2750, -1.4390, -0.8368,\n",
      "        -1.3313, -0.8864, -0.9625, -1.8189, -1.3622, -0.8658, -1.0498, -1.1157,\n",
      "        -0.8368, -0.6305, -1.1846, -0.9125, -1.3907,  0.4753, -1.6969, -1.0007,\n",
      "        -1.6301, -1.4375, -0.1233, -0.5438, -1.2398, -1.1088, -0.9825, -1.1043,\n",
      "        -1.5703, -1.0363, -1.6892, -1.8028, -1.0003, -1.7893,  1.3390, -1.3321,\n",
      "        -1.7055, -1.7865, -0.9318, -1.5530, -0.9922, -0.5113, -1.8229, -1.5902,\n",
      "        -1.3392, -1.3695, -1.5734, -0.9528, -1.0917, -1.5785,  0.1975, -0.2571,\n",
      "        -1.8918,  1.0290, -1.0796, -1.4656, -1.4087, -1.5879, -0.9801, -1.6498,\n",
      "        -1.5068, -1.2324, -1.7274,  0.2238, -1.7064, -1.0206, -0.7347, -1.5752,\n",
      "        -1.3402, -1.4481, -1.2668, -1.5322, -1.6167, -1.5908, -1.0865, -1.8227,\n",
      "         0.2200,  0.7607, -1.2336,  0.0558, -1.1291, -0.7861, -0.0686,  0.5523,\n",
      "        -0.6757, -1.5472, -0.4845, -0.9428, -1.4642, -0.8681, -0.9960, -0.4569,\n",
      "        -0.5789, -1.2274, -1.6015, -0.2180, -0.9216,  1.3984,  0.6082, -1.3098,\n",
      "        -1.1101, -1.0695, -1.6842,  0.1626, -1.0935, -2.5382, -0.8639, -1.1381,\n",
      "        -1.5455, -1.0605, -1.1676, -1.5392, -1.6334, -1.4384, -0.0698, -1.7321,\n",
      "         0.0791, -1.6406,  0.6839, -1.2504, -2.1143, -0.1756, -0.9530, -1.2006,\n",
      "         0.6066, -1.8997, -0.7349, -1.7033, -0.9875, -2.0152, -1.4565, -1.1373,\n",
      "        -1.3649,  1.2461, -1.5227, -0.4721, -0.6384, -1.1232, -0.6613, -0.8417,\n",
      "        -0.1377, -1.3204, -0.9560, -1.1547, -0.9943, -1.8574, -0.4706, -1.0232,\n",
      "        -0.6236, -1.2460, -1.5845, -0.8850, -1.3689, -1.0995, -0.8793, -1.0071,\n",
      "        -0.8220,  0.7788, -1.0918, -1.2340, -1.7951, -1.3052, -1.6507, -1.3822,\n",
      "         0.2808, -0.7682, -0.7775, -0.0479, -1.3094, -0.6880, -1.3737, -0.3614,\n",
      "        -0.8089, -0.9416, -1.6358,  0.2179,  0.4214, -1.1872, -0.7794, -1.9789,\n",
      "        -1.4786, -1.4477, -1.6508, -1.4678, -1.2074, -1.3257, -1.3137, -1.0466,\n",
      "        -1.3045,  0.1041,  4.0237, -1.6904, -1.3791, -1.5638,  0.3159, -0.8842,\n",
      "        -1.4721, -0.9342, -1.5902, -1.0991, -1.4367, -0.9218, -0.8777, -1.5475,\n",
      "        -0.6052, -1.5555, -1.3053,  0.6291, -1.3878, -0.2922, -1.1518, -1.3218,\n",
      "        -0.7601, -0.3137, -1.0712, -1.3559, -0.3167,  1.1487, -1.7676, -0.6587,\n",
      "         1.6231, -1.4661,  0.1506, -1.6311, -0.5598, -0.8635, -1.5113, -1.5471,\n",
      "        -1.5569, -1.4794, -1.6118, -1.6534, -1.0469, -1.3042, -0.4372, -2.2710,\n",
      "        -0.6157, -1.5726, -1.5130, -0.1949, -1.5245, -1.2279, -2.5278, -2.1371,\n",
      "        -0.8589, -1.7278, -1.2750, -1.7398, -2.2238, -1.2673, -1.4950, -1.9617,\n",
      "        -2.3627, -0.4941, -0.9143, -0.9477, -1.8758, -1.1012, -0.7250, -0.4693,\n",
      "        -1.5347,  1.4242, -2.2665, -1.8267, -1.4940, -1.6327, -1.0162, -1.6260,\n",
      "        -1.6751, -1.1344, -1.3836, -0.9766, -0.9213, -1.8294, -1.3602, -1.4935,\n",
      "        -0.0698, -1.0641, -1.5921, -1.6079, -1.9283, -1.3107, -1.4516,  0.2265,\n",
      "        -0.6294, -1.6899, -1.6344, -0.9438, -0.7797, -1.1586, -0.8405, -1.1842,\n",
      "        -1.4313, -1.3911, -1.1788, -1.7048, -1.8113, -1.3104, -1.7446, -1.8136,\n",
      "        -1.4541, -1.4503, -1.0314, -1.0331, -1.7015, -1.3233, -0.7930, -1.3256,\n",
      "        -2.2280, -0.1797, -1.4332, -0.6877,  0.7968, -1.8370, -0.3970, -0.0313,\n",
      "         0.6468, -1.2072, -1.1446, -0.6529, -1.7878, -0.4251, -1.5979, -1.9917,\n",
      "        -1.3104, -0.7977, -1.5776, -1.2578,  0.9486, -2.0112, -1.0274, -1.1449,\n",
      "        -1.3627, -0.9864, -1.2512, -0.9667, -1.4365, -3.0756, -1.4986, -1.2347,\n",
      "        -1.7826, -1.7071, -1.5288, -1.9485, -1.0512,  0.3681, -1.5320, -1.7683],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.1.0.weight\n",
      "Weights: tensor([[[[ 0.0868,  0.0807,  0.0655],\n",
      "          [ 0.0968,  0.1190,  0.0803],\n",
      "          [ 0.0732,  0.0793,  0.0413]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0680,  0.1089,  0.0714],\n",
      "          [ 0.1101,  0.1984,  0.1180],\n",
      "          [ 0.0635,  0.1244,  0.0736]]],\n",
      "\n",
      "\n",
      "        [[[-0.0664, -0.0966, -0.0724],\n",
      "          [-0.0935, -0.1498, -0.1070],\n",
      "          [-0.0643, -0.1027, -0.0668]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0741, -0.1025, -0.0630],\n",
      "          [-0.0934, -0.1247, -0.0955],\n",
      "          [-0.0762, -0.0912, -0.0687]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0672,  0.1088,  0.0680],\n",
      "          [ 0.1084,  0.1742,  0.1107],\n",
      "          [ 0.0642,  0.1044,  0.0693]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0764,  0.1160,  0.0727],\n",
      "          [ 0.1118,  0.1719,  0.1198],\n",
      "          [ 0.0741,  0.1121,  0.0849]]]], device='cuda:0')\n",
      "Shape: torch.Size([576, 1, 3, 3])\n",
      "\n",
      "Layer: features.14.conv.1.1.weight\n",
      "Weights: tensor([0.8642, 0.5685, 0.6013, 0.5244, 0.4927, 0.5738, 0.5502, 0.4916, 0.4808,\n",
      "        0.5081, 0.5092, 0.5848, 0.5012, 0.6260, 0.5022, 0.5647, 0.4085, 0.9866,\n",
      "        0.4931, 0.4930, 0.4943, 0.5262, 0.4858, 0.5491, 0.5660, 0.5487, 0.7488,\n",
      "        1.3358, 0.5756, 0.5594, 0.5771, 1.9306, 0.4798, 0.4944, 0.8171, 0.5401,\n",
      "        0.4965, 0.5241, 0.4280, 0.5559, 0.5070, 0.5456, 0.8561, 0.5784, 0.5124,\n",
      "        0.7685, 0.5808, 0.5610, 0.5484, 0.5782, 0.6242, 0.4747, 0.5546, 0.5712,\n",
      "        0.5127, 0.4553, 0.5349, 0.5629, 0.5102, 0.6490, 0.5033, 0.5267, 0.4707,\n",
      "        0.6058, 0.3775, 0.5514, 0.5518, 0.4595, 0.5291, 0.7187, 0.4883, 0.4361,\n",
      "        0.5138, 1.2296, 2.0168, 0.6100, 2.1563, 1.1074, 1.6090, 0.4836, 1.5690,\n",
      "        0.5196, 0.5229, 0.5217, 0.5952, 0.4860, 0.4763, 0.4780, 0.6426, 0.4565,\n",
      "        0.4252, 0.4952, 0.4726, 0.6129, 0.4697, 0.4716, 0.5505, 0.6350, 0.7283,\n",
      "        0.4807, 0.5429, 0.5437, 0.6089, 0.3599, 0.6397, 0.4939, 0.7377, 0.5085,\n",
      "        0.6130, 0.4489, 0.4733, 0.5375, 0.5651, 0.6421, 0.5370, 0.5715, 0.5049,\n",
      "        0.6534, 0.5999, 1.1673, 0.6953, 0.5683, 0.5114, 0.6617, 0.4937, 0.4469,\n",
      "        0.4836, 0.4863, 0.5484, 0.4103, 0.4724, 0.4916, 1.7947, 0.7127, 0.5303,\n",
      "        0.4846, 0.3896, 0.4476, 0.5894, 0.4833, 0.6214, 1.1264, 0.5573, 0.5231,\n",
      "        0.4399, 0.6605, 0.3865, 0.4852, 0.3524, 0.5081, 0.6111, 0.4050, 0.3768,\n",
      "        0.6532, 0.5250, 0.4701, 0.4701, 0.6304, 0.4798, 0.5747, 0.5183, 0.5465,\n",
      "        0.7043, 0.5398, 0.4856, 0.8669, 0.8752, 0.5407, 0.4835, 0.4776, 0.5189,\n",
      "        0.6787, 1.2388, 0.5127, 0.5300, 0.5121, 1.4925, 0.4441, 0.5441, 0.4893,\n",
      "        0.5335, 0.5844, 1.1370, 0.5283, 0.4497, 0.4701, 0.5692, 0.4326, 0.4527,\n",
      "        0.4681, 1.7458, 0.5092, 0.5807, 0.5624, 0.5410, 0.6516, 2.0036, 0.6252,\n",
      "        0.5404, 0.4373, 0.3420, 0.5084, 0.5071, 0.5157, 0.4061, 0.5276, 0.5263,\n",
      "        0.6789, 0.4702, 0.5919, 0.4866, 0.5101, 0.6830, 0.6785, 0.5086, 0.4812,\n",
      "        0.4917, 0.5327, 0.4943, 0.4758, 0.4796, 0.4242, 0.5199, 0.5191, 0.4931,\n",
      "        0.5582, 1.4455, 0.5093, 0.3762, 0.5105, 0.5034, 0.5296, 0.4407, 0.5436,\n",
      "        0.5535, 0.4969, 0.5009, 0.4989, 0.4544, 0.5157, 0.5165, 0.5292, 0.5281,\n",
      "        0.4868, 0.4533, 0.6792, 0.4898, 0.5513, 0.4483, 0.4729, 0.5915, 0.4931,\n",
      "        0.5105, 0.5044, 0.4830, 0.4815, 0.4467, 0.5739, 0.5758, 0.4605, 0.6817,\n",
      "        0.4985, 1.3626, 0.4332, 0.5318, 0.4854, 0.4901, 0.5484, 0.5493, 0.5079,\n",
      "        0.4359, 0.4908, 0.4733, 0.4835, 0.4913, 0.4688, 0.5354, 0.5142, 1.5072,\n",
      "        0.7744, 0.4205, 0.6701, 0.5409, 0.4798, 0.4587, 0.4619, 0.5080, 0.4538,\n",
      "        0.4846, 0.5215, 0.4490, 0.8188, 0.4395, 0.4655, 0.5854, 0.4752, 0.6035,\n",
      "        0.4545, 0.5001, 0.4385, 0.5266, 0.5532, 0.4789, 0.5435, 1.0128, 0.5425,\n",
      "        0.5429, 0.9153, 0.5128, 0.5083, 0.5436, 1.5463, 0.5943, 0.4856, 0.6434,\n",
      "        0.6060, 0.5340, 0.5658, 0.4957, 0.4728, 0.4640, 0.5335, 0.4831, 0.7003,\n",
      "        0.5246, 0.7043, 1.1870, 0.5726, 0.5327, 0.5037, 0.4650, 0.9204, 0.5650,\n",
      "        0.7810, 0.7639, 0.4804, 0.5990, 0.5256, 0.5504, 0.4750, 0.4886, 0.5009,\n",
      "        0.5936, 0.4862, 0.9605, 0.4605, 1.8715, 0.6025, 0.4018, 1.6114, 0.4795,\n",
      "        0.4916, 1.5614, 0.4588, 0.5499, 0.8004, 0.6040, 0.4163, 0.4688, 0.5673,\n",
      "        0.4820, 1.6566, 0.5683, 0.5095, 0.5879, 0.5987, 0.5306, 0.5526, 1.0983,\n",
      "        0.4954, 0.4960, 0.5436, 0.5195, 0.4578, 0.6050, 0.5058, 0.5119, 0.4889,\n",
      "        0.5009, 0.6057, 0.5170, 0.5291, 0.5753, 0.5302, 0.5169, 0.8672, 0.5057,\n",
      "        0.5382, 0.7900, 0.4910, 0.4289, 0.5783, 1.5051, 0.4810, 0.5339, 0.5558,\n",
      "        0.5619, 0.5081, 0.5578, 1.7051, 0.4972, 0.6405, 0.4873, 0.5280, 0.7944,\n",
      "        0.5450, 0.5436, 0.5242, 0.5296, 0.4948, 0.4822, 0.5195, 0.4752, 0.4907,\n",
      "        0.5320, 0.5419, 0.5338, 1.2384, 1.9983, 0.4880, 0.4853, 0.4739, 0.4820,\n",
      "        0.5247, 0.4981, 0.5272, 0.5195, 0.4960, 0.5281, 0.5273, 0.6117, 0.5180,\n",
      "        0.5171, 0.4408, 0.6284, 0.8474, 0.7502, 0.7996, 0.6032, 0.5661, 0.5519,\n",
      "        0.6610, 0.6193, 0.5066, 0.7977, 0.7558, 0.4641, 0.6237, 0.6460, 0.5176,\n",
      "        0.6229, 0.5136, 0.6882, 0.6344, 0.4859, 0.5124, 0.4164, 0.5274, 0.5377,\n",
      "        0.5389, 0.4446, 0.4670, 1.2659, 0.4610, 0.7225, 0.5259, 0.5814, 0.7276,\n",
      "        0.4867, 0.4858, 0.4292, 0.4975, 0.7283, 0.4593, 0.5009, 0.4167, 0.3662,\n",
      "        0.5116, 0.4657, 0.4241, 0.5289, 0.5669, 0.5046, 0.5067, 0.4175, 0.4972,\n",
      "        0.5074, 0.5159, 0.4382, 1.3880, 0.6021, 0.4905, 0.4719, 0.4817, 0.4997,\n",
      "        0.5121, 0.4080, 0.4992, 0.5234, 0.5198, 0.5184, 0.5207, 0.4696, 0.5626,\n",
      "        0.9320, 0.4871, 0.4610, 0.4508, 0.4517, 0.5482, 0.5107, 0.8016, 0.5436,\n",
      "        0.4385, 0.5523, 0.5309, 0.5328, 0.4743, 0.6850, 0.4833, 0.5222, 0.5872,\n",
      "        0.5921, 0.4295, 0.3804, 0.5065, 0.4934, 0.3403, 0.4637, 0.5083, 0.5231,\n",
      "        0.5003, 0.4830, 0.5010, 0.4961, 0.4758, 0.3805, 0.7579, 0.4817, 0.6178,\n",
      "        0.5967, 0.4550, 0.5532, 0.8073, 1.0307, 0.5124, 0.6010, 0.5042, 0.4624,\n",
      "        0.5700, 0.4991, 0.4739, 0.4820, 0.5755, 0.5080, 0.5053, 0.8567, 0.4337,\n",
      "        0.5105, 0.5460, 0.5038, 0.5120, 0.5375, 0.5201, 0.6339, 0.5638, 0.5596,\n",
      "        0.4852, 0.5195, 0.4686, 0.4263, 0.4300, 0.6920, 0.6378, 0.4596, 0.4783],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.1.1.bias\n",
      "Weights: tensor([ 4.5179e+00,  4.1448e-01,  6.3932e-01,  1.7313e-02,  4.1130e+00,\n",
      "         3.5327e+00,  2.7680e-01,  2.9978e-01,  4.0071e+00,  2.2830e+00,\n",
      "         1.9074e-01,  1.1020e+00,  3.2337e+00, -2.7406e-01,  4.3997e+00,\n",
      "         3.2549e-01,  1.2057e-01,  1.0543e+00, -1.3214e-02,  2.2881e-01,\n",
      "         2.6640e-01,  3.6545e+00,  2.6350e-01,  2.8496e-01,  2.7199e-01,\n",
      "         3.8891e+00,  1.2748e+00, -4.5832e-01,  3.8903e-01,  2.1468e-01,\n",
      "         3.7285e+00, -5.2277e-01,  2.1874e-01,  2.2707e-01,  4.1634e-01,\n",
      "         3.4710e+00,  2.0863e-01,  4.1691e+00,  1.3955e-01,  3.8035e+00,\n",
      "         3.7145e+00,  4.1569e+00, -5.5171e-01,  7.3166e-01,  2.9793e-01,\n",
      "         9.6225e-01,  3.2189e+00,  3.3972e+00,  2.9275e+00,  3.3158e+00,\n",
      "         5.3723e-02,  2.3647e-01,  4.3738e-01,  2.6817e-01,  4.6242e-02,\n",
      "         1.8223e-01,  1.7502e+00,  3.1634e-01,  2.8224e-01,  1.0437e-01,\n",
      "         3.4684e+00,  2.7351e-01,  1.7163e-01,  2.5670e+00,  1.0455e-01,\n",
      "         1.7690e+00,  3.5434e+00,  1.9669e-01,  1.3597e-01,  4.8793e-01,\n",
      "         2.3292e-01,  1.7487e-01,  2.6351e-01, -1.9437e-01, -8.6828e-01,\n",
      "         2.5246e+00,  2.2023e+00,  3.1790e-02, -1.3745e+00,  3.3940e+00,\n",
      "        -1.4316e+00,  1.9887e-01,  3.2719e+00,  4.6049e+00, -4.7013e-01,\n",
      "         1.9146e-01,  2.1279e-01,  1.7857e-01,  2.5207e-01,  3.1023e+00,\n",
      "         1.3481e-01,  2.3498e-01,  2.2483e-01,  2.4783e+00,  2.4561e-01,\n",
      "         3.5463e+00,  2.4029e+00,  9.9869e-01,  1.2280e+00,  2.3176e-01,\n",
      "         3.0405e-01,  2.1899e-02, -8.3019e-02, -3.8510e-01,  7.6767e-01,\n",
      "         3.1126e+00, -7.0762e-02,  2.7667e-01,  3.4034e-01,  1.8447e-01,\n",
      "         2.2115e-01,  4.3863e+00,  1.3922e-01,  2.7009e+00,  8.8260e-01,\n",
      "         4.1704e-01,  3.2032e+00,  5.9472e-01,  3.7600e+00, -4.7009e-01,\n",
      "         5.5367e-01,  2.9814e-01,  2.4220e-01,  3.6408e-01,  2.5379e-01,\n",
      "         1.8962e-01,  2.8074e-01,  2.7381e-01,  1.5407e+00,  1.6961e-01,\n",
      "         1.8935e-01,  2.2445e-01, -1.1388e+00,  9.5352e-02,  3.3404e+00,\n",
      "         2.2390e-01,  1.2217e-01,  1.5674e-01,  1.9396e-01,  1.9206e+00,\n",
      "         1.2993e+00,  9.4830e-01,  1.9056e+00,  2.5393e-01,  4.5131e+00,\n",
      "         6.0723e-02,  1.1165e-01,  3.7239e+00,  8.4568e-02,  2.5873e+00,\n",
      "         1.4257e+00,  9.4602e-02,  9.3613e-02,  6.4790e-02,  2.7904e-01,\n",
      "         1.9859e-01,  4.2976e+00,  3.5580e+00,  2.6433e-01,  2.4989e+00,\n",
      "         3.5218e+00,  2.1408e+00, -1.0404e+00,  2.3425e-01,  2.8465e-01,\n",
      "         1.5917e-01, -2.9006e-01,  1.9821e-01,  3.2712e+00,  2.2681e-01,\n",
      "         1.3158e+00,  4.5736e-01, -1.8084e+00,  4.3215e+00,  1.8238e-01,\n",
      "        -7.7081e-02, -6.6359e-01,  1.3678e-01,  1.4062e-01,  1.8447e-01,\n",
      "         3.3025e-01,  1.0515e-01,  8.7393e-01,  2.2544e-01,  1.8499e-01,\n",
      "         1.9595e-01,  1.9883e+00,  1.3343e-01,  3.0637e-02,  1.9525e-01,\n",
      "        -9.0173e-01,  3.1818e+00,  9.2961e-01,  3.6996e+00,  3.4337e-01,\n",
      "         1.2016e+00, -2.1339e+00, -1.2630e-01,  2.8079e-01,  3.9778e+00,\n",
      "         8.6608e-02,  2.2955e-01,  5.1290e+00,  3.1071e-01,  1.1663e-01,\n",
      "         2.5868e+00,  1.5947e+00,  1.4448e+00,  2.3563e+00,  3.9710e-01,\n",
      "         1.4259e-01,  3.5426e-01, -2.4100e-01,  1.2113e+00,  2.0642e-01,\n",
      "         2.8404e-01,  2.6471e-01, -6.3143e-01,  2.4277e+00,  4.3847e-01,\n",
      "         3.3530e+00,  3.9795e+00,  4.4001e+00,  9.2920e-02,  1.4276e+00,\n",
      "         3.5472e+00,  1.9770e+00,  3.3465e-01, -1.2306e-01,  8.0348e-02,\n",
      "        -1.9054e-02,  3.2575e+00,  2.0020e-01,  3.7895e-01,  3.9798e+00,\n",
      "         2.1386e-01,  4.4956e-01,  3.2746e+00,  1.9268e+00,  3.6778e+00,\n",
      "         3.6008e+00,  2.1279e+00,  2.9134e-01,  4.1245e+00,  2.1431e-01,\n",
      "         9.4790e-01, -2.5009e-02,  3.5597e-01,  1.8147e-01,  4.7286e+00,\n",
      "         1.3347e+00,  1.1541e+00,  5.0280e-01,  3.7816e+00,  4.4386e+00,\n",
      "         3.6542e+00,  2.2619e-01,  1.7159e-02,  1.4174e-01,  1.2298e-01,\n",
      "         1.5912e+00,  4.7688e-01, -6.9780e-01,  1.7237e-01,  2.3883e-01,\n",
      "         1.4879e-01,  3.0384e+00,  1.8594e+00,  4.0435e+00,  1.9841e+00,\n",
      "         1.8740e-01,  2.1697e-01,  4.3318e+00,  4.7999e+00,  1.5003e-01,\n",
      "         3.0280e+00,  1.6735e-02,  6.2181e-02, -3.0984e-01,  7.1625e-01,\n",
      "         1.0092e-01,  2.8401e+00,  3.2547e-01,  1.9374e-01,  2.0590e+00,\n",
      "         2.1228e-01,  3.6565e+00,  1.5252e-01,  1.8919e-01,  1.1510e-01,\n",
      "         1.0157e-01,  4.2769e-01,  1.7210e-01,  2.1877e+00,  3.2197e+00,\n",
      "         3.1880e-01,  3.4695e-01,  2.3411e-01,  4.5317e+00,  2.1310e-01,\n",
      "         2.6258e-01,  2.8943e-01,  2.8523e+00,  3.1409e-01, -8.9582e-04,\n",
      "         1.1789e+00,  3.3062e-01,  2.9909e-01,  2.7318e-01,  3.0273e+00,\n",
      "         1.0122e+00, -4.2109e-01,  5.3088e-01, -6.7000e-02,  6.7973e-01,\n",
      "         4.1974e+00,  3.2047e-01,  3.9270e-01,  4.4665e+00,  2.3860e+00,\n",
      "         1.3119e+00, -1.2647e-01,  2.3752e-01,  8.8927e-01,  4.2374e-01,\n",
      "         2.3873e+00, -7.5090e-01, -1.0608e-01,  3.1507e-01,  3.7607e-01,\n",
      "         2.1085e-01,  4.1418e-01,  3.8852e-01,  2.1854e-01,  9.6967e-02,\n",
      "         2.8783e-01, -3.9702e-01, -3.0782e-02,  1.6101e+00,  2.3155e-01,\n",
      "         1.8971e-01,  4.6223e+00,  2.1615e+00,  2.0473e-01,  2.1241e-01,\n",
      "         4.2796e+00, -7.8173e-01,  3.3647e-01,  1.5535e-01, -9.9451e-01,\n",
      "         3.1587e+00,  4.7192e+00, -6.1404e-01,  1.3484e-01,  2.3874e+00,\n",
      "        -8.0200e-02,  1.3124e+00,  1.1946e-01,  9.9330e-01,  4.7832e-01,\n",
      "         1.2263e-01, -1.6013e+00,  6.7593e-02,  1.0494e+00,  2.9072e+00,\n",
      "         1.0104e-01,  3.3508e+00,  3.8914e+00,  8.8043e-03,  2.1170e-01,\n",
      "         2.0475e+00, -1.9273e-02,  3.4805e-01,  1.8640e-01,  5.5210e-01,\n",
      "         4.3036e+00,  2.8915e+00,  2.8660e+00,  2.2555e-01,  1.8872e+00,\n",
      "         5.1529e-02,  2.2175e-01,  1.1373e+00,  4.3621e+00,  2.4560e+00,\n",
      "         1.3866e-01,  3.6298e+00,  4.8465e+00,  1.4266e+00,  2.4618e-01,\n",
      "         2.0153e-01,  2.6031e-01, -1.3933e-01,  3.1357e+00,  4.3346e-01,\n",
      "         1.0588e+00, -2.1044e-01,  1.9706e+00, -2.6652e-01,  1.3599e+00,\n",
      "         2.1108e+00,  1.6475e+00,  2.0293e-01,  8.4983e-01,  2.7677e-01,\n",
      "         3.8913e+00,  3.2655e+00,  5.5344e-02,  2.6697e-01,  2.4226e-01,\n",
      "         1.9674e-01,  2.6326e-01,  2.8897e-01,  1.7385e-01, -8.2049e-02,\n",
      "         2.2541e-01,  4.1394e-01, -1.2249e-01,  4.2644e-01,  2.1140e-01,\n",
      "         2.7098e-01, -3.4804e-03,  1.0452e+00,  1.4099e+00,  2.4111e-01,\n",
      "         4.2343e+00, -4.9592e-02,  2.9423e-01,  1.0718e-01,  4.0472e-01,\n",
      "         5.0099e-01,  4.0335e+00,  1.2854e+00,  6.0550e-02, -9.6672e-02,\n",
      "         3.8074e-01,  1.2641e+00,  5.8814e-01,  5.1020e-02,  3.8404e-01,\n",
      "         3.4701e+00,  7.8934e-01,  3.5838e-01,  1.8232e-01,  6.0372e-01,\n",
      "         3.0327e-01,  1.8033e-01,  1.3305e+00,  5.1845e-01,  2.9718e-01,\n",
      "         7.2420e-01,  1.8537e-01,  8.4117e-01,  9.5265e-01,  1.8235e-01,\n",
      "         1.2384e-01,  1.6536e-01,  3.0712e-01,  2.2409e-01,  2.0446e-01,\n",
      "         3.2388e+00,  3.9781e+00,  6.3683e-01,  1.3103e-01,  1.1395e+00,\n",
      "         2.6419e-01,  2.3591e-01,  5.2350e-01,  2.8407e-01,  2.3391e-01,\n",
      "         1.1379e-01,  2.8123e-01, -3.5974e-01,  1.9013e-01,  9.0286e-02,\n",
      "         1.4602e-01,  7.9142e-02,  2.3663e+00,  2.1731e-01,  6.8793e-02,\n",
      "         1.2837e-01,  1.8920e+00,  3.6709e-01,  3.4852e+00,  7.8255e-02,\n",
      "         1.2994e-01,  3.9169e+00,  2.8637e+00,  1.9669e-01, -8.1528e-01,\n",
      "         2.8847e-02,  1.6882e-01,  2.2848e-01,  1.5782e-01,  3.4101e+00,\n",
      "         2.1697e-01,  1.5551e-01,  3.8305e+00,  2.3235e-01,  3.2938e+00,\n",
      "         4.2289e+00,  2.4658e-01,  1.7797e-01,  1.6226e+00,  3.3058e-01,\n",
      "         3.6690e+00,  1.9401e-01,  8.5858e-02,  1.5254e-01, -1.4770e-01,\n",
      "         2.4126e-01,  8.4269e-01,  4.5082e+00,  1.5810e-01,  1.1337e-01,\n",
      "         3.2606e+00,  3.5512e+00,  4.4051e+00, -1.2405e-01,  4.2454e+00,\n",
      "         2.4659e-01,  2.0331e-01,  4.1692e-01,  1.5962e-01,  9.1859e-02,\n",
      "         4.5565e+00,  1.1165e-01,  1.0462e-01,  2.1267e-01,  2.4739e-01,\n",
      "         3.9284e+00,  3.6273e+00,  2.1817e-01,  2.2235e-01,  4.9646e-01,\n",
      "         4.5155e-02,  1.2342e-01,  5.7926e-01, -1.1728e-02,  7.9537e-01,\n",
      "         9.2940e-01,  1.6360e-01,  1.0819e+00,  4.9086e-01,  2.8910e-02,\n",
      "         3.3715e+00,  3.9593e-01,  2.2056e+00,  1.5803e-01,  1.3873e+00,\n",
      "         2.2171e-01,  1.9144e-01,  2.8184e-01,  3.9046e-01,  1.3127e-01,\n",
      "         4.4284e+00,  1.9475e-01,  1.6808e-01,  3.4326e+00,  2.9205e-01,\n",
      "         2.8100e-01,  4.9617e+00,  2.9361e-01,  3.8072e+00,  2.9838e-02,\n",
      "         1.0513e-01,  2.6799e-01,  2.3399e-01,  2.3928e-01,  4.3448e-02,\n",
      "         1.8496e-01,  1.2442e-01, -7.3402e-01,  6.8459e-01,  1.6391e-01,\n",
      "         3.1666e-02], device='cuda:0')\n",
      "Shape: torch.Size([576])\n",
      "\n",
      "Layer: features.14.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0538]],\n",
      "\n",
      "         [[ 0.0405]],\n",
      "\n",
      "         [[ 0.0310]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0083]],\n",
      "\n",
      "         [[-0.0269]],\n",
      "\n",
      "         [[-0.0111]]],\n",
      "\n",
      "\n",
      "        [[[-0.0052]],\n",
      "\n",
      "         [[ 0.0305]],\n",
      "\n",
      "         [[ 0.3187]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1080]],\n",
      "\n",
      "         [[-0.0410]],\n",
      "\n",
      "         [[ 0.0302]]],\n",
      "\n",
      "\n",
      "        [[[-0.0942]],\n",
      "\n",
      "         [[-0.1312]],\n",
      "\n",
      "         [[-0.0033]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1046]],\n",
      "\n",
      "         [[-0.0644]],\n",
      "\n",
      "         [[-0.0594]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.1040]],\n",
      "\n",
      "         [[-0.1640]],\n",
      "\n",
      "         [[ 0.0098]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0592]],\n",
      "\n",
      "         [[ 0.1085]],\n",
      "\n",
      "         [[ 0.0100]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0261]],\n",
      "\n",
      "         [[ 0.1327]],\n",
      "\n",
      "         [[ 0.0102]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0175]],\n",
      "\n",
      "         [[ 0.0348]],\n",
      "\n",
      "         [[-0.0980]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0061]],\n",
      "\n",
      "         [[ 0.0018]],\n",
      "\n",
      "         [[ 0.0378]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0545]],\n",
      "\n",
      "         [[ 0.2397]],\n",
      "\n",
      "         [[-0.0068]]]], device='cuda:0')\n",
      "Shape: torch.Size([160, 576, 1, 1])\n",
      "\n",
      "Layer: features.14.conv.3.weight\n",
      "Weights: tensor([2.0001, 3.0690, 2.1995, 2.6506, 2.4443, 3.0268, 2.7616, 4.2054, 2.7950,\n",
      "        3.5043, 2.4131, 2.4065, 2.5563, 2.1848, 2.3045, 2.2772, 3.2411, 2.0874,\n",
      "        4.5582, 2.2123, 3.4077, 2.7890, 2.5905, 2.2312, 2.7587, 2.5490, 3.6211,\n",
      "        2.8622, 2.8162, 2.5381, 3.1120, 2.5798, 2.7786, 2.4798, 2.3162, 3.8977,\n",
      "        2.3651, 3.3775, 2.2783, 2.8029, 2.2384, 2.9567, 2.9893, 3.8085, 2.3301,\n",
      "        2.7076, 2.6217, 2.7108, 3.9463, 2.2933, 2.2586, 2.2421, 2.2483, 2.4748,\n",
      "        2.4606, 2.3461, 2.3457, 2.8188, 2.3376, 1.9580, 2.5647, 2.7695, 2.4796,\n",
      "        2.9853, 2.5451, 2.3056, 2.2633, 2.4383, 3.2932, 1.7793, 2.0911, 3.3688,\n",
      "        2.7705, 2.5582, 2.0668, 2.4369, 2.7557, 2.4616, 2.0222, 3.5438, 2.7680,\n",
      "        2.4652, 3.3052, 2.4949, 2.3305, 2.7112, 3.7348, 2.4240, 2.4292, 2.4307,\n",
      "        2.5798, 2.3785, 2.3208, 3.4096, 2.7397, 2.8142, 3.3101, 2.8058, 2.5114,\n",
      "        2.4586, 2.3392, 2.6736, 2.1785, 2.3646, 2.0859, 2.7855, 2.2522, 2.6208,\n",
      "        2.6276, 2.7167, 2.4414, 2.3090, 1.9961, 2.9135, 2.4276, 3.3626, 2.3305,\n",
      "        3.0630, 3.6676, 3.1886, 2.5065, 1.9672, 3.1328, 2.4882, 2.3008, 2.1660,\n",
      "        2.6977, 3.1456, 2.2368, 2.4529, 2.9223, 2.6659, 3.0190, 3.3405, 3.3434,\n",
      "        2.2128, 3.1375, 4.0217, 2.4894, 2.8488, 2.3746, 2.4647, 3.7627, 2.7561,\n",
      "        2.0635, 3.1380, 2.3772, 3.2165, 2.3424, 1.9993, 2.1463, 2.2593, 2.5559,\n",
      "        2.5494, 2.3325, 2.1285, 2.3695, 2.4301, 2.3888, 2.5819],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.14.conv.3.bias\n",
      "Weights: tensor([ 1.1784e-03, -2.4988e-04,  8.9454e-05, -3.3950e-04,  2.2312e-04,\n",
      "        -1.0689e-03,  1.9809e-04,  3.3180e-04, -1.8088e-04, -8.7599e-04,\n",
      "        -1.1255e-04,  1.4259e-05, -3.7005e-04, -3.9558e-04,  7.5409e-04,\n",
      "        -6.3099e-04, -5.1123e-04,  8.5052e-04,  1.0185e-03, -3.5606e-05,\n",
      "        -1.0598e-04, -3.3975e-05, -4.2180e-04, -7.6880e-05, -2.9648e-04,\n",
      "        -1.5112e-03,  1.3728e-04,  4.2894e-04,  4.6910e-04,  5.2243e-05,\n",
      "         1.4319e-04, -7.6321e-04,  5.2145e-04, -7.9943e-05,  1.3844e-03,\n",
      "        -8.1506e-04, -9.1879e-05, -1.2169e-04, -4.1312e-04,  3.6780e-04,\n",
      "         5.9343e-04,  2.0095e-04,  1.0860e-04,  1.0628e-05,  1.4055e-03,\n",
      "         1.0320e-03,  3.7948e-05,  1.1553e-04,  2.1829e-07, -2.0294e-03,\n",
      "         7.7212e-05,  8.6975e-04, -8.0371e-04,  2.5960e-04,  6.7046e-04,\n",
      "        -2.6918e-04, -7.0511e-05, -4.7571e-05, -4.6849e-04,  7.7162e-04,\n",
      "        -4.9834e-04, -5.2130e-05, -1.2490e-04, -1.8343e-04, -1.5826e-05,\n",
      "         5.1195e-04, -4.0874e-04, -1.9817e-04, -3.2194e-04,  4.3598e-04,\n",
      "        -1.0136e-03, -6.9143e-05,  1.2401e-05,  3.4226e-05,  1.1688e-03,\n",
      "         6.3362e-06,  9.9703e-04,  4.8798e-04, -7.5100e-04, -5.2428e-04,\n",
      "        -1.5707e-05,  4.8960e-04,  2.0340e-04,  2.2366e-04, -7.9977e-04,\n",
      "         6.1548e-05,  8.2423e-04,  2.3376e-04,  4.7247e-04, -3.7435e-04,\n",
      "         2.3088e-04,  4.0327e-04, -2.8730e-04,  9.9384e-04, -2.4178e-04,\n",
      "         1.2356e-04,  1.0230e-03, -2.6112e-04,  1.5219e-04, -3.9729e-04,\n",
      "         4.7102e-04,  1.8307e-04, -2.6768e-04,  6.9568e-04,  7.7717e-04,\n",
      "        -4.8341e-04, -1.0065e-03,  1.9398e-04, -1.5876e-04,  6.5772e-04,\n",
      "         1.9242e-04,  1.5973e-03, -6.6664e-04, -4.8910e-04, -5.5301e-04,\n",
      "         2.0193e-04,  2.8869e-04,  5.7576e-05,  2.8756e-04,  4.1104e-04,\n",
      "         9.6192e-04,  5.6796e-04,  6.6531e-05, -9.8169e-05, -1.9765e-04,\n",
      "         1.1040e-04,  1.8131e-04, -6.1046e-04,  4.1388e-04, -4.3122e-04,\n",
      "        -4.0890e-04, -9.2789e-06,  2.3050e-04, -6.1154e-04, -1.9268e-04,\n",
      "         1.5158e-04, -3.8079e-06, -2.0966e-04, -8.2658e-05, -6.4799e-04,\n",
      "        -3.6372e-04, -5.4580e-04,  1.8475e-04, -3.4798e-04, -1.2524e-05,\n",
      "         4.6109e-04,  1.0103e-03,  2.8322e-04,  7.4059e-04, -2.2497e-04,\n",
      "         1.0309e-03,  4.5232e-04, -9.7320e-04,  4.5137e-04,  2.9859e-04,\n",
      "         7.5383e-04, -2.4530e-04, -2.1087e-04,  2.2084e-04, -5.7706e-05],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.15.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.1637]],\n",
      "\n",
      "         [[ 0.1007]],\n",
      "\n",
      "         [[ 0.0238]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0128]],\n",
      "\n",
      "         [[ 0.0186]],\n",
      "\n",
      "         [[ 0.0010]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0423]],\n",
      "\n",
      "         [[ 0.0739]],\n",
      "\n",
      "         [[-0.0259]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0304]],\n",
      "\n",
      "         [[ 0.0006]],\n",
      "\n",
      "         [[-0.0271]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1068]],\n",
      "\n",
      "         [[ 0.0122]],\n",
      "\n",
      "         [[-0.0824]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0384]],\n",
      "\n",
      "         [[-0.0298]],\n",
      "\n",
      "         [[-0.0015]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0474]],\n",
      "\n",
      "         [[ 0.0182]],\n",
      "\n",
      "         [[-0.0461]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0257]],\n",
      "\n",
      "         [[-0.0323]],\n",
      "\n",
      "         [[ 0.1116]]],\n",
      "\n",
      "\n",
      "        [[[-0.0394]],\n",
      "\n",
      "         [[ 0.0967]],\n",
      "\n",
      "         [[-0.0718]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0159]],\n",
      "\n",
      "         [[ 0.0280]],\n",
      "\n",
      "         [[ 0.0714]]],\n",
      "\n",
      "\n",
      "        [[[-0.0532]],\n",
      "\n",
      "         [[-0.0462]],\n",
      "\n",
      "         [[-0.0181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1215]],\n",
      "\n",
      "         [[ 0.0516]],\n",
      "\n",
      "         [[-0.0750]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 160, 1, 1])\n",
      "\n",
      "Layer: features.15.conv.0.1.weight\n",
      "Weights: tensor([0.8292, 1.0355, 1.0685, 1.0883, 0.8745, 0.9857, 0.4964, 1.8508, 1.3904,\n",
      "        1.0921, 1.0437, 1.1786, 1.0305, 1.0580, 0.8881, 0.7123, 1.2003, 1.1495,\n",
      "        1.0589, 1.0121, 0.8826, 1.3076, 0.7295, 0.8358, 1.0355, 1.1838, 1.2922,\n",
      "        0.7406, 1.1302, 0.7588, 1.0840, 1.2810, 1.3287, 0.9400, 0.5667, 1.0350,\n",
      "        2.0158, 0.5527, 0.6153, 1.0201, 0.5425, 0.8175, 1.0565, 1.2594, 1.3252,\n",
      "        0.5758, 1.0735, 0.9372, 0.4473, 0.8202, 0.4651, 0.9589, 1.1051, 1.0101,\n",
      "        0.9262, 0.8399, 0.8903, 0.4278, 0.6923, 0.7172, 0.7232, 0.8649, 0.9421,\n",
      "        1.1016, 0.7030, 1.7546, 0.8715, 1.4500, 0.6928, 1.0567, 1.2959, 0.7759,\n",
      "        1.0428, 1.3530, 0.9943, 1.4577, 0.9548, 1.1398, 1.0148, 1.0111, 1.4477,\n",
      "        1.0126, 2.3637, 1.0003, 1.1492, 1.1188, 1.2836, 0.8963, 1.0719, 0.9000,\n",
      "        0.9005, 1.2558, 0.8464, 1.1113, 0.7262, 0.8567, 0.5043, 0.3584, 0.9463,\n",
      "        1.0226, 0.8563, 0.9553, 1.3180, 0.8571, 0.3848, 1.1391, 0.4420, 0.4852,\n",
      "        1.1916, 1.0870, 0.8386, 0.8656, 0.7350, 0.7015, 0.8970, 1.1483, 0.9831,\n",
      "        0.7224, 1.0491, 1.0714, 1.1731, 0.5465, 0.6164, 0.8417, 0.8030, 1.3082,\n",
      "        1.0011, 1.1867, 0.8833, 1.2977, 1.2159, 0.8691, 0.3677, 1.1923, 0.7205,\n",
      "        1.3267, 0.7628, 0.8536, 1.0349, 1.1788, 0.9483, 0.6403, 0.3664, 1.1204,\n",
      "        1.1991, 1.0806, 3.2005, 0.4203, 1.0482, 1.1357, 0.8348, 0.8147, 0.7592,\n",
      "        0.7775, 0.7013, 1.1102, 0.6400, 1.0294, 1.2218, 0.9439, 0.9158, 1.0979,\n",
      "        1.1312, 0.9125, 1.1464, 1.9350, 0.9496, 1.1890, 0.5879, 0.8056, 1.0713,\n",
      "        0.5958, 0.7150, 0.9887, 0.9508, 1.0590, 0.7428, 0.7988, 0.4686, 1.1727,\n",
      "        0.6342, 0.9082, 0.8930, 0.6307, 0.5744, 1.0083, 0.9097, 0.8642, 1.1704,\n",
      "        1.0852, 0.8705, 1.2162, 1.0655, 1.1141, 0.4544, 1.0684, 1.2022, 0.8010,\n",
      "        0.5369, 0.8922, 0.3044, 0.8670, 0.7299, 0.7810, 0.7119, 1.1785, 0.8222,\n",
      "        1.1877, 0.9916, 0.9861, 1.0281, 1.1179, 0.5592, 1.0089, 1.0306, 0.9192,\n",
      "        0.5268, 0.7791, 0.7814, 1.0385, 1.0758, 1.0779, 1.1805, 0.3602, 1.1296,\n",
      "        1.1056, 0.9926, 0.8231, 0.8743, 1.2993, 1.2732, 1.3448, 0.8413, 0.7898,\n",
      "        2.1195, 1.2266, 1.1807, 1.1307, 1.1062, 1.0431, 1.0297, 0.5460, 0.3564,\n",
      "        0.8329, 1.1696, 1.2907, 0.7292, 0.9523, 1.0374, 0.9083, 1.0129, 1.1859,\n",
      "        1.2251, 0.8294, 0.8269, 1.0924, 0.7689, 0.7156, 0.9427, 1.1961, 1.0458,\n",
      "        1.0304, 0.4299, 1.4197, 1.0238, 1.1973, 1.0217, 1.0363, 1.0148, 1.2022,\n",
      "        1.0301, 0.8414, 0.8442, 1.2238, 1.1768, 0.1478, 1.4123, 0.7810, 1.0290,\n",
      "        0.4203, 1.3472, 1.0979, 1.1808, 1.1153, 0.9180, 1.6862, 1.1845, 0.5583,\n",
      "        0.8129, 0.3678, 0.9385, 0.9982, 2.7353, 0.8346, 1.0232, 1.0381, 1.1710,\n",
      "        0.5935, 0.6899, 1.2937, 1.0543, 0.6415, 0.8138, 0.9220, 0.6609, 0.9613,\n",
      "        1.0426, 1.0360, 0.7531, 0.8237, 1.1479, 1.0455, 0.9486, 1.0039, 1.0756,\n",
      "        0.6398, 0.9284, 1.0991, 1.2652, 1.6397, 1.1359, 0.3712, 1.7186, 0.7159,\n",
      "        1.0213, 1.0056, 0.9161, 0.9416, 0.9207, 0.9929, 1.0782, 0.9372, 1.0303,\n",
      "        0.7847, 0.8998, 0.7678, 1.3885, 1.1207, 1.3358, 1.1701, 0.5505, 0.7783,\n",
      "        1.1867, 1.2458, 0.8077, 0.7431, 1.7497, 0.9562, 0.8743, 0.9374, 1.1346,\n",
      "        1.0667, 0.8855, 0.6682, 1.1994, 0.4023, 0.7545, 1.3283, 1.2622, 1.1508,\n",
      "        1.0815, 1.2976, 0.8615, 0.9774, 0.7325, 0.8400, 0.7888, 0.6894, 0.9776,\n",
      "        1.0763, 0.7566, 0.8429, 0.7097, 1.3245, 0.9987, 1.0960, 1.3129, 0.5382,\n",
      "        0.8135, 0.8448, 1.1301, 0.8683, 0.7974, 1.1924, 1.1174, 1.0312, 0.9107,\n",
      "        0.8330, 0.9889, 1.0437, 0.5073, 0.7021, 0.9201, 1.1720, 0.7464, 1.1947,\n",
      "        1.0758, 1.0038, 1.1653, 1.1837, 0.4711, 1.0244, 1.1584, 1.1270, 1.3541,\n",
      "        0.8297, 1.2523, 0.9791, 0.8879, 0.9913, 0.9694, 0.7062, 1.1018, 1.0625,\n",
      "        0.9942, 0.3356, 0.8830, 1.2108, 1.2986, 0.4544, 0.5733, 1.3813, 1.0333,\n",
      "        1.0628, 1.1484, 1.1396, 0.7495, 1.2046, 1.0449, 0.9446, 1.0918, 0.9440,\n",
      "        1.3106, 1.0033, 1.0207, 1.1386, 1.0961, 1.0344, 1.1742, 1.2487, 0.7809,\n",
      "        1.5483, 1.0764, 0.5204, 0.7374, 1.0812, 1.1202, 0.9227, 0.8657, 0.6475,\n",
      "        0.9548, 0.8191, 0.8334, 0.8825, 0.3691, 0.8011, 0.5882, 0.4997, 0.7732,\n",
      "        1.2546, 1.2298, 1.2562, 0.2260, 0.8148, 0.3891, 1.4424, 0.9997, 0.9407,\n",
      "        0.7728, 1.4227, 0.7421, 0.9611, 0.8935, 0.7417, 0.9303, 0.9884, 1.0828,\n",
      "        1.5166, 0.8085, 0.9704, 1.1978, 0.9754, 1.0096, 0.8377, 1.3091, 1.0003,\n",
      "        1.0153, 0.9981, 1.1002, 0.9497, 1.2170, 1.4187, 1.1157, 1.1563, 1.0896,\n",
      "        1.2437, 1.1079, 1.2410, 0.5849, 1.2726, 0.9843, 0.7775, 1.1180, 0.9228,\n",
      "        1.0016, 1.2323, 0.8149, 0.7815, 0.7303, 1.0789, 1.0987, 0.7976, 0.7961,\n",
      "        0.8711, 0.9429, 0.8107, 1.0869, 0.9138, 0.8497, 1.0966, 0.8343, 0.8350,\n",
      "        1.3008, 1.0129, 0.8519, 1.1286, 1.1695, 0.8414, 0.8551, 0.9870, 1.1461,\n",
      "        0.6001, 0.9453, 0.4191, 0.7944, 0.8905, 0.9061, 1.5987, 1.0262, 0.7911,\n",
      "        1.2356, 1.1561, 0.8104, 1.1190, 1.1592, 0.7383, 0.3471, 0.6674, 0.9475,\n",
      "        2.8096, 1.0079, 1.2762, 0.4647, 0.6416, 0.9583, 0.9798, 0.9255, 0.5615,\n",
      "        0.9465, 1.0865, 0.4705, 1.0313, 0.6988, 1.1421, 1.0756, 0.9501, 2.9064,\n",
      "        1.1094, 0.8592, 0.5560, 0.9056, 1.0706, 0.8825, 0.9615, 0.9141, 0.5927,\n",
      "        1.0213, 1.1661, 1.1692, 0.8888, 0.9725, 0.4896, 1.0347, 1.2234, 0.8012,\n",
      "        0.5028, 1.0801, 0.8840, 0.5402, 0.9131, 0.8416, 0.7425, 1.2979, 0.9082,\n",
      "        0.8046, 0.7872, 0.9427, 1.0992, 1.2449, 0.9766, 1.2645, 1.0151, 1.1416,\n",
      "        0.4656, 0.8564, 0.8799, 0.4978, 0.4714, 1.5031, 0.7768, 0.9096, 1.2805,\n",
      "        1.2050, 1.0140, 1.0443, 1.0427, 0.7332, 1.0707, 1.0143, 1.0951, 1.0525,\n",
      "        1.2506, 1.0745, 0.8682, 1.1376, 0.8219, 1.1106, 1.1620, 0.8749, 0.9093,\n",
      "        0.9357, 1.1437, 0.8065, 0.9625, 0.9459, 1.2097, 1.0492, 1.0925, 0.7867,\n",
      "        1.2906, 1.2541, 0.8417, 1.5814, 1.1281, 1.1158, 0.8081, 1.1547, 0.8972,\n",
      "        0.6666, 0.9844, 1.2223, 0.7816, 0.9043, 0.8538, 0.8011, 0.6640, 1.3841,\n",
      "        0.9204, 1.0168, 1.1553, 0.7046, 0.4312, 1.0027, 0.8692, 2.3911, 1.0386,\n",
      "        1.0293, 1.1466, 1.0829, 1.2589, 1.0156, 1.1134, 1.3931, 1.2565, 0.8071,\n",
      "        1.2428, 0.9477, 0.9941, 0.7023, 1.2305, 1.0162, 1.0633, 0.8925, 0.5904,\n",
      "        0.8565, 0.5966, 0.8606, 0.6477, 1.0905, 1.0358, 0.8794, 1.1926, 1.0189,\n",
      "        1.3083, 0.7618, 1.1646, 0.9745, 0.7744, 1.2801, 0.8683, 1.2077, 1.0627,\n",
      "        0.8545, 1.0952, 0.4821, 1.2256, 0.9180, 1.0190, 0.6074, 1.3862, 0.7630,\n",
      "        0.9390, 0.8962, 0.8439, 1.0936, 0.6650, 0.8547, 1.0561, 0.4483, 0.3783,\n",
      "        0.5449, 0.7972, 0.9756, 0.8209, 1.4859, 0.7770, 1.0368, 1.0704, 0.8948,\n",
      "        1.3206, 0.7500, 0.6177, 1.2803, 1.1653, 0.4166, 0.7215, 1.0306, 0.7952,\n",
      "        1.1465, 0.8966, 0.8651, 1.4774, 0.3889, 0.3435, 0.7722, 1.2739, 1.0804,\n",
      "        1.0570, 1.2841, 1.1268, 0.6882, 0.3983, 1.2590, 0.8563, 1.1012, 1.4122,\n",
      "        0.7886, 0.8944, 1.0953, 0.5596, 1.1298, 0.7828, 1.3562, 1.2171, 1.0085,\n",
      "        0.8564, 0.6987, 1.0024, 0.5736, 0.8073, 0.7197, 0.8862, 0.8289, 1.5017,\n",
      "        0.7914, 0.8943, 1.0470, 0.7845, 0.8503, 0.8146, 1.2081, 1.1950, 0.6602,\n",
      "        0.9979, 0.5760, 1.1005, 0.7479, 0.6817, 1.1113, 1.1150, 1.1036, 0.8204,\n",
      "        1.3189, 0.5647, 1.4760, 1.0822, 1.0675, 0.8181, 1.1316, 0.6986, 0.9832,\n",
      "        0.9950, 1.0425, 0.9811, 1.1510, 0.8577, 1.1479, 0.8613, 0.7529, 0.6787,\n",
      "        0.8668, 1.0864, 0.9958, 1.0666, 0.8813, 0.8778, 0.9051, 0.8900, 1.1730,\n",
      "        2.1593, 1.2655, 0.6442, 0.4628, 0.9106, 0.9021, 0.9105, 0.8503, 1.2053,\n",
      "        1.3029, 0.9186, 0.8869, 1.5370, 0.6579, 1.1723, 0.9513, 1.0699, 0.8174,\n",
      "        0.7563, 1.2615, 0.8689, 0.8835, 0.9652, 0.3347, 0.4164, 1.0959, 1.3052,\n",
      "        0.8257, 3.2416, 0.7388, 0.8366, 0.8696, 0.9023, 0.9479, 1.0594, 0.8293,\n",
      "        1.0178, 0.7477, 1.3888, 1.1957, 0.7149, 1.1755, 0.8160, 0.8408, 0.8251,\n",
      "        0.8907, 1.2082, 0.6212, 0.9801, 0.3207, 1.1548, 0.7074, 0.8152, 0.4077,\n",
      "        1.2629, 0.6774, 0.7251, 1.0905, 0.8174, 0.7705, 0.9827, 0.8950, 1.1130,\n",
      "        0.7859, 0.8829, 0.9000, 0.8509, 1.2702, 1.2398, 1.0030, 1.1741, 0.7980,\n",
      "        0.6672, 0.9084, 0.9424, 0.9202, 0.7368, 0.3297, 1.0061, 0.8325, 0.4011,\n",
      "        1.0033, 1.2756, 0.9727, 1.2138, 1.0927, 0.7069, 1.1011, 0.8379, 0.8128,\n",
      "        1.0414, 0.4382, 0.4177, 0.5457, 0.3977, 1.3575, 0.7294, 1.2716, 1.0030,\n",
      "        1.0511, 0.8465, 0.9965, 0.5704, 0.4760, 0.3432, 0.8923, 1.0531, 0.8300,\n",
      "        0.9591, 1.1114, 1.0854, 0.3974, 1.2208, 0.8500, 1.0252, 1.4998, 1.1802,\n",
      "        0.7644, 1.0941, 1.1653, 0.9396, 0.8516, 0.9546, 1.2563, 1.2032, 0.5335,\n",
      "        1.0260, 1.2238, 1.1098, 1.2479, 1.5821, 0.6681, 1.2572, 1.0611, 1.1902,\n",
      "        0.6385, 1.2403, 1.3060, 1.4068, 1.2677, 0.7125], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.0.1.bias\n",
      "Weights: tensor([ 1.6540e+00,  5.7923e-01,  4.5722e-01,  4.0107e-01,  4.1945e-01,\n",
      "        -3.1043e-01,  1.6277e+00,  1.3534e+00, -1.5859e+00, -1.1258e+00,\n",
      "        -8.5753e-01,  1.0415e+00,  5.8811e-01,  1.8223e-01,  5.4537e-01,\n",
      "         9.2545e-01, -4.5911e-01, -1.0847e+00, -7.6483e-01,  6.3605e-01,\n",
      "         9.9208e-01,  2.0917e-01,  5.4133e-01,  9.0339e-01,  5.2176e-01,\n",
      "        -5.9087e-01, -5.9429e-01,  1.0862e+00, -6.3782e-01,  9.1577e-01,\n",
      "        -3.1240e-01, -5.4074e-01,  3.5327e-01, -2.5610e-01,  1.2922e+00,\n",
      "         6.6710e-01, -7.9351e-01,  1.6042e+00,  8.0498e-01,  5.4664e-01,\n",
      "         1.0869e+00,  1.1828e+00,  2.8610e-01, -4.4288e-01, -4.9615e-01,\n",
      "         1.4671e+00, -9.1449e-01, -1.6311e-01,  1.5746e+00,  9.7036e-01,\n",
      "         1.6340e+00, -1.2506e+00,  1.9832e-01,  7.0880e-01,  6.4380e-02,\n",
      "         8.6031e-01,  2.5443e-01,  1.6782e+00,  7.6070e-01,  1.0671e+00,\n",
      "         9.5269e-01,  2.6707e-01,  9.6529e-01,  5.6449e-01,  7.9519e-01,\n",
      "         2.8522e-01,  1.8791e-01, -2.2313e+00,  1.5082e+00, -7.0388e-01,\n",
      "         7.4580e-01,  1.2371e+00,  8.7045e-02, -8.9550e-02, -8.9352e-01,\n",
      "         4.2991e-01,  6.8599e-01, -5.7589e-01,  3.7336e-01,  5.0311e-01,\n",
      "        -6.8907e-01,  2.5866e-01, -6.2139e-01, -7.1218e-01, -8.7089e-01,\n",
      "        -2.4817e-01, -4.8067e-01,  3.1233e-01,  6.2725e-01,  6.7389e-01,\n",
      "         3.9578e-02,  2.9321e-01,  7.1606e-01,  6.0110e-01,  7.1649e-01,\n",
      "        -5.2483e-01,  1.4396e+00,  1.2105e+00,  3.5815e-01,  6.9601e-01,\n",
      "         1.6406e-01,  3.5093e-01, -3.9210e-01,  8.9042e-01,  1.5646e+00,\n",
      "         4.3610e-01,  1.1301e+00,  1.8915e+00,  8.3863e-01, -7.9966e-01,\n",
      "         8.5110e-01,  2.9490e-01,  1.4776e+00,  9.8034e-01,  5.7795e-03,\n",
      "        -6.7218e-01,  7.9682e-01,  1.0021e+00,  1.5064e-01,  7.4156e-01,\n",
      "        -2.3334e-01,  1.3399e+00,  9.7890e-01,  7.1803e-01,  1.6210e+00,\n",
      "        -5.1009e-01,  7.3622e-01,  4.1350e-01, -4.8198e-02,  2.3201e-01,\n",
      "         6.6580e-01,  6.2392e-01,  1.5720e+00,  4.8576e-02,  9.8472e-01,\n",
      "        -4.0751e-01,  9.9916e-01,  8.6773e-01, -4.0787e-02, -1.2271e+00,\n",
      "         6.3085e-01, -1.6072e-01,  1.2385e+00,  1.2449e+00, -2.6549e-01,\n",
      "        -9.9464e-01,  5.9015e-01,  1.2788e+00, -1.0579e+00,  1.8898e-01,\n",
      "         7.3636e-01,  2.5389e-01,  1.0914e+00,  9.2913e-01,  8.4567e-01,\n",
      "         3.0651e-01,  2.1543e-01,  5.2855e-01,  4.2756e-01,  6.1152e-01,\n",
      "         8.9443e-01,  3.2739e-01,  2.7988e-01,  7.8058e-01, -6.9426e-01,\n",
      "         1.0997e+00,  6.2505e-01, -4.8714e-01,  3.2373e-01,  8.3128e-01,\n",
      "         5.2902e-01,  1.3510e+00,  1.2210e+00, -4.7137e-01, -1.1626e+00,\n",
      "         4.8405e-01,  9.1280e-01,  1.1160e+00,  1.2746e+00, -2.2658e-02,\n",
      "         9.9069e-01,  6.6992e-01, -5.5859e-01,  9.8314e-01,  1.2577e+00,\n",
      "         6.8433e-01,  5.8398e-01,  9.1120e-01, -7.7793e-01, -4.2460e-01,\n",
      "         4.7031e-01, -2.7103e-01, -1.1375e-01,  1.2506e+00,  1.3377e+00,\n",
      "        -9.0353e-01,  2.9250e-01,  9.7648e-01,  1.2909e+00,  6.3163e-01,\n",
      "         1.3568e+00,  4.1961e-01,  1.0263e+00,  1.0421e+00,  8.9632e-01,\n",
      "        -6.6376e-01, -3.2954e-01,  3.3452e-01,  5.5262e-01,  7.2465e-01,\n",
      "         5.9642e-01,  6.3679e-02,  1.3344e+00,  6.0411e-01,  6.8610e-01,\n",
      "         7.7338e-01,  1.5566e+00,  7.3704e-01,  8.1491e-01,  4.9041e-01,\n",
      "         5.3990e-01,  2.0764e-01, -1.6612e+00,  1.2211e+00, -5.8438e-01,\n",
      "        -3.0342e-01, -4.9151e-02,  6.1061e-01,  9.0037e-01, -1.5377e-01,\n",
      "        -1.0260e+00, -3.2385e-01, -3.7706e-01,  9.2514e-01,  1.5977e+00,\n",
      "         7.0704e-02, -1.2794e+00,  5.6550e-01, -8.7753e-01, -7.6686e-01,\n",
      "        -2.4977e-01,  1.0891e+00,  1.6332e+00,  9.8332e-01, -1.2371e+00,\n",
      "        -1.9744e-01,  7.1444e-01,  2.1662e-01,  8.6798e-02,  9.2023e-01,\n",
      "         1.6217e-01, -3.6144e-01,  5.0611e-01,  7.8855e-01,  2.9904e-01,\n",
      "         4.0091e-01,  7.9400e-01,  9.9679e-01,  4.5771e-01,  1.3356e-01,\n",
      "         2.5465e-01,  4.0817e-01,  1.7512e+00, -5.3251e-01,  6.8974e-01,\n",
      "         3.2274e-01,  7.0006e-01, -1.7073e+00,  6.6714e-01, -1.0542e+00,\n",
      "         6.0531e-01, -6.4744e-01,  3.9136e-01,  7.3225e-01,  1.9573e-01,\n",
      "        -1.0875e+00, -5.0936e-01,  1.0466e+00,  7.3972e-01,  1.2384e+00,\n",
      "        -1.9956e+00, -8.6540e-01,  5.4826e-01,  5.5575e-01,  7.8854e-01,\n",
      "         6.8259e-01,  2.1035e-03,  1.5236e+00,  1.4427e-01,  1.4973e+00,\n",
      "         6.7848e-01,  9.5119e-01,  1.4416e+00,  3.2934e-01,  6.3992e-01,\n",
      "         5.0695e-01, -9.4199e-01,  1.1011e+00,  1.4203e+00, -5.7252e-01,\n",
      "         1.2981e-01,  1.2951e+00,  8.6834e-01,  3.6484e-01,  1.7099e+00,\n",
      "         6.6454e-01,  3.7259e-01,  9.4294e-01,  8.7928e-01,  8.8702e-01,\n",
      "        -3.6134e-01,  1.5262e-01,  5.5136e-01,  4.2363e-02,  6.4006e-01,\n",
      "         1.4531e+00,  1.1486e+00,  4.9314e-01, -6.6687e-01, -1.0717e-01,\n",
      "        -3.0746e-01,  1.2774e+00,  9.0033e-01,  9.1278e-01,  6.5959e-01,\n",
      "         6.6334e-01,  8.5381e-01,  7.1528e-01,  7.8545e-01,  4.7277e-01,\n",
      "         6.6720e-01, -1.7567e-01, -3.8335e-01,  8.1504e-01,  8.6482e-01,\n",
      "         6.1964e-01, -3.3281e-01, -1.3630e+00, -3.3471e-01, -7.6504e-01,\n",
      "        -2.6938e+00,  1.0826e+00,  1.3246e+00,  2.5796e-01,  3.9152e-01,\n",
      "         1.1046e+00, -5.0192e-01,  7.9416e-01,  7.9334e-01,  7.5284e-01,\n",
      "         4.5865e-01, -1.1034e+00,  8.0134e-01,  1.6247e+00, -1.2014e+00,\n",
      "         1.5821e+00,  9.4996e-01,  1.1476e+00, -5.8474e-01,  4.8785e-01,\n",
      "         6.0977e-01,  6.0025e-01,  1.0102e+00,  4.7217e-01,  1.1238e+00,\n",
      "         8.2497e-01,  9.3710e-01,  1.1051e+00,  6.0986e-01, -1.1766e+00,\n",
      "         7.2130e-01,  1.0949e+00,  1.1708e+00, -7.5940e-02,  4.0897e-01,\n",
      "         2.2270e-01, -1.0705e+00,  1.7203e+00,  8.5081e-01,  9.1766e-01,\n",
      "         7.0242e-01,  1.1211e+00,  8.1597e-01, -1.5520e+00, -2.2763e-01,\n",
      "         5.4440e-01,  9.0853e-02,  6.9931e-01, -6.5098e-01,  9.2137e-01,\n",
      "         1.3516e+00,  1.1140e+00,  1.1021e+00,  7.0761e-01,  5.7819e-01,\n",
      "        -1.1620e-01,  7.8819e-01,  8.0562e-01,  6.0173e-01, -5.2713e-01,\n",
      "         1.6689e+00,  3.4108e-01, -1.2797e+00,  5.5726e-01, -6.8087e-01,\n",
      "         8.7446e-01, -5.0500e-01,  1.0109e-01,  1.0734e+00,  8.1537e-01,\n",
      "         2.9148e-01,  9.2661e-01, -3.5180e-01,  5.5219e-01,  7.8048e-01,\n",
      "         1.6153e+00,  1.8172e-01, -6.2763e-01, -9.6533e-01,  1.3747e+00,\n",
      "         1.4199e+00, -5.2350e-01,  1.2774e+00,  7.2079e-01, -5.3346e-01,\n",
      "         2.6831e-01,  2.1471e-01,  3.3242e-02,  6.0973e-01,  7.7627e-01,\n",
      "        -8.6060e-01,  9.3886e-01,  2.0211e-01,  7.0079e-01,  1.4122e+00,\n",
      "        -9.2937e-02, -1.1339e-01, -7.4264e-01,  1.8141e+00,  3.7795e-01,\n",
      "         9.2504e-01, -2.7291e-01, -1.2664e+00,  6.6039e-01,  8.7899e-01,\n",
      "        -1.3528e+00,  6.8461e-01,  1.1194e-01,  9.0252e-01,  1.4387e+00,\n",
      "         6.3523e-01,  9.6737e-02,  7.4116e-01, -8.5806e-02,  1.6394e+00,\n",
      "         9.9061e-01,  1.6170e+00,  1.4351e+00,  1.0046e+00, -1.1266e+00,\n",
      "        -8.6065e-01,  2.5689e-01, -1.1927e+00,  1.0160e+00,  1.6010e+00,\n",
      "        -1.0593e+00, -4.3782e-01, -1.4495e+00,  7.8279e-01, -6.1225e-01,\n",
      "         9.7737e-01, -3.1448e-01,  7.5820e-01,  5.5790e-02,  8.4336e-01,\n",
      "         1.4250e+00,  9.2688e-01, -1.4812e+00,  2.2627e-01, -7.5578e-01,\n",
      "         4.7199e-01, -2.7702e-01,  1.3502e-02, -2.7684e-01, -1.2901e+00,\n",
      "         6.6287e-01,  1.9965e-01,  9.0940e-02, -4.6322e-01,  6.7775e-01,\n",
      "        -2.9140e-01, -1.7586e+00, -9.7554e-01, -8.9916e-01, -6.6173e-01,\n",
      "        -1.1462e+00, -3.8764e-01,  2.3110e-01,  1.2620e+00,  1.0606e+00,\n",
      "        -8.7965e-01,  9.5021e-01, -3.9696e-01, -6.9572e-01,  8.0280e-01,\n",
      "        -3.1718e-02, -5.3944e-01, -2.5231e-01,  1.9147e+00,  5.8990e-01,\n",
      "        -1.2095e+00,  7.9126e-01,  1.0209e+00,  9.1689e-01,  8.0398e-01,\n",
      "         9.4359e-01, -1.2648e+00,  7.6612e-01,  9.4321e-01,  4.8211e-01,\n",
      "         8.8933e-01,  8.5992e-01,  1.2575e+00,  6.8628e-01,  4.8330e-01,\n",
      "         5.0170e-01, -6.6179e-02,  7.0419e-01,  8.2440e-01,  1.0490e-02,\n",
      "        -1.7380e-01,  9.9235e-01,  1.0241e+00,  1.3846e+00,  8.8473e-01,\n",
      "         4.6652e-01, -1.0454e-01,  1.1995e+00,  5.3446e-01,  9.6429e-01,\n",
      "         7.7584e-02, -4.3346e-01, -2.9969e-01, -6.5458e-01,  5.6289e-01,\n",
      "         3.9711e-01,  1.3465e+00,  1.1488e+00,  5.6972e-01,  3.7770e-01,\n",
      "        -9.6767e-01, -1.3031e+00,  1.1461e+00,  8.0084e-01,  5.3760e-01,\n",
      "         6.3371e-01, -1.6533e+00,  2.1365e+00,  7.7976e-01, -1.7224e-01,\n",
      "         1.8325e+00,  9.0906e-01,  1.0153e+00,  3.9513e-01,  5.1834e-01,\n",
      "         1.1311e+00,  9.2125e-01,  2.1563e-01, -1.5991e-01,  1.4554e+00,\n",
      "         1.2036e+00, -3.1430e-01,  4.3086e-02,  1.0693e+00, -1.6405e-01,\n",
      "         5.4535e-01,  7.9199e-01, -1.2992e+00,  3.5415e-01,  9.5366e-01,\n",
      "         8.0361e-01,  1.6681e+00, -9.8974e-01, -9.3574e-01,  7.0405e-01,\n",
      "         1.1559e+00, -7.1095e-01,  1.1599e-01,  1.1056e+00, -7.7539e-01,\n",
      "         9.3812e-01,  1.1919e+00, -3.3101e-01, -2.0813e-01,  9.5160e-01,\n",
      "         8.2445e-01, -6.7447e-01, -5.4425e-01,  4.1633e-01,  6.2243e-01,\n",
      "         5.0643e-01,  1.6354e-01,  5.1972e-01,  1.6502e+00,  8.7069e-01,\n",
      "         5.1166e-01,  1.5476e+00,  1.2734e+00, -5.5736e-01,  9.1783e-01,\n",
      "         7.6301e-01, -7.5567e-02,  2.9676e-01,  1.4648e-01,  6.6533e-01,\n",
      "        -9.9710e-01,  5.0831e-01, -9.0683e-01,  7.1366e-01, -1.5960e-01,\n",
      "        -1.3689e+00, -5.8402e-02,  4.3025e-01,  9.1750e-01,  4.0797e-01,\n",
      "         8.6344e-01,  1.0664e+00,  3.6592e-01,  8.3750e-01,  9.6878e-01,\n",
      "         1.1987e+00, -3.3599e-01,  1.0918e+00,  7.1827e-01,  7.0230e-01,\n",
      "         8.4488e-01,  1.3785e-01,  4.9902e-01,  6.1571e-01, -9.5229e-01,\n",
      "         6.2337e-01,  2.6190e-01,  3.0381e-01,  8.5923e-01,  1.9343e-01,\n",
      "         7.6898e-01, -5.2607e-01, -3.9735e-01,  1.2689e+00,  4.2232e-02,\n",
      "        -2.6883e-01,  8.8556e-01,  3.3043e-02,  6.7951e-01, -3.6018e-01,\n",
      "         1.0828e+00, -3.2535e-01,  6.9675e-01,  7.2426e-01, -1.6270e+00,\n",
      "         8.5068e-01,  1.7766e+00,  9.6485e-01,  1.0313e+00,  1.5407e+00,\n",
      "         3.4670e-01,  1.8376e-01,  1.5065e-01, -1.4995e+00,  2.1595e-01,\n",
      "         7.0442e-01, -6.5956e-01, -4.6595e-01, -1.1835e-01,  9.7328e-01,\n",
      "        -6.4016e-01, -3.1389e-01,  9.9216e-01,  9.4822e-02,  9.9614e-01,\n",
      "         6.7761e-01,  5.2022e-01,  8.4013e-01,  1.1358e+00,  9.0491e-01,\n",
      "         1.1619e+00,  2.1599e-01,  2.8779e-01,  5.9661e-01,  1.0193e+00,\n",
      "         5.9883e-01,  7.0291e-01, -5.1679e-01, -4.5725e-01,  9.9896e-01,\n",
      "         6.4309e-01,  2.6071e-01,  4.1327e-01, -1.5762e+00,  8.3896e-01,\n",
      "        -6.2695e-01, -1.2982e+00,  8.3705e-01,  4.2978e-01,  1.1966e+00,\n",
      "        -2.6212e-01,  8.2140e-01,  1.0626e-01,  1.0357e+00, -9.2935e-01,\n",
      "         1.0062e+00,  4.9386e-01,  1.5737e+00,  9.4750e-01,  6.2702e-01,\n",
      "         9.6768e-01,  6.1246e-01,  5.4833e-01,  1.9470e+00,  1.2924e+00,\n",
      "         1.3381e+00,  1.6217e-01,  1.0071e-01,  9.4637e-01, -1.2877e+00,\n",
      "         9.6947e-01, -6.0351e-01,  6.6861e-01,  7.1240e-01,  4.9459e-02,\n",
      "         5.5673e-01,  1.1424e+00, -5.6736e-01, -3.9942e-01,  1.7209e+00,\n",
      "         3.8326e-01,  2.7324e-01,  9.2103e-01, -1.2811e-01,  6.0507e-01,\n",
      "        -8.6124e-01, -4.2364e-01,  1.3511e+00,  1.5340e+00,  5.4136e-01,\n",
      "        -2.5639e-01,  5.5498e-01,  5.7668e-01, -3.6814e-01,  6.6720e-03,\n",
      "         9.8257e-01,  1.6990e+00, -1.8367e-01,  9.3918e-01, -1.3577e+00,\n",
      "        -5.1255e-01,  1.0278e+00,  9.7543e-01, -5.3113e-01,  9.7291e-01,\n",
      "        -1.0718e+00,  1.0881e+00,  8.6916e-02, -4.9870e-01, -1.1933e+00,\n",
      "         9.6587e-01,  1.2935e+00,  5.9537e-01,  8.1989e-01,  5.6183e-01,\n",
      "         9.9165e-01,  9.2783e-01,  1.4071e-01, -5.8845e-01,  8.9880e-01,\n",
      "         8.4104e-01, -1.8396e-01,  8.5750e-01,  7.2599e-01,  1.3004e+00,\n",
      "         8.2414e-01, -9.5132e-01,  1.0833e+00, -5.0205e-01,  1.3112e+00,\n",
      "        -3.1228e-02,  9.8207e-01,  1.4148e+00,  5.3522e-01, -5.8025e-01,\n",
      "         3.8521e-01,  7.6366e-01, -1.1687e-01,  7.0102e-01, -3.7903e-01,\n",
      "        -4.6806e-01,  1.3369e-01,  9.4359e-01, -2.8070e-01,  1.2048e-01,\n",
      "         7.0264e-01,  8.0967e-01, -4.9675e-01,  4.0729e-01, -1.3570e+00,\n",
      "         8.2750e-01,  4.8914e-01,  6.6422e-01,  1.0621e+00,  7.3969e-01,\n",
      "        -9.9458e-02,  2.4365e-01,  1.0282e+00, -1.1313e+00, -4.4149e-01,\n",
      "        -1.0370e+00,  3.1828e-01,  9.9129e-01, -3.2736e-01, -4.5351e-01,\n",
      "         2.3180e-01,  1.4074e+00,  1.6561e+00,  5.1490e-01,  9.2548e-01,\n",
      "        -4.8532e-01, -9.5988e-01,  7.6457e-02,  4.8828e-01,  9.0430e-01,\n",
      "         1.0011e+00, -2.3853e-01,  9.6987e-01, -1.3114e+00,  1.9051e-01,\n",
      "         4.9271e-01,  8.5917e-01,  8.3048e-01, -5.0095e-01, -4.8982e-02,\n",
      "         7.5670e-01,  8.1517e-01,  1.3435e+00,  1.3644e+00,  6.4444e-01,\n",
      "         4.1807e-02,  8.2943e-01,  1.0544e+00,  9.2456e-01,  8.6674e-01,\n",
      "         7.9598e-01,  6.4868e-01,  3.0967e-01, -6.1481e-01,  9.8672e-01,\n",
      "         2.3103e-01,  8.8581e-01, -2.3274e-01,  2.9472e-01,  1.0344e+00,\n",
      "        -6.4992e-01,  1.0950e+00,  8.5755e-01,  6.6338e-01,  5.0632e-01,\n",
      "        -7.9878e-01,  9.9111e-01,  8.7456e-01,  1.6403e+00, -9.0369e-02,\n",
      "         3.8327e-01,  7.8807e-01,  1.4082e+00, -4.1361e-01,  8.9731e-01,\n",
      "         5.1985e-01, -4.2773e-02,  7.4299e-01,  9.8055e-01, -4.4043e-01,\n",
      "         2.2821e-01, -6.7591e-01,  9.2765e-01,  8.4950e-01,  9.2187e-01,\n",
      "         8.3858e-01, -1.3358e+00, -3.3566e-01,  7.2407e-01,  1.2512e-01,\n",
      "         7.9587e-01, -9.4150e-02,  7.0685e-01,  7.6837e-01,  9.6738e-01,\n",
      "         1.7241e+00,  1.6727e+00,  3.4840e-01,  8.8164e-01,  1.4987e+00,\n",
      "         8.8394e-01, -1.5153e-01,  9.9823e-01,  4.5172e-01,  7.1792e-01,\n",
      "         1.1798e+00,  4.0197e-01,  1.0188e+00,  1.1400e+00,  5.3810e-01,\n",
      "         1.3362e+00,  1.4183e+00,  1.2898e+00,  1.6936e+00, -3.2164e-01,\n",
      "         6.6417e-01,  4.9352e-02, -6.0948e-01,  5.5249e-01,  9.6409e-01,\n",
      "         3.0724e-01,  1.2946e+00,  1.6407e+00,  1.4422e+00,  8.3034e-01,\n",
      "         8.5928e-01,  7.8416e-01,  7.9069e-01,  2.8302e-01,  4.3151e-01,\n",
      "         1.6440e+00, -1.2761e+00, -1.5590e-01,  4.6261e-01, -3.3184e-01,\n",
      "        -1.0087e-01,  9.0674e-01,  1.4386e-01,  2.4455e-01,  3.4275e-01,\n",
      "         9.2332e-01,  5.6605e-01,  2.5490e-02,  6.4873e-01,  1.4835e+00,\n",
      "        -5.5858e-01, -1.0892e-01, -3.1968e-02, -8.8636e-01, -7.8553e-01,\n",
      "         1.2785e+00,  6.1254e-01,  1.1297e+00,  6.1079e-01,  7.5188e-01,\n",
      "        -6.9280e-01,  2.7884e-01, -4.0409e-01,  1.0024e+00,  5.8424e-01],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0380, -0.1183, -0.0411],\n",
      "          [-0.1239, -0.1101, -0.1265],\n",
      "          [-0.0360, -0.1312, -0.0325]]],\n",
      "\n",
      "\n",
      "        [[[-0.0713, -0.1253, -0.0719],\n",
      "          [-0.1454,  0.3327, -0.1306],\n",
      "          [-0.0649, -0.1280, -0.0676]]],\n",
      "\n",
      "\n",
      "        [[[-0.1218, -0.0145, -0.1334],\n",
      "          [-0.0714,  0.5582, -0.0589],\n",
      "          [-0.1455,  0.0019, -0.1474]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0504, -0.0937, -0.0453],\n",
      "          [-0.1124, -0.0190, -0.1093],\n",
      "          [-0.0461, -0.1054, -0.0457]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0671, -0.0462, -0.0816],\n",
      "          [ 0.1705,  0.0365, -0.2395],\n",
      "          [ 0.0772, -0.0764, -0.0797]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0161,  0.0739,  0.0277],\n",
      "          [ 0.0881,  0.2311,  0.0769],\n",
      "          [ 0.0224,  0.1056,  0.0196]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 1, 3, 3])\n",
      "\n",
      "Layer: features.15.conv.1.1.weight\n",
      "Weights: tensor([2.2242, 0.5895, 0.5883, 0.5168, 1.7971, 0.6650, 1.8510, 1.0000, 0.5614,\n",
      "        0.2687, 0.3730, 1.7257, 0.8211, 0.9912, 1.1574, 1.0807, 0.7061, 0.2652,\n",
      "        0.3666, 0.7892, 0.9951, 0.8145, 1.3474, 0.8578, 0.6624, 0.6259, 0.4652,\n",
      "        1.5314, 0.7927, 1.2560, 0.6946, 0.9146, 1.0300, 0.7416, 0.6672, 0.9259,\n",
      "        4.7266, 1.7009, 1.0367, 0.8269, 1.3637, 1.2553, 1.0431, 0.3917, 0.7527,\n",
      "        1.6738, 0.3635, 1.0675, 1.0818, 1.1068, 1.1604, 0.3950, 0.7762, 0.8772,\n",
      "        0.5994, 0.8840, 1.1867, 1.8361, 1.0845, 1.5268, 1.1511, 1.0919, 0.8320,\n",
      "        0.8304, 0.9784, 0.7302, 0.8211, 2.0060, 2.0837, 0.4362, 2.3074, 1.7367,\n",
      "        1.5320, 1.5172, 0.4744, 0.8172, 0.7782, 0.7662, 0.9733, 0.5057, 0.7306,\n",
      "        0.6666, 4.2057, 0.6605, 0.4136, 0.5568, 0.5904, 1.6434, 0.7451, 0.7825,\n",
      "        0.8836, 1.8876, 0.9167, 0.9150, 1.2504, 0.6337, 1.4563, 1.2068, 0.9164,\n",
      "        1.4413, 1.1186, 1.0876, 0.7109, 0.9958, 1.4923, 0.8714, 0.7460, 1.4061,\n",
      "        0.9207, 0.3305, 0.9786, 1.0436, 1.9855, 0.9426, 1.0259, 0.6170, 0.6230,\n",
      "        1.2265, 0.6051, 1.5378, 0.8413, 1.1564, 1.2969, 0.9192, 2.5696, 0.7999,\n",
      "        1.2697, 1.0221, 0.6643, 1.0756, 0.8471, 0.8458, 2.0195, 0.8398, 1.0056,\n",
      "        0.9909, 1.4441, 0.8017, 0.9710, 0.2592, 0.7601, 1.6279, 1.0442, 2.1975,\n",
      "        0.7707, 0.2449, 3.8262, 1.0800, 0.4618, 1.1159, 1.1240, 1.5043, 1.8060,\n",
      "        0.9055, 0.9153, 0.5545, 1.0867, 0.9236, 1.2575, 1.0426, 1.4243, 1.0274,\n",
      "        0.7670, 0.9764, 0.7542, 1.5433, 2.0148, 0.2926, 1.0756, 1.7940, 0.5512,\n",
      "        1.7666, 1.4860, 0.7494, 0.2088, 0.7748, 0.7508, 0.7775, 1.0995, 1.4575,\n",
      "        1.0536, 0.7304, 0.5857, 1.6092, 1.4213, 0.7113, 1.2334, 0.8480, 0.8546,\n",
      "        1.1352, 0.8817, 1.2684, 1.4288, 0.7667, 1.2921, 0.3957, 1.2899, 1.0712,\n",
      "        1.2648, 0.9046, 1.3586, 1.3195, 1.3220, 0.8190, 0.8084, 0.8104, 0.6595,\n",
      "        0.8890, 0.9445, 0.9170, 0.6710, 0.7744, 1.6588, 0.7722, 1.1128, 0.5591,\n",
      "        1.9167, 1.4791, 1.3551, 0.5348, 1.1914, 0.9040, 0.2988, 1.2062, 0.4829,\n",
      "        0.7587, 0.7592, 0.9959, 0.7222, 0.5043, 0.7644, 4.2998, 0.8169, 0.4921,\n",
      "        0.9989, 0.6245, 0.3044, 1.5753, 0.4438, 0.3698, 1.2820, 1.3229, 1.7853,\n",
      "        1.1942, 0.3137, 1.0156, 0.9901, 0.9975, 1.2571, 1.2546, 1.5642, 0.5069,\n",
      "        1.3257, 0.9795, 1.1743, 0.7203, 0.9588, 0.9772, 1.1540, 0.6798, 0.8838,\n",
      "        0.7386, 1.2537, 0.6524, 1.0685, 0.8138, 0.7644, 0.2166, 0.7753, 0.4068,\n",
      "        0.8457, 0.5506, 0.9211, 1.5803, 1.1412, 0.3503, 0.6634, 1.0412, 0.9970,\n",
      "        1.1229, 0.9434, 0.5188, 0.9555, 0.8256, 1.0697, 0.9804, 0.8934, 1.1180,\n",
      "        1.6573, 1.2155, 0.7276, 0.8355, 0.8959, 1.0515, 0.7699, 0.7149, 0.2886,\n",
      "        0.8589, 1.5543, 0.8002, 0.8166, 1.2897, 1.2680, 1.7481, 1.0850, 0.9113,\n",
      "        1.1302, 1.1760, 1.3096, 0.9016, 1.0292, 0.8330, 1.0403, 1.2245, 0.6323,\n",
      "        1.9282, 0.7657, 0.8970, 0.7766, 1.3055, 0.8654, 1.1809, 1.3989, 1.0253,\n",
      "        0.9863, 0.8411, 0.9959, 0.9578, 0.7794, 1.2267, 1.4410, 1.1488, 0.8175,\n",
      "        1.1871, 0.9536, 0.7844, 0.5607, 0.3407, 1.5307, 0.3591, 2.4352, 1.6960,\n",
      "        0.9864, 0.8917, 1.4591, 1.4843, 3.8589, 1.4573, 1.2953, 0.8924, 1.3552,\n",
      "        0.3955, 0.9455, 1.9592, 0.4942, 1.6931, 1.1904, 1.0832, 0.6531, 0.8661,\n",
      "        0.5702, 1.3480, 1.0720, 1.4454, 0.7579, 1.1344, 0.5655, 1.5620, 0.9816,\n",
      "        0.2976, 0.9745, 0.9344, 1.5138, 0.9171, 1.9844, 0.7071, 0.6212, 2.4300,\n",
      "        0.9774, 1.4996, 1.6749, 1.4790, 1.9585, 0.3366, 0.7277, 0.6412, 1.2099,\n",
      "        1.0827, 0.8072, 0.7033, 1.7140, 0.6886, 0.6177, 0.8309, 0.7252, 0.8810,\n",
      "        1.7162, 0.7838, 1.4456, 0.2997, 1.3810, 0.9614, 0.5366, 1.1435, 1.1061,\n",
      "        0.8989, 1.0367, 1.1642, 1.3645, 1.0600, 1.8877, 1.0618, 0.3928, 0.6234,\n",
      "        0.7225, 1.8058, 1.2773, 0.6892, 0.4625, 1.9393, 1.8957, 0.9092, 1.8028,\n",
      "        0.7875, 0.4062, 0.6998, 0.9333, 0.3699, 0.8942, 0.7485, 0.2399, 1.0366,\n",
      "        1.5203, 0.8883, 2.2714, 0.3719, 0.8618, 0.5293, 2.8217, 1.2614, 1.2779,\n",
      "        3.9921, 0.2770, 1.4114, 0.9782, 0.3704, 1.3555, 1.0271, 0.6713, 1.7135,\n",
      "        0.8746, 1.2206, 1.0841, 0.8519, 1.2783, 1.2741, 2.1724, 1.4669, 0.7930,\n",
      "        0.5021, 0.8723, 1.4568, 0.8783, 0.8465, 1.6265, 0.5608, 0.6479, 0.2041,\n",
      "        1.6437, 1.1318, 1.0521, 0.9787, 1.0969, 1.3020, 1.2624, 2.1266, 0.7836,\n",
      "        0.6857, 1.7790, 0.3516, 0.4877, 0.8613, 0.6028, 0.8401, 0.3001, 0.7788,\n",
      "        0.7128, 1.0425, 0.4351, 0.5761, 0.9143, 0.4357, 0.2473, 0.3814, 0.2841,\n",
      "        0.3809, 0.9491, 0.7138, 1.1255, 1.2619, 0.3769, 1.0591, 0.7724, 0.4053,\n",
      "        0.7197, 0.4683, 0.5999, 0.6862, 2.6458, 0.6821, 0.4097, 0.9423, 0.6328,\n",
      "        0.8783, 1.2140, 0.6364, 0.2680, 2.3316, 0.7878, 0.9304, 1.0477, 1.0048,\n",
      "        0.9530, 0.6020, 1.0498, 0.8874, 1.5276, 0.7239, 0.8615, 1.2586, 0.8158,\n",
      "        1.7195, 1.5332, 1.6796, 1.0208, 0.9324, 3.5476, 1.0737, 1.1467, 0.9395,\n",
      "        1.1952, 0.4520, 0.7504, 0.7429, 0.5797, 1.3638, 1.4545, 1.6165, 0.7687,\n",
      "        0.7269, 0.5442, 0.2409, 1.3299, 1.6172, 0.5699, 1.0189, 0.2554, 2.3219,\n",
      "        0.7619, 0.7542, 1.5014, 1.2859, 1.2191, 0.5240, 1.0349, 1.4001, 0.9595,\n",
      "        0.7224, 0.8189, 1.3540, 1.0951, 0.8680, 0.9705, 1.3730, 1.2877, 1.1250,\n",
      "        1.5253, 0.2626, 1.9107, 0.7794, 1.4012, 1.5160, 0.3183, 0.2795, 0.6397,\n",
      "        1.3209, 0.4307, 0.9044, 1.2960, 0.4107, 1.1657, 0.9695, 1.1545, 0.7523,\n",
      "        0.7284, 0.8218, 0.3254, 0.8725, 1.4840, 0.7816, 1.0743, 1.1603, 1.1186,\n",
      "        1.5887, 1.2136, 1.1848, 1.9067, 1.4287, 0.9075, 1.2831, 0.6978, 0.7711,\n",
      "        1.2149, 0.8637, 1.0247, 0.4389, 1.3356, 0.5220, 0.8905, 1.1098, 0.2733,\n",
      "        0.8953, 0.7371, 0.7612, 1.3831, 0.9074, 0.7411, 1.0112, 1.1113, 1.1615,\n",
      "        1.0907, 0.4196, 0.9838, 1.4501, 1.1422, 1.1769, 1.2724, 0.9245, 1.1313,\n",
      "        0.2671, 1.1018, 1.0147, 0.8180, 1.3254, 0.9382, 1.7572, 0.5247, 0.8301,\n",
      "        0.7176, 0.5463, 0.4811, 0.8436, 1.1682, 0.8489, 0.5828, 1.4474, 1.4084,\n",
      "        0.7593, 0.8166, 0.5881, 1.2516, 1.4315, 1.3799, 0.6354, 1.2476, 1.2758,\n",
      "        1.4765, 0.4500, 0.3959, 0.7032, 0.7918, 0.5671, 1.0084, 0.5606, 0.9584,\n",
      "        0.4008, 0.6850, 2.1470, 1.0025, 1.3932, 0.8739, 0.6968, 0.6240, 1.3785,\n",
      "        0.9280, 1.4708, 0.8473, 0.9349, 0.5599, 1.4562, 2.1373, 1.3795, 0.8057,\n",
      "        0.5872, 1.4991, 0.7483, 1.1366, 0.8622, 0.4296, 1.2573, 0.7080, 0.2447,\n",
      "        0.7449, 0.8362, 1.3695, 0.4930, 0.3798, 0.8766, 0.7623, 0.2811, 1.5519,\n",
      "        1.7446, 1.2807, 1.1065, 0.4747, 0.9985, 0.8483, 1.0862, 1.5209, 1.4526,\n",
      "        1.7684, 1.0362, 0.9358, 1.5934, 0.5939, 1.1317, 0.8420, 0.9121, 1.1300,\n",
      "        0.8517, 2.0521, 0.7042, 0.4987, 0.2856, 2.1519, 1.0553, 1.0520, 1.2248,\n",
      "        0.7277, 1.0057, 0.3045, 2.0022, 1.5863, 1.4296, 1.0665, 0.4296, 0.9442,\n",
      "        0.5721, 1.0654, 0.7500, 0.7612, 1.7007, 0.9448, 1.1867, 0.2402, 0.4119,\n",
      "        1.5038, 0.8543, 0.4132, 1.6233, 0.2934, 0.9296, 0.9905, 0.8163, 0.2699,\n",
      "        1.1134, 1.5940, 0.6597, 0.6814, 1.4883, 1.3257, 1.4329, 1.0040, 0.5961,\n",
      "        1.1433, 0.8095, 0.8702, 1.0805, 1.1960, 1.0354, 1.4751, 0.2840, 1.4621,\n",
      "        0.5844, 1.7015, 0.5031, 1.1070, 0.9525, 1.1008, 0.9298, 0.7153, 0.9150,\n",
      "        1.5335, 1.6177, 1.4168, 0.7180, 0.8424, 0.6397, 0.8516, 1.4714, 0.7905,\n",
      "        1.1055, 0.3831, 1.1416, 0.2511, 0.7644, 1.4561, 0.8146, 1.0512, 1.2883,\n",
      "        0.9921, 0.8408, 1.0520, 0.2482, 0.7450, 0.4416, 1.6716, 0.8817, 0.7934,\n",
      "        3.7200, 0.5461, 1.8981, 1.4026, 1.6141, 1.4255, 0.6435, 0.3873, 1.0904,\n",
      "        1.1081, 1.1239, 0.9629, 0.9216, 0.9685, 0.2403, 0.9770, 0.7085, 1.2517,\n",
      "        0.8808, 0.6181, 0.8583, 0.8805, 0.9059, 1.1898, 1.0636, 1.0667, 1.5798,\n",
      "        1.0931, 0.8911, 1.0500, 1.3152, 0.9874, 0.8952, 1.1723, 0.4826, 2.2672,\n",
      "        1.2415, 1.0718, 0.4927, 1.1007, 0.8403, 0.7143, 0.7845, 1.2347, 1.3995,\n",
      "        1.0770, 6.2227, 1.1626, 0.5366, 1.6747, 0.6678, 1.4350, 0.7621, 1.1946,\n",
      "        0.4950, 2.5807, 1.2306, 0.4035, 1.5024, 1.1448, 0.6042, 1.3441, 1.0506,\n",
      "        1.2789, 0.9065, 1.7993, 1.1705, 0.6172, 0.8090, 0.8590, 0.6046, 0.9624,\n",
      "        0.9297, 0.8684, 2.0158, 0.8020, 0.9677, 1.8314, 1.2001, 0.8695, 1.7677,\n",
      "        0.8280, 0.7756, 1.0533, 1.3981, 1.1745, 2.0074, 1.1121, 0.9547, 0.9815,\n",
      "        0.8112, 1.4092, 1.6707, 1.6891, 1.5949, 0.4514, 0.9497, 1.3576, 0.4755,\n",
      "        0.7135, 1.2566, 1.1827, 1.5693, 1.1922, 1.3381, 0.6963, 1.9961, 0.8372,\n",
      "        1.0678, 0.7280, 0.9026, 1.5697, 0.3377, 0.9034, 0.5717, 0.8900, 0.7768,\n",
      "        0.9754, 0.8296, 0.6845, 1.6078, 0.7893, 1.0806, 0.8865, 1.3772, 1.0096,\n",
      "        0.5654, 0.5661, 1.0266, 0.6809, 0.4507, 1.0664, 0.9942, 0.6565, 0.8869,\n",
      "        1.6112, 0.2883, 1.6410, 0.6010, 0.8696, 1.4772], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.1.1.bias\n",
      "Weights: tensor([-2.8789e+00,  2.0656e-01,  1.7321e+00,  4.8485e-01, -4.2535e+00,\n",
      "        -8.6060e-01, -2.0075e+00, -7.7766e-01,  7.9610e-01,  1.9413e+00,\n",
      "         1.3599e+00, -1.1935e+00, -3.8536e-01, -1.7935e+00, -1.5526e+00,\n",
      "        -8.1959e-01, -1.0050e+00,  1.7437e+00,  1.6724e+00, -2.5836e-01,\n",
      "        -6.1100e-01, -1.8756e-01, -1.9039e+00, -3.2842e-01, -8.8920e-02,\n",
      "         2.0268e-01,  3.9735e-01, -1.1879e+00, -2.5040e+00, -1.1172e+00,\n",
      "        -5.7651e-01, -2.2166e+00, -5.5003e-01, -1.3524e+00,  2.2385e-01,\n",
      "        -2.8236e-01, -2.3370e+00, -2.0549e+00, -7.8270e-01, -3.9403e-01,\n",
      "        -1.2389e+00, -7.9318e-01, -1.7064e+00,  9.9155e-01,  1.4480e+00,\n",
      "        -1.6553e+00,  1.6123e+00, -3.3679e+00, -9.9525e-01, -7.5626e-01,\n",
      "        -9.2331e-01, -3.7687e-01, -8.5641e-01, -5.3402e-01, -3.3269e-01,\n",
      "        -5.9287e-01, -6.2264e-01, -2.6235e+00, -9.7360e-01, -1.3019e+00,\n",
      "        -7.6613e-01, -2.3055e+00, -3.2283e-01, -1.7678e-01, -4.5356e-01,\n",
      "        -3.7699e-01, -1.6704e+00,  4.1053e-01, -2.6904e+00, -4.0556e-01,\n",
      "        -1.1897e+00, -1.8815e+00, -4.9932e+00, -3.2252e+00, -5.1234e-01,\n",
      "        -1.4525e-01, -5.1354e-01, -1.7549e+00, -1.9330e+00,  6.0148e-01,\n",
      "         1.1822e-01, -5.9474e-01, -2.5548e+00, -1.2488e+00,  4.5078e-01,\n",
      "         1.8661e+00,  1.7836e-01, -1.2915e+00, -3.6587e-01, -2.8793e-01,\n",
      "        -1.5190e+00, -1.0469e+00, -5.5817e-01, -2.3494e-01, -1.7499e+00,\n",
      "        -1.4132e+00, -1.5826e+00, -1.2237e+00, -4.7373e-01, -9.5555e-01,\n",
      "        -2.1915e+00, -6.2495e-01,  6.0008e-02, -8.8102e-01, -1.6211e+00,\n",
      "        -3.1723e-01,  1.5922e+00, -2.0458e+00, -8.3903e-02,  5.9247e-01,\n",
      "        -5.5867e-01, -4.8358e-01, -1.4476e+00, -2.9856e-01, -5.5931e-01,\n",
      "        -1.0371e+00,  3.8928e-01, -9.3359e-01, -6.9542e-01, -9.9921e-01,\n",
      "        -1.3826e+00, -8.9238e-01, -1.0850e+00, -1.1581e+00, -2.4029e+00,\n",
      "        -2.2810e-02, -9.4852e-01, -6.3023e-01, -1.0313e+00, -6.1930e-01,\n",
      "         5.2681e-02, -6.4595e-01, -3.0518e+00, -2.0791e-01, -5.8481e-01,\n",
      "        -2.5834e+00, -1.6482e+00, -2.8771e-01, -1.8593e+00,  2.2491e+00,\n",
      "        -2.1113e-01, -9.6806e-01, -7.3582e-01, -2.8582e+00, -5.5745e-02,\n",
      "         1.5733e+00, -2.5007e+00, -1.0412e+00, -7.8566e-01, -2.0879e+00,\n",
      "        -8.2383e-01, -3.4412e+00, -2.7804e+00, -4.5938e-01, -3.9845e-01,\n",
      "         7.8715e-01, -2.8132e+00, -4.8651e-01, -6.8695e-01, -1.5162e+00,\n",
      "        -1.5664e+00, -7.0797e-01, -2.6180e-01, -6.6939e-01, -9.7207e-01,\n",
      "        -1.0822e+00, -4.1180e+00,  8.9840e-01, -2.4061e+00, -4.0400e+00,\n",
      "         1.6508e-01, -2.0673e+00, -1.3732e+00, -1.5007e+00,  2.0457e+00,\n",
      "        -2.5311e-01, -1.2183e-01,  7.2162e-02, -9.4546e-01, -7.7000e-01,\n",
      "        -4.4339e-01, -2.4051e-01, -1.0870e+00, -2.2694e+00, -1.3438e+00,\n",
      "        -2.7621e-01, -2.1698e+00, -5.1046e-01, -2.0598e+00, -3.2872e+00,\n",
      "        -6.8313e-01, -3.8226e+00, -4.5849e+00, -1.4163e-01, -1.3159e+00,\n",
      "         4.3638e-01, -6.6812e-01, -9.7513e-01, -9.3911e-01, -5.4096e-01,\n",
      "        -1.1517e+00, -8.6978e-01, -1.1133e+00, -3.0936e-01, -3.0337e-01,\n",
      "        -1.6669e+00, -1.5485e+00, -2.9868e-01, -8.9522e-01, -3.3223e-01,\n",
      "        -3.2380e-01, -7.7904e-01, -1.7688e+00, -3.0301e-01, -7.3713e-01,\n",
      "         1.4098e+00, -2.5587e+00, -2.9554e+00, -1.6933e+00,  1.9066e+00,\n",
      "        -6.0348e-01, -4.5390e-01,  2.4318e+00, -1.1608e+00,  1.3553e+00,\n",
      "        -1.1783e+00, -1.5080e+00, -6.6570e-01, -1.3856e-01,  1.6599e+00,\n",
      "        -1.1626e+00, -2.2292e+00, -2.4132e+00,  1.8593e+00, -6.7837e-01,\n",
      "         8.5203e-03,  7.3496e-01, -1.2188e+00,  2.8118e-01,  1.8491e+00,\n",
      "        -3.9185e+00, -1.3235e+00, -2.7685e+00, -9.8078e-01,  1.9884e+00,\n",
      "        -2.5094e-01, -1.3142e+00, -1.8059e+00, -2.9604e+00, -1.4832e+00,\n",
      "        -8.1100e-01,  1.9352e+00, -7.3760e-01, -8.1818e-01, -2.3823e+00,\n",
      "        -2.7557e-01, -6.7368e-01, -4.4917e-01, -6.2019e-01, -2.0490e-01,\n",
      "        -1.1378e+00, -2.1920e-01, -1.2339e+00,  1.0326e-01, -6.1978e-01,\n",
      "        -1.9347e-01, -7.4273e-02,  2.0438e+00, -1.9197e-01,  4.6282e-01,\n",
      "        -5.1153e-01, -1.0297e+00, -1.4607e+00, -1.1268e+00, -4.3440e-01,\n",
      "        -6.2181e-01,  1.4728e-01, -6.9962e-01, -4.8738e-01, -1.0834e+00,\n",
      "         1.5067e+00, -5.2618e-01, -2.1168e-01, -3.3187e-01, -1.1168e+00,\n",
      "        -6.3107e-01, -2.5075e-01, -7.7032e-01, -5.4068e+00, -1.4055e+00,\n",
      "        -2.3953e-01, -3.7364e-01, -4.3385e-01, -1.9517e+00, -2.1475e-01,\n",
      "        -6.8328e-01,  1.0613e+00, -2.6190e-01, -1.3988e+00,  1.9250e-02,\n",
      "        -8.2294e-01, -6.8413e-01, -9.9744e-01, -4.4076e+00, -3.8665e-01,\n",
      "        -4.2608e-01, -8.2620e-01, -1.3743e+00, -9.6813e-01, -4.5663e-01,\n",
      "        -2.5423e+00, -1.3374e+00, -1.2121e+00, -2.9977e+00, -1.2320e-01,\n",
      "        -2.4526e+00,  2.4875e-01, -3.4024e-01, -2.3044e+00, -1.1266e+00,\n",
      "        -2.0409e+00, -7.8946e-01, -2.1748e+00, -5.2993e-01, -8.0772e-01,\n",
      "        -2.8966e-01, -8.9291e-01, -4.2516e-01, -2.5441e-01, -8.1373e-01,\n",
      "        -8.7342e-01, -4.1225e-01, -1.7255e+00, -1.4637e+00, -9.5855e-01,\n",
      "        -5.1723e-01,  2.0100e-01, -3.2780e-01, -4.0949e+00,  1.7644e+00,\n",
      "        -2.7916e-01, -1.7047e+00,  2.5995e-01, -2.9014e-01, -3.1319e+00,\n",
      "        -1.2453e+00, -2.0518e+00, -9.6368e-01, -1.6617e+00, -5.6628e-01,\n",
      "        -9.1397e-01, -2.2689e-01, -5.5104e-01, -2.0228e+00, -3.5610e-01,\n",
      "        -1.9769e+00, -8.4741e-01, -8.9030e-01,  2.3361e-01, -5.9145e-01,\n",
      "         1.6069e+00, -8.9268e-01, -4.8362e-01, -1.7915e+00,  2.4508e-01,\n",
      "        -1.6151e+00,  6.0015e-01, -1.4464e+00, -9.7514e-01,  1.8544e+00,\n",
      "        -4.5095e-01, -3.5244e-01, -1.3246e+00, -2.6619e-01, -4.9030e+00,\n",
      "        -1.7329e-01, -8.3823e-01, -3.0524e+00, -6.0322e-01, -9.6698e-01,\n",
      "        -4.2311e+00, -2.0191e+00, -4.2522e+00,  1.3729e+00, -9.1555e-01,\n",
      "         1.7969e-01, -2.9311e+00, -1.4508e+00, -3.2016e-01,  1.2299e-01,\n",
      "        -3.3316e+00,  2.4022e-01,  2.0352e+00, -2.5652e-01, -1.7686e-01,\n",
      "        -9.3060e-01, -1.3888e+00, -1.6337e-01, -9.2371e-01,  6.6747e-01,\n",
      "        -1.4991e+00, -1.7344e+00, -1.4694e+00, -6.7509e-01, -3.0767e+00,\n",
      "        -3.4290e-01, -2.3040e+00, -2.8511e+00, -1.8283e+00, -8.0081e-01,\n",
      "        -5.1670e+00, -5.7117e-01,  6.9530e-01,  2.4810e-01, -1.9172e-01,\n",
      "        -2.8203e+00, -6.4872e-01, -8.2229e-01,  3.9774e-01, -2.3996e+00,\n",
      "        -2.2298e+00, -2.4681e+00, -1.4561e+00, -1.8534e-01,  7.3672e-01,\n",
      "        -3.1280e-01, -1.8336e+00,  7.0286e-01, -2.2117e-01, -2.2267e-01,\n",
      "         1.1975e+00, -7.3317e-01, -8.3460e-01, -5.7542e-01, -2.2419e+00,\n",
      "         6.8942e-01, -1.5596e+00, -1.0148e+00, -3.6638e+00, -6.2041e-01,\n",
      "        -2.3565e+00, -2.2575e+00,  2.1631e+00, -3.1162e+00, -4.1441e-01,\n",
      "         2.2245e+00, -6.1218e-01, -2.6879e+00,  1.3214e-01, -1.8466e+00,\n",
      "        -3.8617e-01, -5.5875e-01, -9.1957e-01, -1.6247e+00, -1.5392e+00,\n",
      "        -7.3050e-01, -2.8312e+00, -1.6775e+00, -1.3602e-01, -5.0020e-01,\n",
      "        -1.5122e+00, -7.5014e-01,  1.0861e-01, -2.3309e-01, -2.1951e+00,\n",
      "         3.7597e-01, -1.0457e+00,  2.2237e+00, -3.1847e+00, -4.0316e-01,\n",
      "        -4.8118e-01, -2.4255e+00, -6.1392e-01, -3.2088e+00, -9.6936e-01,\n",
      "        -2.6243e+00, -3.6983e-01,  4.9991e-01, -5.1420e-01,  1.2249e+00,\n",
      "         9.8244e-01, -2.1853e+00, -6.7389e-02, -2.3225e+00,  1.7397e+00,\n",
      "        -3.0689e-01, -6.5268e-01, -4.7262e-01,  8.2964e-03,  3.1270e-01,\n",
      "         6.6271e-01,  8.5763e-01,  1.4830e+00,  1.7907e+00,  1.3615e+00,\n",
      "         6.8042e-01, -2.5975e+00, -3.4693e-01, -8.8616e-01, -1.6154e+00,\n",
      "         2.1267e+00, -7.6307e-01, -1.5031e+00, -1.8553e-01, -1.4549e-01,\n",
      "         7.4270e-01, -5.7733e-01, -1.3638e+00, -3.7763e+00, -2.6155e-01,\n",
      "        -5.5943e-01, -3.5610e-01,  2.0687e+00, -4.7974e-01, -6.1749e-01,\n",
      "         4.8119e-01,  2.2515e+00, -5.0024e+00, -2.7325e-01, -1.2552e+00,\n",
      "        -6.7613e-01, -5.1907e-01,  2.7185e-01,  1.9565e+00, -5.9811e-01,\n",
      "        -3.5356e-01, -7.5986e-01, -1.7115e-01, -3.7285e-01, -3.2983e+00,\n",
      "        -1.0362e+00, -3.2428e+00, -2.2732e+00, -1.8402e+00, -6.0109e-01,\n",
      "        -8.1121e-01, -1.9980e+00, -1.0641e+00, -8.0001e-01, -4.5050e-01,\n",
      "        -4.9876e-01,  1.7826e+00, -1.8029e+00, -2.0994e+00,  7.6306e-01,\n",
      "        -3.2098e+00, -1.4898e+00, -1.3929e+00, -4.4374e-01, -2.7137e-01,\n",
      "         1.5396e+00,  9.4311e-01, -1.1908e+00, -3.2690e+00,  2.0087e+00,\n",
      "        -1.1112e+00,  3.8463e-01, -3.7141e+00, -2.2680e-01, -9.6274e-01,\n",
      "        -2.1649e+00, -1.9576e+00, -7.6261e-01,  1.3054e+00, -1.2817e+00,\n",
      "        -1.4768e+00, -2.7409e-01, -5.2625e-01, -1.7409e+00, -1.3698e+00,\n",
      "        -6.4039e-01, -1.9599e+00, -2.1032e+00, -1.4393e+00, -5.9757e-01,\n",
      "        -1.9924e+00, -9.9858e-01,  2.0370e+00, -4.4619e+00,  4.3123e-04,\n",
      "        -9.5276e-01, -1.8903e+00,  7.7846e-01,  1.8843e+00,  1.8638e+00,\n",
      "        -1.3100e+00,  3.5896e-01, -1.6370e+00, -9.5372e-01, -5.5944e-01,\n",
      "        -8.3830e-01, -6.0701e-01, -2.3812e+00, -1.0484e+00, -9.6616e-02,\n",
      "        -3.0442e-01,  1.3196e-01, -2.0121e+00, -6.9236e-01, -1.2953e-01,\n",
      "        -8.1718e-01, -2.7132e+00, -6.0971e-01, -2.1341e+00, -9.3534e-01,\n",
      "        -2.1983e+00, -1.8572e+00, -1.5427e+00, -8.4860e-02, -2.2615e+00,\n",
      "        -1.4674e-02, -5.9586e-02, -5.7987e-01, -6.9252e-01, -8.2046e-01,\n",
      "        -4.4530e-01, -2.7779e+00, -6.8701e-01, -1.3539e+00, -3.4530e+00,\n",
      "         3.6201e-01, -1.5759e-01, -2.8381e-01, -1.4001e-01, -8.3507e-01,\n",
      "        -5.7111e-01,  1.0115e-01, -5.9008e-01, -7.2415e-01, -8.4900e-01,\n",
      "        -6.8357e-01,  1.0689e+00, -3.8495e-01, -1.0508e+00, -6.5602e-01,\n",
      "        -4.8409e-01, -5.7689e-01, -8.1935e-01, -1.0599e+00,  1.2735e+00,\n",
      "        -4.9219e-01, -2.1097e+00, -1.0187e+00, -7.7531e-01, -1.2676e+00,\n",
      "        -3.7223e+00,  2.3637e-01, -2.0717e+00,  4.1990e-01,  5.9130e-01,\n",
      "         4.7872e-01, -3.7854e-01, -4.7758e-01, -3.1282e-01, -8.8900e-01,\n",
      "        -1.3586e+00, -3.8930e+00, -2.1622e-01, -4.5132e-01,  8.7838e-01,\n",
      "        -1.4784e+00, -1.7915e+00, -1.1509e+00,  8.3270e-01, -7.4391e-01,\n",
      "        -2.5653e+00, -7.2263e-01,  1.7643e+00,  2.9783e-02, -7.7820e-01,\n",
      "        -2.1885e-01, -1.0316e+00, -6.8179e-01,  2.4966e+00, -3.4451e-01,\n",
      "         6.0152e-01,  8.5909e-01, -2.1366e+00, -2.3793e+00, -2.1301e+00,\n",
      "        -3.0380e-01, -1.6324e-01,  9.8643e-01, -1.2687e+00, -7.6117e-01,\n",
      "        -1.4917e+00, -1.7339e+00, -1.8810e+00,  2.5401e-01, -1.2066e+00,\n",
      "        -4.8173e+00, -9.4645e-01, -1.7178e+00,  2.9590e+00, -2.1597e+00,\n",
      "        -2.1243e-02, -5.5538e-01, -1.6830e+00,  8.5943e-01, -7.1583e-01,\n",
      "        -1.1820e+00,  2.5684e+00, -1.2003e-01, -2.6219e-01, -1.2860e+00,\n",
      "         2.0830e+00,  7.0545e-01, -1.8026e+00, -1.4390e-01,  1.0953e+00,\n",
      "        -1.4685e+00, -4.0054e+00, -1.1538e+00, -9.1595e-01,  1.3429e+00,\n",
      "        -8.1435e-01, -3.5236e-01, -5.4932e-01, -2.1612e+00, -1.6113e+00,\n",
      "        -1.8279e+00, -1.9787e+00, -1.6274e+00, -1.3123e+00,  5.2060e-01,\n",
      "        -6.3145e-01, -2.4349e+00, -6.5293e-01, -6.2434e-01, -2.0530e-01,\n",
      "        -5.0941e+00,  1.8349e-01,  2.5546e-01,  5.9956e-01, -3.1157e+00,\n",
      "        -5.5222e-01, -5.0955e-01, -8.3195e-01, -7.1492e-01, -1.0880e+00,\n",
      "         4.4073e-01, -9.2837e-01, -1.8266e+00, -1.6681e+00, -1.9471e+00,\n",
      "         2.0823e+00, -4.5528e-01,  7.3141e-01, -2.0890e+00, -6.7149e-01,\n",
      "         1.2429e-01, -2.2075e+00, -1.4553e-01, -9.2618e-01,  2.0872e+00,\n",
      "         8.3059e-01, -1.2969e+00, -5.6055e-01,  6.5513e-01, -2.0903e+00,\n",
      "         2.0720e+00, -4.5535e-01, -2.5652e-01, -9.9345e-01,  2.3773e+00,\n",
      "        -7.6120e-01, -1.3446e+00, -2.1030e-01,  4.8769e-01, -3.6190e+00,\n",
      "        -1.1556e+00, -1.0853e+00, -5.3123e-01,  2.4976e-01, -1.3864e+00,\n",
      "        -2.0305e-01, -1.5719e+00, -7.7112e-01, -1.6010e+00, -3.9068e-01,\n",
      "        -1.7697e+00,  8.6288e-01, -1.3459e+00, -7.4672e-01, -1.9049e+00,\n",
      "        -2.4548e-01, -5.9181e-01,  1.1824e-02, -7.2569e-01, -2.9538e+00,\n",
      "        -2.6017e-01, -4.3535e-01, -2.7410e+00, -3.6822e+00, -3.3616e+00,\n",
      "        -1.2738e+00, -1.3514e+00,  3.2350e-01, -1.9176e+00, -6.3564e-01,\n",
      "        -2.7572e-01, -7.5871e-01,  2.3393e+00, -7.6319e-01,  1.9796e+00,\n",
      "        -2.6202e-01, -1.0086e+00, -8.1251e-01, -6.6462e-01, -1.7527e+00,\n",
      "        -2.5792e+00, -1.6985e-01, -1.2181e+00,  1.7304e+00, -1.3742e+00,\n",
      "         2.4262e+00, -4.2261e+00, -5.5843e-01, -1.9250e+00, -2.3559e+00,\n",
      "         1.0719e+00, -2.4169e+00, -1.6030e+00, -3.5457e+00, -1.1545e+00,\n",
      "        -9.9285e-01,  7.6851e-01, -1.9802e+00, -4.5258e-01, -5.4922e-01,\n",
      "        -6.7421e-01, -8.4806e-02, -4.5465e-01,  1.1448e+00, -4.4578e-01,\n",
      "        -2.0756e-01, -9.6530e-01, -3.5571e-01,  2.4824e-01, -1.9667e+00,\n",
      "        -5.3181e-01, -4.4217e-01, -1.2888e+00, -5.6563e-01, -6.8182e-01,\n",
      "        -9.0546e-01, -8.1025e-01, -3.6123e-01, -7.1470e-01, -1.4716e+00,\n",
      "        -4.0535e-01, -1.1713e+00, -7.6085e-01,  2.5774e+00, -4.9111e+00,\n",
      "        -6.8714e-01, -7.6617e-01,  2.3308e+00, -5.0002e-01, -2.1778e-01,\n",
      "         1.1048e-01,  3.3571e-02, -7.8506e-01, -2.0634e+00, -1.3558e+00,\n",
      "        -3.7257e+00, -1.1964e+00,  1.3321e+00, -2.4070e+00, -4.1949e-01,\n",
      "        -3.5788e+00, -3.2281e-01, -1.2669e+00,  2.4512e-01, -5.6968e+00,\n",
      "        -2.5001e+00,  1.0233e+00, -2.3116e+00, -8.1443e-01, -8.9200e-01,\n",
      "        -3.5894e+00, -1.6675e+00, -1.7801e+00, -3.5539e-01, -3.0957e+00,\n",
      "        -7.2394e-01, -5.6492e-01, -3.0778e-02, -2.7691e-01,  3.7819e-01,\n",
      "        -5.0868e-01, -2.5203e+00, -7.6316e-01, -1.6667e+00, -2.2055e-01,\n",
      "         2.2814e-01, -2.9720e+00, -6.1991e-01, -3.9426e-01, -2.2437e+00,\n",
      "        -4.3060e-01,  1.4699e-01, -5.0033e-01, -9.5865e-01, -7.8568e-01,\n",
      "        -2.7772e+00, -2.0612e+00, -4.9049e-01, -4.3270e-01, -3.3562e-01,\n",
      "        -1.3909e+00, -2.1421e+00, -1.7401e+00, -2.2957e+00,  4.1467e-01,\n",
      "        -1.4964e+00, -2.3939e+00, -5.0262e-01, -2.9258e-01, -1.2618e+00,\n",
      "        -6.0519e-01, -1.4554e+00, -1.2789e+00, -1.4154e+00, -1.7375e-01,\n",
      "        -4.1368e+00, -2.2754e-01, -5.0843e-01, -1.3647e-01, -3.7505e-01,\n",
      "        -2.1930e+00,  1.0109e+00, -2.1553e+00,  1.7114e+00, -6.9834e-02,\n",
      "        -4.1618e-01, -7.9950e-01, -9.7084e-02, -1.1181e-01, -4.1422e+00,\n",
      "        -2.2165e-01, -1.6181e+00, -1.9955e-01, -8.6922e-01, -6.3160e-01,\n",
      "        -5.9978e-01,  7.8008e-01, -2.1301e+00, -9.4169e-01,  1.8044e+00,\n",
      "        -6.3295e-01, -7.9699e-01,  2.9738e-01, -1.6438e-01, -3.4849e+00,\n",
      "         1.0780e+00, -9.3029e-01,  2.0392e-01, -3.3680e-01, -2.8975e+00],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.15.conv.2.weight\n",
      "Weights: tensor([[[[-0.2272]],\n",
      "\n",
      "         [[ 0.0415]],\n",
      "\n",
      "         [[-0.0017]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1849]],\n",
      "\n",
      "         [[ 0.0578]],\n",
      "\n",
      "         [[-0.0678]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0904]],\n",
      "\n",
      "         [[ 0.0973]],\n",
      "\n",
      "         [[-0.0611]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0134]],\n",
      "\n",
      "         [[ 0.0058]],\n",
      "\n",
      "         [[ 0.0595]]],\n",
      "\n",
      "\n",
      "        [[[-0.0285]],\n",
      "\n",
      "         [[ 0.0246]],\n",
      "\n",
      "         [[ 0.0811]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0683]],\n",
      "\n",
      "         [[-0.0209]],\n",
      "\n",
      "         [[ 0.0525]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0109]],\n",
      "\n",
      "         [[ 0.0670]],\n",
      "\n",
      "         [[ 0.0560]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0557]],\n",
      "\n",
      "         [[-0.0031]],\n",
      "\n",
      "         [[-0.0570]]],\n",
      "\n",
      "\n",
      "        [[[-0.1238]],\n",
      "\n",
      "         [[ 0.0472]],\n",
      "\n",
      "         [[ 0.0007]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0066]],\n",
      "\n",
      "         [[ 0.0504]],\n",
      "\n",
      "         [[-0.0147]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0160]],\n",
      "\n",
      "         [[-0.0191]],\n",
      "\n",
      "         [[-0.0080]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0047]],\n",
      "\n",
      "         [[-0.0416]],\n",
      "\n",
      "         [[-0.0199]]]], device='cuda:0')\n",
      "Shape: torch.Size([160, 960, 1, 1])\n",
      "\n",
      "Layer: features.15.conv.3.weight\n",
      "Weights: tensor([4.1007, 1.2737, 2.8637, 1.3691, 1.9483, 1.4831, 1.6949, 0.9279, 1.7290,\n",
      "        1.2234, 2.4084, 1.9626, 1.5683, 2.7622, 2.6831, 2.5816, 0.9477, 2.5015,\n",
      "        1.1736, 2.3006, 1.1139, 1.6150, 1.5968, 2.4600, 1.6956, 3.0962, 1.2282,\n",
      "        1.2531, 1.2108, 2.0988, 1.2288, 1.9227, 1.5812, 1.6211, 3.2189, 1.0721,\n",
      "        2.0699, 0.9473, 2.3596, 1.3639, 2.9150, 2.0776, 1.6745, 1.0755, 2.5590,\n",
      "        3.9001, 2.7860, 1.6183, 0.9864, 3.3164, 2.9515, 2.9806, 2.9637, 1.7790,\n",
      "        2.4916, 2.2305, 1.9942, 1.2538, 2.8781, 3.2415, 2.4917, 1.4832, 2.0671,\n",
      "        1.2411, 1.7759, 2.2709, 2.4568, 1.7596, 1.1267, 4.3622, 3.5939, 1.0888,\n",
      "        2.0889, 1.7450, 2.8761, 1.7259, 1.4957, 1.9370, 3.3132, 0.9676, 1.4314,\n",
      "        1.7414, 1.1676, 1.8560, 2.5611, 1.5380, 4.6520, 2.6145, 1.9974, 1.9655,\n",
      "        1.6949, 2.0825, 2.3652, 1.2734, 1.4588, 1.3459, 1.0894, 1.4432, 2.0117,\n",
      "        2.2145, 2.6910, 1.6275, 2.8713, 2.3444, 2.7749, 1.4793, 2.5572, 1.6333,\n",
      "        1.8035, 1.6336, 2.1399, 2.7765, 2.5529, 1.3580, 1.7425, 0.9752, 2.0832,\n",
      "        1.4221, 0.9866, 1.0272, 2.5018, 4.0539, 1.2777, 1.8545, 3.6204, 2.7409,\n",
      "        1.5492, 3.0657, 2.2134, 2.0952, 1.5525, 2.0036, 1.1674, 1.0353, 1.0284,\n",
      "        2.4982, 1.2361, 1.0788, 1.9909, 1.1345, 2.0058, 2.1505, 1.1375, 1.6332,\n",
      "        3.5422, 1.4261, 2.3812, 1.0764, 3.3506, 3.5374, 3.2310, 3.1007, 2.7008,\n",
      "        1.8103, 2.2889, 2.5295, 3.1108, 1.6676, 2.0589, 1.7691],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.15.conv.3.bias\n",
      "Weights: tensor([ 1.3007e-03, -2.4517e-04,  2.1623e-04, -2.8150e-04,  2.3198e-04,\n",
      "        -7.8201e-04,  1.1438e-04,  4.7655e-04, -3.9122e-05, -8.0464e-04,\n",
      "        -1.0645e-04,  1.1385e-05, -2.3353e-04, -3.8314e-04,  6.6152e-04,\n",
      "        -6.0227e-04, -3.0568e-04,  6.6401e-04,  7.4072e-04,  5.2545e-05,\n",
      "         7.1765e-05,  4.4370e-05, -3.6061e-04,  6.6429e-05, -2.8675e-04,\n",
      "        -1.3217e-03,  2.0435e-04,  4.3402e-04,  2.7545e-04,  8.5032e-05,\n",
      "         5.4612e-05, -7.8290e-04,  5.2272e-04,  1.7653e-07,  1.2982e-03,\n",
      "        -5.6593e-04,  3.8656e-05,  4.9760e-06, -1.8998e-04,  3.7871e-04,\n",
      "         5.4047e-04,  3.1344e-04,  1.2373e-04, -6.2295e-05,  1.2011e-03,\n",
      "         9.8611e-04,  9.3487e-05,  1.2333e-04, -2.0981e-04, -1.6628e-03,\n",
      "         1.6155e-04,  9.3874e-04, -6.8728e-04,  3.5570e-04,  6.1561e-04,\n",
      "        -1.8652e-04, -1.4172e-04, -2.3704e-04, -4.6230e-04,  8.0459e-04,\n",
      "        -4.2735e-04,  9.3075e-05, -2.9755e-04, -6.4669e-05, -1.1611e-04,\n",
      "         4.2159e-04, -3.0281e-04, -6.5091e-05, -1.9624e-04,  4.5712e-04,\n",
      "        -1.0430e-03, -1.9855e-04,  3.0890e-04, -1.4645e-04,  1.0258e-03,\n",
      "         1.5630e-05,  8.1571e-04,  1.9854e-04, -7.5144e-04, -6.6644e-04,\n",
      "         7.9508e-05,  3.3137e-04,  8.3917e-05,  1.8150e-04, -6.6068e-04,\n",
      "         8.9798e-05,  5.6289e-04,  2.2134e-05,  2.1230e-04, -3.3620e-04,\n",
      "         9.1939e-05,  2.6941e-04, -2.4029e-04,  9.1141e-04, -3.3688e-04,\n",
      "        -9.4868e-05,  9.1344e-04, -2.0892e-04,  2.7027e-05, -4.1934e-04,\n",
      "         4.9366e-04,  1.3471e-04, -4.1218e-04,  6.3904e-04,  7.3611e-04,\n",
      "        -3.8731e-04, -7.7264e-04,  3.3012e-04, -5.9810e-05,  4.5572e-04,\n",
      "         1.3163e-04,  1.4767e-03, -4.9010e-04, -2.5704e-04, -6.2909e-04,\n",
      "         1.8513e-04,  3.1919e-04,  4.7118e-06,  1.9698e-04,  4.3150e-04,\n",
      "         8.1865e-04,  4.8618e-04,  8.6137e-05, -1.8175e-04, -1.3947e-04,\n",
      "         1.4513e-04,  2.5268e-04, -5.0885e-04,  3.6288e-04, -3.2576e-04,\n",
      "        -4.6843e-04,  8.6053e-05,  3.3047e-04, -5.1243e-04,  9.2878e-06,\n",
      "         1.2962e-04,  4.9822e-05, -4.2581e-06, -1.4158e-04, -4.7980e-04,\n",
      "        -2.6200e-04, -4.4181e-04,  1.2736e-04, -2.3192e-04, -1.2334e-04,\n",
      "         5.1344e-04,  8.2786e-04,  1.4751e-04,  6.2538e-04, -4.0931e-04,\n",
      "         8.5219e-04,  5.2457e-04, -8.9732e-04,  3.6770e-04,  2.2034e-04,\n",
      "         7.1903e-04, -1.1045e-04, -1.8283e-04,  2.2770e-04,  2.7114e-05],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.16.conv.0.0.weight\n",
      "Weights: tensor([[[[-0.0902]],\n",
      "\n",
      "         [[ 0.0531]],\n",
      "\n",
      "         [[ 0.0743]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0690]],\n",
      "\n",
      "         [[-0.0804]],\n",
      "\n",
      "         [[-0.0065]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0426]],\n",
      "\n",
      "         [[ 0.0088]],\n",
      "\n",
      "         [[-0.0895]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1358]],\n",
      "\n",
      "         [[ 0.0483]],\n",
      "\n",
      "         [[ 0.0479]]],\n",
      "\n",
      "\n",
      "        [[[-0.0731]],\n",
      "\n",
      "         [[ 0.0360]],\n",
      "\n",
      "         [[ 0.0358]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.1007]],\n",
      "\n",
      "         [[ 0.0324]],\n",
      "\n",
      "         [[-0.0420]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1775]],\n",
      "\n",
      "         [[ 0.0110]],\n",
      "\n",
      "         [[-0.0027]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0508]],\n",
      "\n",
      "         [[-0.0131]],\n",
      "\n",
      "         [[-0.0218]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0431]],\n",
      "\n",
      "         [[-0.0888]],\n",
      "\n",
      "         [[ 0.0302]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0222]],\n",
      "\n",
      "         [[ 0.0278]],\n",
      "\n",
      "         [[-0.0446]]],\n",
      "\n",
      "\n",
      "        [[[-0.0717]],\n",
      "\n",
      "         [[ 0.0907]],\n",
      "\n",
      "         [[ 0.0326]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0757]],\n",
      "\n",
      "         [[ 0.0461]],\n",
      "\n",
      "         [[ 0.1169]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 160, 1, 1])\n",
      "\n",
      "Layer: features.16.conv.0.1.weight\n",
      "Weights: tensor([0.4779, 1.3182, 1.1399, 1.1358, 0.6078, 0.8985, 0.3980, 1.2337, 1.1414,\n",
      "        1.2004, 0.8836, 1.1211, 1.2230, 1.4693, 0.8749, 0.4156, 0.5872, 0.6708,\n",
      "        0.9666, 0.8279, 0.7847, 1.2694, 0.3650, 0.6075, 0.9984, 1.1235, 2.0898,\n",
      "        0.9432, 1.4150, 0.5402, 0.3980, 1.0005, 1.1787, 0.8954, 0.9401, 0.3219,\n",
      "        1.0609, 1.0784, 1.0981, 1.2487, 0.8108, 0.8585, 1.1979, 0.4768, 1.1445,\n",
      "        1.0446, 1.0187, 1.2716, 1.1317, 1.1327, 1.1274, 1.2589, 0.8930, 0.7290,\n",
      "        0.5141, 1.2661, 1.1446, 0.5550, 1.1548, 1.2236, 1.2897, 1.2425, 1.3018,\n",
      "        0.3614, 1.1342, 1.2097, 0.7189, 0.5548, 0.9257, 1.3845, 1.3413, 0.4226,\n",
      "        1.1035, 1.2076, 1.0921, 0.9491, 0.6037, 1.3752, 0.4843, 0.5507, 0.5161,\n",
      "        0.5624, 0.7736, 1.2049, 0.6214, 1.6103, 0.3731, 0.6852, 1.2173, 0.7676,\n",
      "        0.9115, 0.7257, 0.9939, 0.6186, 0.4736, 1.2583, 1.1289, 1.0671, 0.6869,\n",
      "        1.1864, 0.4450, 0.9542, 0.4524, 1.1265, 0.4565, 0.9870, 1.2112, 1.2261,\n",
      "        1.1196, 1.1305, 1.0517, 0.8598, 0.9979, 1.0125, 1.0934, 1.0992, 0.8366,\n",
      "        1.1286, 1.2107, 0.9648, 1.1101, 1.2716, 0.4305, 1.0062, 0.7932, 0.5333,\n",
      "        0.5062, 1.1655, 1.2739, 2.1918, 0.8251, 0.8012, 0.4658, 0.5503, 1.3452,\n",
      "        1.1551, 1.2800, 1.1531, 1.2868, 1.1788, 0.3737, 1.0834, 2.0130, 1.3722,\n",
      "        0.6906, 1.0759, 0.5134, 0.8629, 1.2366, 0.3354, 1.7572, 1.2840, 0.9297,\n",
      "        1.0390, 0.4699, 1.3364, 1.0300, 0.9555, 1.2195, 1.1524, 1.1426, 0.4255,\n",
      "        1.0279, 1.1190, 1.1091, 1.5757, 0.6616, 1.3170, 1.1710, 0.5282, 0.9286,\n",
      "        1.1597, 0.2741, 0.9254, 0.8057, 1.1262, 1.1436, 0.4567, 1.3714, 1.0793,\n",
      "        0.5839, 1.0720, 0.4478, 1.0732, 1.3314, 0.8490, 1.0237, 1.2351, 0.9828,\n",
      "        1.0302, 1.0787, 1.1937, 0.4954, 1.2696, 1.4471, 0.9913, 0.5336, 1.2519,\n",
      "        1.3569, 1.0635, 1.0700, 1.3331, 1.0757, 1.0155, 1.8776, 1.2193, 2.9230,\n",
      "        1.0792, 0.9018, 1.2069, 0.7790, 0.5128, 1.7891, 1.4599, 1.1281, 0.9520,\n",
      "        0.4990, 0.9986, 0.8263, 1.0693, 0.4939, 1.1007, 0.7643, 0.5709, 1.0559,\n",
      "        0.6808, 2.1853, 1.2741, 0.9788, 1.0689, 1.2145, 0.7916, 1.1183, 1.4411,\n",
      "        1.0651, 1.4168, 0.4063, 0.7982, 0.4226, 1.0048, 1.2919, 0.6127, 0.4655,\n",
      "        0.9268, 1.2922, 0.7815, 0.7927, 1.1542, 1.0218, 1.0065, 1.1150, 1.1799,\n",
      "        1.0133, 1.6437, 1.0968, 1.1707, 1.1292, 1.2781, 1.0672, 1.1578, 0.6255,\n",
      "        1.1115, 1.0751, 1.1265, 0.5407, 1.0078, 0.8306, 1.3658, 2.6768, 1.0623,\n",
      "        1.2211, 0.9956, 0.8919, 1.4235, 1.2548, 1.0986, 1.1181, 0.2884, 1.0317,\n",
      "        0.4074, 0.4221, 1.3611, 2.8940, 0.7973, 1.2268, 0.8204, 0.9590, 0.5024,\n",
      "        1.1508, 1.4320, 0.4530, 0.4915, 0.4030, 1.5532, 0.7214, 1.1289, 0.7660,\n",
      "        1.3406, 1.0638, 0.7725, 1.0655, 1.0587, 1.7213, 0.5136, 1.0256, 1.1064,\n",
      "        1.0478, 0.5787, 1.2281, 0.9276, 0.9606, 0.8940, 1.0516, 0.3259, 0.9658,\n",
      "        1.1520, 1.3205, 1.6178, 0.8517, 1.1486, 0.9798, 0.9498, 1.0520, 1.1404,\n",
      "        1.2055, 1.7736, 1.0090, 1.1433, 0.6163, 0.9522, 0.4089, 0.9851, 0.7643,\n",
      "        1.1532, 0.9965, 0.9778, 1.2259, 1.1181, 0.8907, 0.9553, 1.4024, 1.2796,\n",
      "        1.0634, 1.0895, 1.1538, 0.6324, 0.5577, 0.4595, 1.0811, 0.4546, 1.1902,\n",
      "        1.0877, 1.0416, 0.9904, 1.1216, 0.4673, 1.1877, 0.9097, 1.1000, 1.2011,\n",
      "        1.1650, 0.8406, 1.2320, 1.1046, 1.0075, 1.2365, 1.1713, 1.0229, 1.3013,\n",
      "        1.0720, 0.9008, 1.0419, 0.4817, 0.8373, 1.1354, 1.6970, 1.2443, 0.3309,\n",
      "        1.1530, 0.4406, 0.3575, 0.9190, 2.1571, 1.1016, 1.0930, 1.7113, 0.9277,\n",
      "        0.4006, 0.9277, 1.1847, 0.8938, 1.1702, 1.8253, 1.0364, 0.6015, 1.2097,\n",
      "        1.3124, 1.1528, 1.5165, 1.2044, 0.8822, 1.1705, 1.1080, 0.9953, 0.6784,\n",
      "        1.1946, 1.2702, 1.4993, 0.7091, 1.1578, 0.7233, 1.3525, 1.1749, 0.7136,\n",
      "        1.5658, 0.5704, 0.9979, 1.0292, 1.7009, 0.4668, 1.0075, 1.3481, 1.4127,\n",
      "        1.0351, 0.8314, 0.7512, 0.3818, 1.2399, 0.5021, 0.9705, 1.1815, 0.8077,\n",
      "        1.0730, 0.4484, 1.0656, 1.1617, 1.1535, 1.0484, 1.0604, 1.0953, 1.1222,\n",
      "        0.3617, 1.1043, 1.0637, 1.1055, 0.8870, 1.0733, 0.8328, 1.1464, 1.2169,\n",
      "        0.9380, 1.0517, 0.5496, 1.1996, 0.4371, 0.9819, 0.7533, 1.1348, 1.1960,\n",
      "        0.4952, 0.4839, 0.4696, 1.2378, 0.7728, 2.0430, 0.3541, 0.9389, 0.6116,\n",
      "        1.1614, 1.0910, 0.7170, 1.2289, 1.4280, 1.2033, 1.2377, 1.1788, 0.9992,\n",
      "        1.0623, 1.0829, 1.1265, 1.1920, 0.8766, 1.0068, 1.2680, 0.8908, 0.9196,\n",
      "        1.1504, 1.0934, 1.1535, 1.5143, 1.1532, 0.4738, 0.5980, 1.3443, 1.1016,\n",
      "        0.4631, 1.1228, 1.2788, 0.9972, 1.0600, 1.1794, 0.9713, 0.8974, 1.2612,\n",
      "        1.0953, 0.7686, 0.6159, 2.0851, 1.1496, 1.0956, 0.4548, 1.1498, 1.0489,\n",
      "        1.0508, 0.9323, 0.6992, 1.1339, 1.0337, 1.0338, 0.9431, 1.4019, 0.7463,\n",
      "        1.2125, 1.0208, 0.9677, 0.9665, 1.1854, 0.7044, 0.8908, 1.0015, 1.1403,\n",
      "        1.1714, 1.2396, 0.8160, 1.5195, 1.2546, 0.8292, 1.0235, 0.3911, 0.9016,\n",
      "        0.9523, 1.1321, 1.0153, 0.8417, 0.8743, 1.1226, 1.0840, 0.8425, 0.8553,\n",
      "        1.1454, 1.5530, 1.1494, 2.2321, 0.9932, 0.7010, 1.1331, 0.9415, 1.1730,\n",
      "        0.4656, 1.0610, 1.0141, 1.0124, 0.9923, 1.0585, 1.1980, 1.1274, 1.0305,\n",
      "        1.0301, 1.0231, 1.1404, 1.3447, 0.9455, 0.4656, 1.0646, 1.3212, 0.6351,\n",
      "        1.2876, 0.9117, 1.1867, 0.7472, 0.9605, 1.0931, 1.3958, 1.1946, 1.2857,\n",
      "        0.9998, 0.9240, 2.0681, 1.6266, 1.1743, 0.8768, 0.9806, 0.5403, 1.0468,\n",
      "        0.7636, 0.6957, 1.1709, 0.3121, 1.0623, 0.3708, 0.8847, 1.2705, 0.9210,\n",
      "        0.8829, 0.3377, 0.9868, 1.2499, 1.6807, 1.2726, 0.4293, 1.0781, 1.3587,\n",
      "        1.0494, 1.0281, 0.8512, 1.0478, 1.0342, 0.5192, 0.9883, 1.0336, 0.5270,\n",
      "        1.1072, 0.7338, 0.5274, 1.4036, 1.0387, 1.0072, 1.0112, 1.0735, 1.1058,\n",
      "        0.8827, 1.2159, 1.0497, 1.1883, 0.9500, 0.8838, 1.1779, 0.5925, 1.1148,\n",
      "        0.8049, 0.4664, 0.7269, 1.1260, 0.8480, 1.2656, 1.0230, 1.0351, 1.1495,\n",
      "        1.0876, 1.0175, 0.8920, 1.3280, 1.1471, 1.1569, 0.7615, 1.2784, 0.6988,\n",
      "        0.5433, 0.9583, 0.9348, 0.3394, 0.8672, 0.8852, 0.9710, 1.0926, 0.9614,\n",
      "        0.7228, 1.4800, 0.9545, 1.1043, 1.0417, 1.1869, 0.3554, 1.0475, 0.8996,\n",
      "        1.0658, 1.0012, 1.4675, 1.1206, 1.3246, 1.2878, 1.1333, 0.9898, 1.1138,\n",
      "        0.4715, 0.8897, 1.0040, 0.9821, 1.0428, 2.1757, 1.0629, 1.0151, 1.1784,\n",
      "        1.2953, 1.0160, 1.2181, 1.2133, 1.3984, 0.9272, 1.0154, 1.9489, 1.0472,\n",
      "        1.2327, 1.1597, 1.1309, 1.0366, 1.2346, 1.0887, 1.1240, 1.0099, 1.7490,\n",
      "        1.0187, 1.1774, 1.0285, 0.9054, 1.0534, 1.1234, 0.9817, 1.2269, 1.2206,\n",
      "        1.1104, 0.4353, 1.1481, 0.7875, 1.1467, 1.1295, 1.0169, 0.9853, 0.3378,\n",
      "        0.9272, 0.7992, 0.9514, 1.1891, 1.0885, 0.3990, 0.8655, 0.9743, 0.9222,\n",
      "        0.7150, 1.1933, 1.0288, 1.4334, 1.1989, 1.1690, 1.0700, 1.1255, 0.7672,\n",
      "        1.2982, 0.5764, 0.3965, 0.6852, 0.9557, 1.1180, 1.1998, 1.1007, 1.0967,\n",
      "        0.3799, 1.3664, 1.2441, 1.1269, 1.1058, 1.1065, 0.9309, 1.1792, 0.4352,\n",
      "        0.6679, 1.0675, 1.0428, 1.2175, 0.5088, 1.1177, 1.0357, 0.9168, 0.5232,\n",
      "        1.1103, 1.1158, 0.9746, 1.3920, 0.5762, 1.1561, 0.9448, 0.5806, 1.1424,\n",
      "        0.3924, 1.1273, 0.6964, 1.1505, 0.9264, 1.0849, 1.1576, 1.0318, 0.9264,\n",
      "        0.3758, 0.9584, 0.7590, 1.2049, 1.1293, 1.2957, 1.4700, 1.1020, 1.0827,\n",
      "        1.1313, 0.3386, 2.0246, 1.8259, 0.9630, 0.9879, 1.1682, 1.4908, 0.9274,\n",
      "        1.0432, 1.5031, 0.9635, 0.9033, 1.0019, 1.0393, 0.4454, 1.0457, 1.1037,\n",
      "        1.0164, 0.5293, 0.9330, 1.1173, 1.2367, 0.4661, 1.2051, 1.1779, 0.9849,\n",
      "        1.0432, 0.8659, 0.9682, 0.9672, 1.6265, 1.1207, 0.8449, 0.4131, 0.8343,\n",
      "        1.0352, 0.5912, 1.3110, 1.0714, 0.6043, 0.8795, 1.0543, 1.1158, 0.9190,\n",
      "        0.8003, 0.7100, 1.1119, 0.9163, 1.1404, 1.1437, 2.7286, 1.1553, 1.2087,\n",
      "        1.4879, 1.2475, 1.0094, 1.0284, 0.8368, 1.2197, 1.6030, 0.4655, 0.9342,\n",
      "        1.2740, 1.3147, 1.1390, 0.7885, 0.6380, 0.9756, 0.9620, 0.7294, 1.0515,\n",
      "        0.9678, 1.1611, 1.0106, 1.0945, 1.5068, 0.4638, 1.0732, 1.0620, 0.9474,\n",
      "        1.0021, 1.1078, 0.5706, 0.5867, 0.7163, 0.9600, 1.0624, 0.9668, 0.6330,\n",
      "        0.9720, 1.2511, 0.8303, 0.6984, 1.2239, 1.1190, 2.3352, 0.6905, 1.1480,\n",
      "        0.5445, 1.2089, 0.8772, 1.0076, 1.4128, 0.8794, 0.8658, 0.8041, 1.1208,\n",
      "        1.2031, 1.3455, 1.0741, 0.8070, 1.2188, 1.6700, 1.1909, 1.0544, 1.0084,\n",
      "        1.9537, 1.0861, 0.8364, 1.0275, 1.0678, 0.9863, 1.3593, 0.9643, 1.1331,\n",
      "        1.0667, 1.1501, 0.4306, 0.4416, 1.1448, 1.2427, 0.3970, 1.1823, 1.1207,\n",
      "        0.9112, 1.2715, 0.5886, 1.1110, 1.1540, 0.3809, 0.7176, 0.6656, 1.1003,\n",
      "        1.0452, 1.1996, 0.8798, 0.4368, 1.1534, 0.4451, 0.9807, 0.9349, 0.7816,\n",
      "        0.9444, 1.2987, 0.8133, 0.9596, 1.2454, 0.4950], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.0.1.bias\n",
      "Weights: tensor([ 1.6163, -0.0819,  0.0453, -0.8166,  1.5654,  0.8091,  1.5387, -0.1255,\n",
      "        -0.2437, -0.3431,  0.3251,  0.1045, -0.5733,  0.2115,  0.7856,  1.4833,\n",
      "         1.1114,  1.8012, -0.9852, -1.5820,  0.9434, -0.4790,  1.4331,  1.8070,\n",
      "        -0.8138, -0.2914,  0.1542,  0.4896, -0.4511,  1.0723,  1.2604, -0.6572,\n",
      "        -0.3705, -1.3226,  0.6356,  1.2498, -0.0495, -1.2252,  0.6189,  0.0301,\n",
      "         0.8201,  0.1040, -0.4055,  1.5747,  0.0694, -0.4779,  0.7363,  0.0960,\n",
      "        -0.2450,  0.3026, -0.7878, -0.6211,  0.9337,  0.9159,  1.5431, -0.2251,\n",
      "        -0.9401,  1.4758,  0.0032, -0.4945, -1.2176, -0.4192, -0.3916,  1.4319,\n",
      "        -0.2774, -0.5501,  0.9912,  1.6041,  0.8305, -1.6202,  0.5999,  1.4374,\n",
      "        -0.9630, -0.0580, -0.8052,  1.1875,  1.0620,  0.0690,  1.1314,  1.1430,\n",
      "         1.4298,  1.1095,  1.5662,  0.1606,  1.5859, -0.4805,  1.3969,  0.8796,\n",
      "         0.4699,  0.8366,  0.0840,  1.1703, -0.3104,  1.9513,  1.2202, -0.2515,\n",
      "         0.2456, -1.2262,  0.5608, -0.7929,  1.6738,  0.4710,  1.6856, -0.2247,\n",
      "         1.2943, -0.3640, -0.4350,  0.2039, -0.9151,  0.0974,  0.4497,  0.7072,\n",
      "        -0.6647, -0.2382,  0.1185, -0.4348,  0.8643, -0.6414,  0.1182,  0.2810,\n",
      "         0.1655, -0.5807,  1.2326,  0.5965,  1.5175,  1.1934,  1.5696, -0.0899,\n",
      "         0.3862, -2.0583, -0.2133,  0.2517,  1.3651,  1.3428, -0.5395, -0.7243,\n",
      "        -0.5714, -1.0177, -0.5014, -0.6696,  1.4410, -1.1690, -1.1121, -0.6943,\n",
      "         0.9523, -0.9217,  1.1502, -1.2896, -0.7499,  1.2751, -0.8007, -1.4026,\n",
      "         0.0843, -0.2405,  1.7098, -1.2435,  0.2378,  0.2737, -0.2518, -0.7704,\n",
      "        -0.1167,  1.4732,  0.2586,  0.0846,  3.1313, -0.0427, -1.4840, -0.4560,\n",
      "         0.1043,  1.3363, -0.5102, -0.3331,  1.4894, -0.2681,  1.1766, -1.4064,\n",
      "        -0.7179,  1.4918,  0.0336,  0.5504,  0.9977, -0.7710,  1.8896,  0.3290,\n",
      "        -0.2239, -0.7063, -1.2416,  0.0822, -0.1670, -0.1011, -0.6546, -0.8441,\n",
      "         1.2375, -0.9117,  0.3331, -0.2592,  1.5598, -1.1012, -0.3694, -0.2837,\n",
      "        -0.3764, -0.7623, -0.5873, -0.2319, -1.3990, -0.8700, -0.7176, -1.2409,\n",
      "        -0.2366, -0.0282,  0.8956,  1.1614, -0.0048, -0.6294, -1.4728,  0.0031,\n",
      "         1.1418,  0.0620,  0.6898, -0.4689,  1.9488, -0.9402, -0.9908,  1.0776,\n",
      "        -0.7878,  1.4506,  0.2762, -1.1857,  0.1044, -1.6561, -0.4258,  0.8835,\n",
      "        -0.1760, -2.1047,  0.4376, -0.6936,  1.3657,  1.1740,  1.2833, -0.5161,\n",
      "        -0.1962,  1.8895,  1.6273, -0.6522, -0.7736,  0.9549, -0.1459, -0.2308,\n",
      "        -1.0283, -1.0922,  0.4923, -0.8989, -0.2253, -0.5267, -1.2155, -0.1664,\n",
      "        -0.7948, -0.4300,  0.2994,  0.1042,  1.1962,  0.5704, -0.3719, -0.6585,\n",
      "         1.7359, -0.1108,  0.8646, -0.3405, -0.0626, -0.3119, -1.0314, -0.0464,\n",
      "         0.7207, -1.5098, -0.0751, -0.5546, -0.5143,  1.4908, -1.2021,  1.3740,\n",
      "         1.5853, -0.4512, -1.3664, -0.1448,  0.2190,  0.1067,  0.3247,  2.0359,\n",
      "        -0.8039,  0.7062,  1.5076,  1.2855,  1.3673, -1.5344,  1.0847, -0.0119,\n",
      "         0.7912, -1.0450, -1.3588,  0.9204, -0.2919,  0.5432,  0.6344,  1.4354,\n",
      "         0.5666, -0.2495, -0.5365,  1.2063, -0.2062,  0.2606, -0.7547,  1.3695,\n",
      "        -0.0811,  1.3325,  0.3411, -0.1062,  0.1320, -1.4253,  0.2416, -0.6629,\n",
      "         0.0540, -0.7635, -1.0526,  0.2492,  0.0782, -0.7671, -0.1585, -0.4996,\n",
      "         2.2518,  0.2198,  1.5232,  0.2299,  1.0291,  0.1536, -0.7631, -0.1554,\n",
      "        -0.9514, -0.3663,  0.8058, -0.5875, -0.4322, -0.2454, -0.8145, -1.5520,\n",
      "         0.1824,  1.0273,  1.4149,  1.0660, -0.4098,  1.3930, -0.4355,  0.5074,\n",
      "        -0.9695,  0.0122, -0.5999,  1.5066, -0.4423,  0.4764, -0.7625, -0.5984,\n",
      "        -0.9250,  1.3469, -0.2036, -0.3242,  0.3438, -0.1516, -0.2440,  0.5689,\n",
      "        -0.0688,  0.5006,  0.2629, -0.3955,  1.4264,  0.1127, -0.0106, -1.4787,\n",
      "         0.2524,  1.5152, -1.6139,  1.1780,  1.2619, -0.1671, -1.2192, -0.1159,\n",
      "        -0.2670, -1.0352,  0.8055,  1.6372,  0.0338, -0.0346, -0.0883, -0.3997,\n",
      "         0.0893, -0.1025,  1.4426, -0.6336, -0.7714,  0.0699, -1.2389, -1.1750,\n",
      "        -1.5103, -0.0658, -1.2080, -0.1825,  1.0157, -0.4633, -0.3998, -0.9807,\n",
      "         0.1651, -0.4169,  1.4147, -0.4015, -0.1725,  1.1313, -0.2061,  1.5602,\n",
      "         0.1460, -0.1497, -0.6424,  1.5693, -0.5487, -0.9633, -0.2653, -1.2613,\n",
      "        -0.0437,  0.8967,  1.4649, -0.5602,  1.6336, -0.8789, -0.1454, -1.2999,\n",
      "        -0.4107,  1.8670, -0.9041, -0.1706, -1.4048, -0.7355, -0.0933, -0.6492,\n",
      "        -0.8920,  1.6382, -0.4663, -0.3869, -0.0946, -0.3343,  0.0063,  0.8447,\n",
      "        -0.0991, -0.3138,  0.3072,  0.4260,  1.0626,  1.1005,  1.5258,  0.6224,\n",
      "         1.0707, -0.2325, -0.1849,  1.1417,  1.5275,  1.2340, -0.2466,  0.9535,\n",
      "        -1.5864,  1.7937, -0.0884,  0.9827,  0.2903, -1.1652,  0.9095, -0.6660,\n",
      "         0.8776, -0.2040, -0.1456, -0.7172,  0.0487, -0.1010,  0.0554, -0.4741,\n",
      "        -0.1559, -0.2778,  0.3664, -0.0933,  0.4380,  0.0663,  0.3212,  1.0615,\n",
      "         0.2980,  1.2125,  0.1584,  1.0629,  1.2610, -0.3047, -0.7056,  1.6580,\n",
      "         0.1564, -1.5370,  1.3402, -0.3713, -0.5371,  1.3356,  0.1173, -0.2179,\n",
      "         0.3242,  0.9654,  1.5936, -0.4234,  0.2571, -0.2166,  1.7707,  0.0625,\n",
      "        -0.3231, -1.4263,  0.0988,  2.1728, -1.1379, -0.1653, -0.6385, -0.3295,\n",
      "         0.2650,  1.0226, -0.7945, -1.4660, -0.2647, -0.6442, -1.5298,  1.4176,\n",
      "         0.1001,  0.1821,  0.3485, -0.4879,  0.2191,  0.9118, -0.0058, -0.2026,\n",
      "        -1.0459, -0.2265,  1.4180, -0.2542, -0.0307,  0.0114,  0.0173,  0.9268,\n",
      "         0.0432, -1.1151, -0.7554,  1.1240,  1.3393, -0.3840, -0.8974, -0.2229,\n",
      "        -0.8614,  0.0190,  1.0399, -0.4464,  0.1092, -0.7214,  1.0522, -0.5912,\n",
      "        -0.4137, -1.0599,  0.0737,  0.4001,  0.1057,  1.0850,  0.6086, -0.7679,\n",
      "         0.3461, -0.4192, -0.6128, -0.3495,  1.1279, -0.8766,  0.0366,  1.3318,\n",
      "        -0.5299,  0.4977, -0.2896,  0.9060, -0.5839,  0.2341, -0.2696, -0.0333,\n",
      "        -0.2171,  0.1047,  0.2419,  0.4809,  2.8383, -0.3753, -1.1279,  1.2129,\n",
      "         0.7800,  0.8244,  1.4772,  1.2012, -0.2075,  1.5492, -0.0877,  1.2009,\n",
      "         0.0192, -0.2204, -0.6697, -0.4385,  1.4975, -1.2303,  0.1472, -1.2972,\n",
      "        -0.4764,  1.2570,  0.3360, -1.1030, -0.1436, -0.0929,  1.3717,  0.7217,\n",
      "        -0.1811,  1.3528, -1.0382, -0.5932,  1.5596, -0.1594,  0.9649,  1.1714,\n",
      "        -0.3824, -0.2418, -0.6948, -0.7040, -0.6260, -0.5197,  0.8848, -0.7367,\n",
      "         0.4215,  0.2357, -1.0881,  0.3532, -0.0178,  1.1590, -0.6735,  0.9160,\n",
      "         1.4451,  1.0594,  0.3398,  0.6982, -0.5155, -0.7625, -0.2771, -0.2095,\n",
      "         0.3695, -0.8912, -0.0798, -0.3761, -0.6965, -0.0375,  0.8905, -0.3003,\n",
      "        -0.3761,  1.5513,  0.2032, -1.9060,  1.4399, -0.9672, -0.7354, -0.4080,\n",
      "        -0.0074,  0.7384,  0.9086, -0.4033, -0.6997, -0.3539, -1.0290, -0.2118,\n",
      "         1.5533, -1.3463, -0.0803,  1.1365, -0.9844, -0.7246, -0.3989, -1.1225,\n",
      "        -0.7013, -1.1126, -0.8310, -0.6855,  1.5720,  1.1343, -0.4168, -0.7226,\n",
      "        -0.0796, -1.4813, -1.0633, -0.8722,  0.0272, -0.6865,  1.6257, -1.2002,\n",
      "        -0.3972, -0.3041,  0.7312,  0.6334, -0.3338, -0.5597, -1.1272, -0.8866,\n",
      "        -0.4133,  0.7716,  0.3195, -0.4645, -0.2327,  0.6117, -0.5676, -0.7403,\n",
      "        -0.8290, -0.1377, -0.3106,  0.4595,  0.0580,  1.3019,  0.1158, -0.2187,\n",
      "        -0.2386,  1.4109,  0.2544,  1.2755, -0.2534,  0.1841, -0.5649,  0.8122,\n",
      "         1.4786,  1.1907,  0.7337, -0.5861, -0.4552, -0.3872,  1.5983,  0.0575,\n",
      "        -1.1681,  0.7546,  1.3397,  0.2857,  0.0129, -0.2961, -0.1768,  0.2142,\n",
      "        -0.4310, -0.6496,  0.9538, -0.9942,  1.7093,  1.7438,  0.8923,  0.4178,\n",
      "        -0.6317, -0.1072,  0.0441, -0.3335,  1.5694, -0.5095, -0.0919,  0.0090,\n",
      "        -0.0178, -0.0981,  0.2801, -0.8367,  1.5724,  0.7839, -0.6607, -0.7569,\n",
      "        -0.4657,  1.4708,  0.1203,  0.0780, -0.3794,  1.0937, -0.3614,  1.8005,\n",
      "        -0.5493, -1.3248,  1.4480, -0.3726,  0.6304,  1.6496, -1.0894,  1.2930,\n",
      "        -0.6285,  2.0177, -0.5641,  0.8223, -1.5559, -0.3537, -0.7932,  1.0351,\n",
      "         1.6397,  0.4508,  0.1583, -0.3141,  0.1325, -0.6868, -0.0156, -0.7837,\n",
      "         0.7432,  0.7911,  1.2373, -0.7295, -0.7833,  0.3127,  0.2112,  0.2934,\n",
      "        -0.0603,  1.1974,  0.2305,  0.1234, -0.5857,  0.7826,  0.0351,  0.2379,\n",
      "         1.2191,  0.6129,  0.5964,  0.5901,  1.1997,  0.6073, -0.5970, -0.2248,\n",
      "         1.2728,  0.1867, -0.3525,  0.0821,  0.4628,  0.8403, -1.0166,  0.1623,\n",
      "         0.1550, -0.5908,  1.1216,  1.3180, -0.0048, -0.4748,  1.4593, -0.9600,\n",
      "        -0.2116,  1.5260, -1.0583, -0.2036, -1.5837, -0.5280,  0.8042,  0.4265,\n",
      "        -0.8129,  0.8337, -2.2206, -0.2384, -0.6319, -0.3213, -0.1936, -0.8007,\n",
      "        -0.4418, -0.2037,  0.1147,  0.2814, -0.8441, -0.6969,  1.3081,  0.8556,\n",
      "        -0.3912,  0.0034,  0.1537,  1.3592,  0.9981, -0.1208, -1.3246, -2.1098,\n",
      "         0.0529,  0.3600,  0.3433,  0.1083,  0.5428,  0.2848,  1.8904, -1.7153,\n",
      "        -1.1757, -0.1808,  0.0085, -0.1440,  1.8542,  1.0831,  0.5081,  0.1895,\n",
      "         0.7442,  1.0106,  1.2944,  0.4996, -0.3796,  0.1440,  0.9379, -0.5580,\n",
      "         0.1634,  0.6368,  1.3699,  0.0518,  1.3747, -0.0706, -0.7155, -1.3630,\n",
      "        -0.3568,  0.1230,  0.8301,  2.0487,  0.2467, -0.0140,  0.4514, -0.3975,\n",
      "         0.9736,  0.3082, -0.6807, -0.1539, -0.4357,  0.1773, -0.6362, -0.4392,\n",
      "         1.2141, -0.2608, -0.2690,  0.1437,  0.6583,  0.3223,  0.2669, -0.6191,\n",
      "        -1.4324,  1.3166,  1.2256, -1.2668, -0.9815,  1.0828, -0.3688, -0.5047,\n",
      "        -1.3181, -1.3698,  1.6394, -0.4587, -1.1347,  1.3563,  0.9485,  1.3372,\n",
      "         0.4443, -0.1807, -0.2735,  0.9412,  1.3368, -0.5589,  1.3693, -1.3280,\n",
      "        -0.7487,  0.8100,  0.6251, -0.6755,  1.5288, -0.0524, -0.3208,  1.6337],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.1.0.weight\n",
      "Weights: tensor([[[[-4.1363e-02, -1.3195e-01, -4.5281e-02],\n",
      "          [-1.2346e-01, -2.0437e-01, -1.2630e-01],\n",
      "          [-5.0178e-02, -1.2943e-01, -3.5875e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.6544e-02,  1.1429e-01,  7.0258e-02],\n",
      "          [ 9.5012e-02,  2.1150e-01,  9.1723e-02],\n",
      "          [ 5.9869e-02,  1.0497e-01,  6.1298e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3532e-02, -1.1209e-01,  5.4078e-02],\n",
      "          [ 6.0083e-02, -2.4694e-01,  5.9567e-02],\n",
      "          [ 1.3475e-01,  7.1601e-02,  1.3472e-01]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.9753e-03, -6.5354e-02, -2.0659e-04],\n",
      "          [ 9.8032e-02, -7.6449e-02,  9.2812e-02],\n",
      "          [ 7.2093e-02,  2.1133e-01,  6.9919e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6794e-03,  1.8180e-02, -6.2801e-04],\n",
      "          [ 3.5133e-02,  3.4593e-01,  4.4540e-02],\n",
      "          [ 4.6515e-03,  2.1074e-02, -1.5895e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.5187e-02, -5.4358e-02, -3.8957e-02],\n",
      "          [-2.4544e-02, -3.2909e-01, -3.2197e-02],\n",
      "          [-2.7611e-02, -4.4227e-02, -2.3760e-02]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 1, 3, 3])\n",
      "\n",
      "Layer: features.16.conv.1.1.weight\n",
      "Weights: tensor([ 1.7071,  1.5717,  0.4975,  0.7091,  1.8164,  0.6050,  1.2321,  0.7936,\n",
      "         0.4376,  0.8503,  0.9153,  0.7931,  1.0560,  0.9002,  0.7333,  1.3895,\n",
      "         0.6751,  3.2077,  0.2021,  0.3051,  0.6225,  0.2777,  0.9488,  2.9465,\n",
      "         0.2306,  1.4310,  6.2203,  1.9656,  0.4634,  0.9435,  0.6919,  0.9751,\n",
      "         0.9003,  0.2600,  0.7153,  1.2509,  1.1251,  0.2052,  1.1181,  0.4029,\n",
      "         0.4156,  0.8850,  0.3823,  1.5161,  0.7898,  0.7099,  0.3903,  0.9087,\n",
      "         0.9846,  0.5547,  0.3279,  0.9124,  0.3590,  0.8674,  1.0979,  0.7597,\n",
      "         0.1977,  0.6267,  0.4834,  0.7536,  0.8856,  0.5176,  1.6318,  1.3166,\n",
      "         0.2648,  0.9291,  0.5013,  1.1717,  0.4836,  0.3205,  0.8441,  0.9385,\n",
      "         0.5800,  0.3091,  0.2456,  0.9600,  0.6840,  0.6784,  0.5581,  1.2191,\n",
      "         1.5058,  0.9080,  1.6408,  0.3424,  1.8270,  1.1479,  1.1610,  0.6360,\n",
      "         1.5346,  0.9981,  1.6242,  0.3582,  1.2085,  1.6803,  0.5609,  1.2194,\n",
      "         0.3420,  0.2326,  0.8250,  0.2391,  1.2709,  1.1933,  1.4963,  1.1496,\n",
      "         1.9635,  0.7701,  0.3158,  1.2971,  0.2412,  3.1152,  0.7522,  0.6683,\n",
      "         0.9460,  1.2747,  1.5042,  0.4327,  0.9490,  0.2088,  1.8902,  0.8729,\n",
      "         0.3464,  0.8349,  0.5925,  0.5677,  1.6645,  0.4144,  1.1199,  0.8102,\n",
      "         0.7746, 11.6891,  1.2331,  0.8560,  0.6511,  2.1531,  1.1384,  0.3069,\n",
      "         0.8784,  0.2436,  1.1423,  0.6866,  1.1982,  0.2072,  0.7121,  2.6437,\n",
      "         0.7894,  0.2339,  1.2068,  0.2380,  0.9226,  0.8309,  0.9093,  0.8270,\n",
      "         0.6925,  0.5036,  1.0293,  0.2144,  0.8292,  1.5255,  0.2633,  0.3093,\n",
      "         0.7944,  1.5715,  1.7330,  0.2463,  3.7406,  0.6606,  0.3602,  1.1041,\n",
      "         0.6947,  0.7107,  0.7048,  0.2603,  1.2618,  0.4445,  0.4701,  0.2896,\n",
      "         0.7500,  1.4072,  0.8316,  0.5464,  1.0291,  0.5358,  1.6445,  0.9348,\n",
      "         1.2896,  0.3690,  0.2579,  0.8942,  0.8417,  1.4697,  0.2866,  0.1826,\n",
      "         1.3928,  0.2539,  0.3535,  1.2796,  1.4897,  0.1786,  0.6275,  0.6711,\n",
      "         0.6684,  0.3174,  0.3303,  1.3975,  4.6843,  0.2389,  0.3186,  0.2138,\n",
      "         1.2915,  1.3311,  0.3455,  0.6968,  0.3557,  3.4576,  0.1946,  1.1763,\n",
      "         0.5707,  1.0202,  0.9815,  0.3059,  1.9665,  0.2893,  0.2931,  0.8599,\n",
      "         0.2361,  2.2902,  5.5631,  0.1826,  0.3296,  0.2396,  0.8583,  1.4691,\n",
      "         0.3075,  0.2924,  0.6155,  2.6420,  1.0047,  1.6574,  0.6883,  0.5320,\n",
      "         0.3140,  1.6534,  1.1904,  0.2507,  0.9332,  0.5594,  0.7403,  0.8438,\n",
      "         0.2476,  0.2767,  0.7674,  0.2854,  0.7737,  2.5735,  0.1711,  0.5557,\n",
      "         0.2890,  1.2385,  0.7596,  1.6398,  1.2150,  2.3387,  0.6275,  0.8212,\n",
      "         1.4285,  1.0784,  0.6330,  0.9273,  8.6420,  1.1580,  3.0701,  1.6918,\n",
      "         0.5932,  0.3419,  0.6467,  1.1847,  0.6508,  1.1451,  0.2138,  1.2106,\n",
      "         1.7541,  0.3759,  4.3086,  1.5874,  0.7448,  1.0956,  0.5239,  1.3261,\n",
      "         0.3881,  0.3860,  1.2119,  1.2750,  1.2821,  0.3252,  1.2680,  1.0028,\n",
      "         0.7155,  0.2454,  0.5831,  0.5672,  1.2247,  0.6462,  0.6470,  1.5372,\n",
      "         1.5814,  0.8506,  0.4833,  0.4540,  1.1335,  1.4155,  0.9402,  0.5300,\n",
      "         0.3529,  0.9849,  1.7009,  0.8030,  0.3380,  3.9186,  1.8091,  0.7515,\n",
      "         1.1230,  0.4060,  0.2232,  0.5297,  0.3056,  3.7899,  0.8064,  0.5154,\n",
      "         3.0860,  1.6273,  1.1403,  0.7720,  1.1898,  0.5000,  0.4317,  0.9033,\n",
      "         0.3170,  1.0092,  1.3291,  0.9192,  0.8698,  0.9735,  0.7321,  0.1377,\n",
      "         0.3469,  0.8683,  1.1462,  0.4578,  0.7148,  0.7900,  0.3158,  0.4072,\n",
      "         0.2906,  1.1300,  0.3808,  1.0371,  1.2390,  2.1465,  0.8478,  1.0323,\n",
      "         0.8447,  1.1828,  1.1709,  1.5679,  1.7415,  0.3264,  0.8932,  0.7014,\n",
      "         0.9482,  0.9132,  0.7986,  0.9222,  0.8569,  1.0773,  0.6867,  0.3599,\n",
      "         0.3427,  0.8813,  3.8509,  1.2221,  0.8056,  0.9337,  4.2985,  0.6649,\n",
      "         0.7994,  0.4121,  0.6189,  1.3851,  1.1401,  0.8845,  0.8514,  0.1861,\n",
      "         1.5038,  0.8670,  1.8252,  0.2494,  3.2648,  0.7952,  0.1982,  0.1824,\n",
      "         0.2356,  0.9016,  0.2381,  1.6464,  0.4886,  0.2238,  0.6539,  0.2814,\n",
      "         1.4311,  1.0136,  1.5090,  0.4689,  0.2768,  1.4760,  0.3909,  1.0490,\n",
      "         1.9811,  1.2464,  0.2971,  1.5150,  0.3449,  0.3443,  1.2707,  0.5148,\n",
      "         0.9166,  0.6587,  0.7154,  0.7798,  1.1901,  0.5989,  0.9714,  0.1468,\n",
      "         0.3064,  1.6019,  4.0584,  0.3653,  0.2212,  0.3146,  0.8043,  0.5890,\n",
      "         0.7715,  1.2956,  0.3502,  0.3313,  0.5446,  1.1273,  0.4059,  1.2493,\n",
      "         1.1926,  0.7641,  1.6331,  1.7136,  0.6637,  1.5723,  1.5631,  0.6627,\n",
      "         0.5943,  0.3335,  0.8679,  0.4810,  0.9534,  1.1324,  1.2077,  1.1065,\n",
      "         0.4383,  1.3496,  1.1742,  0.4417,  1.9551,  0.2340,  0.9001,  0.7877,\n",
      "         0.6151,  0.6937,  0.3594,  0.9143,  1.0262,  1.2768,  0.8081,  0.7579,\n",
      "         0.8007,  1.1510,  1.5227,  0.8944,  2.5713,  1.1290,  0.4566,  1.2526,\n",
      "         1.2068,  0.6563,  0.3120,  1.0347,  0.5421,  0.3379,  0.2236,  1.3104,\n",
      "         1.2961,  0.2643,  1.5769,  0.2708,  0.2848,  1.3954,  1.6047,  0.3271,\n",
      "         0.5723,  0.8479,  0.8386,  3.8724,  0.7792,  0.8936,  1.5083,  0.6144,\n",
      "         0.7532,  0.1999,  1.1823,  1.7650,  0.6061,  0.9046,  0.5003,  1.2084,\n",
      "         1.0839,  0.8990,  0.6993,  0.1563,  0.9581,  0.1500,  3.1111,  0.6728,\n",
      "         0.9866,  0.5656,  0.7720,  0.8385,  0.6712,  0.4934,  0.8448,  0.3203,\n",
      "         0.2191,  1.2425,  0.6868,  0.5237,  0.6894,  0.5957,  1.2693,  0.8669,\n",
      "         1.0038,  0.2153,  0.2264,  0.6342,  1.5735,  0.9297,  3.4635,  0.9798,\n",
      "         3.3893,  0.6142,  1.2559,  0.6648,  0.8027,  0.9461,  0.7206,  0.7472,\n",
      "         0.7876,  0.1670,  0.8062,  0.3727,  0.4395,  1.2104,  0.7412,  0.9143,\n",
      "         0.9126,  0.4329,  0.3482,  1.3703,  0.5530,  0.2293,  1.4831,  1.1503,\n",
      "         1.0181,  0.8053,  1.0121,  0.7011,  0.3155,  0.7316,  1.1368,  1.2217,\n",
      "         1.1730,  1.3446,  1.6949,  0.6794,  0.4753,  0.7325,  0.2306,  1.4535,\n",
      "         0.8786,  0.7532,  1.5819,  1.5303,  1.0933,  1.1216,  1.2915,  0.6685,\n",
      "         1.2142,  0.3344,  0.3381,  0.8438,  1.0098,  0.2278,  0.6924,  0.3424,\n",
      "         1.1654,  1.1335,  0.7650,  0.3276,  0.3032,  1.3613,  1.4306,  0.7898,\n",
      "         0.9919,  1.4142,  0.2294,  0.2733,  1.8753,  0.5239,  0.7997,  0.8873,\n",
      "         1.1882,  0.8764,  0.4780,  1.0689,  0.1627,  0.2504,  0.5799,  0.2555,\n",
      "         0.5951,  0.4960,  0.6828,  1.9151,  1.2737,  0.4606,  0.7157,  0.5378,\n",
      "         1.3662,  1.3204,  1.5504,  0.6647,  0.6195,  0.5986,  1.2038,  0.9637,\n",
      "         0.6593,  0.6920,  1.6180,  0.9187,  0.8631,  0.7643,  0.7421,  1.4185,\n",
      "         0.8802,  1.2329,  0.6566,  3.5034,  0.9075,  0.2299,  0.2227,  0.3484,\n",
      "         3.2193,  0.5723,  0.7325,  1.6111,  0.3667,  1.1544,  0.1674,  0.9065,\n",
      "         0.7147,  0.2181,  0.7378,  1.6980,  0.1769,  2.6863,  0.5246,  0.3203,\n",
      "         0.7653,  0.2211,  0.5270,  0.5129,  1.2313,  0.6641,  0.2481,  0.3211,\n",
      "         0.8571,  0.5962,  0.2215,  0.2409,  0.8628,  0.3248,  1.0537,  0.2312,\n",
      "         0.7662,  1.2132,  1.6856,  0.5958,  3.3437,  0.1770,  0.2662,  0.3434,\n",
      "         0.7961,  1.0368,  0.7072,  0.8695,  1.0158,  1.0020,  0.4817,  0.3005,\n",
      "         0.6425,  0.6714,  0.8847,  0.9600,  1.4487,  1.0942,  1.5435,  1.1490,\n",
      "         1.6354,  1.1519,  1.4430,  0.5280,  0.4861,  1.1458,  0.9577,  0.6495,\n",
      "         1.1888,  0.5234,  0.3865,  0.8257,  0.9608,  0.8420,  0.6660,  0.5642,\n",
      "         0.7093,  0.4090,  1.3225,  0.5954,  1.9698,  0.3227,  0.4867,  0.6266,\n",
      "         0.3177,  0.8164,  0.7229,  4.0965,  1.7136,  1.7362,  0.4882,  1.8581,\n",
      "         0.2515,  0.3415,  0.6554,  0.9193,  1.0588,  2.7511,  0.6093,  0.4775,\n",
      "         0.6334,  0.4932,  1.8915,  0.2252,  1.2633,  1.3817,  0.2298,  0.2687,\n",
      "         0.6517,  1.7617,  0.5395,  1.6051,  0.5414,  0.8443,  0.5290,  2.0347,\n",
      "         0.3963,  0.3648,  1.7554,  0.9357,  1.9058,  1.5723,  0.1987,  0.7013,\n",
      "         0.5596,  2.0878,  1.3219,  1.9952,  0.3428,  0.2154,  0.2793,  2.3415,\n",
      "         1.3518,  0.3752,  0.6552,  0.8642,  0.6185,  0.9658,  0.8464,  0.2461,\n",
      "         0.6702,  1.4000,  0.9315,  7.7121,  3.2894,  1.7937,  1.5981,  0.7784,\n",
      "         0.3022,  1.6009,  1.7080,  0.8095,  0.2731,  0.9860,  1.4429,  1.6230,\n",
      "         0.7129,  0.8656,  2.0518,  0.4799,  1.0678,  0.3597,  0.7099,  1.3391,\n",
      "         1.0566,  0.5867,  0.5427,  0.9579,  0.6836,  0.9583,  0.2842,  1.6669,\n",
      "         0.6816,  1.0297,  1.0042,  0.9484,  0.8549,  0.3764,  0.9265,  0.5201,\n",
      "         1.0681,  1.1496,  0.2369,  1.1872,  0.1968,  0.6544,  0.8984,  0.7934,\n",
      "         0.3029,  0.9317,  0.2201,  1.3177,  0.5771,  0.5054,  0.8066,  2.7376,\n",
      "         1.1827,  0.7280,  1.1235,  1.1059,  0.2180,  2.3714,  1.4716,  0.3479,\n",
      "         0.9493,  0.3167,  0.9000,  0.3841,  0.7518,  1.0113,  0.2238,  0.7863,\n",
      "         0.7138,  0.5372,  0.4433,  0.8251,  0.8511,  0.3312,  1.8807,  0.2556,\n",
      "         0.2361,  1.1301,  0.9232,  1.5491,  0.9164,  1.4187,  0.8637,  1.4955,\n",
      "         0.7341,  0.9661,  0.3814,  1.2516,  0.2699,  1.0903,  1.0220,  1.0257,\n",
      "         0.5559,  0.6249,  1.3740,  1.2895,  1.5285,  1.2341,  0.4751,  0.2662,\n",
      "         0.3843,  1.7780,  0.7502,  1.5735,  0.8143,  0.9366,  1.6979,  0.8473,\n",
      "         0.4292,  0.3509,  0.4856,  0.9024,  0.1806,  1.5272,  3.0266,  0.6457,\n",
      "         0.5894,  1.0479,  1.1554,  1.1259,  0.3695,  1.3816,  0.5367,  0.2255,\n",
      "         0.1428,  0.8587,  0.4882,  0.2010,  1.1284,  0.4365,  0.3657,  0.3016,\n",
      "         0.2846,  0.2484,  1.1890,  0.7124,  0.1850,  1.3031,  0.5553,  1.1804,\n",
      "         1.1042,  0.7570,  0.3195,  0.7986,  0.9819,  0.7817,  0.8368,  0.2125,\n",
      "         0.2342,  0.8858,  0.6232,  0.9961,  1.8214,  0.5480,  0.2625,  1.3418],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.1.1.bias\n",
      "Weights: tensor([-2.7901e+00, -4.2372e+00, -2.5770e-01, -2.6268e+00, -2.6233e+00,\n",
      "        -2.4007e-01, -1.9776e+00, -1.4387e+00, -8.3689e-02, -2.2629e+00,\n",
      "        -1.9199e+00, -1.4699e+00, -3.5208e+00, -1.9024e+00, -3.3222e-01,\n",
      "        -1.9570e+00, -5.3105e-02, -3.5752e+00,  9.7066e-01,  2.6896e-01,\n",
      "        -5.6178e-01,  1.6978e+00, -1.1183e+00, -3.1878e+00,  9.3124e-01,\n",
      "        -4.7359e+00, -4.6857e+00, -5.3739e+00,  4.3532e-01, -7.4190e-01,\n",
      "        -5.7689e-01, -3.5036e+00, -2.7261e+00,  8.9816e-01, -7.9739e-01,\n",
      "        -1.9633e+00, -3.0295e+00,  1.7724e-01, -2.0472e+00,  1.6154e-02,\n",
      "         1.1464e-01, -2.1799e+00, -7.9684e-01, -2.4241e+00, -1.6332e+00,\n",
      "        -1.8725e+00, -6.9956e-02, -2.4402e+00, -2.8206e+00, -1.6883e-01,\n",
      "        -3.4613e-01, -2.6942e+00,  1.5264e+00, -6.0199e-01, -1.0985e+00,\n",
      "        -1.3912e+00,  1.7686e+00, -5.0618e-01, -1.1626e-01, -1.3373e+00,\n",
      "        -3.1149e+00, -1.1119e+00, -4.6983e+00, -2.0133e+00,  1.1096e+00,\n",
      "        -2.6278e+00, -1.6795e-01, -1.5010e+00, -2.1363e-01,  4.2500e-01,\n",
      "        -1.7708e+00, -1.0248e+00, -2.2721e+00,  1.4098e+00,  6.8683e-01,\n",
      "        -8.3504e-01, -4.9729e-02, -1.1281e+00, -2.2952e-01, -1.5788e+00,\n",
      "        -2.0091e+00, -5.3981e-01, -2.3285e+00,  1.9262e+00, -2.6372e+00,\n",
      "        -5.1795e-01, -1.6908e+00,  3.2114e-02, -3.8180e+00, -1.2707e+00,\n",
      "        -4.6820e+00,  1.0560e+00, -3.2142e+00, -2.7479e+00, -8.7245e-02,\n",
      "        -2.7317e+00,  1.1020e+00,  1.8724e+00, -1.4363e+00,  1.6585e+00,\n",
      "        -1.9128e+00, -3.2955e+00, -2.4053e+00, -3.3880e+00, -2.1289e+00,\n",
      "        -2.0277e+00,  2.0624e+00, -2.8162e+00,  1.3960e+00, -2.6015e+00,\n",
      "        -1.0167e+00, -8.0351e-01, -2.1561e+00, -4.2899e+00, -4.0634e+00,\n",
      "        -2.2444e-01, -1.3010e+00,  7.9894e-01, -5.3751e+00, -1.7638e+00,\n",
      "         1.4971e+00, -1.9037e+00, -3.0276e-01, -1.6418e-01, -2.4063e+00,\n",
      "         1.5644e-01, -1.1946e+00, -2.0353e+00, -3.8055e-01, -4.2187e+00,\n",
      "        -4.1150e+00, -1.9323e+00, -4.6264e-01, -2.2264e+00, -3.2651e+00,\n",
      "         2.4001e+00, -2.4134e+00,  1.5905e+00, -3.3998e+00, -1.8446e+00,\n",
      "        -1.3567e+00,  1.6189e+00, -2.0124e+00, -1.3865e+00, -4.9968e-01,\n",
      "         2.4639e+00, -1.3712e+00,  2.0081e+00, -2.8320e+00, -9.4340e-01,\n",
      "        -2.4306e+00, -2.9179e+00, -5.8548e-01, -8.3869e-01, -1.3401e+00,\n",
      "         6.8959e-01, -1.8001e+00, -3.9842e+00,  8.8998e-01,  1.1502e+00,\n",
      "        -1.7197e+00, -2.4275e+00, -5.0493e+00,  1.2101e+00, -4.7876e+00,\n",
      "        -2.0923e-01,  4.6144e-01, -3.5394e+00, -4.5619e-01, -4.5296e-01,\n",
      "        -1.9490e+00,  1.0574e+00, -2.2937e+00, -6.1161e-01,  5.7718e-02,\n",
      "         5.1722e-01, -2.3911e+00, -2.2302e+00, -2.1223e+00, -2.1326e-01,\n",
      "        -1.1192e+00, -1.2883e+00, -3.1269e+00, -1.8153e+00, -3.3174e+00,\n",
      "        -4.1434e-01,  9.5043e-01, -2.2591e+00, -2.1317e+00, -4.5547e+00,\n",
      "         2.1984e-02,  1.4471e+00, -1.8254e+00,  1.2208e+00,  2.4425e+00,\n",
      "        -4.2266e+00, -1.9840e+00,  2.1736e+00, -5.2115e-01, -1.6110e+00,\n",
      "        -1.6863e+00,  2.8384e+00, -3.4460e-01, -4.1050e+00, -2.0522e+00,\n",
      "         6.3969e-01,  2.4332e+00,  1.7337e+00, -3.8020e+00, -3.3586e+00,\n",
      "        -1.1478e-02, -3.3412e-01,  2.1330e+00, -1.3325e+00,  1.4261e+00,\n",
      "        -3.3380e+00, -6.1278e-02, -2.5546e+00, -1.3940e+00,  1.0415e+00,\n",
      "        -3.6297e+00,  1.8916e+00, -2.2233e-01, -8.6412e-01,  8.7897e-01,\n",
      "        -2.2445e+00, -4.8478e+00,  1.7537e+00,  8.6776e-02,  1.5505e+00,\n",
      "        -2.5912e+00, -2.9505e+00,  1.3103e+00,  1.5968e+00, -6.7479e-01,\n",
      "        -1.8850e+00, -1.4377e+00, -3.3701e+00, -5.7725e-01, -2.2755e-01,\n",
      "         1.7683e+00, -2.9064e+00, -1.3936e+00,  1.2491e-02, -2.4036e+00,\n",
      "        -2.2748e-01, -3.1257e-01, -2.5267e+00,  1.7216e+00,  7.7692e-01,\n",
      "        -1.2553e+00,  1.9006e+00, -1.5054e+00, -1.5318e+00,  1.9368e+00,\n",
      "        -2.0905e-01,  2.7160e-01, -4.0330e+00, -1.1810e+00, -4.4605e+00,\n",
      "        -1.2311e+00, -6.1493e+00, -1.5174e+00, -2.8405e+00, -1.9562e+00,\n",
      "        -2.5049e+00, -4.8875e-01, -2.0439e+00, -6.2988e+00, -3.0729e+00,\n",
      "        -1.2225e+00, -5.2690e+00, -1.9355e-01,  3.6661e-01, -1.5133e-01,\n",
      "        -3.7002e+00, -1.5883e+00, -1.9517e+00,  1.8867e+00, -1.4238e+00,\n",
      "        -2.8970e+00,  1.9315e-01, -2.4345e+00, -4.2609e+00, -1.9239e+00,\n",
      "        -3.0475e+00, -2.2730e-01, -1.9042e+00, -7.3176e-01,  6.4587e-01,\n",
      "        -1.7078e+00, -1.4702e+00, -1.5735e+00,  3.5789e-01, -1.6562e+00,\n",
      "        -2.5516e+00, -4.6188e-01,  3.0186e-01,  1.2250e+00, -1.2783e-01,\n",
      "        -4.2490e+00, -2.5375e-01, -9.8664e-01, -1.7823e+00, -3.3848e+00,\n",
      "        -2.3334e+00, -8.6206e-01,  8.0980e-02, -3.0447e+00, -4.0435e+00,\n",
      "        -3.6754e+00, -9.8918e-02,  1.2246e-01, -1.2673e+00, -4.5878e+00,\n",
      "        -1.6091e+00,  1.8399e+00, -1.5527e+00, -5.4311e+00, -1.7849e+00,\n",
      "        -2.9971e+00, -2.4110e-01,  1.5687e+00, -1.6680e-01,  6.9738e-01,\n",
      "        -2.1456e+00, -3.9757e-01, -4.3987e-01, -5.8353e+00, -4.3703e+00,\n",
      "        -1.3741e+00, -1.6269e+00, -1.9172e+00, -7.2169e-02, -2.9874e-01,\n",
      "        -2.7310e+00, -8.9045e-02, -3.4996e+00, -1.5844e+00, -3.1110e+00,\n",
      "        -1.9390e+00, -2.5192e+00, -2.2710e+00,  1.8709e+00,  2.1584e+00,\n",
      "        -6.8986e-01, -1.2351e+00, -4.6789e-02, -1.7785e+00, -5.1528e-01,\n",
      "         1.6106e+00,  1.4010e-01,  1.1884e+00, -2.7483e+00,  1.8109e+00,\n",
      "        -1.3742e+00, -3.8367e+00, -5.8111e+00, -2.6140e+00, -3.2814e+00,\n",
      "        -2.3729e+00, -1.3296e+00, -3.1530e+00, -7.3798e-01, -4.5765e+00,\n",
      "         9.5137e-01, -2.5300e+00, -6.8127e-01, -2.3737e+00, -1.4461e+00,\n",
      "        -1.9114e+00, -2.5938e+00, -7.0925e-01, -2.7243e+00, -1.4514e+00,\n",
      "         3.0790e-01,  5.3322e-01, -1.0850e+00, -1.1561e+00, -1.5344e+00,\n",
      "        -7.5170e-01, -2.7486e+00, -1.9941e+00, -1.1650e+00, -1.5390e+00,\n",
      "         4.0276e-01, -2.5706e-01, -2.2537e+00, -3.1953e+00, -1.7327e+00,\n",
      "        -2.1243e+00,  1.2180e+00, -9.9923e-01, -9.6128e-01, -2.6623e+00,\n",
      "         1.0462e+00, -1.5039e+00, -8.3736e-01,  4.6794e-01,  1.4780e+00,\n",
      "         9.6832e-01, -2.1045e+00,  3.9359e-01, -5.5404e-01, -9.3849e-02,\n",
      "         1.8286e+00, -5.8126e-01,  9.7283e-01, -3.9743e+00, -2.9599e+00,\n",
      "        -2.1019e+00, -3.5179e-01, -1.3130e-02, -1.2596e+00,  2.0095e+00,\n",
      "        -8.0963e-01, -6.2289e+00, -3.7402e+00,  2.5941e+00, -1.9296e+00,\n",
      "        -2.6883e-01,  2.0273e-01, -3.1303e+00, -1.3099e+00, -2.6979e+00,\n",
      "        -2.9964e-01, -6.1638e-01, -1.7710e+00, -1.5914e+00, -1.4152e+00,\n",
      "        -2.5421e+00,  2.5728e+00,  2.0419e+00, -2.6591e+00, -1.8154e+00,\n",
      "         5.2418e-02,  8.7286e-01,  2.0004e+00, -2.2495e+00, -1.4137e+00,\n",
      "        -2.6638e+00, -1.9964e+00,  1.0102e-01,  1.9868e+00, -1.6630e-01,\n",
      "        -3.6898e+00,  1.2668e-02, -2.6510e+00, -3.5892e+00, -1.5336e+00,\n",
      "        -4.3131e+00, -4.3443e+00, -5.6595e-02, -1.5950e+00, -2.4667e+00,\n",
      "        -4.1053e-01, -2.2415e-01,  2.4039e+00, -2.0289e+00, -9.6288e-02,\n",
      "        -9.7849e-01, -1.4475e+00, -3.5171e+00, -1.3075e+00,  2.4330e-01,\n",
      "        -2.5451e+00, -3.2314e+00,  5.6235e-02, -5.1974e+00,  8.6595e-01,\n",
      "        -1.6385e+00, -1.8292e+00, -3.6186e-01, -7.3963e-01,  1.4923e+00,\n",
      "        -2.7592e+00, -2.9770e+00, -3.9994e+00, -1.4960e+00, -2.2515e+00,\n",
      "        -3.0795e-01, -4.0720e+00, -4.4978e+00, -2.0692e+00, -7.1995e+00,\n",
      "        -3.4361e+00,  2.5221e-01, -3.2592e+00, -2.8405e+00, -3.6662e-01,\n",
      "         1.3105e+00, -9.0819e-01, -2.2537e-01,  1.6567e+00,  7.5214e-01,\n",
      "        -1.9579e+00, -3.1107e+00,  2.0275e+00, -1.8882e+00,  7.8145e-01,\n",
      "         7.0531e-01, -1.6948e+00, -4.5721e+00,  3.7775e-01, -1.3596e-01,\n",
      "        -4.6118e-01, -6.0256e-01, -2.4868e+00, -1.2782e+00, -2.1485e+00,\n",
      "        -2.2230e+00, -2.8143e-02, -1.9953e+00,  2.2171e+00, -3.2979e+00,\n",
      "        -2.7319e+00, -1.6947e+00, -2.5510e+00, -1.8722e-01, -4.0492e+00,\n",
      "        -2.5362e+00, -8.0323e-01, -2.3639e+00,  2.2804e+00, -2.8216e+00,\n",
      "         7.5536e-01, -1.0249e+00, -2.1650e-01, -2.3850e+00, -1.7635e-01,\n",
      "        -3.2332e-01, -2.4883e+00, -1.1257e-01,  1.9593e+00, -3.6454e-01,\n",
      "         1.9881e+00,  4.0985e-01, -4.0349e+00, -7.4169e-01, -8.1657e-01,\n",
      "        -1.4910e+00, -1.0169e+00, -3.2549e+00, -6.8290e-01, -2.8005e+00,\n",
      "         1.8307e+00,  9.1882e-01, -2.4115e-01, -2.1039e+00, -2.8761e+00,\n",
      "        -1.5324e+00, -2.7944e+00, -2.0304e+00, -9.6621e-01, -1.3405e+00,\n",
      "        -1.5183e+00, -1.5637e+00, -2.6221e+00, -4.3452e-01, -1.9233e+00,\n",
      "        -2.0242e+00,  1.6837e+00, -1.7899e+00, -1.6092e-01,  2.8752e-01,\n",
      "        -3.1261e+00, -9.1396e-01, -2.9283e+00, -2.0261e+00, -5.5059e-01,\n",
      "        -3.2729e-01, -4.6139e+00, -1.5473e-01,  1.2834e+00, -3.3284e+00,\n",
      "        -1.1812e+00, -2.4776e+00, -1.3115e+00, -2.6637e+00, -4.0220e-01,\n",
      "        -1.2609e-01, -1.0132e+00, -3.0200e+00, -3.0455e+00, -3.0936e+00,\n",
      "        -3.7078e+00, -5.0898e+00, -9.1558e-01,  2.4575e-01, -1.7840e+00,\n",
      "         1.2460e+00, -1.5493e+00, -1.7820e+00, -6.8439e-01, -2.1784e+00,\n",
      "        -1.8686e+00, -3.1829e+00, -1.8464e+00, -3.7589e+00, -3.8107e-01,\n",
      "        -3.7832e+00,  3.8758e-01, -4.2345e-01, -3.5251e+00, -1.6037e+00,\n",
      "         2.1818e+00, -2.5239e-01,  2.1435e-01, -4.0219e+00, -1.3649e+00,\n",
      "        -1.8671e-01,  3.0188e-01,  9.0437e-01, -4.2679e+00, -1.6965e+00,\n",
      "        -4.8994e-01, -2.7190e+00, -2.1597e+00,  2.3390e+00,  1.4637e+00,\n",
      "        -2.9095e+00, -1.4549e-01, -1.1980e+00, -8.8818e-01, -2.8027e+00,\n",
      "        -2.8604e+00, -1.0443e+00, -3.0260e+00,  7.6987e-01,  1.0133e+00,\n",
      "        -1.8400e-01,  1.0810e+00, -7.7502e-01, -9.1917e-03, -1.7208e+00,\n",
      "        -5.0423e+00, -3.0600e+00, -5.0195e-02, -1.9618e+00, -2.3027e-01,\n",
      "        -1.7172e+00, -2.0892e+00, -1.3836e+00, -7.1391e-01, -1.0881e+00,\n",
      "        -5.8334e-01, -3.4307e+00, -2.0674e+00, -2.9062e-01, -2.1189e+00,\n",
      "        -4.9156e+00, -2.2899e+00, -3.5371e+00, -1.6685e+00, -2.5540e-01,\n",
      "        -4.5441e+00, -4.8813e-01, -1.4878e+00, -4.1993e-01, -1.4195e+00,\n",
      "        -1.0480e+00,  1.3449e-01,  1.2796e+00,  8.7203e-01, -2.8009e+00,\n",
      "        -2.4869e-01, -4.0239e-01, -4.9540e+00, -3.1026e-01, -3.5073e+00,\n",
      "         1.5932e+00, -1.9161e+00, -8.2103e-01,  3.7245e-01, -2.0542e+00,\n",
      "        -1.6974e+00,  1.7404e+00, -1.5604e+00, -1.0545e+00,  3.5865e+00,\n",
      "        -2.0625e+00,  2.1344e+00, -1.2033e+00, -1.1355e+00, -1.6099e+00,\n",
      "        -5.2452e-02,  7.7946e-02, -4.6157e-01, -1.9732e+00, -1.0121e+00,\n",
      "         1.9639e+00, -1.7733e-01, -2.1550e+00,  2.1971e+00, -1.0257e+00,\n",
      "         1.4960e+00, -1.8952e+00, -3.4800e+00, -4.1625e+00, -5.5395e-01,\n",
      "        -2.0270e+00,  6.2796e-01,  7.3199e-01, -5.4110e-01, -2.3546e+00,\n",
      "        -9.2520e-01, -2.4695e-01, -2.9224e+00, -3.3000e+00, -1.9823e+00,\n",
      "         3.3644e-03,  2.1766e+00, -2.9171e-01, -1.5000e+00, -2.6382e+00,\n",
      "        -2.2851e+00, -4.2868e+00, -1.1155e+00, -3.8985e+00, -3.4746e+00,\n",
      "        -5.0929e+00, -1.3843e+00, -3.7960e+00, -9.6932e-02, -7.0763e-01,\n",
      "        -7.5928e-01, -2.9867e+00, -4.2954e-01, -1.6988e+00, -9.2872e-02,\n",
      "         2.3274e-01, -2.4043e+00, -2.9412e+00, -2.3394e+00, -7.1529e-01,\n",
      "        -2.3914e-01, -2.5468e+00,  1.4409e+00, -1.7596e+00, -1.2699e-01,\n",
      "        -5.9428e+00,  8.8083e-01, -1.3369e-01, -8.2796e-02,  2.1314e+00,\n",
      "        -2.6756e+00, -4.0886e-01, -1.7476e+00, -2.3211e+00, -3.4215e+00,\n",
      "        -6.4154e-02, -4.8691e+00,  1.9467e-01,  1.8761e+00, -9.6136e-01,\n",
      "        -2.9261e+00, -1.4721e+00, -1.0755e+00, -1.3994e+00, -7.1301e-01,\n",
      "        -2.6129e-01, -7.8235e-01, -5.7038e+00,  8.5063e-01, -1.7618e+00,\n",
      "        -3.3237e+00,  1.8787e+00,  1.7379e+00, -1.6399e+00, -2.5693e+00,\n",
      "        -1.7747e-01, -4.6490e+00, -1.1812e+00, -7.3622e-01, -8.2602e-02,\n",
      "        -2.8962e+00, -6.4097e-01, -3.1680e-02, -2.4919e+00, -2.4327e+00,\n",
      "        -4.6724e+00, -2.0194e+00,  1.2551e+00, -6.0087e-01, -9.0048e-01,\n",
      "        -4.7269e+00, -4.6031e+00, -5.1371e+00,  1.7576e+00,  7.8656e-01,\n",
      "         2.0536e+00, -5.7109e+00, -2.2907e+00, -1.2456e-02, -1.0971e+00,\n",
      "        -2.1339e+00, -5.7602e-01, -2.2391e+00, -1.7711e+00,  1.0031e+00,\n",
      "        -9.2485e-01, -1.0957e+00, -1.0744e+00, -4.4569e+00, -1.6846e+00,\n",
      "        -5.2583e+00, -4.5659e+00, -1.4619e+00,  1.9639e-01, -1.9995e+00,\n",
      "        -4.6899e+00, -1.9869e+00, -1.1633e-01, -1.5346e+00, -4.7248e+00,\n",
      "        -4.1817e+00, -1.8754e-01, -6.9516e-01, -5.4616e+00,  1.1348e-01,\n",
      "        -1.2714e+00, -7.5417e-02, -1.9271e+00, -3.7681e+00, -1.0875e+00,\n",
      "        -2.0061e-01, -1.0068e+00, -2.1972e+00, -2.6606e-01, -1.0301e+00,\n",
      "         2.5468e+00, -4.7862e+00, -3.1970e-01, -3.4350e+00, -1.8785e+00,\n",
      "        -1.0784e+00, -1.9807e+00, -2.6435e-01, -8.6835e-01, -8.7121e-01,\n",
      "        -2.3590e+00, -1.2470e+00,  2.4771e+00, -3.5332e+00,  3.5575e-01,\n",
      "        -1.7765e+00, -6.4997e-01, -1.3976e+00,  5.5224e-02, -1.4167e+00,\n",
      "         1.4937e-01, -4.3030e+00, -2.7283e-01, -9.2415e-01, -1.6615e+00,\n",
      "        -1.2728e+00, -3.4141e+00, -1.8797e+00, -3.2489e+00, -2.7534e+00,\n",
      "         1.3081e+00, -1.5087e+00, -1.9515e+00,  1.6488e-01, -1.9323e+00,\n",
      "         7.9171e-02, -5.9317e-01,  7.2782e-01, -6.2029e-01, -2.6939e+00,\n",
      "         1.8374e+00,  6.4665e-01, -4.7876e-01, -6.9897e-01,  2.5425e-01,\n",
      "        -2.0496e+00, -5.8776e-01,  2.1667e+00, -3.6762e+00,  1.8418e+00,\n",
      "         1.8622e+00, -3.4868e+00, -2.3848e+00, -4.7977e+00, -8.5913e-01,\n",
      "        -1.3494e+00, -1.6916e+00, -4.0410e+00, -1.0355e+00, -6.9671e-01,\n",
      "         1.8475e-01, -1.9959e+00,  1.6280e+00, -2.9831e+00, -8.6323e-01,\n",
      "        -3.8186e+00, -1.3188e-01, -3.1735e-01, -1.4230e+00, -3.1759e+00,\n",
      "        -2.2403e+00, -3.4860e+00, -1.0299e+00,  2.6548e+00,  2.9324e+00,\n",
      "        -5.5744e+00, -4.4503e-01, -2.3033e+00, -1.9505e+00, -2.2138e+00,\n",
      "        -1.2720e+00, -2.9025e+00,  2.1372e-01,  1.1379e+00,  2.9380e-02,\n",
      "        -2.0611e+00,  3.6888e-01, -4.1077e+00, -2.2654e+00, -1.6613e+00,\n",
      "        -1.2600e-01, -2.7723e+00, -3.7648e+00, -2.6687e+00,  7.5806e-01,\n",
      "        -3.7688e+00, -9.9462e-02,  1.8723e+00,  6.6609e-01, -8.9563e-01,\n",
      "         8.2681e-03,  1.3516e+00, -3.9613e+00,  7.8282e-03,  2.8332e-02,\n",
      "         3.1610e-01,  2.0236e+00,  2.1679e+00, -1.9395e+00, -1.9777e+00,\n",
      "         1.7846e+00, -1.6620e+00, -4.0551e-02, -1.1508e+00, -1.9732e+00,\n",
      "        -2.0870e+00,  3.5060e-01, -8.7135e-01, -9.3870e-01, -2.2069e+00,\n",
      "        -6.6295e-01,  2.2249e+00, -2.1073e-01, -6.4969e-01, -2.0456e-01,\n",
      "        -3.8444e+00, -2.6696e+00, -3.9768e-01,  1.6206e-01, -1.7660e+00],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.16.conv.2.weight\n",
      "Weights: tensor([[[[ 0.0064]],\n",
      "\n",
      "         [[-0.0493]],\n",
      "\n",
      "         [[ 0.0077]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0260]],\n",
      "\n",
      "         [[-0.0230]],\n",
      "\n",
      "         [[-0.0521]]],\n",
      "\n",
      "\n",
      "        [[[-0.0745]],\n",
      "\n",
      "         [[-0.0461]],\n",
      "\n",
      "         [[-0.0035]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0059]],\n",
      "\n",
      "         [[ 0.0696]],\n",
      "\n",
      "         [[ 0.0314]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1389]],\n",
      "\n",
      "         [[-0.0691]],\n",
      "\n",
      "         [[ 0.0247]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0117]],\n",
      "\n",
      "         [[-0.0764]],\n",
      "\n",
      "         [[ 0.0890]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0987]],\n",
      "\n",
      "         [[ 0.0955]],\n",
      "\n",
      "         [[-0.0370]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0081]],\n",
      "\n",
      "         [[ 0.0201]],\n",
      "\n",
      "         [[ 0.0142]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0784]],\n",
      "\n",
      "         [[-0.0133]],\n",
      "\n",
      "         [[-0.0051]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0563]],\n",
      "\n",
      "         [[ 0.0494]],\n",
      "\n",
      "         [[ 0.0142]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0700]],\n",
      "\n",
      "         [[ 0.0574]],\n",
      "\n",
      "         [[-0.0038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0301]],\n",
      "\n",
      "         [[ 0.0029]],\n",
      "\n",
      "         [[ 0.0037]]]], device='cuda:0')\n",
      "Shape: torch.Size([160, 960, 1, 1])\n",
      "\n",
      "Layer: features.16.conv.3.weight\n",
      "Weights: tensor([4.1770, 1.3750, 2.9380, 1.5528, 2.3422, 1.7846, 1.8868, 1.4199, 1.9198,\n",
      "        1.6157, 2.6138, 2.2402, 2.0136, 3.5225, 3.2321, 3.0290, 1.6298, 2.6078,\n",
      "        1.6848, 2.3608, 1.4972, 1.7952, 1.7831, 2.7959, 1.4643, 3.3063, 1.5421,\n",
      "        1.5153, 1.5015, 2.0795, 1.4534, 2.3065, 1.8142, 1.8469, 3.3954, 1.6430,\n",
      "        2.3940, 1.3272, 2.2110, 1.6348, 2.7791, 2.0876, 1.8231, 1.5492, 2.5588,\n",
      "        4.1108, 3.0423, 1.8198, 1.5013, 3.3192, 2.8878, 3.6083, 3.9295, 1.7852,\n",
      "        2.5881, 2.2011, 2.1993, 1.2850, 2.9850, 3.1305, 2.3196, 1.5268, 2.8813,\n",
      "        1.6123, 2.1757, 3.0542, 3.1965, 2.0745, 1.5377, 4.0051, 3.5852, 1.4613,\n",
      "        2.2791, 2.0417, 3.3025, 2.2245, 1.5178, 1.6814, 3.1092, 1.3473, 1.5207,\n",
      "        2.0840, 1.4428, 2.0320, 3.1664, 1.8095, 4.9656, 2.4513, 2.2318, 2.4022,\n",
      "        2.0303, 2.3750, 2.7550, 1.5621, 1.5475, 1.4438, 1.2102, 1.5648, 2.2060,\n",
      "        2.6533, 3.0861, 1.8621, 3.2651, 2.7386, 2.8063, 1.9648, 2.7481, 1.9286,\n",
      "        1.9701, 1.7816, 3.2024, 4.1407, 3.2408, 1.5027, 1.9282, 1.4803, 2.8148,\n",
      "        1.5371, 1.4678, 1.3998, 2.7603, 3.8203, 1.8060, 1.9424, 4.1827, 2.9053,\n",
      "        1.5544, 2.3633, 2.5889, 1.6807, 1.9203, 2.2434, 1.4019, 1.2921, 1.5244,\n",
      "        2.7562, 1.3857, 1.5662, 1.8294, 1.4453, 2.4020, 2.1976, 1.5405, 1.8371,\n",
      "        3.8185, 1.6317, 3.0662, 1.4370, 3.2931, 3.0340, 3.4469, 2.9724, 3.3298,\n",
      "        1.9206, 2.5640, 3.2050, 3.0547, 1.9853, 2.0626, 2.0527],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.16.conv.3.bias\n",
      "Weights: tensor([ 3.4682e-04, -1.3780e-04,  3.3335e-04, -9.0408e-05,  9.4047e-05,\n",
      "        -5.4908e-04, -8.3256e-05,  3.6286e-04, -6.0185e-05, -7.1941e-04,\n",
      "        -8.6678e-05,  9.0329e-07, -3.7167e-05, -3.4093e-05,  4.8243e-04,\n",
      "        -3.6128e-04, -2.8973e-04,  4.1555e-04,  3.6208e-04,  1.3821e-05,\n",
      "        -3.8372e-05,  1.1180e-04, -1.1206e-04,  3.6017e-05, -1.7007e-04,\n",
      "        -7.5231e-04,  9.2172e-05,  2.0837e-04,  1.2037e-04, -1.0829e-04,\n",
      "         1.1458e-04, -5.1764e-04,  2.3367e-04,  6.4387e-05,  6.0126e-04,\n",
      "        -2.3102e-04,  2.0957e-04,  9.0441e-06, -3.4376e-04,  1.7996e-04,\n",
      "         3.1081e-04,  2.5533e-04,  3.6211e-05, -1.8024e-04,  7.8160e-04,\n",
      "         5.0005e-04,  8.2161e-05,  1.4182e-04, -4.6208e-05, -7.3464e-04,\n",
      "         1.5571e-04,  3.5057e-04, -4.1648e-04,  1.4829e-04,  4.7434e-04,\n",
      "        -1.5853e-04, -1.1153e-04, -2.4632e-04, -1.9664e-04,  4.2530e-04,\n",
      "        -2.4826e-04,  4.0465e-05, -1.2616e-04,  8.3958e-05,  3.6575e-05,\n",
      "         2.1308e-04, -3.2301e-04,  4.5229e-05, -1.3433e-04,  2.2394e-04,\n",
      "        -7.5279e-04, -4.4561e-06,  1.7849e-04, -1.5264e-04,  4.2220e-04,\n",
      "        -3.9005e-05,  4.2530e-04, -3.3016e-05, -2.9358e-04, -3.8267e-04,\n",
      "        -3.2631e-05,  1.2089e-04,  1.7529e-04,  6.3597e-05, -2.4780e-04,\n",
      "         8.7492e-05,  2.1045e-04,  1.6282e-04,  1.5502e-04, -1.8277e-04,\n",
      "         6.1941e-05,  3.8306e-05, -2.1893e-04,  4.2383e-04, -2.6847e-04,\n",
      "        -1.3573e-04,  5.7846e-04, -3.0186e-04, -9.7492e-05, -2.7174e-04,\n",
      "         2.5094e-04,  1.6142e-04, -9.5506e-05,  2.7317e-04,  2.5436e-04,\n",
      "        -1.8036e-04, -3.8656e-04,  2.4924e-04,  1.0208e-04,  1.5260e-04,\n",
      "         1.0478e-05,  9.6706e-04, -4.3459e-04, -1.3878e-04, -4.5736e-04,\n",
      "         1.9234e-04,  2.9861e-04,  1.0444e-04,  2.0183e-05,  2.3997e-04,\n",
      "         6.5722e-04,  1.2744e-04,  1.0233e-04, -1.2095e-04,  3.3711e-05,\n",
      "         3.5875e-04,  2.9552e-04, -6.3218e-05,  1.2921e-04, -1.8580e-04,\n",
      "        -3.1216e-04,  1.8303e-04,  1.8062e-04, -3.5565e-04, -1.6842e-04,\n",
      "         1.8831e-04,  5.1554e-06, -1.4670e-04, -1.8701e-04, -4.3747e-04,\n",
      "        -1.2587e-04, -1.1783e-04,  7.7015e-05, -1.4475e-04,  1.2159e-04,\n",
      "         3.0137e-04,  3.4761e-04,  2.2704e-04,  2.7623e-04, -1.6617e-04,\n",
      "         5.8136e-04,  2.0506e-04, -5.8385e-04,  6.6452e-05,  2.0238e-04,\n",
      "         1.6672e-04, -7.5126e-05, -1.7468e-04,  1.9897e-04,  8.1976e-05],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([160])\n",
      "\n",
      "Layer: features.17.conv.0.0.weight\n",
      "Weights: tensor([[[[ 0.0097]],\n",
      "\n",
      "         [[ 0.0017]],\n",
      "\n",
      "         [[ 0.0357]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0469]],\n",
      "\n",
      "         [[ 0.0379]],\n",
      "\n",
      "         [[ 0.0278]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0841]],\n",
      "\n",
      "         [[ 0.0753]],\n",
      "\n",
      "         [[ 0.0660]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0043]],\n",
      "\n",
      "         [[-0.0098]],\n",
      "\n",
      "         [[ 0.1263]]],\n",
      "\n",
      "\n",
      "        [[[-0.1442]],\n",
      "\n",
      "         [[ 0.0275]],\n",
      "\n",
      "         [[ 0.2205]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0251]],\n",
      "\n",
      "         [[-0.0580]],\n",
      "\n",
      "         [[ 0.0095]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.1005]],\n",
      "\n",
      "         [[-0.0738]],\n",
      "\n",
      "         [[-0.0479]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0372]],\n",
      "\n",
      "         [[-0.0390]],\n",
      "\n",
      "         [[ 0.0284]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0623]],\n",
      "\n",
      "         [[-0.0989]],\n",
      "\n",
      "         [[ 0.0034]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0367]],\n",
      "\n",
      "         [[ 0.0369]],\n",
      "\n",
      "         [[ 0.0450]]],\n",
      "\n",
      "\n",
      "        [[[-0.1218]],\n",
      "\n",
      "         [[-0.0514]],\n",
      "\n",
      "         [[ 0.0950]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0281]],\n",
      "\n",
      "         [[-0.0096]],\n",
      "\n",
      "         [[ 0.0095]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 160, 1, 1])\n",
      "\n",
      "Layer: features.17.conv.0.1.weight\n",
      "Weights: tensor([1.2225, 1.0308, 0.9264, 1.2183, 1.1288, 1.1772, 1.2754, 1.0019, 1.1402,\n",
      "        1.2538, 1.1721, 1.2315, 1.3119, 1.3612, 1.3461, 1.1681, 1.0746, 1.3760,\n",
      "        1.5788, 0.9717, 1.2051, 1.4534, 1.0223, 1.1907, 1.2769, 1.6123, 1.0325,\n",
      "        0.8411, 1.6020, 0.4704, 1.2456, 1.3465, 1.1700, 1.2164, 1.2480, 0.7038,\n",
      "        1.1126, 1.1079, 0.9620, 1.1644, 0.9885, 1.0587, 1.1087, 1.1730, 1.1308,\n",
      "        1.2235, 1.1617, 1.0470, 1.3858, 1.1432, 1.2303, 1.5644, 0.8808, 0.7925,\n",
      "        1.3227, 1.7434, 1.2768, 1.2934, 1.0963, 1.1726, 1.1827, 1.1962, 0.9948,\n",
      "        1.1677, 0.9663, 1.1600, 1.2084, 1.2096, 1.0665, 1.0423, 0.9773, 1.1338,\n",
      "        0.5499, 0.5936, 1.1984, 1.1376, 1.0695, 1.0126, 1.2668, 1.3358, 1.1613,\n",
      "        1.2527, 1.2441, 1.0968, 1.0768, 1.1078, 1.2903, 1.1385, 1.1231, 1.1598,\n",
      "        1.1264, 0.9364, 1.1705, 1.2148, 0.9064, 1.0348, 0.9386, 0.9003, 1.0962,\n",
      "        1.3823, 1.3129, 1.3765, 1.1837, 1.1541, 1.1299, 1.1277, 0.8636, 1.4357,\n",
      "        1.2011, 1.2024, 0.8383, 1.2080, 1.1586, 0.9157, 1.0748, 0.9604, 1.1141,\n",
      "        1.1610, 1.1644, 0.9128, 1.1326, 1.2246, 1.3878, 1.3592, 0.9720, 1.0871,\n",
      "        1.0175, 1.1356, 1.0409, 1.1823, 1.1102, 1.1861, 1.0154, 1.3404, 1.0867,\n",
      "        1.3580, 0.9485, 0.5140, 1.3147, 1.4521, 1.0217, 1.1849, 1.1985, 1.1500,\n",
      "        0.5546, 1.1625, 1.0905, 1.3018, 1.1732, 1.3466, 0.9884, 1.3546, 1.2814,\n",
      "        1.0529, 1.1549, 1.2405, 1.1402, 0.9112, 0.9359, 0.6557, 1.5013, 1.1514,\n",
      "        0.5552, 1.1598, 1.1488, 1.0706, 0.7302, 0.7948, 1.4020, 1.5745, 1.1275,\n",
      "        1.3207, 1.0580, 1.0263, 1.0859, 1.3422, 1.1487, 1.2190, 1.1184, 1.6872,\n",
      "        0.5712, 1.7730, 1.1064, 1.1948, 1.8826, 1.2235, 1.0453, 0.6272, 0.9767,\n",
      "        1.4110, 0.8307, 1.0800, 1.1248, 0.9451, 1.1946, 1.8198, 1.0654, 1.2046,\n",
      "        1.2657, 1.2448, 1.0200, 0.8099, 1.3087, 1.1408, 1.1846, 1.1626, 1.0713,\n",
      "        1.0800, 1.0733, 1.1262, 1.1675, 1.0961, 1.1846, 1.0666, 1.2284, 1.2005,\n",
      "        1.2552, 1.1687, 1.3621, 1.7310, 1.1173, 1.1673, 1.0598, 1.2037, 1.1255,\n",
      "        1.3946, 1.3622, 1.7157, 1.1287, 1.0711, 0.6784, 1.0143, 2.0187, 1.1411,\n",
      "        1.2254, 1.2482, 0.9549, 0.9109, 1.3905, 1.1350, 1.1471, 1.6176, 1.1585,\n",
      "        1.3409, 1.0638, 1.1838, 0.9778, 1.0903, 1.2861, 0.7641, 1.2614, 1.0113,\n",
      "        1.0897, 1.2865, 0.9788, 1.1709, 1.1883, 1.2307, 1.3865, 1.1860, 1.1174,\n",
      "        1.1589, 1.0610, 1.5008, 0.9458, 1.1177, 1.0240, 0.9899, 1.3104, 1.0868,\n",
      "        1.3464, 1.0361, 0.9881, 1.1724, 0.9367, 1.2177, 0.9759, 1.1749, 1.1238,\n",
      "        0.9589, 1.3527, 1.0872, 2.0360, 1.2813, 1.2465, 1.0520, 1.1625, 2.8268,\n",
      "        1.2432, 1.8906, 1.5047, 1.0994, 1.4443, 1.1536, 1.1033, 1.2017, 1.2142,\n",
      "        1.3240, 1.0647, 1.2188, 1.2772, 1.1847, 0.8213, 1.1460, 1.3964, 0.9340,\n",
      "        0.5276, 0.9708, 1.2849, 1.0680, 1.2345, 1.1808, 1.1089, 1.1488, 0.8978,\n",
      "        1.2127, 1.0758, 1.1520, 1.0425, 1.4640, 0.9423, 1.0537, 0.6353, 1.2585,\n",
      "        1.3274, 1.0286, 1.2060, 1.1978, 1.1092, 1.0811, 1.1547, 0.9571, 1.3146,\n",
      "        1.0964, 1.8795, 1.0317, 1.0832, 1.4907, 1.3531, 1.0864, 0.9534, 0.9980,\n",
      "        1.1298, 1.0095, 1.2843, 1.1119, 1.0594, 1.2132, 1.0209, 0.9333, 1.0846,\n",
      "        1.3372, 1.2471, 1.2533, 1.2233, 1.1562, 1.2264, 0.7328, 1.1826, 1.4111,\n",
      "        0.9939, 0.9617, 1.0170, 1.1696, 1.2723, 0.9770, 1.2317, 1.1727, 1.2277,\n",
      "        0.8660, 1.2409, 1.2129, 1.3354, 1.3858, 1.1016, 1.1326, 1.1277, 0.5803,\n",
      "        1.3036, 1.1465, 1.1723, 1.2570, 0.9508, 0.8946, 1.2648, 0.9136, 1.0555,\n",
      "        0.9555, 1.1369, 0.7709, 1.2026, 1.2792, 1.2681, 1.1438, 0.9708, 1.0980,\n",
      "        0.4545, 1.1014, 1.0798, 0.9373, 1.3654, 1.0679, 1.3861, 1.0941, 1.2709,\n",
      "        1.0982, 1.0350, 1.1273, 1.8630, 1.4348, 1.2076, 1.0758, 0.4643, 0.4953,\n",
      "        1.1676, 1.1566, 1.2385, 1.1513, 1.0245, 0.9667, 1.3995, 1.0889, 1.1362,\n",
      "        1.4941, 1.1752, 1.3042, 1.1631, 0.9172, 1.1629, 0.9260, 1.3399, 1.1960,\n",
      "        1.3699, 1.0571, 1.2593, 1.0362, 1.1376, 1.0146, 1.1802, 1.2204, 1.1505,\n",
      "        1.2011, 1.0936, 1.0238, 1.2246, 1.3918, 1.2698, 1.9807, 1.1129, 1.1177,\n",
      "        1.1840, 1.2296, 1.2546, 1.3722, 1.1678, 0.8779, 1.2332, 1.2058, 0.7448,\n",
      "        1.1397, 1.1409, 1.1548, 1.1489, 0.8901, 1.1432, 1.5045, 1.2920, 1.1001,\n",
      "        0.9052, 1.3669, 1.1377, 1.4649, 1.2202, 1.1440, 1.1837, 1.1418, 1.1609,\n",
      "        1.4126, 1.2216, 0.9819, 1.1470, 0.8581, 0.5538, 1.3193, 1.2188, 1.1495,\n",
      "        1.3195, 1.2280, 1.2452, 1.0636, 1.0553, 1.3007, 1.7840, 1.2864, 1.1827,\n",
      "        1.3842, 0.6307, 1.3317, 1.2239, 1.1903, 1.2077, 1.2265, 1.1239, 1.2933,\n",
      "        0.9395, 1.2508, 1.1395, 1.1873, 1.1611, 1.0524, 1.1936, 1.1885, 1.8910,\n",
      "        0.9767, 1.2122, 1.2396, 1.1435, 1.2017, 1.3440, 1.1846, 1.3600, 0.9363,\n",
      "        0.8648, 1.0764, 1.0257, 1.0267, 0.7067, 1.1186, 1.4242, 1.0688, 1.1080,\n",
      "        1.2976, 1.1428, 0.9020, 1.0951, 1.2108, 1.1411, 1.0910, 0.8840, 1.1719,\n",
      "        1.2029, 1.0173, 1.0475, 1.2173, 1.2158, 0.9356, 1.2224, 1.3330, 1.8696,\n",
      "        1.0809, 0.8976, 1.6917, 1.0522, 1.0347, 1.0706, 0.9558, 1.1135, 1.2481,\n",
      "        0.9909, 1.1766, 1.2075, 1.1212, 1.4541, 1.2597, 1.1464, 1.0761, 1.2163,\n",
      "        1.1270, 1.1082, 1.2148, 0.9159, 1.0549, 1.0996, 0.6197, 1.2933, 1.3598,\n",
      "        1.0422, 1.1091, 0.4146, 1.3706, 1.1353, 1.0978, 1.5187, 1.2267, 1.4250,\n",
      "        1.0993, 1.2296, 1.1036, 1.1756, 1.0527, 1.0834, 1.1090, 1.1401, 0.7188,\n",
      "        0.9871, 1.2077, 1.1201, 1.0277, 1.2370, 1.0586, 1.1977, 0.9785, 1.1431,\n",
      "        1.7492, 1.3793, 1.1830, 1.0214, 1.2485, 1.0434, 0.9489, 1.0544, 1.1221,\n",
      "        1.2007, 1.1860, 1.1593, 1.1902, 1.1810, 1.1586, 1.2652, 1.1456, 1.1274,\n",
      "        0.9244, 0.9339, 2.0692, 1.0483, 1.1797, 1.1416, 1.2096, 1.0752, 1.1271,\n",
      "        1.2234, 1.2377, 0.9164, 1.1951, 1.1751, 1.1958, 1.1493, 1.2276, 1.1723,\n",
      "        1.3300, 0.9984, 1.8169, 1.1777, 1.2130, 0.9590, 1.0892, 0.5232, 1.2352,\n",
      "        1.1126, 1.2071, 0.9615, 1.0853, 1.1508, 1.1771, 1.3512, 1.0970, 1.0871,\n",
      "        1.0055, 1.2626, 1.1988, 1.1398, 1.1469, 1.2180, 1.4314, 1.1223, 1.1508,\n",
      "        1.0092, 1.2610, 1.0797, 1.2802, 1.0923, 0.9439, 1.0446, 1.3606, 1.1729,\n",
      "        1.0694, 1.1094, 1.1338, 1.1212, 1.4470, 1.2144, 1.0031, 1.3295, 1.2607,\n",
      "        1.2633, 1.1995, 1.0389, 0.9906, 1.2685, 1.2888, 1.1185, 1.2429, 1.7430,\n",
      "        1.0430, 1.0683, 1.8128, 1.0496, 1.2121, 0.5165, 1.0037, 0.9353, 0.8897,\n",
      "        1.3603, 1.1417, 1.2663, 0.7870, 1.1563, 1.2385, 1.2406, 1.2144, 1.8873,\n",
      "        1.0439, 0.9592, 1.0955, 1.1663, 1.4387, 1.1019, 1.0606, 1.0890, 1.5171,\n",
      "        1.5925, 1.4028, 0.9870, 1.6567, 1.0873, 1.1672, 1.1546, 1.0617, 1.0491,\n",
      "        0.9302, 1.1558, 0.5141, 0.9845, 1.3673, 1.1588, 1.3015, 1.2974, 1.2276,\n",
      "        0.9851, 1.0953, 1.0879, 1.0865, 0.6891, 0.9182, 1.1735, 1.1242, 1.4690,\n",
      "        1.0774, 1.1024, 1.1574, 1.2551, 1.1561, 1.2267, 1.1765, 1.1164, 1.1696,\n",
      "        1.1914, 1.2335, 1.0605, 1.1887, 1.1594, 0.9171, 1.2146, 1.5977, 1.1320,\n",
      "        1.1136, 1.1865, 1.3605, 1.0943, 1.1181, 1.1288, 1.0748, 1.2786, 1.1453,\n",
      "        1.3435, 1.2243, 1.0941, 1.0539, 1.1789, 1.2303, 1.1033, 0.6240, 1.6028,\n",
      "        1.1839, 1.3616, 1.1978, 1.1328, 1.3012, 1.1849, 1.3876, 1.2868, 1.2573,\n",
      "        1.3741, 1.3298, 0.9060, 1.3991, 1.1743, 1.4056, 1.3380, 1.3227, 1.2626,\n",
      "        1.1201, 1.0958, 1.2717, 1.0598, 1.2329, 0.9291, 0.9577, 1.3002, 1.1202,\n",
      "        1.2646, 1.1256, 1.4177, 1.2073, 1.0882, 1.2316, 1.1231, 1.1916, 1.0127,\n",
      "        1.2447, 0.7745, 1.0887, 0.9758, 1.4148, 1.7035, 1.2604, 1.4592, 1.1675,\n",
      "        0.8795, 1.2176, 1.1899, 1.1043, 1.0997, 1.3282, 1.0307, 1.2589, 1.2014,\n",
      "        1.2275, 1.2435, 1.1609, 1.0344, 1.2557, 1.1107, 1.1372, 1.2200, 0.9641,\n",
      "        0.9054, 0.9254, 0.6158, 1.4729, 1.0315, 1.2416, 1.0285, 1.1597, 1.1078,\n",
      "        1.1433, 1.4679, 1.1327, 1.0599, 1.1626, 1.2185, 1.0316, 1.2827, 1.2752,\n",
      "        1.1762, 1.1154, 1.1650, 1.1934, 1.2138, 0.8026, 1.0945, 1.2496, 1.1071,\n",
      "        1.1972, 1.2466, 1.0176, 1.1539, 0.4310, 1.0874, 1.7770, 1.1254, 1.1999,\n",
      "        1.1290, 1.2507, 1.1404, 1.0869, 1.1002, 1.1560, 1.1596, 1.0853, 1.3798,\n",
      "        1.1409, 1.0217, 0.8441, 1.4424, 1.1579, 1.0941, 1.2004, 1.1570, 1.1322,\n",
      "        1.4651, 1.0020, 1.1144, 1.1966, 0.9222, 1.1102, 1.2533, 1.1172, 1.3839,\n",
      "        1.1107, 1.0609, 1.1657, 1.0708, 1.3796, 1.1140, 1.0999, 1.1975, 1.0600,\n",
      "        0.8867, 1.2671, 1.1879, 1.3077, 0.9800, 1.3599, 1.2318, 1.4430, 1.0031,\n",
      "        1.3026, 1.0476, 1.0635, 1.1069, 1.1762, 1.0803, 1.1776, 0.6351, 1.1740,\n",
      "        1.2197, 1.0472, 1.2014, 1.2465, 1.3952, 1.4341, 1.1949, 1.1902, 1.0255,\n",
      "        1.1233, 0.9174, 1.0505, 0.9620, 1.1540, 1.2959, 0.9197, 1.3116, 0.9549,\n",
      "        1.0992, 1.1544, 1.2321, 1.0284, 1.4261, 0.7980], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.0.1.bias\n",
      "Weights: tensor([-8.7007e-01, -4.8041e-01, -3.9488e-01, -1.0840e+00, -1.0521e+00,\n",
      "        -7.4641e-01, -4.1211e-01, -8.4041e-01, -6.4251e-01, -8.1812e-01,\n",
      "        -7.2789e-01, -1.1881e+00, -7.7827e-01, -2.7047e-01, -1.1008e+00,\n",
      "        -7.6671e-01, -6.1463e-01, -1.0390e+00, -1.0081e+00,  7.7525e-01,\n",
      "        -9.6957e-01, -1.3609e+00, -1.0023e+00,  2.6909e-01, -7.9082e-01,\n",
      "         1.5269e+00, -6.9646e-01,  1.7012e+00, -7.5340e-01,  1.2071e+00,\n",
      "        -1.0402e+00, -1.1026e+00, -9.9138e-01, -6.9190e-01, -9.9332e-01,\n",
      "         5.9829e-01, -5.7349e-01, -7.0965e-01, -5.5946e-01, -1.2398e+00,\n",
      "        -4.3898e-01, -6.7281e-01, -1.0863e+00,  2.8440e-01, -7.5439e-01,\n",
      "        -1.1037e+00, -7.1672e-01, -7.5317e-01,  9.8112e-01, -4.6733e-01,\n",
      "        -5.9403e-01,  1.3605e-01, -5.2270e-01, -2.2031e-01, -1.0558e+00,\n",
      "        -8.0915e-01, -1.4952e+00, -4.9085e-01, -7.8576e-01, -1.2953e+00,\n",
      "        -8.8194e-01, -9.6047e-01,  9.1252e-01, -1.0554e+00, -6.3340e-01,\n",
      "        -6.4879e-01, -9.9140e-01, -1.1937e+00, -8.7861e-01, -9.6494e-01,\n",
      "        -3.3320e-01, -9.8288e-01,  1.3671e+00,  1.7486e+00, -9.4326e-01,\n",
      "        -3.3522e-01, -8.0245e-01, -7.3134e-01, -5.4505e-01, -1.1150e+00,\n",
      "        -1.0340e+00, -2.9841e-01, -1.2314e+00, -1.9096e-01, -7.2022e-01,\n",
      "        -1.3333e+00, -1.0699e+00, -1.1012e+00, -1.0339e+00, -1.0064e+00,\n",
      "        -9.8016e-01, -7.3287e-01, -7.3636e-01,  8.5526e-02, -4.4037e-02,\n",
      "         1.8607e-01, -8.9632e-02, -3.4198e-01, -1.1192e+00, -8.2071e-01,\n",
      "        -3.9943e-01, -4.7701e-01, -8.7289e-01, -1.0093e+00, -5.4000e-03,\n",
      "        -7.4473e-01, -5.7312e-01, -3.5808e-02, -5.0927e-01, -8.9860e-01,\n",
      "        -4.3826e-01, -1.4646e-01,  7.5926e-01, -1.3357e+00, -6.5477e-01,\n",
      "        -2.4842e-01, -1.0486e+00,  8.5209e-01,  4.8086e-01, -5.6006e-01,\n",
      "         6.4566e-01, -7.9509e-01, -8.2511e-01, -6.1725e-01, -1.0803e+00,\n",
      "        -7.2726e-01, -7.7145e-01, -1.2781e+00, -3.0576e-01, -1.5585e+00,\n",
      "        -9.1833e-01, -6.6179e-01, -9.0467e-01, -1.2178e+00, -1.2216e+00,\n",
      "        -8.7628e-01, -5.4967e-01,  1.3622e+00, -8.1755e-01, -9.5292e-01,\n",
      "        -4.1386e-01, -1.0978e+00, -4.1453e-01, -9.9352e-01,  1.3835e+00,\n",
      "        -6.5662e-01, -8.1551e-01, -7.6722e-01, -3.1247e-01,  3.0490e-01,\n",
      "        -2.2622e-02,  1.4351e-01, -6.3547e-01, -1.1562e+00,  7.7549e-02,\n",
      "        -8.2373e-01, -4.6235e-01, -1.6498e-01, -1.0329e+00,  1.1713e+00,\n",
      "        -1.1535e+00, -1.6001e+00,  1.5387e+00, -1.3711e+00, -1.1236e+00,\n",
      "         7.7802e-01, -3.6273e-01,  9.7933e-01, -1.1847e+00,  2.7919e-01,\n",
      "        -8.4495e-01, -2.2598e-01, -9.9886e-01, -7.4802e-01, -5.1104e-01,\n",
      "        -8.9318e-01, -1.0534e+00, -7.7348e-01, -9.4078e-01, -1.1755e+00,\n",
      "         1.3539e+00, -1.9585e-01, -8.6296e-01, -7.5446e-01, -1.1012e+00,\n",
      "        -8.7311e-01, -7.3291e-01,  1.2283e+00, -2.4039e-01, -7.4838e-01,\n",
      "        -8.7804e-02, -5.5860e-01, -9.2190e-01, -3.9560e-01, -9.9463e-01,\n",
      "        -4.5369e-01, -9.0233e-01, -8.0050e-01, -6.0245e-01, -1.3321e+00,\n",
      "        -7.0541e-01,  1.5524e+00, -8.5557e-01, -5.7699e-01, -1.1335e+00,\n",
      "        -7.0244e-01, -8.5731e-01, -1.1947e+00, -4.5258e-01, -7.1543e-01,\n",
      "        -8.0039e-01, -7.5565e-01, -7.0040e-01, -3.5678e-01, -4.5826e-01,\n",
      "        -1.0829e+00, -1.1594e+00, -6.1747e-01, -1.1799e+00, -8.2975e-01,\n",
      "        -1.2143e+00, -1.5229e+00, -1.2142e+00, -5.5775e-01, -9.8782e-01,\n",
      "        -1.0354e+00, -1.1674e+00,  1.8411e+00, -2.7947e-01, -9.1546e-01,\n",
      "         1.5370e+00, -6.7948e-01, -7.8440e-01, -8.3725e-01, -5.6790e-01,\n",
      "         4.9891e-01, -8.0191e-01, -9.6857e-01, -1.0965e+00, -1.2750e+00,\n",
      "        -8.6108e-01, -1.5099e+00, -1.2972e+00, -1.2284e-01, -7.8435e-01,\n",
      "        -7.7853e-01, -5.9243e-01, -9.1819e-01, -5.9724e-01,  1.0392e+00,\n",
      "        -7.1961e-01, -7.4948e-01, -7.8781e-01, -2.8313e-01, -7.7056e-01,\n",
      "        -6.3518e-01, -8.3860e-01, -8.4557e-01,  1.1386e-01, -1.1459e+00,\n",
      "        -9.5067e-01, -1.1367e+00, -8.5222e-01, -5.7608e-01, -7.2881e-01,\n",
      "        -8.4667e-01, -2.0918e-01, -4.9375e-01, -5.5328e-01, -7.9185e-01,\n",
      "        -3.7105e-01, -9.2154e-01, -5.2033e-01, -6.9296e-01,  1.0433e+00,\n",
      "        -1.0489e+00, -4.8048e-01, -4.0103e-01, -5.8024e-01,  1.3573e+00,\n",
      "        -6.4145e-01, -5.6518e-01, -3.2046e-01, -1.1292e+00, -8.3604e-01,\n",
      "        -6.6761e-01, -1.0207e+00, -1.4309e+00, -1.1961e+00, -1.4035e+00,\n",
      "         3.9862e-02, -1.1515e+00, -1.0802e+00, -7.9675e-01, -7.8732e-01,\n",
      "        -9.7887e-01, -5.5925e-01, -6.5280e-01, -5.3422e-01, -1.4946e+00,\n",
      "        -4.6016e-01, -1.1101e+00, -3.1886e-01, -1.1605e+00,  6.5122e-01,\n",
      "        -5.7268e-01,  1.3895e+00, -5.6506e-02, -1.3012e+00, -5.6216e-01,\n",
      "        -8.0027e-01, -1.0459e+00, -8.6712e-01, -4.5194e-01, -5.4588e-01,\n",
      "        -8.1242e-01,  5.3424e-01, -1.1249e+00, -7.9425e-01,  5.9849e-01,\n",
      "        -2.3146e-01, -1.3443e+00,  1.2787e+00, -7.5414e-01, -6.0842e-01,\n",
      "        -4.9262e-01, -8.9493e-01, -7.4211e-01, -4.2155e-01, -1.0704e+00,\n",
      "        -1.3014e+00, -7.8659e-01, -5.7214e-01, -1.2015e+00, -1.2861e+00,\n",
      "        -1.1093e+00,  2.0554e-01, -8.3689e-01, -1.0766e+00, -7.0501e-01,\n",
      "        -7.6212e-01, -3.8770e-01,  5.3828e-01, -8.9898e-01, -1.3691e+00,\n",
      "        -8.8655e-01, -8.7511e-01, -8.4498e-01, -1.2812e-01, -6.4580e-01,\n",
      "        -3.7022e-01, -5.6434e-01, -1.3828e+00, -1.0765e+00, -7.3411e-01,\n",
      "        -1.3407e+00, -9.2049e-01,  1.1123e+00, -7.6135e-01, -8.2910e-01,\n",
      "        -6.0494e-01, -8.0528e-01, -6.1469e-01, -7.5197e-01, -3.8817e-01,\n",
      "        -1.4723e-01, -4.1217e-01, -6.2019e-01, -5.1364e-01,  9.2885e-01,\n",
      "        -1.2180e+00, -6.6824e-01, -4.4785e-01, -9.6981e-01, -1.0888e+00,\n",
      "        -1.2671e+00, -1.2535e+00,  1.1647e+00, -6.2083e-01, -9.3097e-01,\n",
      "        -8.1980e-01, -9.4716e-01, -1.1382e-01, -1.8100e-01, -9.9823e-01,\n",
      "        -1.9452e-01, -7.5240e-01, -8.7709e-01, -8.4976e-01,  1.0351e+00,\n",
      "        -5.7279e-01, -2.6757e-01, -1.5428e+00, -1.1328e+00,  1.1254e-01,\n",
      "        -8.0132e-01,  1.2256e+00, -4.6071e-01, -1.4041e+00, -6.7351e-01,\n",
      "         1.8943e+00,  1.0495e+00, -1.1112e+00, -2.2161e-01, -4.5264e-01,\n",
      "        -7.3609e-01, -9.8826e-01, -1.0724e+00,  1.2904e+00, -1.2163e+00,\n",
      "         1.0129e-01, -9.0095e-01,  1.2489e+00,  1.2078e+00, -1.0114e+00,\n",
      "         5.9100e-01, -6.0782e-01, -1.2544e+00, -1.0638e+00, -2.8467e-02,\n",
      "        -1.2526e+00, -7.7422e-01, -4.3935e-01,  6.9557e-02, -7.7339e-01,\n",
      "        -9.5045e-01, -7.2053e-01, -7.1353e-01, -9.4575e-01,  1.6096e-01,\n",
      "        -6.4532e-01, -7.3376e-01, -6.6687e-01, -7.6235e-01,  1.2769e-01,\n",
      "        -1.3082e+00, -9.6715e-01, -6.5385e-01, -6.9240e-01,  1.5634e-02,\n",
      "        -8.3238e-01, -8.8397e-01, -1.0672e+00, -9.6628e-01, -1.0247e+00,\n",
      "        -2.9625e-01, -1.3296e-02, -1.2394e+00, -1.0636e+00, -6.3193e-01,\n",
      "        -1.1434e+00,  6.9823e-01, -5.6163e-01, -1.1708e+00, -6.7806e-01,\n",
      "         1.4222e+00, -9.7400e-01, -8.0020e-01, -2.5219e-01, -8.1897e-01,\n",
      "        -8.7378e-01, -1.1333e+00, -7.3476e-01, -8.8053e-01, -6.2699e-02,\n",
      "        -9.8575e-01, -1.2465e+00, -1.2385e+00, -2.7312e-01, -5.4973e-01,\n",
      "        -6.2511e-01, -8.4179e-01, -1.1485e+00, -7.4539e-01, -2.8541e-01,\n",
      "        -1.1456e+00, -1.0557e+00, -8.0273e-01, -1.0177e+00, -3.3927e-01,\n",
      "        -6.6803e-01,  5.8888e-01,  1.3236e+00,  1.2906e-01, -8.3115e-01,\n",
      "        -8.5767e-01, -9.7503e-02, -9.0530e-01,  2.3347e-01, -7.4270e-01,\n",
      "        -9.3015e-01, -3.5350e-02, -9.8496e-01,  8.2963e-02, -1.3290e+00,\n",
      "        -5.7949e-01,  1.1815e+00, -9.7422e-01, -7.9956e-01, -2.8604e-01,\n",
      "        -9.3768e-01, -2.2295e-01, -1.1936e-01, -9.7270e-01, -6.5197e-01,\n",
      "        -3.5886e-01, -6.7779e-01, -2.0287e-01, -9.0051e-01, -7.2788e-01,\n",
      "        -8.2416e-01,  1.2307e-01, -7.5160e-01, -8.6455e-01,  5.3431e-01,\n",
      "        -1.0078e+00, -7.6090e-01, -6.5442e-01, -9.2044e-01, -1.0340e+00,\n",
      "        -7.6056e-01,  6.9593e-02,  1.1570e+00, -1.2025e+00, -8.1045e-01,\n",
      "         1.5762e+00,  1.0355e+00, -7.3802e-01, -8.7857e-01, -2.7727e-01,\n",
      "        -1.2263e+00, -6.7678e-01, -9.9524e-01, -1.0119e+00, -4.6559e-01,\n",
      "        -6.0247e-01,  4.4470e-01, -5.3364e-01, -2.0897e-01, -9.5669e-01,\n",
      "        -1.4179e+00, -3.1756e-01, -8.0817e-01, -7.7342e-01, -9.0818e-01,\n",
      "        -1.2291e-01, -1.0499e+00, -6.3579e-01, -1.3413e+00, -7.2617e-01,\n",
      "        -3.7888e-02, -3.1723e-01, -3.6858e-01, -1.0628e+00, -1.2936e+00,\n",
      "         1.4439e-01, -7.5175e-01, -8.7679e-01, -9.4452e-01, -9.1185e-01,\n",
      "        -3.7743e-01, -6.8427e-01, -4.8270e-01, -4.6427e-01, -1.0187e+00,\n",
      "        -8.1989e-01, -7.0672e-01, -6.7032e-01, -1.3357e+00, -8.9167e-01,\n",
      "        -6.6680e-01, -8.6036e-01, -9.5876e-01,  1.4796e+00, -8.7902e-01,\n",
      "        -5.3537e-01,  5.7721e-01, -1.1307e+00,  1.2484e+00, -5.1061e-01,\n",
      "        -9.9787e-01, -7.4566e-01,  1.9463e-01, -1.5762e-01, -6.1983e-01,\n",
      "        -1.1995e+00, -1.0510e+00, -6.1314e-01,  1.1936e+00, -5.3323e-01,\n",
      "        -1.2398e+00, -5.3519e-01, -7.1303e-01,  5.7844e-01,  4.4322e-02,\n",
      "        -1.0782e+00, -7.4498e-01, -5.2612e-01, -4.8679e-01, -6.2347e-01,\n",
      "        -1.1906e-01, -1.0862e+00, -1.3553e+00,  2.8185e-01, -1.3553e+00,\n",
      "        -8.2809e-01, -2.0696e-01, -4.8617e-01, -2.5230e-01, -4.5957e-01,\n",
      "        -9.8299e-01,  6.4168e-01, -7.7739e-01,  3.0727e-01, -1.2787e+00,\n",
      "        -5.4346e-01, -5.8409e-01, -8.8162e-01, -7.9848e-01, -7.8904e-01,\n",
      "        -1.0398e-02,  8.0172e-01, -2.2951e-01, -1.1211e+00, -9.3402e-01,\n",
      "        -7.0589e-01, -1.0840e+00, -6.6688e-01, -6.9906e-01, -1.1256e+00,\n",
      "        -7.4277e-01, -7.8674e-01, -2.8906e-02, -2.5370e-01, -5.0291e-01,\n",
      "        -1.0972e+00, -6.2841e-01, -3.6407e-01, -1.2514e+00, -1.0861e+00,\n",
      "         8.1287e-02, -1.2341e-01, -1.0496e+00, -1.0644e+00, -8.2415e-01,\n",
      "        -1.0365e+00,  1.3288e+00, -5.9424e-01, -7.1404e-01, -5.4033e-01,\n",
      "        -8.7963e-01, -5.2149e-01, -7.0078e-01, -9.7678e-01, -6.4786e-01,\n",
      "        -3.6397e-01, -7.0006e-01, -9.9290e-01, -4.3363e-01, -5.3613e-01,\n",
      "        -9.1764e-01, -4.5087e-01, -1.3940e+00, -1.0072e+00, -7.5657e-01,\n",
      "        -8.3429e-01, -8.2408e-01, -3.9467e-01, -1.0125e+00, -7.7371e-01,\n",
      "         1.4873e+00, -1.0411e+00, -1.0349e+00, -7.4756e-01, -9.7777e-01,\n",
      "        -1.0262e+00, -1.0948e+00, -1.1392e+00, -3.9797e-01, -1.2393e-01,\n",
      "        -1.4584e+00, -8.1482e-01, -8.5643e-01, -1.2328e+00,  3.1607e-04,\n",
      "        -4.1837e-01, -1.0671e-01, -6.5056e-01, -4.7685e-01, -8.0500e-01,\n",
      "         6.9434e-01, -4.3879e-01, -6.2023e-01, -1.5536e-01, -1.0602e+00,\n",
      "        -5.5021e-01, -7.0980e-01, -6.2662e-01,  1.3323e+00, -4.7604e-01,\n",
      "        -5.2645e-01, -6.3433e-01, -8.3293e-01,  4.1350e-01, -8.5338e-01,\n",
      "         1.1553e+00, -7.8002e-01, -7.7313e-01,  5.0840e-01, -3.2096e-01,\n",
      "         8.2950e-01, -1.0117e+00, -5.0751e-01, -7.5923e-01, -8.4524e-01,\n",
      "        -1.2180e+00, -7.6912e-01, -1.2923e+00, -6.3148e-01, -9.0004e-01,\n",
      "        -2.3183e-01, -6.8277e-01,  1.1904e-01, -1.0615e+00, -8.2570e-01,\n",
      "        -3.8923e-01, -6.3869e-01, -6.4314e-01, -8.3839e-01, -9.2041e-01,\n",
      "        -6.9861e-01,  1.5037e+00, -4.9579e-01, -8.8492e-01, -6.4084e-01,\n",
      "        -8.5981e-02,  8.2541e-02, -6.8523e-01, -4.8327e-01, -6.2659e-01,\n",
      "        -4.5340e-01, -1.3787e+00, -3.0779e-01, -8.3912e-02, -8.2263e-01,\n",
      "        -1.1984e+00, -9.5331e-01,  1.3605e-01, -9.1783e-01, -9.6991e-01,\n",
      "        -7.7407e-01, -1.1557e+00, -9.0664e-01, -7.5820e-01, -6.6964e-01,\n",
      "        -1.1810e+00, -2.5609e-01, -1.3674e+00, -8.5312e-01, -9.7928e-01,\n",
      "        -7.7661e-01, -9.9744e-01,  5.6366e-01, -5.7008e-01, -3.1684e-01,\n",
      "        -1.0085e+00, -5.4843e-01, -9.1353e-01, -8.0671e-01, -5.2555e-01,\n",
      "        -7.6502e-01, -3.4291e-01, -7.6447e-01, -9.4081e-01,  3.5583e-01,\n",
      "        -1.2003e+00, -8.7628e-01, -8.6149e-01, -5.8954e-01, -7.5184e-01,\n",
      "        -3.6255e-01,  2.9214e+00, -1.6814e+00, -6.5614e-01, -7.6957e-01,\n",
      "        -1.4946e+00, -8.5269e-01,  4.6887e-01,  3.4996e-01, -7.7400e-01,\n",
      "        -5.8103e-01, -4.2580e-02, -3.0026e-01, -6.2726e-01, -4.3378e-01,\n",
      "        -2.9948e-02, -1.0037e+00, -2.6220e-01, -6.1995e-02, -9.1846e-01,\n",
      "        -9.5776e-01, -1.2310e+00, -1.0779e+00, -3.5398e-01, -1.2414e+00,\n",
      "        -1.1467e+00,  1.5563e+00, -4.0335e-01,  1.1315e+00, -1.2223e+00,\n",
      "        -1.1574e+00, -1.0923e+00, -7.3038e-01, -1.0891e+00, -1.1091e+00,\n",
      "        -1.3208e+00, -8.9400e-01, -7.6963e-01, -5.4631e-01, -1.0357e+00,\n",
      "         9.2335e-01, -1.2502e+00, -8.9445e-01, -1.1116e+00,  7.9903e-01,\n",
      "        -3.6437e-01, -9.2716e-01, -1.3485e+00,  5.7721e-01, -6.7214e-01,\n",
      "        -9.1139e-01, -6.1674e-01, -1.1362e+00, -1.3416e-03, -7.7286e-01,\n",
      "        -4.5785e-01, -6.5970e-01, -7.2355e-01, -8.8723e-01, -8.0770e-01,\n",
      "        -9.0912e-01, -6.0693e-01, -8.2711e-01, -1.1069e+00, -9.6960e-01,\n",
      "        -7.6480e-01, -5.1899e-01, -5.4280e-01,  1.6039e+00, -1.1548e+00,\n",
      "        -8.8935e-01, -4.6674e-01, -7.5294e-01, -1.1867e+00, -8.5284e-01,\n",
      "        -8.2388e-01, -6.9340e-01, -7.2715e-01, -1.1559e+00,  7.3237e-01,\n",
      "        -1.1956e+00, -1.0234e+00,  8.2745e-02, -6.4497e-01, -8.7165e-01,\n",
      "        -9.6508e-01, -9.1956e-01, -1.3222e+00, -1.0022e+00,  9.6649e-01,\n",
      "        -8.5816e-01, -1.0598e+00, -6.6324e-01,  2.7906e-01, -8.4632e-01,\n",
      "        -5.6552e-01, -5.7879e-01,  1.0889e+00, -9.5100e-01, -7.4023e-01,\n",
      "        -9.0626e-01, -2.1790e-01, -8.3817e-01, -1.6773e+00, -7.1517e-01,\n",
      "        -7.5572e-01,  1.4614e-01, -9.8426e-01, -5.1607e-01, -7.6655e-01,\n",
      "        -1.7402e+00, -7.9207e-01, -6.8897e-01, -2.0438e-01, -1.0678e+00,\n",
      "        -1.2826e+00, -8.3207e-01, -8.4067e-01, -1.0068e+00, -8.5198e-01,\n",
      "        -6.6772e-01, -8.7422e-01, -5.4337e-01, -9.5822e-01,  1.0017e+00,\n",
      "        -9.4836e-01, -9.5782e-01, -8.4735e-01, -8.1481e-01, -5.4998e-01,\n",
      "        -4.8486e-01, -9.8552e-01, -8.4593e-01, -3.6875e-01, -6.1053e-01,\n",
      "        -6.9147e-01, -5.2535e-01, -6.7843e-01, -4.3001e-01, -8.2579e-01,\n",
      "        -1.2099e+00, -4.3289e-01, -7.8390e-01, -2.1110e-01, -4.7325e-01,\n",
      "        -1.8447e-01, -5.9307e-01, -5.6624e-01, -1.9224e-01, -9.2398e-01,\n",
      "        -8.6332e-01, -4.6482e-01, -1.1265e+00, -1.0009e+00, -7.1501e-02,\n",
      "        -8.4673e-01, -1.0622e+00, -5.5951e-01, -8.6174e-01, -1.0917e+00,\n",
      "        -9.5259e-01, -9.2726e-02, -6.2837e-01, -6.5700e-01, -8.9124e-01,\n",
      "        -1.1094e+00, -5.7060e-01, -1.0382e+00, -2.9362e-01, -9.4134e-01,\n",
      "         2.3400e-01, -5.8797e-01, -1.2064e+00, -3.4123e-01, -3.8593e-01,\n",
      "        -8.1553e-01, -6.7636e-01, -1.7350e-01, -9.9678e-01,  1.0997e+00],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.1.0.weight\n",
      "Weights: tensor([[[[-0.0374, -0.0797, -0.0440],\n",
      "          [-0.0817, -0.0449, -0.0802],\n",
      "          [-0.0510, -0.0868, -0.0536]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0798,  0.0697,  0.0811],\n",
      "          [ 0.0590,  0.0880,  0.0541],\n",
      "          [ 0.0738,  0.0610,  0.0756]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3262, -0.0494,  0.3328],\n",
      "          [ 0.0016, -0.3545, -0.0064],\n",
      "          [ 0.1280, -0.1280,  0.1204]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0448,  0.0889,  0.0493],\n",
      "          [ 0.0948,  0.1191,  0.0952],\n",
      "          [ 0.0618,  0.0951,  0.0663]]],\n",
      "\n",
      "\n",
      "        [[[-0.0515, -0.0787, -0.0486],\n",
      "          [-0.0708, -0.0692, -0.0806],\n",
      "          [-0.0520, -0.0780, -0.0599]]],\n",
      "\n",
      "\n",
      "        [[[-0.0661, -0.0871, -0.0677],\n",
      "          [-0.0844, -0.0619, -0.0910],\n",
      "          [-0.0737, -0.0904, -0.0691]]]], device='cuda:0')\n",
      "Shape: torch.Size([960, 1, 3, 3])\n",
      "\n",
      "Layer: features.17.conv.1.1.weight\n",
      "Weights: tensor([0.7587, 1.0664, 0.9705, 0.6082, 0.7812, 0.7878, 0.6075, 0.7936, 0.8870,\n",
      "        1.0368, 0.5334, 0.5831, 0.6696, 0.7771, 1.0082, 1.1344, 0.5582, 0.6761,\n",
      "        1.9203, 1.5345, 0.7622, 0.9057, 0.9129, 0.8063, 0.8314, 2.3288, 0.5858,\n",
      "        2.2591, 1.3567, 1.4320, 0.6711, 1.4772, 0.9889, 0.9211, 0.8904, 1.0256,\n",
      "        0.5789, 0.5701, 1.1698, 0.7213, 0.9732, 0.5093, 0.7124, 1.1624, 0.4908,\n",
      "        0.6800, 0.5939, 0.8533, 1.3514, 1.1481, 1.0865, 1.4354, 0.9105, 1.0940,\n",
      "        1.2686, 1.3776, 0.7773, 2.0565, 0.7616, 0.7070, 0.5508, 0.5787, 1.5386,\n",
      "        0.6691, 0.8811, 0.7028, 0.5752, 0.5422, 0.8223, 0.7076, 1.4864, 0.5488,\n",
      "        1.5501, 2.5208, 0.6455, 0.8321, 0.6538, 0.6959, 1.1856, 0.3516, 0.5158,\n",
      "        0.8066, 0.7978, 1.1485, 0.8331, 0.5523, 0.5358, 0.5882, 0.5461, 0.5065,\n",
      "        0.6259, 0.7775, 0.7970, 0.9614, 0.9105, 1.4090, 1.4759, 1.0065, 0.6589,\n",
      "        1.3362, 0.8483, 1.2836, 0.5555, 0.6484, 1.7035, 0.5763, 0.9487, 1.3715,\n",
      "        0.8254, 0.7428, 0.9394, 0.6388, 1.2328, 0.5573, 0.8811, 0.9473, 0.6521,\n",
      "        1.6287, 1.4338, 0.9296, 1.3734, 0.5636, 0.5720, 0.5848, 0.7023, 0.9326,\n",
      "        0.6355, 0.4733, 1.2563, 0.6182, 0.6673, 0.9119, 0.6702, 0.9529, 0.6456,\n",
      "        0.5558, 1.0551, 1.6924, 0.6318, 0.9611, 1.0017, 0.4924, 0.5773, 0.7533,\n",
      "        1.6367, 0.5137, 0.8998, 0.6067, 2.0592, 1.3863, 2.5879, 1.5236, 1.9661,\n",
      "        0.6047, 1.9058, 0.5817, 0.6042, 0.9441, 0.5708, 1.8214, 0.5975, 0.5170,\n",
      "        2.0205, 0.7226, 0.7123, 1.5199, 0.9606, 1.2712, 1.3232, 1.4577, 0.8369,\n",
      "        0.8351, 0.6559, 1.1761, 1.2447, 1.4653, 0.7371, 0.5316, 0.5512, 1.3035,\n",
      "        1.6551, 1.1269, 0.6104, 0.9549, 0.6955, 0.8394, 0.9233, 1.5016, 1.3674,\n",
      "        1.2155, 0.9076, 0.8814, 0.6895, 1.0577, 0.7058, 1.0133, 0.6170, 0.6981,\n",
      "        0.6465, 0.8558, 0.7862, 1.1409, 1.1637, 0.9293, 0.7379, 0.8444, 0.6293,\n",
      "        0.6710, 1.0281, 0.6369, 0.8581, 0.8065, 1.2208, 0.8770, 0.9425, 0.8310,\n",
      "        0.6585, 0.6993, 1.0934, 3.5703, 0.6635, 0.6288, 0.6711, 0.9483, 0.5454,\n",
      "        0.6046, 1.2709, 2.3365, 1.0654, 0.7535, 1.9913, 0.9633, 1.0635, 0.5958,\n",
      "        0.5756, 1.5387, 0.6483, 0.6165, 0.9288, 0.6432, 0.5571, 1.1255, 0.6877,\n",
      "        1.0329, 0.6925, 0.5874, 0.8346, 0.9654, 0.5674, 1.7405, 0.9987, 0.7529,\n",
      "        0.7770, 1.7009, 0.7985, 1.7518, 0.5632, 0.7565, 1.1755, 0.5175, 0.8128,\n",
      "        0.5739, 0.8853, 1.2051, 0.7004, 1.0302, 0.9307, 1.0529, 0.8661, 0.5188,\n",
      "        0.8718, 0.7607, 1.1962, 0.5663, 1.7853, 0.7294, 1.5382, 0.9048, 1.0748,\n",
      "        1.3870, 0.7219, 0.5314, 1.5559, 0.5351, 0.8246, 0.9361, 0.5502, 1.8910,\n",
      "        1.0733, 1.0342, 1.4895, 0.6557, 1.2132, 0.8106, 1.0794, 0.8649, 1.0292,\n",
      "        1.0744, 1.1541, 0.4776, 0.6958, 0.6945, 1.2526, 0.7283, 0.7028, 0.9903,\n",
      "        1.3398, 1.2330, 0.7571, 0.7281, 1.0747, 0.8898, 0.7464, 0.8764, 0.6743,\n",
      "        0.5631, 1.3260, 0.5710, 0.8039, 1.3770, 0.8872, 0.6004, 1.7430, 1.1765,\n",
      "        0.6556, 0.9857, 0.7798, 0.8653, 0.8686, 0.5188, 0.5162, 0.7288, 0.7111,\n",
      "        0.4919, 0.6298, 0.7297, 1.1827, 1.9145, 0.5620, 0.5695, 0.7586, 0.9055,\n",
      "        1.4267, 0.8885, 0.8819, 0.5170, 0.8941, 0.5242, 0.9635, 0.8390, 1.7875,\n",
      "        0.7824, 0.5324, 0.7111, 0.5640, 0.6278, 0.7590, 1.7346, 0.5653, 1.0730,\n",
      "        1.1302, 0.7190, 0.7547, 1.0680, 0.8851, 1.0108, 0.5835, 0.5683, 0.5555,\n",
      "        0.8675, 0.5251, 1.6061, 0.6329, 1.2068, 0.8895, 0.6511, 0.5724, 0.7917,\n",
      "        1.4587, 0.9412, 1.1447, 0.5180, 1.0823, 0.9537, 0.7763, 1.3692, 0.9814,\n",
      "        0.7411, 0.8954, 1.7923, 0.5611, 1.0508, 0.5627, 0.5508, 0.9988, 0.6707,\n",
      "        1.1065, 0.5749, 0.5301, 0.8364, 1.5495, 1.8188, 0.8246, 1.7332, 1.0611,\n",
      "        0.8968, 0.4849, 0.7644, 1.5050, 0.9194, 1.0088, 0.7762, 1.5382, 1.6735,\n",
      "        0.5355, 2.1029, 0.6111, 0.5820, 0.7909, 0.9374, 0.8603, 0.7484, 0.5738,\n",
      "        1.3661, 0.8186, 1.0640, 0.5567, 1.0454, 0.6780, 1.6733, 0.6158, 0.5625,\n",
      "        1.4702, 0.6467, 1.0085, 0.6637, 0.5809, 0.5416, 1.2362, 0.8241, 0.8063,\n",
      "        0.9943, 0.7541, 0.7035, 0.5827, 0.4946, 1.0205, 0.7479, 0.7849, 0.8279,\n",
      "        0.7131, 1.6224, 0.6039, 0.5734, 0.5463, 2.1434, 0.8288, 0.5482, 0.8168,\n",
      "        0.5864, 0.8184, 0.6240, 0.5558, 0.7693, 1.0950, 1.0674, 0.5378, 0.8111,\n",
      "        1.0255, 0.8071, 1.1438, 0.7899, 0.7178, 0.5697, 1.7313, 0.5375, 0.5582,\n",
      "        0.6250, 0.7562, 0.8995, 1.0144, 1.6962, 1.7325, 1.1181, 0.8333, 0.6116,\n",
      "        1.1146, 0.9563, 0.8680, 0.8136, 0.6681, 0.8460, 0.7428, 2.0466, 0.8286,\n",
      "        1.7539, 1.8633, 0.5533, 1.2574, 0.8157, 0.9576, 0.7358, 1.1000, 0.8401,\n",
      "        0.7786, 1.2233, 0.5533, 1.4082, 0.5768, 1.0057, 0.5578, 1.3610, 2.5851,\n",
      "        0.6079, 1.5519, 1.0206, 1.0129, 0.5734, 0.6347, 0.7675, 0.6048, 1.5151,\n",
      "        1.7394, 0.6235, 0.5592, 1.3990, 1.0454, 0.5630, 1.2370, 1.0151, 0.6798,\n",
      "        1.2653, 0.8508, 0.5965, 1.1471, 0.5580, 1.2267, 0.5526, 0.9185, 0.6140,\n",
      "        0.6017, 1.0826, 0.8651, 0.5809, 1.0535, 0.9282, 0.5865, 0.9076, 0.9328,\n",
      "        0.8723, 1.2119, 1.1979, 1.0913, 0.6763, 0.5875, 1.5110, 0.9235, 0.7256,\n",
      "        0.7886, 0.6432, 0.7194, 0.5130, 0.7171, 0.6432, 0.5273, 0.8609, 0.5557,\n",
      "        0.5716, 0.5785, 0.7271, 0.7649, 0.5113, 0.6941, 1.8621, 0.7144, 1.4813,\n",
      "        1.2118, 0.5997, 1.3182, 1.4860, 0.5143, 0.5789, 1.7184, 1.2996, 0.7793,\n",
      "        0.5120, 0.7325, 0.5360, 2.8055, 1.0204, 0.6400, 1.5173, 0.5416, 1.5430,\n",
      "        1.2931, 0.5621, 0.9018, 1.0160, 0.9147, 0.9251, 0.5801, 0.6659, 0.6853,\n",
      "        1.0345, 1.2581, 0.5457, 1.0502, 0.8944, 0.8209, 1.0546, 0.5165, 1.5800,\n",
      "        0.5708, 1.2275, 0.5927, 0.5517, 1.2237, 0.5624, 0.6583, 0.9011, 0.9232,\n",
      "        0.9331, 1.1311, 2.4525, 0.7155, 1.0393, 0.6836, 0.8102, 0.7833, 0.6574,\n",
      "        0.5713, 0.6847, 1.2508, 0.5897, 0.5398, 0.6685, 0.7851, 0.7153, 0.8129,\n",
      "        0.5710, 2.0822, 1.1100, 1.1336, 0.7264, 0.7757, 0.7156, 1.6686, 0.6171,\n",
      "        0.5673, 0.5374, 0.7898, 0.9426, 0.9129, 0.9329, 0.9403, 0.8765, 0.8839,\n",
      "        0.4954, 1.4239, 1.5968, 0.5651, 1.5305, 0.5305, 0.9298, 0.9450, 0.8478,\n",
      "        0.6647, 0.5407, 0.6463, 0.9635, 3.5926, 0.7540, 0.6425, 0.8262, 0.5197,\n",
      "        0.6102, 0.7822, 0.7164, 0.5786, 0.9843, 0.5377, 0.7399, 1.7398, 0.8439,\n",
      "        0.8191, 0.5846, 1.3614, 0.7749, 0.6242, 0.6215, 1.7327, 0.6890, 0.9841,\n",
      "        0.9798, 0.6479, 1.5125, 0.7372, 0.5286, 1.3124, 1.3312, 1.0576, 0.8857,\n",
      "        0.5657, 0.9799, 0.9292, 1.6030, 0.5600, 0.9197, 1.5295, 0.8393, 2.1555,\n",
      "        0.5013, 1.1598, 0.7935, 1.0109, 1.4491, 1.0737, 0.5125, 1.0645, 0.7066,\n",
      "        1.0279, 0.7747, 1.6681, 0.7420, 0.7108, 0.5929, 0.5471, 0.7994, 0.7203,\n",
      "        0.7937, 0.6337, 1.5824, 0.9556, 0.6413, 0.7694, 0.8122, 1.3174, 0.8823,\n",
      "        0.9552, 1.0955, 2.1535, 0.6418, 1.3021, 1.4057, 0.7812, 0.6188, 1.6274,\n",
      "        0.9356, 0.4862, 0.8329, 0.5579, 0.9145, 0.6787, 1.4320, 0.6374, 0.4788,\n",
      "        2.0252, 0.7311, 0.6793, 0.8789, 0.5381, 0.7380, 1.2394, 0.8887, 1.1358,\n",
      "        0.8927, 0.6118, 1.8316, 0.6539, 0.7307, 0.8112, 1.2614, 0.9619, 0.6483,\n",
      "        2.0435, 0.6009, 0.7221, 0.6779, 0.6325, 0.5757, 0.8493, 2.5043, 0.8077,\n",
      "        0.5408, 0.7360, 0.6107, 0.5692, 1.9878, 1.2228, 0.6925, 0.6559, 0.9586,\n",
      "        1.1479, 0.6144, 1.2793, 1.6767, 0.6655, 0.9307, 1.2867, 0.7073, 0.5771,\n",
      "        0.7300, 0.7580, 0.8831, 0.5670, 0.6561, 2.5240, 1.1107, 2.1209, 0.6598,\n",
      "        0.9263, 0.7212, 0.6981, 0.7981, 0.5186, 0.6818, 0.7319, 0.6309, 0.7878,\n",
      "        0.6790, 1.1916, 0.6697, 0.6461, 0.6518, 1.5724, 0.6067, 0.9683, 0.6062,\n",
      "        2.1148, 0.5783, 0.5888, 0.7850, 0.6759, 1.2123, 0.8218, 1.8252, 0.5772,\n",
      "        0.6376, 1.0422, 1.0713, 0.6936, 0.6039, 0.8192, 0.5366, 0.5115, 1.0356,\n",
      "        1.1173, 0.9309, 1.8661, 1.2430, 0.7569, 0.6825, 0.7642, 0.6305, 0.5220,\n",
      "        1.0466, 0.9591, 0.8925, 0.6396, 1.7179, 0.8315, 0.6326, 1.1416, 0.7746,\n",
      "        0.9181, 0.7437, 0.5494, 0.7122, 0.5254, 1.4153, 0.9763, 1.0020, 0.8311,\n",
      "        1.0465, 1.0238, 1.1953, 0.9440, 2.2031, 0.6690, 0.7192, 0.9786, 1.6794,\n",
      "        0.7319, 0.6488, 0.9116, 0.6128, 0.9565, 1.2027, 1.1660, 0.8383, 0.6989,\n",
      "        0.6134, 0.7828, 1.0238, 0.4811, 0.6881, 0.8199, 0.5581, 0.8112, 0.7870,\n",
      "        1.3563, 0.8676, 1.1975, 0.5750, 1.8311, 0.7811, 0.6706, 0.5291, 0.6739,\n",
      "        1.2235, 0.9226, 0.5344, 0.6565, 1.1260, 0.5909, 0.8898, 0.5581, 1.5523,\n",
      "        0.9594, 0.6182, 0.6874, 1.3639, 0.8483, 1.3418, 0.8842, 1.1812, 0.8936,\n",
      "        1.9223, 0.9223, 0.7757, 0.7892, 0.5305, 0.7075, 0.5372, 1.3412, 0.8452,\n",
      "        1.1343, 0.9135, 0.6766, 0.7180, 0.7482, 0.9758, 0.5768, 0.7424, 0.7745,\n",
      "        0.6112, 0.8148, 0.5207, 1.3131, 0.5610, 1.3510, 0.7813, 1.0624, 0.7843,\n",
      "        0.8542, 0.5704, 0.9079, 0.8481, 0.6130, 1.5241], device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.1.1.bias\n",
      "Weights: tensor([ 1.3612e+00, -1.4581e+00,  1.6107e+00,  1.1966e-01, -6.6897e-01,\n",
      "        -3.2968e-01,  2.8615e+00, -7.2919e-03, -8.2911e-01, -6.1160e-01,\n",
      "         2.7219e+00,  2.1528e+00,  1.3834e+00,  1.7660e+00,  7.4900e-02,\n",
      "        -1.4669e+00,  2.7132e+00,  1.5913e+00, -2.3653e+00, -2.6979e-01,\n",
      "        -4.1775e-01,  1.2268e+00, -1.7699e+00,  6.6138e-01,  1.0138e+00,\n",
      "        -1.2110e+00,  2.9969e+00, -1.9202e+00, -1.8954e+00, -5.6541e-01,\n",
      "         1.7380e+00, -2.6009e-01, -8.6394e-01, -7.6715e-01, -8.2517e-01,\n",
      "        -8.3704e-02,  2.8657e+00,  1.6965e+00, -1.8296e+00, -3.6655e-01,\n",
      "        -3.3773e-01,  2.7607e+00, -3.2329e-01,  1.8112e-01,  2.2468e+00,\n",
      "        -1.6934e-01,  1.8308e+00, -6.7473e-01, -2.5122e-01, -1.2947e+00,\n",
      "        -1.0776e+00, -7.7153e-02,  1.6801e+00, -1.1755e+00, -3.9835e-01,\n",
      "        -1.2373e+00, -1.8215e+00, -7.6795e-01, -2.9759e-01, -2.5959e-01,\n",
      "         2.7944e+00,  1.8411e+00, -2.0567e-01,  1.5234e-02, -3.5922e-01,\n",
      "         1.3357e+00,  3.1590e+00,  3.4765e+00, -6.1554e-01, -3.4262e-01,\n",
      "        -1.0704e+00,  3.3149e+00, -7.5551e-01, -2.5937e+00, -8.0624e-02,\n",
      "         4.5163e-01, -1.1910e-01, -2.5226e-01, -1.1624e+00,  1.7902e+00,\n",
      "         2.4029e+00,  8.6172e-01, -4.9098e-01, -1.4802e+00, -5.9383e-01,\n",
      "         1.1908e-01,  3.3327e+00,  1.0888e-03,  3.0821e+00,  3.0301e+00,\n",
      "        -5.7279e-02, -2.9757e-01, -4.0877e-01,  4.1786e-01,  2.8705e+00,\n",
      "         3.5812e-02, -1.5666e+00, -1.1561e+00, -3.2286e-01, -1.5782e+00,\n",
      "         7.6618e-01,  3.5763e-01,  3.4889e+00, -5.2898e-02, -2.9526e+00,\n",
      "         2.1606e+00, -1.0265e+00,  1.6601e-03,  9.5592e-01, -1.6767e-01,\n",
      "        -6.0979e-01,  1.2243e+00,  1.5288e-01, -1.2323e-01,  1.8327e+00,\n",
      "         3.5678e-02, -1.7683e-01, -3.4394e-01, -4.1182e-02, -9.6599e-01,\n",
      "        -8.8563e-02,  2.5892e+00,  2.0098e+00,  2.2309e+00, -9.8329e-02,\n",
      "        -1.0172e+00,  1.6540e+00,  3.8152e+00, -1.8638e+00, -1.8092e-01,\n",
      "        -1.6013e-01, -6.2437e-01, -1.2226e-01, -1.0490e+00, -3.8929e-01,\n",
      "         2.0753e+00, -9.8770e-01, -8.6939e-01,  1.6696e+00,  1.0155e+00,\n",
      "        -8.2252e-01,  3.0450e+00,  1.4655e+00, -4.8703e-01, -9.2438e-01,\n",
      "         2.0807e+00, -9.3019e-01,  1.5440e+00, -1.4108e+00, -1.0660e-01,\n",
      "        -2.4496e+00,  8.3537e-02, -1.5079e+00, -4.9279e-02, -3.2222e+00,\n",
      "         2.4822e+00,  1.7593e+00,  6.6853e-02, -1.7721e-01, -1.1072e+00,\n",
      "         2.1012e+00, -8.0953e-02, -1.6377e+00, -6.4959e-01, -2.7602e-01,\n",
      "        -3.0068e-01,  1.5234e+00, -1.7623e-01, -1.5283e-01,  3.1370e+00,\n",
      "        -5.5981e-01,  8.6045e-01, -3.4433e-01, -1.8293e+00, -1.6063e+00,\n",
      "        -3.0628e+00, -2.9981e-01,  2.4269e+00,  2.6461e+00,  9.8638e-01,\n",
      "        -9.3416e-01,  3.8410e+00,  1.5556e+00, -3.4631e-01,  1.0482e+00,\n",
      "        -6.8717e-01, -7.9012e-01, -7.1508e-01, -1.0464e+00, -1.2377e+00,\n",
      "         3.0849e+00, -6.5599e-01, -3.2198e-01, -1.3291e+00, -1.4213e-01,\n",
      "         6.0606e-01,  2.2621e+00, -3.4967e-01,  1.3444e+00, -1.4581e+00,\n",
      "        -6.1343e-01,  3.5413e+00, -1.9523e+00, -8.6813e-01, -4.9285e-01,\n",
      "        -6.0781e-01,  1.9912e-02, -2.9759e-01, -1.1798e+00,  1.4276e+00,\n",
      "        -9.0183e-01, -5.9997e-01, -1.6385e+00, -3.3684e-01, -9.6220e-01,\n",
      "        -4.8835e-01, -2.0436e-01, -1.3545e-01, -1.6612e+00, -1.0168e+00,\n",
      "        -2.8382e-01, -1.1007e-01, -5.1380e-02, -4.3392e-01,  2.9996e+00,\n",
      "         2.0201e+00,  1.1964e+00, -1.5390e+00, -1.1474e+00, -4.4637e-01,\n",
      "        -1.4178e+00, -1.1934e+00,  1.5670e+00,  2.4791e+00,  1.3343e+00,\n",
      "        -1.9749e-01,  2.6278e-02,  4.0344e-02, -8.0081e-01, -2.5013e-01,\n",
      "         3.1009e+00, -1.2223e+00, -4.4052e-01,  5.1411e-01, -2.7212e-01,\n",
      "         1.6172e+00, -3.6168e-01, -1.1249e+00,  2.0849e+00, -8.3719e-01,\n",
      "         8.6257e-01, -3.5003e-01, -4.0002e-01, -1.6957e+00, -2.8052e-01,\n",
      "        -1.7701e+00,  3.6354e+00,  1.2332e+00,  3.2731e-01,  2.8304e+00,\n",
      "        -3.8827e-01,  3.6190e+00, -5.4439e-01,  7.0811e-01,  1.5873e+00,\n",
      "        -5.0832e-01,  8.1512e-02,  8.1664e-04,  7.0744e-01,  2.4960e+00,\n",
      "         7.8672e-01, -4.8797e-01, -1.2983e+00,  2.4920e+00, -6.9507e-02,\n",
      "        -3.5180e-01, -2.0065e+00,  7.3922e-01, -1.0645e+00, -3.8677e-01,\n",
      "         1.8520e+00,  2.9491e+00, -1.8661e+00,  2.3204e+00,  8.8573e-01,\n",
      "        -8.8509e-01,  3.3309e+00, -1.8726e+00, -1.3883e+00,  2.8384e+00,\n",
      "         7.7064e-02, -1.2329e-01, -2.3607e+00, -5.2309e-01, -8.4040e-01,\n",
      "        -6.2683e-01, -1.0481e+00, -1.2631e+00, -1.1319e+00,  3.4985e+00,\n",
      "         1.2026e+00, -2.8553e-01, -1.4944e+00, -2.8606e-01,  7.3377e-01,\n",
      "        -1.3200e+00, -3.8551e-01, -1.5983e+00, -7.3831e-01, -2.5390e-01,\n",
      "        -1.3576e+00,  1.3198e-03, -6.0160e-01, -4.0921e-01, -9.4315e-02,\n",
      "         2.5038e+00,  1.1070e-01,  1.6386e-01, -4.8175e-01,  1.9640e+00,\n",
      "         2.3225e+00,  1.3091e-02, -9.6090e-01, -3.2102e-01,  1.6761e+00,\n",
      "        -9.7486e-01, -3.7567e-01,  8.8710e-01, -7.1554e-01,  2.8196e+00,\n",
      "         2.6708e+00, -1.8136e-01,  1.2826e+00,  4.4758e+00,  1.9672e+00,\n",
      "        -1.2443e-01,  1.7907e-01, -8.0427e-01,  3.3864e+00,  2.5101e+00,\n",
      "        -3.2428e-01,  2.1186e-02, -1.5530e-01, -1.0311e+00, -6.7175e-01,\n",
      "         2.5794e+00, -1.3950e+00,  2.0442e+00,  3.3366e+00, -7.0287e-01,\n",
      "        -6.1519e-01,  7.9781e-01,  7.7236e-02,  1.7443e+00,  2.7133e+00,\n",
      "        -2.6858e-01,  1.2501e+00, -8.6941e-01,  2.6201e+00,  1.3769e+00,\n",
      "        -1.5473e+00, -1.8152e-01, -3.3245e-01, -1.3976e+00,  7.8833e-01,\n",
      "        -2.5921e-01,  2.0400e+00,  2.9704e+00,  2.7967e+00,  5.1358e-01,\n",
      "         2.8392e+00, -1.1235e+00,  1.0194e+00, -1.4418e+00, -8.9359e-01,\n",
      "        -3.0048e-01,  3.0471e+00,  3.8079e-01,  2.2507e-01, -8.8708e-01,\n",
      "        -1.4143e+00,  2.7862e+00, -1.3153e+00,  2.4989e+00, -4.0791e-01,\n",
      "        -2.5079e+00, -1.2253e+00, -8.9878e-01, -6.9718e-01, -7.6701e-01,\n",
      "         2.5907e+00,  4.8933e-01, -9.6327e-03,  9.0343e-02,  2.6160e+00,\n",
      "        -7.2116e-02,  1.6218e-01,  3.0687e+00, -1.4265e-03, -6.4237e-01,\n",
      "        -8.9607e-01, -1.0061e+00, -4.8482e-01, -1.2013e+00,  4.9607e-01,\n",
      "        -8.6756e-01,  3.4741e+00, -6.2468e-01, -2.0578e+00, -9.6600e-01,\n",
      "         4.4822e-01, -5.8431e-01, -8.1272e-01, -9.5561e-01,  3.5423e+00,\n",
      "        -2.2197e-01,  3.0138e+00,  2.0470e+00, -7.6725e-01,  3.2042e+00,\n",
      "         1.2797e+00, -1.9322e-01,  2.4860e+00,  1.3267e-01, -2.4535e-01,\n",
      "        -1.2688e+00,  1.3759e+00, -1.2234e+00, -2.7105e-01, -2.3814e+00,\n",
      "         1.7489e+00,  2.3447e+00,  5.3102e-01, -4.3485e-02,  5.5479e-01,\n",
      "        -4.2871e-01,  2.0756e+00,  3.1207e+00, -1.5428e+00,  6.4229e-01,\n",
      "        -5.9041e-01, -1.0290e+00, -4.9755e-01, -1.1109e-01,  1.9137e+00,\n",
      "         2.7424e+00,  4.3710e-01,  2.1129e+00, -4.4037e-01, -3.3344e-01,\n",
      "        -3.3834e-01, -2.8485e-01,  1.6619e+00,  1.9493e+00,  2.6130e+00,\n",
      "        -1.4419e+00,  1.0285e+00,  2.5304e+00,  2.4350e+00,  1.8527e+00,\n",
      "        -5.1093e-01,  1.0713e-01,  1.8019e+00, -3.1901e-01, -9.5149e-01,\n",
      "        -8.6441e-01,  2.6737e+00, -9.8428e-01, -1.1026e+00,  1.1935e+00,\n",
      "        -1.6040e+00,  9.4047e-01, -3.4207e-01,  2.7886e+00, -2.6895e+00,\n",
      "         3.1098e+00,  2.1182e+00,  2.5493e+00, -2.0584e-01, -5.2711e-01,\n",
      "        -1.0625e+00, -2.2833e-01, -1.0686e+00,  3.9987e-01, -5.1431e-01,\n",
      "         1.6875e+00,  4.5465e-01, -1.2631e+00,  5.8445e-01, -2.9782e-01,\n",
      "        -2.0363e-01,  5.9190e-01,  3.8582e+00, -2.8443e+00, -5.2476e-01,\n",
      "         2.7781e-01, -1.1698e+00,  2.0599e+00, -1.5630e+00,  8.9582e-01,\n",
      "        -1.1626e+00,  7.9056e-01, -1.2215e+00, -7.2748e-01, -3.5238e-01,\n",
      "        -1.3142e+00,  1.8226e+00, -1.8033e+00,  2.8361e+00, -1.1494e+00,\n",
      "         3.1704e+00, -1.7313e+00, -5.3470e+00,  1.0121e-01, -1.5738e-01,\n",
      "        -1.6081e+00, -7.5735e-01,  2.0050e+00,  1.6509e+00,  5.7606e-02,\n",
      "         1.4009e+00, -1.8641e+00, -4.8647e-01, -8.6311e-02,  8.0940e-02,\n",
      "        -4.1174e-01,  3.2449e-01,  1.5968e+00, -1.4843e+00, -1.8346e-01,\n",
      "        -5.1082e-01, -1.0287e+00, -6.5500e-01, -1.7113e-01, -1.0996e+00,\n",
      "         3.3566e+00,  6.5597e-02,  3.0168e+00,  1.7524e-01, -6.7743e-02,\n",
      "         7.3173e-02, -9.2302e-01, -7.8335e-01,  2.2924e+00, -1.3288e+00,\n",
      "         7.7575e-02,  1.7860e+00,  1.0463e+00,  2.0312e+00, -1.1038e+00,\n",
      "        -1.3351e+00,  2.8198e-01, -1.5075e+00, -2.7841e-01, -1.8122e-01,\n",
      "        -1.9570e+00, -9.3537e-01, -2.6289e-01, -7.9157e-01, -4.0695e-02,\n",
      "         1.1081e+00,  2.9932e+00,  8.8522e-01,  1.3843e+00,  2.9665e+00,\n",
      "        -9.5727e-01,  3.5144e+00,  1.9116e+00,  1.3597e-01,  1.7972e+00,\n",
      "        -4.7913e-01,  2.9003e+00, -2.2984e-01, -1.2844e+00,  1.8899e+00,\n",
      "        -4.1327e-01,  1.1958e-01,  3.0923e-02, -1.1651e-01, -1.4314e+00,\n",
      "         3.1594e+00,  2.3780e+00, -2.7664e-01, -1.7475e+00,  1.3115e+00,\n",
      "         2.4655e-01, -3.5044e-01,  2.1113e+00, -1.8297e+00, -1.1087e+00,\n",
      "        -9.9829e-02, -1.5212e+00,  2.3628e+00, -4.4948e-01, -1.2155e+00,\n",
      "         1.9188e+00, -7.7816e-01, -1.0889e+00, -8.0812e-01, -7.5876e-01,\n",
      "         1.4348e+00,  1.0057e-01, -4.1049e-01,  4.3499e-01, -3.6414e-01,\n",
      "         3.2061e+00, -6.9293e-01, -5.6858e-01,  1.9224e-01, -1.4463e+00,\n",
      "         2.3658e+00, -3.3974e-01,  1.7170e+00,  1.3957e-01,  2.7401e+00,\n",
      "         1.6664e+00, -1.7369e+00,  3.4047e+00,  1.1343e+00, -6.2601e-01,\n",
      "         6.6805e-01,  2.2872e-01, -5.4435e-01, -5.6576e+00, -2.5126e-01,\n",
      "        -8.0014e-01, -2.5854e-01,  9.2482e-01, -3.6210e-01,  1.8531e+00,\n",
      "         2.2861e+00, -2.9500e-02, -6.9242e-01,  2.5382e+00,  1.6595e+00,\n",
      "        -3.5153e-02,  3.2955e+00,  1.6207e-02, -5.9805e-01,  2.3107e+00,\n",
      "        -2.8510e+00,  1.4486e+00, -6.3997e-01, -2.3957e-01, -5.3212e-01,\n",
      "        -3.2289e-01, -7.6050e-01,  2.0191e+00,  2.2691e+00,  2.8664e+00,\n",
      "        -7.7794e-01, -1.2298e+00, -1.0249e+00, -1.0115e+00,  7.4511e-01,\n",
      "         2.0119e-01, -6.5566e-01,  3.2685e+00, -2.2111e+00, -1.7637e+00,\n",
      "         3.0585e+00, -2.0839e+00,  3.6976e+00,  2.0589e+00, -7.6803e-01,\n",
      "        -4.8002e-01, -2.1268e-01,  1.3680e+00, -2.2101e-01, -8.8409e-01,\n",
      "        -2.7433e+00, -7.3310e-02, -2.1116e-01,  1.0108e+00,  2.6934e+00,\n",
      "         1.8324e-01, -5.5102e-01, -4.7406e-01,  2.7330e+00,  1.7914e+00,\n",
      "         1.1055e-02, -3.1515e-01, -5.9872e-01,  1.6499e+00,  7.0509e-01,\n",
      "         1.4999e+00, -1.7862e+00, -4.2784e-01,  1.6751e+00,  2.4284e+00,\n",
      "        -5.6564e-01,  1.3206e+00,  8.0587e-01,  3.1152e-01, -3.8162e-01,\n",
      "        -2.3918e+00,  1.3436e+00,  2.5397e+00, -4.4075e-01, -1.6574e+00,\n",
      "        -1.3146e+00, -6.6645e-01,  1.8572e+00,  3.3940e-01,  1.3196e+00,\n",
      "        -5.7763e-01,  1.6520e+00, -7.9059e-01, -1.9973e-01,  7.5620e-01,\n",
      "        -3.5685e+00,  3.2001e+00, -1.6207e+00, -4.2206e-01, -1.3511e+00,\n",
      "        -2.2452e-02, -1.5928e+00,  3.7997e+00, -5.5102e-01,  1.0380e+00,\n",
      "         3.5063e-01,  1.3918e+00, -2.2798e+00,  1.1646e+00, -2.6389e-01,\n",
      "         1.6539e+00,  2.0324e+00, -9.4660e-02, -1.1824e-01, -5.5950e-01,\n",
      "         1.9498e+00, -6.9491e-01, -1.0190e+00,  2.1081e+00, -1.7859e-01,\n",
      "         7.0710e-01,  2.0586e-01,  1.4852e+00, -8.4782e-01, -1.1726e+00,\n",
      "        -2.2889e+00, -3.4532e-01, -1.8030e+00, -1.9736e+00, -1.8118e-01,\n",
      "         4.0843e-02, -1.4087e+00,  2.6225e+00,  2.9756e+00, -8.5650e-01,\n",
      "         2.6463e+00, -9.9667e-01,  1.5259e+00, -2.4194e+00,  1.4721e+00,\n",
      "         2.8494e+00, -1.9958e+00, -4.6007e-01,  2.1858e+00, -7.4440e-01,\n",
      "         2.0101e+00, -3.5633e-01, -2.9955e-02,  8.4514e-01, -1.0201e+00,\n",
      "        -7.8239e-01,  1.9064e+00, -2.5018e+00, -4.3810e-02,  2.4750e+00,\n",
      "        -5.2080e-01, -1.8151e+00, -9.2955e-01, -1.2331e-01, -5.1146e-01,\n",
      "         4.5736e-02, -3.5504e-01, -2.0420e-01,  1.6542e+00,  2.1409e+00,\n",
      "        -5.0277e-01,  2.1685e-01,  1.3300e+00,  2.3531e+00,  1.2397e+00,\n",
      "        -2.5414e-02,  2.0403e+00, -4.9600e-01,  1.5962e-01,  1.4546e+00,\n",
      "         1.7370e+00,  4.0783e-01,  4.1097e-01,  1.7464e+00, -1.2419e+00,\n",
      "        -1.0191e-01, -2.1227e-01,  7.1643e-01,  1.4162e-01,  1.2842e+00,\n",
      "         1.9650e+00, -6.0583e-01, -5.9502e-01, -3.8868e-01, -3.0428e-02,\n",
      "         3.4434e-02, -1.9690e+00, -1.2923e+00, -1.0242e+00, -9.1736e-02,\n",
      "        -7.7134e-01, -5.7264e-01,  1.6698e+00, -7.3716e-01,  3.9366e+00,\n",
      "         1.7711e+00, -3.0052e-01,  2.8414e+00, -4.3783e-01,  3.3070e-04,\n",
      "        -1.0264e-01, -2.0695e-01, -8.8297e-02,  1.9835e+00, -2.9555e-01,\n",
      "         2.5530e+00, -3.6338e-01, -9.0099e-02, -7.4666e-01,  2.9481e+00,\n",
      "         1.5978e+00, -4.6199e-01, -2.8903e-01,  1.3783e-01, -5.7364e-01,\n",
      "        -1.6024e+00,  3.2721e+00,  1.5761e+00, -5.5855e-01, -8.9702e-01,\n",
      "        -3.0992e-01,  1.6643e+00, -6.4872e-01,  4.0943e+00,  3.1088e+00,\n",
      "        -4.9226e-01, -1.5756e+00, -9.1734e-01, -1.3183e+00, -2.2485e+00,\n",
      "        -5.4741e-01,  1.7179e+00, -4.6363e-01,  2.1230e+00,  2.6671e+00,\n",
      "        -1.0642e+00,  6.0945e-01, -1.0113e+00,  5.8231e-02, -4.7532e-01,\n",
      "        -7.9154e-01, -1.7060e-01,  2.9550e-01,  1.0027e+00, -9.3423e-01,\n",
      "        -4.4962e-01,  3.3124e+00, -4.1193e-01,  2.4519e+00, -2.6214e-01,\n",
      "        -8.4228e-01, -1.7479e-01, -5.4038e-01,  4.1966e-01, -1.0613e+00,\n",
      "        -1.5100e+00, -1.0039e+00, -3.3389e+00, -1.0138e-01,  8.3347e-01,\n",
      "        -6.8873e-01, -1.4933e+00, -2.7640e-01, -3.1441e-01, -1.0977e+00,\n",
      "         1.5740e+00, -3.6987e-01, -2.7199e-01,  1.1999e-01, -7.5947e-01,\n",
      "        -7.7273e-02,  1.4720e-01, -6.8978e-01,  1.7565e+00,  1.8444e+00,\n",
      "        -4.3870e-01, -7.4424e-01,  2.9132e+00, -5.8483e-01, -6.0143e-01,\n",
      "         5.9293e-01, -1.0403e+00, -1.6899e+00,  2.1354e+00, -8.1832e-01,\n",
      "        -9.8220e-02, -1.4241e-01,  2.4876e+00,  1.5645e+00, -1.4373e+00,\n",
      "        -7.4741e-01,  2.7101e+00, -3.9443e-02, -8.0224e-01,  2.0639e+00,\n",
      "        -3.2980e-01,  2.6575e+00, -1.1798e+00, -9.4915e-01,  2.1309e+00,\n",
      "        -3.5050e-01, -1.2180e+00, -3.1273e-01,  3.2632e-01,  6.5155e-01,\n",
      "         3.5122e-01, -5.9713e-01, -1.3647e+00,  1.2823e-01, -5.4141e-01,\n",
      "        -3.8496e-01,  1.4676e+00, -3.5638e-01,  2.9907e+00,  5.2175e-01,\n",
      "        -6.0225e-01, -1.1133e+00, -7.8676e-01,  1.3281e+00, -1.6679e-01,\n",
      "         1.3477e+00,  2.5180e+00,  2.7822e+00,  9.9954e-01, -3.4648e-01,\n",
      "        -8.7015e-02, -4.4609e-01,  4.2189e+00, -5.3846e-01,  2.4236e+00,\n",
      "         3.6758e-02, -4.4750e-01, -1.9632e+00, -3.9972e-02,  3.0201e-01,\n",
      "         2.5163e+00, -6.2884e-01,  9.0364e-02,  1.8523e+00, -5.7828e-01],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([960])\n",
      "\n",
      "Layer: features.17.conv.2.weight\n",
      "Weights: tensor([[[[-0.0730]],\n",
      "\n",
      "         [[-0.1115]],\n",
      "\n",
      "         [[ 0.0360]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0826]],\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[-0.0478]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0376]],\n",
      "\n",
      "         [[-0.0376]],\n",
      "\n",
      "         [[-0.1792]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1503]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[-0.0234]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1230]],\n",
      "\n",
      "         [[-0.0447]],\n",
      "\n",
      "         [[ 0.0064]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[-0.0195]],\n",
      "\n",
      "         [[-0.0642]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0545]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         [[-0.0136]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0252]],\n",
      "\n",
      "         [[-0.1260]],\n",
      "\n",
      "         [[ 0.1013]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0480]],\n",
      "\n",
      "         [[-0.0107]],\n",
      "\n",
      "         [[-0.0183]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0914]],\n",
      "\n",
      "         [[ 0.0399]],\n",
      "\n",
      "         [[-0.0351]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0170]],\n",
      "\n",
      "         [[ 0.0420]],\n",
      "\n",
      "         [[-0.1040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0555]],\n",
      "\n",
      "         [[-0.0144]],\n",
      "\n",
      "         [[ 0.0324]]]], device='cuda:0')\n",
      "Shape: torch.Size([320, 960, 1, 1])\n",
      "\n",
      "Layer: features.17.conv.3.weight\n",
      "Weights: tensor([2.0997, 2.3501, 2.0975, 2.0840, 2.2689, 2.1707, 2.0478, 2.1034, 2.2229,\n",
      "        2.2575, 2.3291, 2.1630, 2.1499, 2.2988, 2.0962, 2.0990, 2.1443, 2.2327,\n",
      "        2.1570, 2.1169, 2.2002, 2.1186, 2.1057, 2.1018, 2.2704, 2.0499, 2.5515,\n",
      "        2.2089, 2.0757, 2.1090, 2.1943, 2.1196, 2.2852, 2.1379, 2.1092, 2.2696,\n",
      "        2.1809, 2.1484, 2.1548, 2.1028, 2.0968, 2.1264, 2.0294, 2.2025, 2.1333,\n",
      "        2.0593, 2.1518, 2.0779, 2.0908, 2.1288, 2.1184, 2.1336, 2.2105, 2.0712,\n",
      "        2.1533, 2.4576, 2.1617, 2.5691, 2.0904, 2.4347, 2.0480, 2.1241, 2.1132,\n",
      "        2.1749, 2.2247, 2.1309, 2.0916, 2.0485, 2.0984, 2.2191, 2.1322, 2.1173,\n",
      "        2.0714, 2.5145, 2.0877, 2.0870, 2.5766, 2.0989, 2.0725, 2.1561, 2.1959,\n",
      "        2.1340, 2.0584, 2.6102, 2.1185, 2.0304, 2.1545, 2.0475, 2.2402, 2.2299,\n",
      "        2.2215, 2.0758, 2.0969, 2.2440, 2.1207, 2.1253, 2.6521, 2.1763, 2.3153,\n",
      "        2.1377, 2.1752, 2.1843, 2.1186, 2.0781, 2.0438, 2.1649, 2.3639, 2.1702,\n",
      "        2.5182, 2.1061, 2.1844, 2.2463, 2.2147, 2.2579, 2.2200, 2.0596, 2.1904,\n",
      "        2.2365, 2.2848, 2.1153, 2.1187, 2.0953, 2.2802, 2.0718, 2.0794, 2.0946,\n",
      "        2.0985, 2.1557, 2.1356, 2.1666, 2.1791, 2.1284, 2.4955, 2.0024, 2.0482,\n",
      "        2.2878, 2.1199, 2.0794, 2.0782, 2.1353, 2.1516, 2.6806, 2.2556, 2.2250,\n",
      "        2.0807, 2.2981, 2.1040, 2.2671, 2.1884, 2.1016, 2.4998, 2.9493, 2.1977,\n",
      "        2.0818, 2.1222, 2.2132, 2.2133, 2.1224, 2.0696, 2.1448, 2.1046, 2.2274,\n",
      "        2.1585, 2.2109, 2.3310, 2.2450, 2.0847, 2.1535, 2.1182, 2.0715, 2.1150,\n",
      "        2.1223, 2.2013, 2.1173, 2.0698, 2.1985, 2.0591, 2.0856, 2.1492, 2.1087,\n",
      "        2.1255, 2.1582, 2.1539, 2.1297, 2.1382, 2.1514, 2.1663, 2.1545, 2.2590,\n",
      "        2.3771, 2.5504, 2.2019, 2.0621, 2.2981, 2.9265, 2.4147, 2.4635, 2.2865,\n",
      "        2.0711, 2.1095, 2.1289, 2.0450, 2.1147, 2.4937, 2.2396, 2.0974, 2.1513,\n",
      "        2.0547, 2.1554, 2.0902, 2.1117, 2.0988, 2.1667, 2.0688, 2.1813, 2.0871,\n",
      "        2.2603, 2.0952, 2.8831, 2.2839, 2.1099, 2.1480, 2.0930, 2.0597, 2.2453,\n",
      "        4.1119, 2.8073, 2.1591, 2.1091, 2.1374, 2.0817, 2.0908, 2.1125, 2.3781,\n",
      "        2.1571, 2.2223, 2.2264, 2.1000, 2.1025, 2.1951, 2.7233, 2.1006, 2.2223,\n",
      "        2.1726, 2.0763, 2.0699, 2.1648, 2.2990, 2.1629, 2.1034, 2.1681, 2.1144,\n",
      "        2.0961, 2.8421, 2.0972, 2.0938, 2.2313, 2.1416, 2.6339, 2.2152, 2.1601,\n",
      "        2.1836, 2.1412, 2.1457, 2.1640, 2.1070, 2.1725, 2.0901, 2.1398, 2.1326,\n",
      "        2.2038, 2.0924, 2.4771, 2.0133, 2.1479, 2.1326, 2.1298, 2.1396, 2.0593,\n",
      "        2.0883, 2.3135, 2.1199, 3.7568, 2.1863, 2.1480, 2.3684, 2.1404, 2.0723,\n",
      "        2.2841, 2.0521, 2.0992, 2.2620, 2.1073, 2.2883, 2.1213, 2.1007, 2.7023,\n",
      "        2.1148, 2.1033, 2.0513, 2.3512, 2.0712, 2.4376, 2.1533, 2.3549, 2.1412,\n",
      "        2.3335, 2.1605, 2.1525, 2.1116, 2.1446, 2.1204, 2.1206, 2.2174, 2.1093,\n",
      "        2.1008, 2.1310, 2.1179, 2.1530, 2.5544], device='cuda:0')\n",
      "Shape: torch.Size([320])\n",
      "\n",
      "Layer: features.17.conv.3.bias\n",
      "Weights: tensor([ 2.3470e-07, -4.3375e-06,  5.9915e-07,  1.3464e-06, -2.1303e-06,\n",
      "         8.0569e-07,  1.3114e-06, -9.6028e-07, -9.6011e-07, -1.2917e-06,\n",
      "         3.9069e-06,  9.5997e-07,  2.4035e-07, -1.9699e-07, -8.8980e-07,\n",
      "         1.3806e-06,  8.0579e-07, -2.1623e-06,  1.0374e-06,  1.5600e-06,\n",
      "        -5.7231e-07,  6.6681e-07, -8.6863e-07, -6.6899e-07,  1.0050e-06,\n",
      "        -1.2817e-06,  5.5471e-06,  1.8290e-06, -1.5945e-06,  4.3203e-07,\n",
      "        -2.2319e-06, -2.0674e-07, -5.0910e-06, -6.5491e-07, -3.0063e-07,\n",
      "         9.9739e-07, -6.3074e-07, -3.2691e-06, -1.3533e-06, -9.1251e-07,\n",
      "        -9.8658e-07,  1.3592e-06,  7.1932e-07, -2.1115e-06, -4.8499e-07,\n",
      "         1.1597e-06,  2.3174e-06, -4.9887e-07, -3.9462e-07,  1.8767e-07,\n",
      "         8.7762e-07, -1.1877e-06,  3.4507e-06,  6.5551e-07,  2.1193e-07,\n",
      "        -8.8026e-07, -3.2721e-07, -3.7043e-06, -1.7423e-07, -1.4898e-06,\n",
      "        -4.4614e-07,  7.5661e-07,  9.8600e-07,  4.5519e-07, -2.7407e-06,\n",
      "        -3.9109e-07, -1.4842e-06, -4.4029e-07, -1.0285e-06, -6.6177e-07,\n",
      "         2.1115e-07,  1.0009e-06,  1.2127e-06, -5.3947e-06,  1.4753e-06,\n",
      "         5.4616e-07,  5.0176e-06, -1.1087e-06, -1.4895e-06,  7.1702e-07,\n",
      "        -5.8833e-08,  1.3734e-06, -1.2076e-06,  4.5602e-06,  2.3537e-07,\n",
      "         7.9268e-07,  1.8918e-06,  1.8664e-06, -2.9002e-06,  1.9211e-06,\n",
      "        -2.2850e-06, -9.9747e-08,  5.3888e-07, -2.7694e-06,  1.2010e-06,\n",
      "         6.1381e-07, -3.5916e-06, -1.5972e-06,  3.4351e-06, -1.3014e-06,\n",
      "        -8.0027e-07,  2.5128e-06,  2.1826e-07,  7.1546e-08, -7.1366e-07,\n",
      "         1.7182e-06, -2.0250e-06,  5.7898e-07, -1.6469e-06, -1.0810e-06,\n",
      "        -1.4821e-06,  4.1470e-07,  1.6665e-06,  5.2718e-07, -1.9257e-06,\n",
      "        -1.5452e-06,  4.3677e-06, -1.8553e-06, -1.6233e-06,  9.0238e-08,\n",
      "         1.0989e-07, -1.3810e-06, -3.1943e-06,  2.0860e-07,  2.8254e-07,\n",
      "         5.3708e-07, -2.1459e-07, -1.0804e-06,  1.5085e-06,  8.3130e-07,\n",
      "        -8.1279e-07,  1.1531e-06, -7.9237e-08,  3.6651e-06, -1.0080e-06,\n",
      "         4.7506e-06,  1.7277e-07,  9.6104e-07,  7.2058e-07, -5.3148e-07,\n",
      "        -7.8146e-07,  3.7612e-07,  1.0578e-06, -3.0038e-06, -1.6283e-06,\n",
      "        -1.6374e-06, -1.0985e-06,  2.3923e-06, -7.3715e-07,  2.0854e-06,\n",
      "         2.2279e-06,  7.9412e-06, -2.4028e-06, -8.8342e-07,  7.3430e-07,\n",
      "         3.0134e-06, -1.5578e-06, -3.7246e-07, -7.9232e-07,  1.1712e-06,\n",
      "         1.9168e-06, -2.6310e-07, -4.2978e-06,  8.2528e-07,  9.5469e-07,\n",
      "         9.6557e-07, -4.1894e-07, -3.2758e-07,  1.2228e-06,  1.2405e-06,\n",
      "        -5.8992e-07, -1.5111e-06,  1.0637e-06, -6.3514e-07,  2.2522e-07,\n",
      "         4.6418e-07, -9.8048e-07, -7.8535e-07,  8.1447e-07, -5.9195e-07,\n",
      "         5.8919e-07,  1.3499e-06,  5.7600e-07,  3.8153e-07,  3.4492e-07,\n",
      "        -1.3974e-06, -1.4052e-06, -2.1195e-07,  3.1420e-06,  3.9576e-06,\n",
      "        -2.2742e-07,  1.8039e-06, -6.6738e-07, -4.6434e-07, -8.3817e-06,\n",
      "         1.2701e-06, -1.0735e-06, -5.6933e-07, -3.2007e-07, -8.7497e-07,\n",
      "        -7.1661e-07,  4.0771e-06, -7.1818e-07, -1.6768e-06, -5.5563e-07,\n",
      "        -6.2959e-07,  4.9914e-07, -4.0235e-06,  1.3047e-06,  5.0963e-07,\n",
      "         2.6750e-08,  1.8550e-06,  1.2023e-06,  2.9131e-07,  1.6690e-06,\n",
      "        -1.8330e-06,  1.4446e-06, -6.2570e-07,  8.7794e-06,  1.0381e-06,\n",
      "         2.0755e-07,  9.1790e-07, -1.4399e-06,  5.5219e-07, -1.7848e-06,\n",
      "         1.2225e-05,  1.4915e-06, -6.4929e-07, -3.8240e-08,  5.5057e-07,\n",
      "        -5.8242e-07, -4.9635e-07,  2.4773e-07,  8.5991e-07,  1.6944e-06,\n",
      "         2.4711e-06,  3.5879e-07, -3.8817e-07, -8.7023e-07,  1.3631e-06,\n",
      "        -1.3116e-06,  6.7915e-07, -1.2116e-06,  9.5260e-08,  7.9367e-08,\n",
      "        -1.8464e-07,  6.4646e-07, -2.8743e-06, -1.3700e-07, -3.2181e-06,\n",
      "         8.4600e-07,  3.3610e-07,  1.3817e-06,  6.3797e-06, -3.8336e-07,\n",
      "        -7.7952e-07, -1.2989e-07,  1.2214e-07,  8.1034e-07, -9.0381e-07,\n",
      "        -2.5213e-06, -4.0345e-07, -1.1255e-06,  1.0691e-06,  4.3110e-07,\n",
      "        -1.5333e-06,  5.4066e-07, -1.9988e-07, -1.9016e-06, -4.1119e-07,\n",
      "        -1.5995e-06,  2.0356e-06, -2.8742e-06,  2.7677e-06,  8.1113e-07,\n",
      "        -7.3807e-07, -5.4904e-07,  1.3343e-06, -5.2305e-07,  2.5440e-06,\n",
      "        -3.1623e-07,  1.1611e-06,  7.2345e-06, -1.7759e-06,  2.1388e-07,\n",
      "        -4.8484e-07,  1.3002e-06, -2.5207e-07, -2.7678e-06,  2.4762e-07,\n",
      "        -6.3246e-07,  2.1116e-07, -4.1300e-06, -2.2052e-06,  6.4271e-07,\n",
      "        -2.5188e-06, -3.6479e-06,  4.6466e-07,  4.1034e-07, -1.2004e-06,\n",
      "         3.2650e-06,  6.6602e-07, -1.9230e-06,  5.8200e-07, -2.1599e-06,\n",
      "        -2.6744e-06, -2.3687e-06, -1.0030e-07, -4.5833e-07,  7.5728e-07,\n",
      "         1.1909e-06, -7.1843e-07,  6.2217e-07,  2.0658e-06,  1.0208e-06,\n",
      "        -6.9387e-07,  7.8042e-07,  5.9316e-07,  5.4229e-07,  4.5152e-06],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([320])\n",
      "\n",
      "Layer: features.18.0.weight\n",
      "Weights: tensor([[[[ 0.0456]],\n",
      "\n",
      "         [[ 0.0229]],\n",
      "\n",
      "         [[-0.0672]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0022]],\n",
      "\n",
      "         [[-0.0020]],\n",
      "\n",
      "         [[-0.1942]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0343]],\n",
      "\n",
      "         [[-0.0669]],\n",
      "\n",
      "         [[ 0.0341]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0340]],\n",
      "\n",
      "         [[-0.0280]],\n",
      "\n",
      "         [[ 0.0235]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0421]],\n",
      "\n",
      "         [[ 0.0051]],\n",
      "\n",
      "         [[ 0.0335]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0326]],\n",
      "\n",
      "         [[ 0.0287]],\n",
      "\n",
      "         [[ 0.0018]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.0238]],\n",
      "\n",
      "         [[ 0.0562]],\n",
      "\n",
      "         [[ 0.0086]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0420]],\n",
      "\n",
      "         [[ 0.0155]],\n",
      "\n",
      "         [[-0.0487]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0202]],\n",
      "\n",
      "         [[ 0.0903]],\n",
      "\n",
      "         [[-0.0486]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0016]],\n",
      "\n",
      "         [[-0.0266]],\n",
      "\n",
      "         [[ 0.0428]]],\n",
      "\n",
      "\n",
      "        [[[-0.0438]],\n",
      "\n",
      "         [[-0.0728]],\n",
      "\n",
      "         [[-0.0009]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0581]],\n",
      "\n",
      "         [[-0.0106]],\n",
      "\n",
      "         [[ 0.0109]]]], device='cuda:0')\n",
      "Shape: torch.Size([1280, 320, 1, 1])\n",
      "\n",
      "Layer: features.18.1.weight\n",
      "Weights: tensor([3.8923, 3.7667, 3.3817,  ..., 3.5836, 3.9387, 3.2627], device='cuda:0')\n",
      "Shape: torch.Size([1280])\n",
      "\n",
      "Layer: features.18.1.bias\n",
      "Weights: tensor([-5.1805, -5.2606, -4.3261,  ..., -4.9339, -5.5779, -4.2295],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([1280])\n",
      "\n",
      "Layer: classifier.1.weight\n",
      "Weights: tensor([[-0.0309,  0.0898,  0.0147,  ..., -0.0181, -0.0262,  0.1674],\n",
      "        [-0.0318, -0.0282, -0.0380,  ..., -0.0220,  0.0125, -0.0089],\n",
      "        [ 0.0143, -0.0222, -0.0077,  ..., -0.0173,  0.0577, -0.0649],\n",
      "        ...,\n",
      "        [ 0.0538,  0.0217, -0.0798,  ..., -0.0052, -0.0263, -0.0141],\n",
      "        [-0.0663, -0.0272,  0.0635,  ...,  0.0210, -0.0556,  0.0413],\n",
      "        [-0.0185,  0.0414, -0.0821,  ..., -0.0369, -0.0260, -0.0199]],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([1000, 1280])\n",
      "\n",
      "Layer: classifier.1.bias\n",
      "Weights: tensor([ 2.1759e-02, -3.8201e-02,  8.6484e-02,  1.3767e-01,  1.8519e-01,\n",
      "         5.6217e-02,  3.5687e-02, -4.7612e-02, -1.0376e-01, -7.7673e-02,\n",
      "         6.5267e-03, -3.6171e-02, -7.4770e-02,  4.9748e-02,  2.3051e-02,\n",
      "        -8.1528e-02, -4.4763e-02, -6.6116e-02,  9.5336e-02,  4.2249e-03,\n",
      "         8.4689e-02,  1.3176e-01,  7.1000e-02, -2.1138e-02, -6.4721e-02,\n",
      "        -3.1600e-02,  9.2663e-02,  3.5424e-02,  8.1185e-03, -2.2670e-02,\n",
      "        -1.3106e-02, -5.3038e-02,  2.8974e-02, -3.3529e-02,  4.0875e-02,\n",
      "        -5.2171e-02, -9.1241e-02,  1.7495e-02, -9.8909e-03, -1.1621e-01,\n",
      "        -2.3539e-02,  7.0240e-02,  1.4311e-02, -1.7219e-01,  8.9669e-03,\n",
      "        -7.8850e-03,  6.6452e-02, -1.5262e-01, -1.7436e-02,  4.4306e-02,\n",
      "         5.9609e-03, -2.5121e-01,  8.3942e-02,  2.7448e-03, -1.4524e-02,\n",
      "         5.3815e-02, -4.1285e-02,  2.3073e-02,  5.0124e-02,  6.0352e-02,\n",
      "         6.4563e-02, -6.4193e-02, -2.5406e-02, -1.0834e-01,  2.3466e-03,\n",
      "         9.8597e-02,  2.6912e-02,  4.6962e-02,  8.3510e-02,  7.0992e-03,\n",
      "         1.5721e-02, -3.8679e-02,  5.3070e-02,  6.4631e-02,  7.8723e-02,\n",
      "         7.1729e-02, -7.7484e-02,  6.2620e-02,  6.0857e-02, -5.1906e-02,\n",
      "        -1.0443e-02,  9.8344e-04, -4.5740e-02, -9.3690e-02, -4.9720e-02,\n",
      "         1.9576e-02, -5.1810e-02, -4.9939e-02, -1.1830e-01,  5.3034e-02,\n",
      "        -3.9437e-02, -1.1271e-01,  8.1097e-02, -1.1569e-01, -5.0654e-02,\n",
      "         7.6500e-02, -3.1321e-02, -2.6480e-02,  9.3492e-03, -3.3137e-02,\n",
      "        -2.5618e-02,  1.0236e-02,  8.7786e-02,  1.1769e-01, -3.1551e-02,\n",
      "        -1.0335e-02,  2.9418e-02,  7.1980e-02,  3.8963e-02,  6.4526e-03,\n",
      "         8.0937e-03,  2.3551e-01, -2.4858e-02, -1.4636e-01, -3.6966e-02,\n",
      "        -2.3484e-02, -5.8476e-03, -4.6393e-02, -3.7587e-02, -6.7214e-03,\n",
      "        -7.7484e-02, -8.3600e-02, -1.1597e-01, -1.3936e-01, -6.8658e-02,\n",
      "        -8.2619e-02,  3.8626e-02, -3.5660e-02, -2.8984e-02,  2.3736e-02,\n",
      "         4.9350e-02,  7.3211e-02,  2.6313e-02, -3.6207e-02, -6.9666e-02,\n",
      "        -8.3124e-02, -7.1829e-02,  6.6844e-02, -7.5483e-03, -3.7575e-03,\n",
      "         2.9821e-02,  4.6552e-02,  9.1609e-02,  5.1975e-02, -4.9553e-02,\n",
      "        -1.4043e-02,  1.9281e-03,  5.6804e-02,  5.7567e-02,  1.2884e-01,\n",
      "        -4.6818e-02, -9.1833e-02, -7.9148e-02,  6.7961e-02,  2.2747e-03,\n",
      "         2.9198e-02,  3.7929e-02, -4.9269e-02, -9.2705e-02,  5.0969e-02,\n",
      "        -1.7532e-01,  3.7426e-02,  6.7318e-02,  3.1232e-02, -1.3836e-01,\n",
      "        -8.6507e-02, -9.4722e-02, -1.2160e-01,  7.0386e-02, -1.9250e-02,\n",
      "        -9.8683e-05,  1.8012e-02, -2.3702e-02, -2.2758e-02,  1.5100e-02,\n",
      "        -1.0245e-01, -6.5812e-02, -4.6851e-02,  4.1509e-02, -1.3821e-02,\n",
      "         2.3694e-04, -3.4171e-02, -4.4291e-02,  1.4750e-02, -2.4416e-03,\n",
      "        -9.1880e-03, -7.9510e-02,  1.8713e-02, -7.1789e-02, -1.9625e-02,\n",
      "        -4.1965e-02, -8.0849e-03,  9.6346e-02, -4.2456e-02,  3.8668e-03,\n",
      "         7.6865e-02,  1.5238e-02, -3.6998e-03, -7.2717e-02,  6.0691e-02,\n",
      "         1.6882e-02,  2.0819e-02,  1.5493e-02,  3.0001e-02,  5.6379e-02,\n",
      "         4.4300e-02, -3.3139e-02, -2.9747e-02, -5.7565e-02,  7.2294e-03,\n",
      "        -5.7491e-02, -1.0030e-02, -4.7524e-02, -1.6543e-02, -1.2909e-02,\n",
      "        -2.4050e-02, -5.7157e-02,  2.6132e-02,  4.5742e-02, -7.1283e-02,\n",
      "        -1.5704e-02, -6.8699e-02,  3.3962e-02,  9.2513e-02, -1.5126e-02,\n",
      "         3.6705e-02, -1.9274e-02,  3.5817e-02,  3.7677e-02,  4.3234e-03,\n",
      "        -1.6532e-03, -1.3130e-02,  2.2826e-02,  4.6023e-02,  8.0874e-02,\n",
      "        -2.6528e-02,  4.1537e-02,  4.5623e-02,  1.7410e-02,  6.4491e-02,\n",
      "        -2.7972e-05,  2.5951e-02, -8.8895e-03,  3.7338e-03, -3.1510e-02,\n",
      "         6.6573e-02, -6.1966e-02,  4.0275e-02,  2.9269e-02, -1.5630e-02,\n",
      "         1.4343e-02,  3.0889e-02,  5.0117e-02, -6.1998e-02, -8.1080e-03,\n",
      "        -3.5373e-02,  2.2778e-03,  1.3711e-02,  5.4320e-02,  5.6836e-02,\n",
      "         3.4657e-02,  2.6575e-02, -9.1060e-02, -4.8084e-02, -5.1528e-02,\n",
      "        -3.4631e-02,  1.3081e-02, -8.5762e-02, -2.0387e-01,  1.1557e-02,\n",
      "         9.9856e-02,  1.2320e-02,  3.8506e-02,  5.4058e-02, -3.5820e-04,\n",
      "        -6.5856e-02,  2.9529e-02, -1.7874e-02,  2.9289e-02,  8.7353e-02,\n",
      "        -4.9136e-03,  3.5807e-02, -6.3528e-02,  1.6685e-02,  6.1764e-02,\n",
      "         2.1796e-02, -4.7948e-03, -2.9393e-03,  2.9731e-02,  1.1207e-01,\n",
      "         3.8425e-02, -7.0862e-02, -6.5369e-02, -7.6716e-03, -2.0744e-02,\n",
      "         1.0158e-02,  7.1974e-02,  9.1440e-02,  2.8697e-02,  2.6167e-02,\n",
      "        -8.2433e-03,  1.0477e-02, -1.8223e-02, -1.3806e-01, -1.3427e-03,\n",
      "         1.1035e-01, -7.2570e-02, -1.9594e-02, -1.7605e-02, -6.6978e-02,\n",
      "         5.7448e-02, -8.4071e-02,  3.1210e-04,  8.1264e-02,  2.3168e-02,\n",
      "         4.3522e-02, -7.4895e-02,  3.5869e-02,  1.1987e-01, -6.3634e-02,\n",
      "         4.7128e-02, -6.8041e-02, -4.3383e-02, -9.0246e-03,  1.8648e-02,\n",
      "        -1.5107e-03, -6.9079e-02, -9.4028e-02, -8.6315e-02,  1.0699e-01,\n",
      "         4.4169e-02, -6.3228e-03,  6.1734e-02, -2.1603e-02, -3.2142e-02,\n",
      "        -1.0470e-02,  1.1779e-01, -5.4961e-02, -1.3106e-01,  2.3816e-02,\n",
      "        -3.0674e-02, -7.7992e-02,  2.2358e-02,  2.5552e-02,  3.0577e-02,\n",
      "        -1.0091e-01,  8.4993e-03,  8.5013e-02, -8.6217e-02, -3.1999e-03,\n",
      "        -2.1920e-02,  4.7596e-02,  6.5499e-02,  6.0879e-02,  1.7218e-03,\n",
      "        -1.9187e-01, -2.2729e-02,  3.2150e-03,  7.8484e-02,  1.0896e-01,\n",
      "        -5.5114e-02,  3.2676e-02, -1.3837e-02, -5.4210e-02, -6.0103e-02,\n",
      "         3.8518e-02,  2.3118e-02,  5.5637e-02,  7.7218e-02,  9.7587e-02,\n",
      "        -1.6902e-02, -2.5875e-02,  4.7955e-03,  6.2340e-02,  2.0932e-02,\n",
      "        -7.0329e-03,  1.6159e-02, -8.9607e-02,  7.6677e-02,  1.1844e-01,\n",
      "        -3.2178e-02,  4.3110e-02, -8.8705e-03, -3.1841e-03, -2.5350e-02,\n",
      "         1.0359e-01,  1.2105e-01, -4.3323e-02,  4.3707e-02, -4.3305e-02,\n",
      "        -9.8725e-02, -1.7726e-02, -6.9717e-02,  1.0889e-02, -3.5041e-02,\n",
      "        -4.9308e-02, -7.8309e-02, -1.3301e-01,  1.7833e-02,  6.2831e-02,\n",
      "         9.8556e-03, -3.1123e-02, -8.7687e-03,  3.7695e-02,  5.2987e-02,\n",
      "         7.1595e-02, -7.9733e-04, -2.6659e-02, -2.0375e-01,  2.7824e-02,\n",
      "         1.6127e-02, -4.7017e-02, -5.1233e-02,  6.9227e-02,  1.2703e-02,\n",
      "         2.9774e-03,  1.1040e-01,  5.2093e-02,  9.0800e-02,  7.4486e-02,\n",
      "        -4.5281e-02,  9.8721e-03,  1.1958e-02, -1.5291e-02,  5.4391e-02,\n",
      "         7.8265e-02, -7.7085e-03,  3.7656e-03, -1.5114e-01,  8.7733e-02,\n",
      "         8.2804e-02,  5.2043e-02, -3.1355e-03, -5.6770e-02,  1.8722e-02,\n",
      "         2.8936e-02, -8.5516e-03,  4.2825e-02,  5.5554e-02, -2.5874e-02,\n",
      "         1.6024e-02,  4.0612e-02, -7.5031e-02, -1.5514e-02,  1.0229e-02,\n",
      "         1.2989e-01,  2.5244e-02, -1.2789e-01, -4.9721e-02, -3.5407e-02,\n",
      "        -5.1666e-02, -4.5894e-02, -1.4511e-02,  6.2196e-02,  1.0736e-02,\n",
      "         2.6042e-03, -1.0734e-01,  9.3253e-02,  4.0905e-02,  1.8040e-02,\n",
      "         4.7686e-02,  5.1363e-02, -4.4714e-02,  2.4218e-02, -3.2573e-02,\n",
      "         9.5893e-02, -6.2473e-03, -2.0327e-03, -3.0909e-04, -7.0400e-02,\n",
      "         4.7608e-02, -9.1080e-02, -6.2095e-02,  3.4302e-02, -1.3073e-02,\n",
      "         3.2697e-02, -1.1750e-01, -3.9678e-02, -2.4665e-02,  4.8345e-03,\n",
      "         3.4342e-02, -4.4545e-02,  1.5457e-03,  1.1384e-02, -6.1163e-02,\n",
      "        -5.4197e-03,  4.4379e-02,  2.7037e-02,  4.2701e-02,  4.7243e-02,\n",
      "        -7.4355e-02, -9.5610e-02, -3.4513e-04,  1.4558e-01,  7.1724e-04,\n",
      "         3.8392e-02, -5.1980e-02,  7.6596e-03, -1.0494e-01, -4.1825e-04,\n",
      "         2.0539e-01, -1.0602e-02, -3.3545e-02, -1.3269e-02, -2.9299e-02,\n",
      "        -1.6159e-02,  7.8544e-02, -6.0047e-02,  1.1704e-01, -3.1155e-02,\n",
      "         4.1310e-03,  6.4262e-03,  1.7818e-02,  1.7642e-02, -5.5694e-02,\n",
      "         1.9591e-02, -1.5116e-02, -5.4255e-02, -1.0799e-01,  8.0096e-02,\n",
      "        -3.7383e-02, -4.8735e-02,  7.5206e-03,  5.0670e-02, -7.0732e-02,\n",
      "        -9.8109e-02,  2.4151e-02,  2.5499e-02, -9.0664e-02,  9.2635e-02,\n",
      "         1.0295e-01, -8.3082e-02,  4.8536e-02,  1.1743e-01,  1.8717e-02,\n",
      "        -4.1570e-02,  4.9754e-02,  4.3435e-02, -3.2104e-02,  3.0354e-02,\n",
      "         1.1755e-03, -6.4568e-02,  2.8158e-02, -2.2090e-02, -8.8716e-02,\n",
      "        -4.7254e-02, -6.0459e-02,  3.0191e-02,  1.8739e-02,  4.4473e-02,\n",
      "        -5.6224e-02, -5.6793e-03,  4.6966e-03,  9.4855e-02,  1.3508e-02,\n",
      "        -8.4364e-02,  3.6586e-03,  7.2912e-02, -4.0470e-03,  8.4746e-03,\n",
      "        -1.5605e-01, -8.7538e-02, -1.1369e-01,  5.7046e-02, -4.0967e-02,\n",
      "        -7.8850e-03, -3.0861e-02, -1.7784e-02, -1.1933e-01, -9.9079e-02,\n",
      "        -7.1401e-02, -5.9642e-02,  6.4467e-02,  2.7444e-02,  7.7600e-02,\n",
      "        -4.7095e-03, -3.2259e-02, -4.9815e-02, -2.4038e-02, -6.1542e-02,\n",
      "        -3.2030e-02,  1.2647e-04,  8.8844e-02,  1.6196e-02,  9.0690e-04,\n",
      "        -4.9813e-02, -8.5015e-02,  4.8673e-02, -9.0798e-02, -4.6787e-02,\n",
      "        -1.2712e-02,  3.6751e-02, -2.3141e-02,  8.0363e-02, -7.0418e-02,\n",
      "        -2.6232e-02, -9.4983e-02,  6.1626e-02, -3.6305e-03, -4.1558e-02,\n",
      "         1.1837e-01,  2.5935e-02,  1.1315e-01, -1.0301e-01, -1.3866e-02,\n",
      "         8.7182e-02, -9.2959e-02,  1.0768e-01,  1.1268e-01, -1.0893e-01,\n",
      "        -1.5261e-02, -9.6170e-02, -1.0470e-01, -3.4821e-02, -8.4202e-02,\n",
      "        -2.6397e-03, -5.3756e-02,  1.0055e-01,  2.7442e-02, -2.9799e-02,\n",
      "         5.6761e-02,  4.1616e-02,  1.5896e-01,  4.4687e-02,  4.3399e-02,\n",
      "        -7.5085e-02,  6.9780e-02, -4.8791e-02, -1.5854e-02,  8.0413e-02,\n",
      "        -6.8915e-03, -2.4046e-02,  9.2444e-02,  4.5542e-02, -3.7568e-03,\n",
      "        -5.2385e-02, -1.6288e-02, -1.0512e-01,  6.1213e-02, -1.0220e-02,\n",
      "         1.5200e-01, -3.3409e-02, -5.2192e-02, -6.4991e-02,  2.0251e-01,\n",
      "         1.7485e-02,  7.7578e-02, -2.1579e-02,  1.7711e-01,  1.0416e-01,\n",
      "         1.0483e-01,  1.1128e-02,  4.8838e-02,  2.4974e-02, -4.5526e-02,\n",
      "         1.0087e-01, -7.3625e-03,  1.3869e-02, -2.5341e-02,  8.9742e-02,\n",
      "         1.6953e-02, -7.1514e-02,  1.7016e-02,  3.4162e-02,  3.8251e-02,\n",
      "         1.3468e-02, -9.0501e-04, -6.1143e-02, -5.4297e-03,  4.3234e-02,\n",
      "        -5.3631e-02, -4.7698e-02, -2.2575e-02,  8.3111e-02, -2.0549e-02,\n",
      "        -1.0866e-01, -1.5742e-01,  1.3322e-01, -5.5099e-02,  9.4562e-03,\n",
      "         1.2072e-01,  1.4985e-01,  5.6022e-02,  7.8961e-02, -7.9504e-02,\n",
      "         1.2549e-01, -5.3772e-02, -5.8687e-02, -5.3185e-02, -1.9522e-02,\n",
      "        -9.4153e-02, -6.6292e-02, -2.2187e-02, -4.9738e-02, -4.6311e-02,\n",
      "         4.5460e-02, -5.4092e-02,  2.7340e-02,  1.9418e-02, -4.6023e-02,\n",
      "         2.4003e-02,  5.4532e-02,  4.1836e-02, -1.9981e-02, -2.0242e-02,\n",
      "        -4.2995e-02, -2.7995e-02, -7.1998e-02,  4.7350e-02, -4.7205e-02,\n",
      "        -1.5801e-02, -7.0171e-02, -6.4111e-02,  8.0037e-02,  2.1058e-02,\n",
      "        -2.5234e-02,  5.5529e-02, -2.1639e-02,  6.6098e-02, -2.8537e-02,\n",
      "        -3.3965e-02, -2.2606e-02, -2.6984e-02, -8.0632e-02, -1.3393e-01,\n",
      "        -2.7979e-02,  6.3010e-02, -6.0645e-02, -7.4302e-02, -9.8073e-02,\n",
      "        -7.6732e-02,  2.1717e-03,  9.7566e-03,  8.5136e-02, -3.0419e-02,\n",
      "         1.0428e-02,  2.3635e-02,  1.3292e-02, -3.1691e-03,  5.7605e-02,\n",
      "        -1.0547e-01,  7.4959e-02,  7.8002e-02,  8.2632e-02,  3.0370e-02,\n",
      "         2.3103e-02,  6.5391e-02, -6.0195e-02, -1.1504e-01, -4.6636e-02,\n",
      "         7.0626e-02, -1.5607e-01, -7.6096e-02,  2.9304e-02, -7.7186e-03,\n",
      "         1.3368e-02, -5.4386e-02, -1.0961e-01, -8.0009e-02,  2.6333e-02,\n",
      "         1.1087e-01,  5.2759e-02,  4.8152e-02,  9.7065e-03,  3.7476e-02,\n",
      "         5.8032e-03, -1.2221e-01, -1.9149e-02,  1.8671e-01,  5.2131e-02,\n",
      "        -1.0432e-01, -7.4389e-02,  2.1806e-02,  3.1331e-02, -1.2556e-02,\n",
      "        -1.1358e-01,  2.0806e-02,  9.6195e-02, -1.2207e-01, -1.3307e-01,\n",
      "         1.5290e-02, -1.2306e-01,  4.7516e-02,  8.9312e-02,  6.2900e-02,\n",
      "         1.0541e-01, -2.3712e-02, -8.1403e-02, -7.8356e-02,  1.3234e-01,\n",
      "        -2.1572e-01, -9.9673e-02,  4.8654e-02, -6.1532e-02,  4.9032e-02,\n",
      "         1.2883e-02, -1.8990e-02,  6.5594e-02,  3.0963e-02,  1.0802e-01,\n",
      "        -8.7336e-02, -4.0793e-02, -4.1875e-02, -4.0262e-02, -1.1958e-02,\n",
      "         5.4002e-02, -1.8207e-02, -9.2747e-02, -3.0435e-02,  5.0732e-04,\n",
      "        -3.4509e-02, -1.3300e-01, -2.0584e-02, -3.4287e-03,  3.3798e-02,\n",
      "         7.6019e-02, -1.4586e-01, -6.5083e-02,  1.1133e-01, -2.0991e-02,\n",
      "        -9.6636e-02, -2.9523e-02, -5.6462e-02, -1.1754e-02,  4.6690e-02,\n",
      "         1.1320e-01, -1.0074e-01, -4.4988e-02, -1.0872e-02, -1.4765e-01,\n",
      "        -3.6564e-02, -2.6572e-03, -4.8331e-02, -3.4319e-02,  1.9803e-01,\n",
      "        -1.3178e-01,  4.5631e-02,  4.2718e-02,  1.0053e-01,  3.9020e-02,\n",
      "        -7.0034e-02,  2.3410e-02,  2.1263e-02, -3.7163e-02,  9.3094e-02,\n",
      "         2.4271e-02, -2.6040e-02,  1.3311e-02,  2.6087e-02, -4.6824e-02,\n",
      "        -1.1358e-01, -6.8842e-02, -1.8327e-03, -6.3799e-02,  4.0115e-02,\n",
      "        -5.0009e-02, -6.0691e-02, -1.5473e-01,  5.2722e-02, -4.2528e-02,\n",
      "         7.4972e-03,  2.7294e-02, -2.5042e-02, -9.8724e-03, -6.6574e-02,\n",
      "         1.5013e-02, -1.4917e-02, -8.4133e-02,  8.3032e-02,  3.3268e-02,\n",
      "         5.7603e-03,  5.1148e-03,  1.8273e-02, -3.2597e-02, -2.3411e-03,\n",
      "         2.0215e-02,  4.3740e-02, -4.7150e-02, -2.4824e-02, -2.1241e-02,\n",
      "         4.0492e-03,  8.1200e-02, -1.3477e-01, -4.4830e-02,  1.6292e-01,\n",
      "         2.0333e-01, -1.0446e-01, -4.2683e-02,  4.2209e-02, -3.5972e-03,\n",
      "        -8.8700e-03, -1.3101e-01,  1.7674e-02,  2.1332e-02,  9.0498e-02,\n",
      "         4.1140e-02,  5.9341e-02,  7.0453e-03,  5.3495e-03,  7.5509e-02,\n",
      "         6.0445e-02,  1.4946e-02,  9.3456e-02,  7.2941e-03,  1.7047e-01,\n",
      "         1.1177e-01,  5.5514e-02,  1.1050e-02,  1.7548e-01, -5.4500e-02,\n",
      "         1.2232e-02,  1.1792e-01,  3.8718e-02, -2.6624e-02,  5.7266e-02,\n",
      "        -9.7332e-02, -7.3740e-02, -8.5785e-02,  6.4664e-02,  4.0530e-02,\n",
      "        -2.6749e-02, -5.6534e-02,  9.1496e-02, -2.1283e-02, -5.4996e-02,\n",
      "         6.2924e-02, -1.1378e-02, -3.2570e-02, -1.0129e-01,  4.4521e-02,\n",
      "         1.0998e-01, -3.1790e-02, -3.5012e-02, -5.1933e-02, -4.7872e-02,\n",
      "         1.1166e-02, -2.3371e-03, -4.0132e-02,  5.0213e-02, -1.9110e-02,\n",
      "         7.4315e-03, -5.0644e-02, -1.4163e-02, -8.8041e-02,  2.1981e-02,\n",
      "         2.6356e-02, -1.4305e-03, -7.6577e-02,  4.3847e-02,  7.9371e-02,\n",
      "         6.0871e-02,  8.0120e-02, -1.4258e-02, -9.4902e-02, -5.1128e-02,\n",
      "        -2.3421e-02, -5.8587e-02,  3.9033e-02,  1.0619e-01,  3.4509e-02,\n",
      "        -1.0888e-01,  1.2591e-01, -7.0609e-02,  1.0308e-02,  1.9289e-02,\n",
      "        -8.1256e-02,  6.3079e-02,  1.1605e-01,  6.3520e-02,  1.8339e-02,\n",
      "         1.1817e-01, -1.2815e-03,  6.0986e-02,  1.3635e-01,  2.0476e-01,\n",
      "         6.9247e-02,  1.8607e-01,  2.8667e-01,  1.1520e-01,  1.5935e-01,\n",
      "         1.2082e-01, -1.5299e-02, -7.8271e-02,  9.7610e-03,  1.3395e-01,\n",
      "         6.7636e-02,  1.0475e-01, -4.2235e-02, -4.6976e-02, -5.1201e-03,\n",
      "        -2.0377e-02, -2.3326e-02, -1.9136e-02, -7.3393e-03, -3.2787e-02,\n",
      "         8.8231e-02,  5.1196e-02, -4.9468e-02, -3.9990e-02,  1.0419e-02],\n",
      "       device='cuda:0')\n",
      "Shape: torch.Size([1000])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name}\")\n",
    "    print(f\"Weights: {param.data}\")  # Use .data to access the raw tensor\n",
    "    print(f\"Shape: {param.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pls\n",
      "wk\n"
     ]
    }
   ],
   "source": [
    "print('pls')\n",
    "sim.get_activation_param_encodings()\n",
    "print('wk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
