{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sveska za importovanje i pravljenje jobova za CAS-VIT mrežu\n",
    "\n",
    "CAS-ViT se zasniva na Visual Transformer arhitekturi, više informacija na linku.\n",
    "\n",
    "https://paperswithcode.com/paper/cas-vit-convolutional-additive-self-attention\n",
    "\n",
    "(samo sam sortirao po broju parametara i uzeo ovu random mrezu, nemam pojma da li je dobra, i rad za sada ne razumem)\n",
    "\n",
    "Ova sveska uz prateće fajlove automatski skida weightove za CAS-ViT model zadate veličine, i posle taj model šalje na AIHUB za testiranje.\n",
    "\n",
    "Za sada sam pokrenuo samo xs model, koji se izvršava super brzo i ima manje parametara od MobileNetV2, doduše mnogo više layera koji su raspoređeni na više COMPUTE unita, što je koliko ja razumem dobro.\n",
    "\n",
    "Ne znam da li je dobro da modele čuvamo na GIT-u (Drakula neka kaže kako bi to trebalo), pa sam sve fajlove koje se generišu stavio u gitignore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/centar15-desktop1/LPCV_2025_T1/.venv/lib/python3.12/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "2025-02-24 17:18:51.282238: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-24 17:18:51.289128: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740413931.297259   35810 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740413931.299673   35810 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-24 17:18:51.308856: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import torch\n",
    "import rcvit\n",
    "import torchsummary\n",
    "import os\n",
    "import sys\n",
    "\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(ROOT_DIR)\n",
    "from utils import helper, input_getter, qai_hub_jobs, tfhelper\n",
    "\n",
    "import skimage as ski"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File CASVIT_s.pth already exists.\n"
     ]
    }
   ],
   "source": [
    "# Model selection (options: \"xs\", \"s\", \"m\", \"t\")\n",
    "\n",
    "modelID = \"s\"\n",
    "\n",
    "driveFileIDs = dict()\n",
    "\n",
    "driveFileIDs[\"xs\"] = \"16wKcwF6QMW5w_lyPYnDKjMNuoxQDfrLK\"\n",
    "driveFileIDs[\"s\"]  = \"1facFRq8s8oelYUtK1fj3fcfdoWoKDBQQ\"\n",
    "driveFileIDs[\"m\"]  = \"13sQpSEf0h_uuh0jRy9V0yIW6ZsbDpVGy\"\n",
    "driveFileIDs[\"t\"]  = \"1NqoIUPbwBC91RTjTUvubAbOfGqo1VYT0\"\n",
    "\n",
    "networks = dict()\n",
    "networks[\"xs\"] = rcvit.rcvit_xs\n",
    "networks[\"s\"]  = rcvit.rcvit_s\n",
    "networks[\"m\"]  = rcvit.rcvit_m\n",
    "networks[\"t\"]  = rcvit.rcvit_t\n",
    "\n",
    "file_id = driveFileIDs[modelID]\n",
    "\n",
    "modelName = \"CASVIT_{}\".format(modelID)\n",
    "\n",
    "file_path = modelName + \".pth\"\n",
    "\n",
    "if not os.path.exists(file_path):\n",
    "    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", file_path, quiet=False)\n",
    "    print(\"Model downloaded successfully.\")\n",
    "else:\n",
    "    print(f\"File {file_path} already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RCViT(\n",
      "  (patch_embed): Sequential(\n",
      "    (0): Conv2d(3, 24, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(24, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "    (4): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      "  (network): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(48, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "                (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(48, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (proj): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Embedding(\n",
      "      (proj): Conv2d(48, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(64, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "                (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (proj): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Embedding(\n",
      "      (proj): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (3): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (4): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (5): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "                (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (5): Embedding(\n",
      "      (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (6): Sequential(\n",
      "      (0): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): AdditiveBlock(\n",
      "        (local_perception): LocalIntegration(\n",
      "          (network): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "            (3): GELU(approximate='none')\n",
      "            (4): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "        )\n",
      "        (norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (attn): AdditiveTokenMixer(\n",
      "          (qkv): Conv2d(256, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (oper_q): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (oper_k): Sequential(\n",
      "            (0): SpatialOperation(\n",
      "              (block): Sequential(\n",
      "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "                (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (2): ReLU(inplace=True)\n",
      "                (3): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (4): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (1): ChannelOperation(\n",
      "              (block): Sequential(\n",
      "                (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "                (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (2): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (dwc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (drop_path): Identity()\n",
      "        (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (act): GELU(approximate='none')\n",
      "          (fc2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (head): Linear(in_features=256, out_features=1000, bias=True)\n",
      "  (dist_head): Linear(in_features=256, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "net: rcvit.RCViT = networks[modelID]()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#net.cuda()\n",
    "\n",
    "#torchsummary.summary(net, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading pre-trained weights\n",
    "\n",
    "weightDict = torch.load(file_path, map_location=torch.device(\"cpu\"))\n",
    "net.load_state_dict(weightDict[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(net, torch.randn((1, 3, 224, 224)), 'model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_247069/3282206843.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  net(torch.tensor(input_tensor)).shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net = net.half()\n",
    "\n",
    "# net = net.cuda()\n",
    "\n",
    "net.eval()\n",
    "\n",
    "net = net.half()\n",
    "\n",
    "net = net.float()\n",
    "\n",
    "input = input_getter.local_image_getter(\"/home/centar15-desktop1/LPCV_2025_T1/datasets/imagenet/coco_80/bowl/0000021345.jpg\")\n",
    "input_tensor = input.get_input_torch()\n",
    "#input_tensor = input_tensor.half()\n",
    "net(torch.tensor(input_tensor)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input.get_input_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(input.get_input_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (float) and bias type (c10::Half) should be the same",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqai_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[1;32m      5\u001b[0m cj \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39msubmit_compile_job(\n\u001b[1;32m      6\u001b[0m     model\u001b[38;5;241m=\u001b[39mtraced_model,\n\u001b[1;32m      7\u001b[0m     device\u001b[38;5;241m=\u001b[39mhub\u001b[38;5;241m.\u001b[39mDevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSnapdragon 8 Elite QRD\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      8\u001b[0m     input_specs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(image\u001b[38;5;241m=\u001b[39minput_tensor\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mshape),)\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:1000\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    987\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`optimize` is deprecated and has no effect. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `with torch.jit.optimized_execution()` instead\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    991\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    992\u001b[0m     )\n\u001b[1;32m    994\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_utils_internal\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    995\u001b[0m     check_if_torch_exportable,\n\u001b[1;32m    996\u001b[0m     log_torch_jit_trace_exportability,\n\u001b[1;32m    997\u001b[0m     log_torchscript_usage,\n\u001b[1;32m    998\u001b[0m )\n\u001b[0;32m-> 1000\u001b[0m traced_func \u001b[38;5;241m=\u001b[39m \u001b[43m_trace_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1008\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1009\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1010\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_compilation_unit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1011\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1012\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m log_torchscript_usage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrace\u001b[39m\u001b[38;5;124m\"\u001b[39m, model_id\u001b[38;5;241m=\u001b[39m_get_model_id(traced_func))\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_if_torch_exportable():\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:696\u001b[0m, in \u001b[0;36m_trace_impl\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_kwarg_inputs, _store_inputs)\u001b[0m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    695\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexample_kwarg_inputs should be a dict\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    704\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    706\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs_is_kwarg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mexample_kwarg_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    707\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    708\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    710\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    712\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    713\u001b[0m ):\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m example_inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/jit/_trace.py:1276\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit, example_inputs_is_kwarg, _store_inputs)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1275\u001b[0m     example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m-> 1276\u001b[0m     \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1282\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1283\u001b[0m \u001b[43m        \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1284\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_store_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1287\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m   1289\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1729\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/LPCV_2025_T1/src/casvit/rcvit.py:295\u001b[0m, in \u001b[0;36mRCViT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 295\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpatch_embed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_tokens(x)\n\u001b[1;32m    297\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfork_feat:\n\u001b[1;32m    298\u001b[0m         \u001b[38;5;66;03m# otuput features of four stages for dense prediction\u001b[39;00m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1729\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1729\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1727\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1729\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1730\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1731\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/LPCV_2025_T1/.venv/lib/python3.12/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (float) and bias type (c10::Half) should be the same"
     ]
    }
   ],
   "source": [
    "traced_model = torch.jit.trace(net, input_tensor)\n",
    "\n",
    "import qai_hub as hub\n",
    "\n",
    "cj = hub.submit_compile_job(\n",
    "    model=traced_model,\n",
    "    device=hub.Device(\"Snapdragon 8 Elite QRD\"),\n",
    "    input_specs=dict(image=input_tensor.cpu().numpy().shape),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading tmpe3gnn88s.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 23.5M/23.5M [00:01<00:00, 22.9MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled compile job (jpx96yy1p) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/jpx96yy1p/\n",
      "\n",
      "Waiting for compile job (jpx96yy1p) completion. Type Ctrl+C to stop waiting at any time.\n",
      "    ✅ SUCCESS                          \u0007\n",
      "Scheduled profile job (jpyzj667g) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/jpyzj667g/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading dataset: 294kB [00:00, 798kB/s]                            2.67MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduled inference job (jp042ll6g) successfully. To see the status and results:\n",
      "    https://app.aihub.qualcomm.com/jobs/jp042ll6g/\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kada se uradi ovi jobovi na linkovima se moze naci vizuelizacija mreze i informacije za dalju analizu\n",
    "\n",
    "compile, profile, inference = qai_hub_jobs.compile_profile_inference_tensor(net, input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tmp33ojkcks.h5: 100%|\u001b[34m██████████\u001b[0m| 14.5k/14.5k [00:00<00:00, 1.64MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 predictions for Cloud model on :\n",
      "659 b'mixing bowl'        65.9%\n",
      "969 b'eggnog'             25.8%\n",
      "968 b'cup'                 3.0%\n",
      "666 b'mortar'              1.7%\n",
      "809 b'soup bowl'           1.0%\n"
     ]
    }
   ],
   "source": [
    "categories = helper.get_imagenet_categories()\n",
    "\n",
    "# Rezultati dobijeni na cloudu\n",
    "\n",
    "helper.inference_job_probabilities(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 predictions for Torch Local on :\n",
      "659 b'mixing bowl'        73.3%\n",
      "969 b'eggnog'             18.5%\n",
      "968 b'cup'                 3.1%\n",
      "666 b'mortar'              1.9%\n",
      "809 b'soup bowl'           1.2%\n"
     ]
    }
   ],
   "source": [
    "# Vraca verovatnoce lokalne PyTorch mreze\n",
    "\n",
    "helper.print_probablities_from_output(net(input.get_input_torch()), categories=categories, modelname = 'Torch Local')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CASVIT_s.tflite: 100%|\u001b[34m██████████\u001b[0m| 22.1M/22.1M [00:07<00:00, 2.97MB/s]\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded model to CASVIT_s.tflite\n",
      "Top-5 predictions for TensorFlow on :\n",
      "659 b'mixing bowl'        73.3%\n",
      "969 b'eggnog'             18.5%\n",
      "968 b'cup'                 3.1%\n",
      "666 b'mortar'              1.9%\n",
      "809 b'soup bowl'           1.2%\n"
     ]
    }
   ],
   "source": [
    "# Vraca verovatnoce TensorFlow mreze\n",
    "\n",
    "download_path = tfhelper.download_model_from_compile_job(compile, modelName)\n",
    "TFModel = tfhelper.TFHelper(download_path)\n",
    "TFModel.run_inference(input.get_input_numpy())\n",
    "helper.print_probablities_from_output(TFModel.run_inference(input.get_input_numpy()), categories=categories, modelname = 'TensorFlow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
